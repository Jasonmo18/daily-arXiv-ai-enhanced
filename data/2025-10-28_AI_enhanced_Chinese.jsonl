{"id": "2510.20905", "categories": ["cs.LG", "math.PR"], "pdf": "https://arxiv.org/pdf/2510.20905", "abs": "https://arxiv.org/abs/2510.20905", "authors": ["Xingyu Wang", "Chang-Han Rhee"], "title": "Global Dynamics of Heavy-Tailed SGDs in Nonconvex Loss Landscape: Characterization and Control", "comment": "60 pages, 2 figures, 4 tables", "summary": "Stochastic gradient descent (SGD) and its variants enable modern artificial\nintelligence. However, theoretical understanding lags far behind their\nempirical success. It is widely believed that SGD has a curious ability to\navoid sharp local minima in the loss landscape, which are associated with poor\ngeneralization. To unravel this mystery and further enhance such capability of\nSGDs, it is imperative to go beyond the traditional local convergence analysis\nand obtain a comprehensive understanding of SGDs' global dynamics. In this\npaper, we develop a set of technical machinery based on the recent large\ndeviations and metastability analysis in Wang and Rhee (2023) and obtain sharp\ncharacterization of the global dynamics of heavy-tailed SGDs. In particular, we\nreveal a fascinating phenomenon in deep learning: by injecting and then\ntruncating heavy-tailed noises during the training phase, SGD can almost\ncompletely avoid sharp minima and achieve better generalization performance for\nthe test data. Simulation and deep learning experiments confirm our theoretical\nprediction that heavy-tailed SGD with gradient clipping finds local minima with\na more flat geometry and achieves better generalization performance.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u5927\u504f\u5dee\u548c\u4e9a\u7a33\u6001\u5206\u6790\u6280\u672f\uff0c\u63ed\u793a\u4e86\u91cd\u5c3eSGD\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u6709\u8da3\u73b0\u8c61\uff1a\u901a\u8fc7\u5728\u8bad\u7ec3\u9636\u6bb5\u6ce8\u5165\u5e76\u622a\u65ad\u91cd\u5c3e\u566a\u58f0\uff0cSGD\u51e0\u4e4e\u53ef\u4ee5\u5b8c\u5168\u907f\u514d\u5c16\u9510\u5c40\u90e8\u6781\u5c0f\u503c\uff0c\u5e76\u5728\u6d4b\u8bd5\u6570\u636e\u4e0a\u83b7\u5f97\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u867d\u7136SGD\u53ca\u5176\u53d8\u4f53\u63a8\u52a8\u4e86\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\uff0c\u4f46\u7406\u8bba\u7406\u89e3\u8fdc\u843d\u540e\u4e8e\u5176\u7ecf\u9a8c\u6210\u529f\u3002\u4eba\u4eec\u666e\u904d\u8ba4\u4e3aSGD\u5177\u6709\u907f\u514d\u635f\u5931\u666f\u89c2\u4e2d\u5c16\u9510\u5c40\u90e8\u6781\u5c0f\u503c\u7684\u80fd\u529b\uff0c\u8fd9\u4e9b\u6781\u5c0f\u503c\u4e0e\u8f83\u5dee\u7684\u6cdb\u5316\u6027\u80fd\u76f8\u5173\u3002\u4e3a\u4e86\u89e3\u5f00\u8fd9\u4e00\u8c1c\u56e2\u5e76\u8fdb\u4e00\u6b65\u589e\u5f3aSGD\u7684\u8fd9\u79cd\u80fd\u529b\uff0c\u9700\u8981\u8d85\u8d8a\u4f20\u7edf\u7684\u5c40\u90e8\u6536\u655b\u5206\u6790\uff0c\u5168\u9762\u7406\u89e3SGD\u7684\u5168\u5c40\u52a8\u6001\u3002", "method": "\u57fa\u4e8eWang\u548cRhee\uff082023\uff09\u6700\u8fd1\u7684\u5927\u504f\u5dee\u548c\u4e9a\u7a33\u6001\u5206\u6790\u6280\u672f\uff0c\u5f00\u53d1\u4e86\u4e00\u5957\u6280\u672f\u673a\u5236\uff0c\u5bf9\u91cd\u5c3eSGD\u7684\u5168\u5c40\u52a8\u6001\u8fdb\u884c\u4e86\u7cbe\u786e\u8868\u5f81\u3002\u5177\u4f53\u5305\u62ec\u5728\u8bad\u7ec3\u9636\u6bb5\u6ce8\u5165\u5e76\u622a\u65ad\u91cd\u5c3e\u566a\u58f0\uff0c\u4ee5\u53ca\u4f7f\u7528\u68af\u5ea6\u88c1\u526a\u7684\u91cd\u5c3eSGD\u65b9\u6cd5\u3002", "result": "\u6a21\u62df\u548c\u6df1\u5ea6\u5b66\u4e60\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u7406\u8bba\u9884\u6d4b\uff1a\u5e26\u6709\u68af\u5ea6\u88c1\u526a\u7684\u91cd\u5c3eSGD\u80fd\u591f\u627e\u5230\u51e0\u4f55\u5f62\u72b6\u66f4\u5e73\u5766\u7684\u5c40\u90e8\u6781\u5c0f\u503c\uff0c\u5e76\u5b9e\u73b0\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002\u91cd\u5c3eSGD\u51e0\u4e4e\u53ef\u4ee5\u5b8c\u5168\u907f\u514d\u5c16\u9510\u6781\u5c0f\u503c\u3002", "conclusion": "\u91cd\u5c3eSGD\u901a\u8fc7\u6ce8\u5165\u548c\u622a\u65ad\u91cd\u5c3e\u566a\u58f0\uff0c\u80fd\u591f\u6709\u6548\u907f\u514d\u5c16\u9510\u5c40\u90e8\u6781\u5c0f\u503c\uff0c\u4ece\u800c\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u83b7\u5f97\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002\u8fd9\u4e00\u53d1\u73b0\u4e3a\u7406\u89e3SGD\u7684\u5168\u5c40\u52a8\u6001\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2510.20925", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20925", "abs": "https://arxiv.org/abs/2510.20925", "authors": ["Rattana Pukdee", "Ziqi Ke", "Chirag Gupta"], "title": "Learning from Interval Targets", "comment": "NeurIPS 2025", "summary": "We study the problem of regression with interval targets, where only upper\nand lower bounds on target values are available in the form of intervals. This\nproblem arises when the exact target label is expensive or impossible to\nobtain, due to inherent uncertainties. In the absence of exact targets,\ntraditional regression loss functions cannot be used. First, we study the\nmethodology of using a loss functions compatible with interval targets, for\nwhich we establish non-asymptotic generalization bounds based on smoothness of\nthe hypothesis class that significantly relaxing prior assumptions of\nrealizability and small ambiguity degree. Second, we propose a novel min-max\nlearning formulation: minimize against the worst-case (maximized) target labels\nwithin the provided intervals. The maximization problem in the latter is\nnon-convex, but we show that good performance can be achieved with the\nincorporation of smoothness constraints. Finally, we perform extensive\nexperiments on real-world datasets and show that our methods achieve\nstate-of-the-art performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u533a\u95f4\u76ee\u6807\u56de\u5f52\u95ee\u9898\uff0c\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\uff1a\u4f7f\u7528\u517c\u5bb9\u533a\u95f4\u76ee\u6807\u7684\u635f\u5931\u51fd\u6570\u5e76\u5efa\u7acb\u6cdb\u5316\u8fb9\u754c\uff0c\u4ee5\u53ca\u63d0\u51fa\u6700\u5c0f-\u6700\u5927\u5b66\u4e60\u516c\u5f0f\u6765\u5bf9\u6297\u533a\u95f4\u5185\u7684\u6700\u574f\u60c5\u51b5\u76ee\u6807\u6807\u7b7e\u3002", "motivation": "\u5f53\u7cbe\u786e\u7684\u76ee\u6807\u6807\u7b7e\u7531\u4e8e\u6210\u672c\u9ad8\u6602\u6216\u56fa\u6709\u4e0d\u786e\u5b9a\u6027\u800c\u65e0\u6cd5\u83b7\u5f97\u65f6\uff0c\u9700\u8981\u5904\u7406\u53ea\u6709\u4e0a\u4e0b\u754c\u533a\u95f4\u5f62\u5f0f\u7684\u76ee\u6807\u503c\uff0c\u4f20\u7edf\u56de\u5f52\u635f\u5931\u51fd\u6570\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u65e0\u6cd5\u4f7f\u7528\u3002", "method": "1. \u4f7f\u7528\u517c\u5bb9\u533a\u95f4\u76ee\u6807\u7684\u635f\u5931\u51fd\u6570\uff0c\u57fa\u4e8e\u5047\u8bbe\u7c7b\u7684\u5e73\u6ed1\u6027\u5efa\u7acb\u975e\u6e10\u8fd1\u6cdb\u5316\u8fb9\u754c\uff1b2. \u63d0\u51fa\u6700\u5c0f-\u6700\u5927\u5b66\u4e60\u516c\u5f0f\uff1a\u5728\u63d0\u4f9b\u7684\u533a\u95f4\u5185\u6700\u5c0f\u5316\u5bf9\u6297\u6700\u574f\u60c5\u51b5\u76ee\u6807\u6807\u7b7e\uff0c\u5e76\u901a\u8fc7\u5e73\u6ed1\u6027\u7ea6\u675f\u89e3\u51b3\u975e\u51f8\u6700\u5927\u5316\u95ee\u9898\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u533a\u95f4\u76ee\u6807\u56de\u5f52\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u517c\u5bb9\u533a\u95f4\u76ee\u6807\u7684\u635f\u5931\u51fd\u6570\u548c\u6700\u5c0f-\u6700\u5927\u5b66\u4e60\u516c\u5f0f\uff0c\u5728\u653e\u677e\u5148\u524d\u5047\u8bbe\u6761\u4ef6\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u6027\u80fd\u3002"}}
{"id": "2510.20955", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20955", "abs": "https://arxiv.org/abs/2510.20955", "authors": ["Jeff Pflueger", "Michael Everett"], "title": "Safety Assessment in Reinforcement Learning via Model Predictive Control", "comment": "7 pages, 4 figures", "summary": "Model-free reinforcement learning approaches are promising for control but\ntypically lack formal safety guarantees. Existing methods to shield or\notherwise provide these guarantees often rely on detailed knowledge of the\nsafety specifications. Instead, this work's insight is that many\ndifficult-to-specify safety issues are best characterized by invariance.\nAccordingly, we propose to leverage reversibility as a method for preventing\nthese safety issues throughout the training process. Our method uses\nmodel-predictive path integral control to check the safety of an action\nproposed by a learned policy throughout training. A key advantage of this\napproach is that it only requires the ability to query the black-box dynamics,\nnot explicit knowledge of the dynamics or safety constraints. Experimental\nresults demonstrate that the proposed algorithm successfully aborts before all\nunsafe actions, while still achieving comparable training progress to a\nbaseline PPO approach that is allowed to violate safety.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u9006\u6027\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u79ef\u5206\u63a7\u5236\u6765\u68c0\u67e5\u5b66\u4e60\u7b56\u7565\u63d0\u51fa\u7684\u52a8\u4f5c\u5b89\u5168\u6027\uff0c\u65e0\u9700\u663e\u5f0f\u52a8\u6001\u6a21\u578b\u6216\u5b89\u5168\u7ea6\u675f\u77e5\u8bc6\u3002", "motivation": "\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7f3a\u4e4f\u5f62\u5f0f\u5316\u5b89\u5168\u4fdd\u8bc1\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u8be6\u7ec6\u7684\u5b89\u5168\u89c4\u8303\u77e5\u8bc6\u3002\u8bb8\u591a\u96be\u4ee5\u660e\u786e\u89c4\u8303\u7684\u5b89\u5168\u95ee\u9898\u66f4\u9002\u5408\u7528\u4e0d\u53d8\u6027\u6765\u8868\u5f81\u3002", "method": "\u5229\u7528\u53ef\u9006\u6027\u4f5c\u4e3a\u9632\u6b62\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b89\u5168\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u79ef\u5206\u63a7\u5236\u68c0\u67e5\u5b66\u4e60\u7b56\u7565\u63d0\u51fa\u7684\u52a8\u4f5c\u5b89\u5168\u6027\uff0c\u4ec5\u9700\u67e5\u8be2\u9ed1\u76d2\u52a8\u6001\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u6240\u6709\u4e0d\u5b89\u5168\u52a8\u4f5c\u53d1\u751f\u524d\u6210\u529f\u4e2d\u6b62\uff0c\u540c\u65f6\u8bad\u7ec3\u8fdb\u5ea6\u4e0e\u5141\u8bb8\u8fdd\u53cd\u5b89\u5168\u7684\u57fa\u7ebfPPO\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "\u57fa\u4e8e\u53ef\u9006\u6027\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u4f9b\u5b89\u5168\u4fdd\u8bc1\uff0c\u4ec5\u9700\u67e5\u8be2\u52a8\u6001\u7cfb\u7edf\u800c\u65e0\u9700\u663e\u5f0f\u52a8\u6001\u6a21\u578b\u6216\u5b89\u5168\u7ea6\u675f\u77e5\u8bc6\u3002"}}
{"id": "2510.20960", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20960", "abs": "https://arxiv.org/abs/2510.20960", "authors": ["Sizhe Rao", "Runqiu Zhang", "Sajal Saha", "Liang Chen"], "title": "An Ensembled Penalized Federated Learning Framework for Falling People Detection", "comment": "12 pages, 3 figures", "summary": "Falls among elderly and disabled individuals remain a leading cause of injury\nand mortality worldwide, necessitating robust, accurate, and privacy-aware fall\ndetection systems. Traditional fall detection approaches, whether centralized\nor point-wise, often struggle with key challenges such as limited\ngeneralizability, data privacy concerns, and variability in individual movement\nbehaviors. To address these limitations, we propose EPFL-an Ensembled Penalized\nFederated Learning framework that integrates continual learning, personalized\nmodeling, and a novel Specialized Weighted Aggregation (SWA) strategy. EPFL\nleverages wearable sensor data to capture sequential motion patterns while\npreserving user privacy through homomorphic encryption and federated training.\nUnlike existing federated models, EPFL incorporates both penalized local\ntraining and ensemble-based inference to improve inter-client consistency and\nadaptability to behavioral differences. Extensive experiments on a benchmark\nfall detection dataset demonstrate the effectiveness of our approach, achieving\na Recall of 88.31 percent and an F1-score of 89.94 percent, significantly\noutperforming both centralized and baseline models. This work presents a\nscalable, secure, and accurate solution for real-world fall detection in\nhealthcare settings, with strong potential for continuous improvement via its\nadaptive feedback mechanism.", "AI": {"tldr": "\u63d0\u51faEPFL\u6846\u67b6\uff0c\u96c6\u6210\u6301\u7eed\u5b66\u4e60\u3001\u4e2a\u6027\u5316\u5efa\u6a21\u548c\u4e13\u95e8\u52a0\u6743\u805a\u5408\u7b56\u7565\uff0c\u7528\u4e8e\u8001\u5e74\u4eba\u8dcc\u5012\u68c0\u6d4b\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8dcc\u5012\u68c0\u6d4b\u7cfb\u7edf\u5728\u6cdb\u5316\u6027\u3001\u6570\u636e\u9690\u79c1\u548c\u4e2a\u4f53\u884c\u4e3a\u5dee\u5f02\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u8001\u5e74\u4eba\u548c\u6b8b\u75be\u4eba\u63d0\u4f9b\u66f4\u5b89\u5168\u53ef\u9760\u7684\u8dcc\u5012\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u91c7\u7528\u96c6\u6210\u60e9\u7f5a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u540c\u6001\u52a0\u5bc6\u548c\u8054\u90a6\u8bad\u7ec3\u4fdd\u62a4\u9690\u79c1\uff0c\u4f7f\u7528\u60e9\u7f5a\u672c\u5730\u8bad\u7ec3\u548c\u96c6\u6210\u63a8\u7406\u63d0\u9ad8\u6a21\u578b\u4e00\u81f4\u6027\u548c\u9002\u5e94\u6027\u3002", "result": "\u5728\u57fa\u51c6\u8dcc\u5012\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u5b9e\u73b088.31%\u7684\u53ec\u56de\u7387\u548c89.94%\u7684F1\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u548c\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "EPFL\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u5b89\u5168\u4e14\u51c6\u786e\u7684\u8dcc\u5012\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u901a\u8fc7\u81ea\u9002\u5e94\u53cd\u9988\u673a\u5236\u6301\u7eed\u6539\u8fdb\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.20963", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20963", "abs": "https://arxiv.org/abs/2510.20963", "authors": ["Yongqiang Chen", "Gang Niu", "James Cheng", "Bo Han", "Masashi Sugiyama"], "title": "Towards Scalable Oversight with Collaborative Multi-Agent Debate in Error Detection", "comment": "Preprint, ongoing work", "summary": "Accurate detection of errors in large language models (LLM) responses is\ncentral to the success of scalable oversight, or providing effective\nsupervision to superhuman intelligence. Yet, self-diagnosis is often unreliable\non complex tasks unless aided by reliable external feedback. Multi-agent debate\n(MAD) seems to be a natural alternative to external feedback: multiple LLMs\nprovide complementary perspectives and cross-checks for error detection.\nHowever, prior MAD protocols frame debate as a zero-sum game, where the\ndebaters compete to win the game instead of seeking the truth. Consequently, it\nleads to debate hacking: debaters tend to mislead the judge by misinterpreting\nthe task or presenting overconfident claims, which introduce more mistakes and\nunderperform single-agent methods. To mitigate the issue, we introduce a new\ncollaborative MAD protocol, termed ColMAD, that reframes MAD as a non-zero sum\ngame. Specifically, ColMAD encourages multiple agents to criticize each other\nin a supportive way, such that they can complement the missing points of each\nother. Therefore, the judge agent can make a more informative conclusion based\non more comprehensive evidence. Empirically, we show that ColMAD significantly\noutperforms previous competitive MAD by 19% and brings non-trivial improvements\nover single-agent methods in error detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aColMAD\u7684\u534f\u4f5c\u5f0f\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u534f\u8bae\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u4ece\u96f6\u548c\u535a\u5f08\u91cd\u6784\u4e3a\u975e\u96f6\u548c\u535a\u5f08\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u8fa9\u8bba\u65b9\u6cd5\u4e2d\u7684\u8fa9\u8bba\u9ed1\u5ba2\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u9519\u8bef\u68c0\u6d4b\u5bf9\u4e8e\u53ef\u6269\u5c55\u76d1\u7763\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u81ea\u8bca\u65ad\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u5f80\u5f80\u4e0d\u53ef\u9760\u3002\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u65b9\u6cd5\u5c06\u8fa9\u8bba\u89c6\u4e3a\u96f6\u548c\u535a\u5f08\uff0c\u5bfc\u81f4\u8fa9\u8bba\u9ed1\u5ba2\u73b0\u8c61\u2014\u2014\u8fa9\u8bba\u8005\u503e\u5411\u4e8e\u8bef\u5bfc\u6cd5\u5b98\u800c\u975e\u5bfb\u6c42\u771f\u76f8\uff0c\u53cd\u800c\u5f15\u5165\u66f4\u591a\u9519\u8bef\u3002", "method": "\u63d0\u51faColMAD\u534f\u4f5c\u534f\u8bae\uff0c\u9f13\u52b1\u591a\u4e2a\u667a\u80fd\u4f53\u4ee5\u652f\u6301\u6027\u65b9\u5f0f\u76f8\u4e92\u6279\u8bc4\uff0c\u76f8\u4e92\u8865\u5145\u7f3a\u5931\u7684\u89c2\u70b9\uff0c\u4f7f\u6cd5\u5b98\u667a\u80fd\u4f53\u80fd\u591f\u57fa\u4e8e\u66f4\u5168\u9762\u7684\u8bc1\u636e\u505a\u51fa\u66f4\u660e\u667a\u7684\u7ed3\u8bba\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cColMAD\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u7684\u7ade\u4e89\u6027\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u65b9\u6cd519%\uff0c\u5e76\u5728\u9519\u8bef\u68c0\u6d4b\u65b9\u9762\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u5e26\u6765\u4e86\u975e\u5e73\u51e1\u7684\u6539\u8fdb\u3002", "conclusion": "\u901a\u8fc7\u5c06\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u91cd\u6784\u4e3a\u975e\u96f6\u548c\u534f\u4f5c\u6e38\u620f\uff0cColMAD\u6709\u6548\u7f13\u89e3\u4e86\u8fa9\u8bba\u9ed1\u5ba2\u95ee\u9898\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9519\u8bef\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.20970", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20970", "abs": "https://arxiv.org/abs/2510.20970", "authors": ["Jubilee Lee", "Daniele E. Schiavazzi"], "title": "On the accuracy of implicit neural representations for cardiovascular anatomies and hemodynamic fields", "comment": null, "summary": "Implicit neural representations (INRs, also known as neural fields) have\nrecently emerged as a powerful framework for knowledge representation,\nsynthesis, and compression. By encoding fields as continuous functions within\nthe weights and biases of deep neural networks-rather than relying on voxel- or\nmesh-based structured or unstructured representations-INRs offer both\nresolution independence and high memory efficiency. However, their accuracy in\ndomain-specific applications remains insufficiently understood. In this work,\nwe assess the performance of state-of-the-art INRs for compressing hemodynamic\nfields derived from numerical simulations and for representing cardiovascular\nanatomies via signed distance functions. We investigate several strategies to\nmitigate spectral bias, including specialized activation functions, both fixed\nand trainable positional encoding, and linear combinations of nonlinear\nkernels. On realistic, space- and time-varying hemodynamic fields in the\nthoracic aorta, INRs achieved remarkable compression ratios of up to\napproximately 230, with maximum absolute errors of 1 mmHg for pressure and 5-10\ncm/s for velocity, without extensive hyperparameter tuning. Across 48 thoracic\naortic anatomies, the average and maximum absolute anatomical discrepancies\nwere below 0.5 mm and 1.6 mm, respectively. Overall, the SIREN, MFN-Gabor, and\nMHE architectures demonstrated the best performance. Source code and data is\navailable at https://github.com/desResLab/nrf.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INRs\uff09\u5728\u8840\u6d41\u52a8\u529b\u5b66\u573a\u538b\u7f29\u548c\u5fc3\u8840\u7ba1\u89e3\u5256\u8868\u793a\u65b9\u9762\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u591a\u79cd\u7b56\u7565\u7f13\u89e3\u9891\u8c31\u504f\u5dee\uff0c\u5728\u4e3b\u52a8\u8109\u8840\u6d41\u573a\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8fbe230\u500d\u7684\u538b\u7f29\u6bd4\uff0c\u89e3\u5256\u8bef\u5dee\u4f4e\u4e8e1.6\u6beb\u7c73\u3002", "motivation": "\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u4f5c\u4e3a\u77e5\u8bc6\u8868\u793a\u3001\u5408\u6210\u548c\u538b\u7f29\u7684\u5f3a\u5927\u6846\u67b6\uff0c\u5177\u6709\u5206\u8fa8\u7387\u72ec\u7acb\u6027\u548c\u9ad8\u5185\u5b58\u6548\u7387\uff0c\u4f46\u5176\u5728\u7279\u5b9a\u9886\u57df\u5e94\u7528\u4e2d\u7684\u51c6\u786e\u6027\u5c1a\u672a\u5145\u5206\u4e86\u89e3\u3002", "method": "\u7814\u7a76\u4e86\u591a\u79cd\u7f13\u89e3\u9891\u8c31\u504f\u5dee\u7684\u7b56\u7565\uff0c\u5305\u62ec\u4e13\u7528\u6fc0\u6d3b\u51fd\u6570\u3001\u56fa\u5b9a\u548c\u53ef\u8bad\u7ec3\u4f4d\u7f6e\u7f16\u7801\u3001\u975e\u7ebf\u6027\u6838\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u8bc4\u4f30\u4e86INRs\u5728\u6570\u503c\u6a21\u62df\u8840\u6d41\u52a8\u529b\u5b66\u573a\u538b\u7f29\u548c\u5fc3\u8840\u7ba1\u89e3\u5256\u8868\u793a\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5728\u80f8\u4e3b\u52a8\u8109\u7a7a\u95f4\u548c\u65f6\u95f4\u53d8\u5316\u8840\u6d41\u573a\u4e2d\uff0cINRs\u5b9e\u73b0\u4e86\u7ea6230\u500d\u7684\u538b\u7f29\u6bd4\uff0c\u538b\u529b\u6700\u5927\u7edd\u5bf9\u8bef\u5dee1 mmHg\uff0c\u901f\u5ea6\u8bef\u5dee5-10 cm/s\uff1b\u572848\u4e2a\u80f8\u4e3b\u52a8\u8109\u89e3\u5256\u4e2d\uff0c\u5e73\u5747\u548c\u6700\u5927\u7edd\u5bf9\u89e3\u5256\u5dee\u5f02\u5206\u522b\u4f4e\u4e8e0.5\u6beb\u7c73\u548c1.6\u6beb\u7c73\u3002", "conclusion": "SIREN\u3001MFN-Gabor\u548cMHE\u67b6\u6784\u8868\u73b0\u51fa\u6700\u4f73\u6027\u80fd\uff0cINRs\u5728\u8840\u6d41\u52a8\u529b\u5b66\u573a\u538b\u7f29\u548c\u5fc3\u8840\u7ba1\u89e3\u5256\u8868\u793a\u65b9\u9762\u5177\u6709\u663e\u8457\u6f5c\u529b\u3002"}}
{"id": "2510.20976", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20976", "abs": "https://arxiv.org/abs/2510.20976", "authors": ["Jiyu Cui", "Fang Wu", "Haokai Zhao", "Minggao Feng", "Xenophon Evangelopoulos", "Andrew I. Cooper", "Yejin Choi"], "title": "L^2M^3OF: A Large Language Multimodal Model for Metal-Organic Frameworks", "comment": "18 pages, 7 figures", "summary": "Large language models have demonstrated remarkable reasoning capabilities\nacross diverse natural language tasks. However, comparable breakthroughs in\nscientific discovery are more limited, because understanding complex physical\nphenomena demands multifaceted representations far beyond language alone. A\ncompelling example is the design of functional materials such as MOFs-critical\nfor a range of impactful applications like carbon capture and hydrogen storage.\nNavigating their vast and intricate design space in language-based\nrepresentations interpretable by LLMs is challenging due to the numerous\npossible three-dimensional atomic arrangements and strict reticular rules of\ncoordination geometry and topology. Despite promising early results in\nLLM-assisted discovery for simpler materials systems, MOF design remains\nheavily reliant on tacit human expertise rarely codified in textual information\nalone. To overcome this barrier, we introduce L2M3OF, the first multimodal LLM\nfor MOFs. L2M3OF integrates crystal representation learning with language\nunderstanding to process structural, textual, and knowledge modalities jointly.\nL2M3OF employs a pre-trained crystal encoder with a lightweight projection\nlayer to compress structural information into a token space, enabling efficient\nalignment with language instructions. To facilitate training and evaluation, we\ncurate a structure-property-knowledge database of crystalline materials and\nbenchmark L2M3OF against state-of-the-art closed-source LLMs such as GPT-5,\nGemini-2.5-Pro and DeepSeek-R1. Experiments show that L2M3OF outperforms\nleading text-based closed-source LLMs in property prediction and knowledge\ngeneration tasks, despite using far fewer parameters. These results highlight\nthe importance of multimodal approaches for porous material understanding and\nestablish L2M3OF as a foundation for next-generation AI systems in materials\ndiscovery.", "AI": {"tldr": "L2M3OF\u662f\u9996\u4e2a\u7528\u4e8e\u91d1\u5c5e\u6709\u673a\u6846\u67b6\u6750\u6599\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u6574\u5408\u6676\u4f53\u7ed3\u6784\u8868\u793a\u5b66\u4e60\u548c\u8bed\u8a00\u7406\u89e3\uff0c\u5728\u6750\u6599\u6027\u80fd\u9884\u6d4b\u548c\u77e5\u8bc6\u751f\u6210\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u4ec5\u57fa\u4e8e\u6587\u672c\u7684\u95ed\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u79d1\u5b66\u53d1\u73b0\u9886\u57df\u7a81\u7834\u6709\u9650\uff0c\u56e0\u4e3a\u7406\u89e3\u590d\u6742\u7269\u7406\u73b0\u8c61\u9700\u8981\u8d85\u8d8a\u8bed\u8a00\u7684\u591a\u6a21\u6001\u8868\u793a\u3002\u91d1\u5c5e\u6709\u673a\u6846\u67b6\u6750\u6599\u8bbe\u8ba1\u5c24\u5176\u5177\u6709\u6311\u6218\u6027\uff0c\u5176\u4e09\u7ef4\u539f\u5b50\u6392\u5217\u548c\u914d\u4f4d\u51e0\u4f55\u89c4\u5219\u96be\u4ee5\u7528\u7eaf\u8bed\u8a00\u8868\u793a\uff0c\u4e14\u4f9d\u8d56\u96be\u4ee5\u6587\u672c\u5316\u7684\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u3002", "method": "L2M3OF\u6574\u5408\u4e86\u7ed3\u6784\u3001\u6587\u672c\u548c\u77e5\u8bc6\u6a21\u6001\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u6676\u4f53\u7f16\u7801\u5668\u548c\u8f7b\u91cf\u7ea7\u6295\u5f71\u5c42\u5c06\u7ed3\u6784\u4fe1\u606f\u538b\u7f29\u5230\u6807\u8bb0\u7a7a\u95f4\uff0c\u5b9e\u73b0\u4e0e\u8bed\u8a00\u6307\u4ee4\u7684\u9ad8\u6548\u5bf9\u9f50\u3002\u6784\u5efa\u4e86\u6676\u4f53\u6750\u6599\u7684\u7ed3\u6784-\u6027\u80fd-\u77e5\u8bc6\u6570\u636e\u5e93\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cL2M3OF\u5728\u6027\u80fd\u9884\u6d4b\u548c\u77e5\u8bc6\u751f\u6210\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86GPT-5\u3001Gemini-2.5-Pro\u548cDeepSeek-R1\u7b49\u9886\u5148\u7684\u57fa\u4e8e\u6587\u672c\u7684\u95ed\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e14\u4f7f\u7528\u7684\u53c2\u6570\u6570\u91cf\u66f4\u5c11\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u51f8\u663e\u4e86\u591a\u6a21\u6001\u65b9\u6cd5\u5728\u591a\u5b54\u6750\u6599\u7406\u89e3\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c06L2M3OF\u786e\u7acb\u4e3a\u6750\u6599\u53d1\u73b0\u9886\u57df\u4e0b\u4e00\u4ee3\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u57fa\u7840\u3002"}}
{"id": "2510.21003", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21003", "abs": "https://arxiv.org/abs/2510.21003", "authors": ["Enshu Liu", "Qian Chen", "Xuefei Ning", "Shengen Yan", "Guohao Dai", "Zinan Lin", "Yu Wang"], "title": "Distilled Decoding 2: One-step Sampling of Image Auto-regressive Models with Conditional Score Distillation", "comment": "Published at NeurIPS 2025", "summary": "Image Auto-regressive (AR) models have emerged as a powerful paradigm of\nvisual generative models. Despite their promising performance, they suffer from\nslow generation speed due to the large number of sampling steps required.\nAlthough Distilled Decoding 1 (DD1) was recently proposed to enable few-step\nsampling for image AR models, it still incurs significant performance\ndegradation in the one-step setting, and relies on a pre-defined mapping that\nlimits its flexibility. In this work, we propose a new method, Distilled\nDecoding 2 (DD2), to further advances the feasibility of one-step sampling for\nimage AR models. Unlike DD1, DD2 does not without rely on a pre-defined\nmapping. We view the original AR model as a teacher model which provides the\nground truth conditional score in the latent embedding space at each token\nposition. Based on this, we propose a novel \\emph{conditional score\ndistillation loss} to train a one-step generator. Specifically, we train a\nseparate network to predict the conditional score of the generated distribution\nand apply score distillation at every token position conditioned on previous\ntokens. Experimental results show that DD2 enables one-step sampling for image\nAR models with an minimal FID increase from 3.40 to 5.43 on ImageNet-256.\nCompared to the strongest baseline DD1, DD2 reduces the gap between the\none-step sampling and original AR model by 67%, with up to 12.3$\\times$\ntraining speed-up simultaneously. DD2 takes a significant step toward the goal\nof one-step AR generation, opening up new possibilities for fast and\nhigh-quality AR modeling. Code is available at\nhttps://github.com/imagination-research/Distilled-Decoding-2.", "AI": {"tldr": "DD2\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6761\u4ef6\u5206\u6570\u84b8\u998f\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u73b0\u56fe\u50cf\u81ea\u56de\u5f52\u6a21\u578b\u7684\u4e00\u6b65\u91c7\u6837\uff0c\u76f8\u6bd4DD1\u51cf\u5c11\u4e8667%\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u540c\u65f6\u8bad\u7ec3\u901f\u5ea6\u63d0\u534712.3\u500d\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u50cf\u81ea\u56de\u5f52\u6a21\u578b\u751f\u6210\u901f\u5ea6\u6162\uff0c\u9700\u8981\u5927\u91cf\u91c7\u6837\u6b65\u9aa4\u3002\u867d\u7136DD1\u5b9e\u73b0\u4e86\u5c11\u6b65\u91c7\u6837\uff0c\u4f46\u5728\u4e00\u6b65\u91c7\u6837\u65f6\u6027\u80fd\u4e0b\u964d\u660e\u663e\uff0c\u4e14\u4f9d\u8d56\u9884\u5b9a\u4e49\u6620\u5c04\u9650\u5236\u4e86\u7075\u6d3b\u6027\u3002", "method": "\u5c06\u539f\u59cbAR\u6a21\u578b\u89c6\u4e3a\u6559\u5e08\u6a21\u578b\uff0c\u5728\u6f5c\u5728\u5d4c\u5165\u7a7a\u95f4\u63d0\u4f9b\u6761\u4ef6\u5206\u6570\u771f\u503c\u3002\u63d0\u51fa\u6761\u4ef6\u5206\u6570\u84b8\u998f\u635f\u5931\u6765\u8bad\u7ec3\u4e00\u6b65\u751f\u6210\u5668\uff0c\u5728\u6bcf\u4e2atoken\u4f4d\u7f6e\u57fa\u4e8e\u5148\u524dtoken\u8fdb\u884c\u5206\u6570\u84b8\u998f\u3002", "result": "\u5728ImageNet-256\u4e0a\uff0cDD2\u5c06FID\u4ece3.40\u8f7b\u5fae\u589e\u52a0\u52305.43\uff0c\u76f8\u6bd4DD1\u57fa\u7ebf\u5c06\u4e00\u6b65\u91c7\u6837\u4e0e\u539f\u59cbAR\u6a21\u578b\u7684\u5dee\u8ddd\u51cf\u5c11\u4e8667%\uff0c\u540c\u65f6\u8bad\u7ec3\u901f\u5ea6\u63d0\u534712.3\u500d\u3002", "conclusion": "DD2\u663e\u8457\u63a8\u8fdb\u4e86\u4e00\u6b65\u81ea\u56de\u5f52\u751f\u6210\u7684\u76ee\u6807\uff0c\u4e3a\u5feb\u901f\u9ad8\u8d28\u91cf\u7684\u81ea\u56de\u5f52\u5efa\u6a21\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027\u3002"}}
{"id": "2510.21017", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21017", "abs": "https://arxiv.org/abs/2510.21017", "authors": ["Yuhong Luo", "Austin Hoag", "Xintong Wang", "Philip S. Thomas", "Przemyslaw A. Grabowicz"], "title": "Fair Representation Learning with Controllable High Confidence Guarantees via Adversarial Inference", "comment": "Accepted by NeurIPS 2025", "summary": "Representation learning is increasingly applied to generate representations\nthat generalize well across multiple downstream tasks. Ensuring fairness\nguarantees in representation learning is crucial to prevent unfairness toward\nspecific demographic groups in downstream tasks. In this work, we formally\nintroduce the task of learning representations that achieve high-confidence\nfairness. We aim to guarantee that demographic disparity in every downstream\nprediction remains bounded by a *user-defined* error threshold $\\epsilon$, with\n*controllable* high probability. To this end, we propose the ***F**air\n**R**epresentation learning with high-confidence **G**uarantees (FRG)*\nframework, which provides these high-confidence fairness guarantees by\nleveraging an optimized adversarial model. We empirically evaluate FRG on three\nreal-world datasets, comparing its performance to six state-of-the-art fair\nrepresentation learning methods. Our results demonstrate that FRG consistently\nbounds unfairness across a range of downstream models and tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FRG\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u5177\u6709\u9ad8\u7f6e\u4fe1\u5ea6\u516c\u5e73\u6027\u4fdd\u8bc1\u7684\u8868\u793a\uff0c\u786e\u4fdd\u4e0b\u6e38\u9884\u6d4b\u4e2d\u7684\u4eba\u53e3\u7edf\u8ba1\u5dee\u5f02\u4e0d\u8d85\u8fc7\u7528\u6237\u5b9a\u4e49\u7684\u8bef\u5dee\u9608\u503c\u3002", "motivation": "\u968f\u7740\u8868\u793a\u5b66\u4e60\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u786e\u4fdd\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u516c\u5e73\u6027\u4fdd\u8bc1\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u9632\u6b62\u5bf9\u7279\u5b9a\u4eba\u53e3\u7fa4\u4f53\u7684\u4e0d\u516c\u5e73\u3002", "method": "\u63d0\u51faFRG\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u7684\u5bf9\u6297\u6a21\u578b\u63d0\u4f9b\u9ad8\u7f6e\u4fe1\u5ea6\u516c\u5e73\u6027\u4fdd\u8bc1\uff0c\u786e\u4fdd\u4e0b\u6e38\u9884\u6d4b\u4e2d\u7684\u4eba\u53e3\u7edf\u8ba1\u5dee\u5f02\u4ee5\u53ef\u63a7\u7684\u9ad8\u6982\u7387\u4fdd\u6301\u6709\u754c\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cFRG\u5728\u4e00\u7cfb\u5217\u4e0b\u6e38\u6a21\u578b\u548c\u4efb\u52a1\u4e2d\u59cb\u7ec8\u80fd\u591f\u9650\u5236\u4e0d\u516c\u5e73\u6027\uff0c\u4f18\u4e8e\u516d\u79cd\u6700\u5148\u8fdb\u7684\u516c\u5e73\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "FRG\u6846\u67b6\u80fd\u591f\u6709\u6548\u5b66\u4e60\u5177\u6709\u9ad8\u7f6e\u4fe1\u5ea6\u516c\u5e73\u6027\u4fdd\u8bc1\u7684\u8868\u793a\uff0c\u4e3a\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b\u53ef\u9760\u7684\u516c\u5e73\u6027\u4fdd\u969c\u3002"}}
{"id": "2510.21022", "categories": ["cs.LG", "astro-ph.SR"], "pdf": "https://arxiv.org/pdf/2510.21022", "abs": "https://arxiv.org/abs/2510.21022", "authors": ["Jasmine R. Kobayashi", "Daniela Martin", "Valmir P Moraes Filho", "Connor O'Brien", "Jinsu Hong", "Sudeshna Boro Saikia", "Hala Lamdouar", "Nathan D. Miles", "Marcella Scoczynski", "Mavis Stone", "Sairam Sundaresan", "Anna Jungbluth", "Andr\u00e9s Mu\u00f1oz-Jaramillo", "Evangelia Samara", "Joseph Gallego"], "title": "CIPHER: Scalable Time Series Analysis for Physical Sciences with Application to Solar Wind Phenomena", "comment": "5 pages, 2 figures, Machine Learning and the Physical Sciences\n  Workshop @ NeurIPS 2025", "summary": "Labeling or classifying time series is a persistent challenge in the physical\nsciences, where expert annotations are scarce, costly, and often inconsistent.\nYet robust labeling is essential to enable machine learning models for\nunderstanding, prediction, and forecasting. We present the \\textit{Clustering\nand Indexation Pipeline with Human Evaluation for Recognition} (CIPHER), a\nframework designed to accelerate large-scale labeling of complex time series in\nphysics. CIPHER integrates \\textit{indexable Symbolic Aggregate approXimation}\n(iSAX) for interpretable compression and indexing, density-based clustering\n(HDBSCAN) to group recurring phenomena, and a human-in-the-loop step for\nefficient expert validation. Representative samples are labeled by domain\nscientists, and these annotations are propagated across clusters to yield\nsystematic, scalable classifications. We evaluate CIPHER on the task of\nclassifying solar wind phenomena in OMNI data, a central challenge in space\nweather research, showing that the framework recovers meaningful phenomena such\nas coronal mass ejections and stream interaction regions. Beyond this case\nstudy, CIPHER highlights a general strategy for combining symbolic\nrepresentations, unsupervised learning, and expert knowledge to address label\nscarcity in time series across the physical sciences. The code and\nconfiguration files used in this study are publicly available to support\nreproducibility.", "AI": {"tldr": "CIPHER\u662f\u4e00\u4e2a\u7528\u4e8e\u52a0\u901f\u7269\u7406\u79d1\u5b66\u4e2d\u590d\u6742\u65f6\u95f4\u5e8f\u5217\u5927\u89c4\u6a21\u6807\u6ce8\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u7b26\u53f7\u8868\u793a\u3001\u65e0\u76d1\u7763\u5b66\u4e60\u548c\u4e13\u5bb6\u77e5\u8bc6\u6765\u89e3\u51b3\u6807\u6ce8\u7a00\u7f3a\u95ee\u9898\u3002", "motivation": "\u7269\u7406\u79d1\u5b66\u4e2d\u65f6\u95f4\u5e8f\u5217\u6807\u6ce8\u9762\u4e34\u4e13\u5bb6\u6807\u6ce8\u7a00\u7f3a\u3001\u6210\u672c\u9ad8\u4e14\u4e0d\u4e00\u81f4\u7684\u6311\u6218\uff0c\u800c\u53ef\u9760\u7684\u6807\u6ce8\u5bf9\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u7406\u89e3\u3001\u9884\u6d4b\u548c\u9884\u62a5\u81f3\u5173\u91cd\u8981\u3002", "method": "CIPHER\u6846\u67b6\u6574\u5408\u4e86iSAX\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u538b\u7f29\u548c\u7d22\u5f15\uff0c\u4f7f\u7528HDBSCAN\u8fdb\u884c\u57fa\u4e8e\u5bc6\u5ea6\u7684\u805a\u7c7b\u6765\u5206\u7ec4\u91cd\u590d\u73b0\u8c61\uff0c\u5e76\u5305\u542b\u4eba\u673a\u4ea4\u4e92\u6b65\u9aa4\u8fdb\u884c\u9ad8\u6548\u4e13\u5bb6\u9a8c\u8bc1\u3002", "result": "\u5728\u592a\u9633\u98ce\u73b0\u8c61\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cCIPHER\u6210\u529f\u8bc6\u522b\u51fa\u6709\u610f\u4e49\u7684\u7269\u7406\u73b0\u8c61\uff0c\u5982\u65e5\u5195\u7269\u8d28\u629b\u5c04\u548c\u6d41\u76f8\u4e92\u4f5c\u7528\u533a\u3002", "conclusion": "CIPHER\u5c55\u793a\u4e86\u7ed3\u5408\u7b26\u53f7\u8868\u793a\u3001\u65e0\u76d1\u7763\u5b66\u4e60\u548c\u4e13\u5bb6\u77e5\u8bc6\u6765\u89e3\u51b3\u7269\u7406\u79d1\u5b66\u4e2d\u65f6\u95f4\u5e8f\u5217\u6807\u6ce8\u7a00\u7f3a\u95ee\u9898\u7684\u901a\u7528\u7b56\u7565\uff0c\u4ee3\u7801\u548c\u914d\u7f6e\u6587\u4ef6\u5df2\u516c\u5f00\u4ee5\u652f\u6301\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2510.21038", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21038", "abs": "https://arxiv.org/abs/2510.21038", "authors": ["Gereon Elvers", "Gilad Landau", "Oiwi Parker Jones"], "title": "Elementary, My Dear Watson: Non-Invasive Neural Keyword Spotting in the LibriBrain Dataset", "comment": "16 pages, 7 figures, 6 tables", "summary": "Non-invasive brain-computer interfaces (BCIs) are beginning to benefit from\nlarge, public benchmarks. However, current benchmarks target relatively simple,\nfoundational tasks like Speech Detection and Phoneme Classification, while\napplication-ready results on tasks like Brain-to-Text remain elusive. We\npropose Keyword Spotting (KWS) as a practically applicable, privacy-aware\nintermediate task. Using the deep 52-hour, within-subject LibriBrain corpus, we\nprovide standardized train/validation/test splits for reproducible\nbenchmarking, and adopt an evaluation protocol tailored to extreme class\nimbalance. Concretely, we use area under the precision-recall curve (AUPRC) as\na robust evaluation metric, complemented by false alarms per hour (FA/h) at\nfixed recall to capture user-facing trade-offs. To simplify deployment and\nfurther experimentation within the research community, we are releasing an\nupdated version of the pnpl library with word-level dataloaders and Colab-ready\ntutorials. As an initial reference model, we present a compact 1-D Conv/ResNet\nbaseline with focal loss and top-k pooling that is trainable on a single\nconsumer-class GPU. The reference model achieves approximately 13x the\npermutation baseline AUPRC on held-out sessions, demonstrating the viability of\nthe task. Exploratory analyses reveal: (i) predictable within-subject scaling -\nperformance improves log-linearly with more training hours - and (ii) the\nexistence of word-level factors (frequency and duration) that systematically\nmodulate detectability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u5173\u952e\u8bcd\u68c0\u6d4b\uff08KWS\uff09\u4f5c\u4e3a\u8111\u673a\u63a5\u53e3\u7684\u5b9e\u7528\u4e2d\u95f4\u4efb\u52a1\uff0c\u4f7f\u7528LibriBrain\u8bed\u6599\u5e93\u63d0\u4f9b\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u91c7\u7528AUPRC\u548cFA/h\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u53d1\u5e03\u4e86\u4e00\u4e2a\u53ef\u5728\u6d88\u8d39\u7ea7GPU\u4e0a\u8bad\u7ec3\u7684\u7d27\u51d11-D Conv/ResNet\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u975e\u4fb5\u5165\u5f0f\u8111\u673a\u63a5\u53e3\u57fa\u51c6\u4e3b\u8981\u9488\u5bf9\u7b80\u5355\u7684\u57fa\u7840\u4efb\u52a1\uff0c\u800c\u9762\u5411\u5b9e\u9645\u5e94\u7528\u7684\u4efb\u52a1\uff08\u5982\u8111\u5230\u6587\u672c\uff09\u6210\u679c\u8f83\u5c11\u3002\u4f5c\u8005\u63d0\u51fa\u5173\u952e\u8bcd\u68c0\u6d4b\u4f5c\u4e3a\u9690\u79c1\u4fdd\u62a4\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u95f4\u4efb\u52a1\u3002", "method": "\u4f7f\u752852\u5c0f\u65f6\u7684LibriBrain\u8bed\u6599\u5e93\uff0c\u63d0\u4f9b\u6807\u51c6\u5316\u8bad\u7ec3/\u9a8c\u8bc1/\u6d4b\u8bd5\u5206\u5272\uff0c\u91c7\u7528\u9488\u5bf9\u6781\u7aef\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u8bc4\u4f30\u534f\u8bae\uff08AUPRC\u548cFA/h\uff09\u3002\u63d0\u51fa\u7d27\u51d1\u76841-D Conv/ResNet\u57fa\u7ebf\u6a21\u578b\uff0c\u4f7f\u7528\u7126\u70b9\u635f\u5931\u548ctop-k\u6c60\u5316\u3002", "result": "\u53c2\u8003\u6a21\u578b\u5728\u4fdd\u7559\u4f1a\u8bdd\u4e0a\u5b9e\u73b0\u4e86\u7ea613\u500d\u7f6e\u6362\u57fa\u7ebf\u7684AUPRC\uff0c\u8bc1\u660e\u4e86\u4efb\u52a1\u7684\u53ef\u884c\u6027\u3002\u63a2\u7d22\u6027\u5206\u6790\u663e\u793a\uff1a\u6027\u80fd\u968f\u8bad\u7ec3\u65f6\u95f4\u5bf9\u6570\u7ebf\u6027\u63d0\u5347\uff0c\u5355\u8bcd\u9891\u7387\u548c\u6301\u7eed\u65f6\u95f4\u7b49\u8bcd\u7ea7\u56e0\u7d20\u7cfb\u7edf\u6027\u5730\u8c03\u8282\u68c0\u6d4b\u80fd\u529b\u3002", "conclusion": "\u5173\u952e\u8bcd\u68c0\u6d4b\u662f\u8111\u673a\u63a5\u53e3\u7684\u4e00\u4e2a\u53ef\u884c\u4e14\u5b9e\u7528\u7684\u4e2d\u95f4\u4efb\u52a1\uff0c\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u57fa\u51c6\u548c\u5de5\u5177\uff0c\u652f\u6301\u8fdb\u4e00\u6b65\u5b9e\u9a8c\u548c\u90e8\u7f72\u3002"}}
{"id": "2510.21066", "categories": ["cs.LG", "astro-ph.SR", "physics.space-ph"], "pdf": "https://arxiv.org/pdf/2510.21066", "abs": "https://arxiv.org/abs/2510.21066", "authors": ["Daniela Martin", "Connor O'Brien", "Valmir P Moraes Filho", "Jinsu Hong", "Jasmine R. Kobayashi", "Evangelia Samara", "Joseph Gallego"], "title": "Scalable Machine Learning Analysis of Parker Solar Probe Solar Wind Data", "comment": null, "summary": "We present a scalable machine learning framework for analyzing Parker Solar\nProbe (PSP) solar wind data using distributed processing and the\nquantum-inspired Kernel Density Matrices (KDM) method. The PSP dataset\n(2018--2024) exceeds 150 GB, challenging conventional analysis approaches. Our\nframework leverages Dask for large-scale statistical computations and KDM to\nestimate univariate and bivariate distributions of key solar wind parameters,\nincluding solar wind speed, proton density, and proton thermal speed, as well\nas anomaly thresholds for each parameter. We reveal characteristic trends in\nthe inner heliosphere, including increasing solar wind speed with distance from\nthe Sun, decreasing proton density, and the inverse relationship between speed\nand density. Solar wind structures play a critical role in enhancing and\nmediating extreme space weather phenomena and can trigger geomagnetic storms;\nour analyses provide quantitative insights into these processes. This approach\noffers a tractable, interpretable, and distributed methodology for exploring\ncomplex physical datasets and facilitates reproducible analysis of large-scale\nin situ measurements. Processed data products and analysis tools are made\npublicly available to advance future studies of solar wind dynamics and space\nweather forecasting. The code and configuration files used in this study are\npublicly available to support reproducibility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u5e15\u514b\u592a\u9633\u63a2\u6d4b\u5668\uff08PSP\uff09\u7684\u592a\u9633\u98ce\u6570\u636e\uff0c\u91c7\u7528\u5206\u5e03\u5f0f\u5904\u7406\u548c\u91cf\u5b50\u542f\u53d1\u7684\u6838\u5bc6\u5ea6\u77e9\u9635\u65b9\u6cd5\uff0c\u5904\u7406\u8d85\u8fc7150GB\u7684\u6570\u636e\u96c6\u3002", "motivation": "PSP\u6570\u636e\u96c6\uff082018-2024\uff09\u8d85\u8fc7150GB\uff0c\u4f20\u7edf\u5206\u6790\u65b9\u6cd5\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u53ef\u6269\u5c55\u7684\u6846\u67b6\u6765\u5206\u6790\u592a\u9633\u98ce\u53c2\u6570\u53ca\u5176\u5bf9\u7a7a\u95f4\u5929\u6c14\u7684\u5f71\u54cd\u3002", "method": "\u5229\u7528Dask\u8fdb\u884c\u5927\u89c4\u6a21\u7edf\u8ba1\u8ba1\u7b97\uff0c\u4f7f\u7528\u91cf\u5b50\u542f\u53d1\u7684\u6838\u5bc6\u5ea6\u77e9\u9635\uff08KDM\uff09\u65b9\u6cd5\u4f30\u8ba1\u592a\u9633\u98ce\u53c2\u6570\u7684\u5355\u53d8\u91cf\u548c\u53cc\u53d8\u91cf\u5206\u5e03\uff0c\u5305\u62ec\u592a\u9633\u98ce\u901f\u3001\u8d28\u5b50\u5bc6\u5ea6\u548c\u8d28\u5b50\u70ed\u901f\u5ea6\u7b49\u5173\u952e\u53c2\u6570\u3002", "result": "\u63ed\u793a\u4e86\u5185\u65e5\u7403\u5c42\u7684\u7279\u5f81\u8d8b\u52bf\uff1a\u592a\u9633\u98ce\u901f\u968f\u8ddd\u592a\u9633\u8ddd\u79bb\u589e\u52a0\u800c\u589e\u52a0\uff0c\u8d28\u5b50\u5bc6\u5ea6\u51cf\u5c11\uff0c\u901f\u5ea6\u4e0e\u5bc6\u5ea6\u5448\u53cd\u6bd4\u5173\u7cfb\u3002\u592a\u9633\u98ce\u7ed3\u6784\u5728\u589e\u5f3a\u548c\u8c03\u8282\u6781\u7aef\u7a7a\u95f4\u5929\u6c14\u73b0\u8c61\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u63a2\u7d22\u590d\u6742\u7269\u7406\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u53ef\u5904\u7406\u3001\u53ef\u89e3\u91ca\u548c\u5206\u5e03\u5f0f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4fc3\u8fdb\u5927\u89c4\u6a21\u539f\u4f4d\u6d4b\u91cf\u7684\u53ef\u91cd\u590d\u5206\u6790\uff0c\u76f8\u5173\u6570\u636e\u4ea7\u54c1\u548c\u5de5\u5177\u5df2\u516c\u5f00\u4ee5\u652f\u6301\u672a\u6765\u592a\u9633\u98ce\u52a8\u529b\u5b66\u548c\u7a7a\u95f4\u5929\u6c14\u9884\u62a5\u7814\u7a76\u3002"}}
{"id": "2510.21067", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21067", "abs": "https://arxiv.org/abs/2510.21067", "authors": ["Raul Cavalcante Dinardi", "Bruno Yamamoto", "Anna Helena Reali Costa", "Artur Jordao"], "title": "The Virtues of Brevity: Avoid Overthinking in Parallel Test-Time Reasoning", "comment": "Accepted at NeurIPS 2025 Workshop on Efficient Reasoning", "summary": "Reasoning models represent a significant advance in LLM capabilities,\nparticularly for complex reasoning tasks such as mathematics and coding.\nPrevious studies confirm that parallel test-time compute-sampling multiple\nsolutions and selecting the best one-can further enhance the predictive\nperformance of LLMs. However, strategies in this area often require complex\nscoring, thus increasing computational cost and complexity. In this work, we\ndemonstrate that the simple and counterintuitive heuristic of selecting the\nshortest solution is highly effective. We posit that the observed effectiveness\nstems from models operating in two distinct regimes: a concise, confident\nconventional regime and a verbose overthinking regime characterized by\nuncertainty, and we show evidence of a critical point where the overthinking\nregime begins to be significant. By selecting the shortest answer, the\nheuristic preferentially samples from the conventional regime. We confirm that\nthis approach is competitive with more complex methods such as self-consistency\nacross two challenging benchmarks while significantly reducing computational\noverhead. The shortest-answer heuristic provides a Pareto improvement over\nself-consistency and applies even to tasks where output equality is not well\ndefined.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u9009\u62e9\u6700\u77ed\u7b54\u6848\u7684\u7b80\u5355\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u63d0\u5347LLM\u63a8\u7406\u6027\u80fd\u65b9\u9762\u4e0e\u590d\u6742\u65b9\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u5e76\u884c\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u7b56\u7565\u9700\u8981\u590d\u6742\u8bc4\u5206\uff0c\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c\u548c\u590d\u6742\u6027\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u9009\u62e9\u6700\u77ed\u7b54\u6848\u7684\u7b80\u5355\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u57fa\u4e8e\u6a21\u578b\u5b58\u5728\u7b80\u6d01\u81ea\u4fe1\u548c\u5197\u957f\u8fc7\u5ea6\u601d\u8003\u4e24\u79cd\u5de5\u4f5c\u6a21\u5f0f\u7684\u5047\u8bbe\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0e\u81ea\u4e00\u81f4\u6027\u7b49\u590d\u6742\u65b9\u6cd5\u8868\u73b0\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u6700\u77ed\u7b54\u6848\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u4f9b\u4e86\u76f8\u5bf9\u4e8e\u81ea\u4e00\u81f4\u6027\u7684\u5e15\u7d2f\u6258\u6539\u8fdb\uff0c\u9002\u7528\u4e8e\u8f93\u51fa\u76f8\u7b49\u6027\u5b9a\u4e49\u4e0d\u660e\u786e\u7684\u4efb\u52a1\u3002"}}
{"id": "2510.21086", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.21086", "abs": "https://arxiv.org/abs/2510.21086", "authors": ["Jiaqi Xue", "Mayank Kumar", "Yuzhang Shang", "Shangqian Gao", "Rui Ning", "Mengxin Zheng", "Xiaoqian Jiang", "Qian Lou"], "title": "DictPFL: Efficient and Private Federated Learning on Encrypted Gradients", "comment": "Accepted by NeurIPS 2025", "summary": "Federated Learning (FL) enables collaborative model training across\ninstitutions without sharing raw data. However, gradient sharing still risks\nprivacy leakage, such as gradient inversion attacks. Homomorphic Encryption\n(HE) can secure aggregation but often incurs prohibitive computational and\ncommunication overhead. Existing HE-based FL methods sit at two extremes:\nencrypting all gradients for full privacy at high cost, or partially encrypting\ngradients to save resources while exposing vulnerabilities. We present DictPFL,\na practical framework that achieves full gradient protection with minimal\noverhead. DictPFL encrypts every transmitted gradient while keeping\nnon-transmitted parameters local, preserving privacy without heavy computation.\nIt introduces two key modules: Decompose-for-Partial-Encrypt (DePE), which\ndecomposes model weights into a static dictionary and an updatable lookup\ntable, only the latter is encrypted and aggregated, while the static dictionary\nremains local and requires neither sharing nor encryption; and\nPrune-for-Minimum-Encrypt (PrME), which applies encryption-aware pruning to\nminimize encrypted parameters via consistent, history-guided masks. Experiments\nshow that DictPFL reduces communication cost by 402-748$\\times$ and accelerates\ntraining by 28-65$\\times$ compared to fully encrypted FL, while outperforming\nstate-of-the-art selective encryption methods by 51-155$\\times$ in overhead and\n4-19$\\times$ in speed. Remarkably, DictPFL's runtime is within 2$\\times$ of\nplaintext FL, demonstrating for the first time, that HE-based private federated\nlearning is practical for real-world deployment. The code is publicly available\nat https://github.com/UCF-ML-Research/DictPFL.", "AI": {"tldr": "DictPFL\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u6a21\u578b\u6743\u91cd\u4e3a\u9759\u6001\u5b57\u5178\u548c\u53ef\u66f4\u65b0\u67e5\u627e\u8868\uff0c\u4ec5\u52a0\u5bc6\u4f20\u8f93\u90e8\u5206\u53c2\u6570\uff0c\u5b9e\u73b0\u5168\u68af\u5ea6\u4fdd\u62a4\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u68af\u5ea6\u5171\u4eab\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u800c\u5168\u540c\u6001\u52a0\u5bc6\u65b9\u6cd5\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u8fc7\u9ad8\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5b8c\u5168\u52a0\u5bc6\u548c\u90e8\u5206\u52a0\u5bc6\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faDePE\u6a21\u5757\u5c06\u6a21\u578b\u6743\u91cd\u5206\u89e3\u4e3a\u9759\u6001\u5b57\u5178\u548c\u53ef\u66f4\u65b0\u67e5\u627e\u8868\uff0c\u4ec5\u52a0\u5bc6\u4f20\u8f93\u540e\u8005\uff1b\u5f15\u5165PrME\u6a21\u5757\u901a\u8fc7\u52a0\u5bc6\u611f\u77e5\u526a\u679d\u6700\u5c0f\u5316\u52a0\u5bc6\u53c2\u6570\u6570\u91cf\u3002", "result": "\u76f8\u6bd4\u5b8c\u5168\u52a0\u5bc6\u8054\u90a6\u5b66\u4e60\uff0c\u901a\u4fe1\u6210\u672c\u964d\u4f4e402-748\u500d\uff0c\u8bad\u7ec3\u901f\u5ea6\u63d0\u534728-65\u500d\uff1b\u76f8\u6bd4\u9009\u62e9\u6027\u52a0\u5bc6\u65b9\u6cd5\uff0c\u5f00\u9500\u964d\u4f4e51-155\u500d\uff0c\u901f\u5ea6\u63d0\u53474-19\u500d\u3002", "conclusion": "DictPFL\u9996\u6b21\u8bc1\u660e\u57fa\u4e8e\u540c\u6001\u52a0\u5bc6\u7684\u79c1\u6709\u8054\u90a6\u5b66\u4e60\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u662f\u53ef\u884c\u7684\uff0c\u5176\u8fd0\u884c\u65f6\u95f4\u4ec5\u6bd4\u660e\u6587\u8054\u90a6\u5b66\u4e60\u61622\u500d\u4ee5\u5185\u3002"}}
{"id": "2510.21113", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21113", "abs": "https://arxiv.org/abs/2510.21113", "authors": ["Maitreyi Swaroop", "Tamar Krishnamurti", "Bryan Wilder"], "title": "Distributionally Robust Feature Selection", "comment": "Accepted at NeurIPS 2025", "summary": "We study the problem of selecting limited features to observe such that\nmodels trained on them can perform well simultaneously across multiple\nsubpopulations. This problem has applications in settings where collecting each\nfeature is costly, e.g. requiring adding survey questions or physical sensors,\nand we must be able to use the selected features to create high-quality\ndownstream models for different populations. Our method frames the problem as a\ncontinuous relaxation of traditional variable selection using a noising\nmechanism, without requiring backpropagation through model training processes.\nBy optimizing over the variance of a Bayes-optimal predictor, we develop a\nmodel-agnostic framework that balances overall performance of downstream\nprediction across populations. We validate our approach through experiments on\nboth synthetic datasets and real-world data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u591a\u4e2a\u5b50\u7fa4\u4f53\u4e2d\u540c\u65f6\u9009\u62e9\u6709\u9650\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fde\u7eed\u677e\u5f1b\u4f20\u7edf\u53d8\u91cf\u9009\u62e9\u548c\u4f7f\u7528\u52a0\u566a\u673a\u5236\uff0c\u65e0\u9700\u901a\u8fc7\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\uff0c\u4ee5\u5e73\u8861\u4e0d\u540c\u7fa4\u4f53\u4e0b\u6e38\u9884\u6d4b\u7684\u6574\u4f53\u6027\u80fd\u3002", "motivation": "\u5728\u6536\u96c6\u6bcf\u4e2a\u7279\u5f81\u6210\u672c\u9ad8\u6602\u7684\u80cc\u666f\u4e0b\uff0c\u9700\u8981\u9009\u62e9\u6709\u9650\u7279\u5f81\u6765\u8bad\u7ec3\u6a21\u578b\uff0c\u4f7f\u5176\u5728\u591a\u4e2a\u5b50\u7fa4\u4f53\u4e2d\u90fd\u80fd\u8868\u73b0\u826f\u597d\uff0c\u4f8b\u5982\u6dfb\u52a0\u8c03\u67e5\u95ee\u9898\u6216\u7269\u7406\u4f20\u611f\u5668\u65f6\u3002", "method": "\u5c06\u95ee\u9898\u6784\u5efa\u4e3a\u4f20\u7edf\u53d8\u91cf\u9009\u62e9\u7684\u8fde\u7eed\u677e\u5f1b\uff0c\u4f7f\u7528\u52a0\u566a\u673a\u5236\uff0c\u901a\u8fc7\u4f18\u5316\u8d1d\u53f6\u65af\u6700\u4f18\u9884\u6d4b\u5668\u7684\u65b9\u5dee\u6765\u5f00\u53d1\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5e73\u8861\u4e0d\u540c\u7fa4\u4f53\u4e0b\u6e38\u9884\u6d4b\u7684\u6574\u4f53\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u7279\u5f81\u6536\u96c6\u6210\u672c\u9ad8\u6602\u7684\u573a\u666f\u3002"}}
{"id": "2510.21129", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21129", "abs": "https://arxiv.org/abs/2510.21129", "authors": ["Linyuan Geng", "Linxiao Yang", "Xinyue Gu", "Liang Sun"], "title": "SolarBoost: Distributed Photovoltaic Power Forecasting Amid Time-varying Grid Capacity", "comment": null, "summary": "This paper presents SolarBoost, a novel approach for forecasting power output\nin distributed photovoltaic (DPV) systems. While existing centralized\nphotovoltaic (CPV) methods are able to precisely model output dependencies due\nto uniformity, it is difficult to apply such techniques to DPV systems, as DPVs\nface challenges such as missing grid-level data, temporal shifts in installed\ncapacity, geographic variability, and panel diversity. SolarBoost overcomes\nthese challenges by modeling aggregated power output as a composite of output\nfrom small grids, where each grid output is modeled using a unit output\nfunction multiplied by its capacity. This approach decouples the homogeneous\nunit output function from dynamic capacity for accurate prediction. Efficient\nalgorithms over an upper-bound approximation are proposed to overcome\ncomputational bottlenecks in loss functions. We demonstrate the superiority of\ngrid-level modeling via theoretical analysis and experiments. SolarBoost has\nbeen validated through deployment across various cities in China, significantly\nreducing potential losses and provides valuable insights for the operation of\npower grids. The code for this work is available at\nhttps://github.com/DAMO-DI-ML/SolarBoost.", "AI": {"tldr": "SolarBoost\u662f\u4e00\u79cd\u7528\u4e8e\u5206\u5e03\u5f0f\u5149\u4f0f\u7cfb\u7edf\u529f\u7387\u8f93\u51fa\u9884\u6d4b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u603b\u529f\u7387\u8f93\u51fa\u5efa\u6a21\u4e3a\u5c0f\u7535\u7f51\u8f93\u51fa\u7684\u7ec4\u5408\uff0c\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u5149\u4f0f\u7cfb\u7edf\u9762\u4e34\u7684\u7535\u7f51\u7ea7\u6570\u636e\u7f3a\u5931\u3001\u5bb9\u91cf\u53d8\u5316\u3001\u5730\u7406\u5dee\u5f02\u7b49\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u96c6\u4e2d\u5f0f\u5149\u4f0f\u9884\u6d4b\u65b9\u6cd5\u96be\u4ee5\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u5149\u4f0f\u7cfb\u7edf\uff0c\u56e0\u4e3a\u5206\u5e03\u5f0f\u5149\u4f0f\u9762\u4e34\u7535\u7f51\u7ea7\u6570\u636e\u7f3a\u5931\u3001\u5b89\u88c5\u5bb9\u91cf\u65f6\u95f4\u53d8\u5316\u3001\u5730\u7406\u53d8\u5f02\u6027\u548c\u9762\u677f\u591a\u6837\u6027\u7b49\u6311\u6218\u3002", "method": "\u5c06\u603b\u529f\u7387\u8f93\u51fa\u5efa\u6a21\u4e3a\u5c0f\u7535\u7f51\u8f93\u51fa\u7684\u7ec4\u5408\uff0c\u6bcf\u4e2a\u7535\u7f51\u8f93\u51fa\u4f7f\u7528\u5355\u4f4d\u8f93\u51fa\u51fd\u6570\u4e58\u4ee5\u5176\u5bb9\u91cf\u6765\u5efa\u6a21\uff0c\u5c06\u540c\u8d28\u7684\u5355\u4f4d\u8f93\u51fa\u51fd\u6570\u4e0e\u52a8\u6001\u5bb9\u91cf\u89e3\u8026\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u4e0a\u754c\u8fd1\u4f3c\u7684\u9ad8\u6548\u7b97\u6cd5\u6765\u514b\u670d\u635f\u5931\u51fd\u6570\u4e2d\u7684\u8ba1\u7b97\u74f6\u9888\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7535\u7f51\u7ea7\u5efa\u6a21\u7684\u4f18\u8d8a\u6027\uff0c\u5728\u4e2d\u56fd\u591a\u4e2a\u57ce\u5e02\u90e8\u7f72\u9a8c\u8bc1\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6f5c\u5728\u635f\u5931\uff0c\u4e3a\u7535\u7f51\u8fd0\u884c\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "conclusion": "SolarBoost\u901a\u8fc7\u521b\u65b0\u7684\u7535\u7f51\u7ea7\u5efa\u6a21\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u5f0f\u5149\u4f0f\u7cfb\u7edf\u529f\u7387\u9884\u6d4b\u7684\u6311\u6218\uff0c\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.21135", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21135", "abs": "https://arxiv.org/abs/2510.21135", "authors": ["Yuhao Fu", "Yinghao Zhang", "Yalin Liu", "Bishenghui Tao", "Junhong Ruan"], "title": "Cloud-Fog-Edge Collaborative Computing for Sequential MIoT Workflow: A Two-Tier DDPG-Based Scheduling Framework", "comment": "14 pages, 3 figures, 2 tables", "summary": "The Medical Internet of Things (MIoT) demands stringent end-to-end latency\nguarantees for sequential healthcare workflows deployed over heterogeneous\ncloud-fog-edge infrastructures. Scheduling these sequential workflows to\nminimize makespan is an NP-hard problem. To tackle this challenge, we propose a\nTwo-tier DDPG-based scheduling framework that decomposes the scheduling\ndecision into a hierarchical process: a global controller performs layer\nselection (edge, fog, or cloud), while specialized local controllers handle\nnode assignment within the chosen layer. The primary optimization objective is\nthe minimization of the workflow makespan. Experiments results validate our\napproach, demonstrating increasingly superior performance over baselines as\nworkflow complexity rises. This trend highlights the frameworks ability to\nlearn effective long-term strategies, which is critical for complex,\nlarge-scale MIoT scheduling scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDDPG\u7684\u4e24\u5c42\u8c03\u5ea6\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5f02\u6784\u4e91-\u96fe-\u8fb9\u7f18\u57fa\u7840\u8bbe\u65bd\u4e0a\u6700\u5c0f\u5316\u533b\u7597\u7269\u8054\u7f51\u4e2d\u987a\u5e8f\u5de5\u4f5c\u6d41\u7684\u5b8c\u6210\u65f6\u95f4\u3002", "motivation": "\u533b\u7597\u7269\u8054\u7f51\u5bf9\u987a\u5e8f\u533b\u7597\u5de5\u4f5c\u6d41\u5728\u5f02\u6784\u4e91-\u96fe-\u8fb9\u7f18\u57fa\u7840\u8bbe\u65bd\u4e0a\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u6709\u4e25\u683c\u8981\u6c42\uff0c\u800c\u8c03\u5ea6\u8fd9\u4e9b\u987a\u5e8f\u5de5\u4f5c\u6d41\u4ee5\u6700\u5c0f\u5316\u5b8c\u6210\u65f6\u95f4\u662f\u4e00\u4e2aNP\u96be\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u5c42DDPG\u8c03\u5ea6\u6846\u67b6\uff0c\u5c06\u8c03\u5ea6\u51b3\u7b56\u5206\u89e3\u4e3a\u5206\u5c42\u8fc7\u7a0b\uff1a\u5168\u5c40\u63a7\u5236\u5668\u6267\u884c\u5c42\u9009\u62e9\uff08\u8fb9\u7f18\u3001\u96fe\u6216\u4e91\uff09\uff0c\u800c\u4e13\u95e8\u7684\u672c\u5730\u63a7\u5236\u5668\u5904\u7406\u9009\u5b9a\u5c42\u5185\u7684\u8282\u70b9\u5206\u914d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u968f\u7740\u5de5\u4f5c\u6d41\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u8be5\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u4f18\u52bf\u8d8a\u6765\u8d8a\u660e\u663e\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u5b66\u4e60\u6709\u6548\u7684\u957f\u671f\u7b56\u7565\uff0c\u8fd9\u5bf9\u4e8e\u590d\u6742\u3001\u5927\u89c4\u6a21\u7684\u533b\u7597\u7269\u8054\u7f51\u8c03\u5ea6\u573a\u666f\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.21172", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21172", "abs": "https://arxiv.org/abs/2510.21172", "authors": ["Angshul Majumdar"], "title": "A Unified Matrix Factorization Framework for Classical and Robust Clustering", "comment": null, "summary": "This paper presents a unified matrix factorization framework for classical\nand robust clustering. We begin by revisiting the well-known equivalence\nbetween crisp k-means clustering and matrix factorization, following and\nrigorously rederiving an unpublished formulation by Bauckhage. Extending this\nframework, we derive an analogous matrix factorization interpretation for fuzzy\nc-means clustering, which to the best of our knowledge has not been previously\nformalized. These reformulations allow both clustering paradigms to be\nexpressed as optimization problems over factor matrices, thereby enabling\nprincipled extensions to robust variants. To address sensitivity to outliers,\nwe propose robust formulations for both crisp and fuzzy clustering by replacing\nthe Frobenius norm with the l1,2-norm, which penalizes the sum of Euclidean\nnorms across residual columns. We develop alternating minimization algorithms\nfor the standard formulations and IRLS-based algorithms for the robust\ncounterparts. All algorithms are theoretically proven to converge to a local\nminimum.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u77e9\u9635\u5206\u89e3\u6846\u67b6\uff0c\u7528\u4e8e\u7ecf\u5178\u548c\u9c81\u68d2\u805a\u7c7b\u3002\u91cd\u65b0\u63a8\u5bfc\u4e86k-means\u805a\u7c7b\u4e0e\u77e9\u9635\u5206\u89e3\u7684\u7b49\u4ef7\u5173\u7cfb\uff0c\u5e76\u9996\u6b21\u5f62\u5f0f\u5316\u5730\u5efa\u7acb\u4e86\u6a21\u7ccac-means\u805a\u7c7b\u7684\u77e9\u9635\u5206\u89e3\u89e3\u91ca\u3002\u901a\u8fc7\u7528l1,2\u8303\u6570\u66ff\u4ee3Frobenius\u8303\u6570\uff0c\u63d0\u51fa\u4e86\u9c81\u68d2\u805a\u7c7b\u53d8\u4f53\uff0c\u5e76\u5f00\u53d1\u4e86\u76f8\u5e94\u7684\u4f18\u5316\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u805a\u7c7b\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\uff0c\u4e14\u5bf9\u5f02\u5e38\u503c\u654f\u611f\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u7ecf\u5178\u805a\u7c7b\u4e0e\u77e9\u9635\u5206\u89e3\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u5f00\u53d1\u5bf9\u5f02\u5e38\u503c\u5177\u6709\u9c81\u68d2\u6027\u7684\u805a\u7c7b\u65b9\u6cd5\u3002", "method": "1. \u91cd\u65b0\u63a8\u5bfck-means\u4e0e\u77e9\u9635\u5206\u89e3\u7684\u7b49\u4ef7\u5173\u7cfb\uff1b2. \u9996\u6b21\u5f62\u5f0f\u5316\u6a21\u7ccac-means\u7684\u77e9\u9635\u5206\u89e3\u89e3\u91ca\uff1b3. \u7528l1,2\u8303\u6570\u66ff\u4ee3Frobenius\u8303\u6570\u6784\u5efa\u9c81\u68d2\u805a\u7c7b\uff1b4. \u5f00\u53d1\u4ea4\u66ff\u6700\u5c0f\u5316\u7b97\u6cd5\u548cIRLS\u7b97\u6cd5\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86\u7ecf\u5178\u805a\u7c7b\u4e0e\u77e9\u9635\u5206\u89e3\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u9c81\u68d2\u805a\u7c7b\u53d8\u4f53\uff0c\u6240\u6709\u7b97\u6cd5\u90fd\u88ab\u7406\u8bba\u8bc1\u660e\u80fd\u591f\u6536\u655b\u5230\u5c40\u90e8\u6700\u5c0f\u503c\u3002", "conclusion": "\u77e9\u9635\u5206\u89e3\u6846\u67b6\u4e3a\u7ecf\u5178\u548c\u9c81\u68d2\u805a\u7c7b\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63d0\u51fa\u7684\u9c81\u68d2\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u5f02\u5e38\u503c\uff0c\u7b97\u6cd5\u5177\u6709\u7406\u8bba\u6536\u655b\u4fdd\u8bc1\u3002"}}
{"id": "2510.21176", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21176", "abs": "https://arxiv.org/abs/2510.21176", "authors": ["Shadi Aljawarneh", "Juan A. Lara", "Muneer Bani Yassein"], "title": "A visual big data system for the prediction of weather-related variables: Jordan-Spain case study", "comment": null, "summary": "The Meteorology is a field where huge amounts of data are generated, mainly\ncollected by sensors at weather stations, where different variables can be\nmeasured. Those data have some particularities such as high volume and\ndimensionality, the frequent existence of missing values in some stations, and\nthe high correlation between collected variables. In this regard, it is crucial\nto make use of Big Data and Data Mining techniques to deal with those data and\nextract useful knowledge from them that can be used, for instance, to predict\nweather phenomena. In this paper, we propose a visual big data system that is\ndesigned to deal with high amounts of weather-related data and lets the user\nanalyze those data to perform predictive tasks over the considered variables\n(temperature and rainfall). The proposed system collects open data and loads\nthem onto a local NoSQL database fusing them at different levels of temporal\nand spatial aggregation in order to perform a predictive analysis using\nunivariate and multivariate approaches as well as forecasting based on training\ndata from neighbor stations in cases with high rates of missing values. The\nsystem has been assessed in terms of usability and predictive performance,\nobtaining an overall normalized mean squared error value of 0.00013, and an\noverall directional symmetry value of nearly 0.84. Our system has been rated\npositively by a group of experts in the area (all aspects of the system except\ngraphic desing were rated 3 or above in a 1-5 scale). The promising preliminary\nresults obtained demonstrate the validity of our system and invite us to keep\nworking on this area.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u89c6\u5316\u5927\u6570\u636e\u7cfb\u7edf\uff0c\u7528\u4e8e\u5904\u7406\u6c14\u8c61\u6570\u636e\u5e76\u6267\u884c\u9884\u6d4b\u4efb\u52a1\uff0c\u7cfb\u7edf\u6574\u5408\u5f00\u653e\u6570\u636e\u5230NoSQL\u6570\u636e\u5e93\uff0c\u91c7\u7528\u5355\u53d8\u91cf\u3001\u591a\u53d8\u91cf\u548c\u90bb\u8fd1\u7ad9\u70b9\u9884\u6d4b\u65b9\u6cd5\uff0c\u5728\u7f3a\u5931\u503c\u60c5\u51b5\u4e0b\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u6c14\u8c61\u9886\u57df\u4ea7\u751f\u5927\u91cf\u6570\u636e\uff0c\u5177\u6709\u9ad8\u5bb9\u91cf\u3001\u9ad8\u7ef4\u5ea6\u3001\u7f3a\u5931\u503c\u9891\u7e41\u548c\u53d8\u91cf\u9ad8\u5ea6\u76f8\u5173\u7b49\u7279\u70b9\uff0c\u9700\u8981\u5229\u7528\u5927\u6570\u636e\u548c\u6570\u636e\u6316\u6398\u6280\u672f\u6765\u63d0\u53d6\u6709\u7528\u77e5\u8bc6\u4ee5\u9884\u6d4b\u5929\u6c14\u73b0\u8c61\u3002", "method": "\u5f00\u53d1\u53ef\u89c6\u5316\u5927\u6570\u636e\u7cfb\u7edf\uff0c\u6536\u96c6\u5f00\u653e\u6570\u636e\u5e76\u52a0\u8f7d\u5230\u672c\u5730NoSQL\u6570\u636e\u5e93\uff0c\u5728\u4e0d\u540c\u65f6\u95f4\u548c\u7a7a\u95f4\u805a\u5408\u7ea7\u522b\u878d\u5408\u6570\u636e\uff0c\u4f7f\u7528\u5355\u53d8\u91cf\u3001\u591a\u53d8\u91cf\u65b9\u6cd5\u4ee5\u53ca\u57fa\u4e8e\u90bb\u8fd1\u7ad9\u70b9\u8bad\u7ec3\u6570\u636e\u7684\u9884\u6d4b\u65b9\u6cd5\u5904\u7406\u7f3a\u5931\u503c\u3002", "result": "\u7cfb\u7edf\u5728\u53ef\u7528\u6027\u548c\u9884\u6d4b\u6027\u80fd\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u603b\u4f53\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\u4e3a0.00013\uff0c\u65b9\u5411\u5bf9\u79f0\u6027\u63a5\u8fd10.84\uff0c\u4e13\u5bb6\u8bc4\u5206\u663e\u793a\u9664\u56fe\u5f62\u8bbe\u8ba1\u5916\u6240\u6709\u65b9\u9762\u5747\u83b7\u5f973\u5206\u4ee5\u4e0a\uff081-5\u5206\u5236\uff09\u3002", "conclusion": "\u521d\u6b65\u7ed3\u679c\u8bc1\u660e\u4e86\u7cfb\u7edf\u7684\u6709\u6548\u6027\uff0c\u9f13\u52b1\u7ee7\u7eed\u5728\u8be5\u9886\u57df\u5f00\u5c55\u5de5\u4f5c\u3002"}}
{"id": "2510.21192", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21192", "abs": "https://arxiv.org/abs/2510.21192", "authors": ["Luca Demetrio", "Giovanni Apruzzese", "Kathrin Grosse", "Pavel Laskov", "Emil Lupu", "Vera Rimmer", "Philine Widmer"], "title": "Gen-Review: A Large-scale Dataset of AI-Generated (and Human-written) Peer Reviews", "comment": null, "summary": "How does the progressive embracement of Large Language Models (LLMs) affect\nscientific peer reviewing? This multifaceted question is fundamental to the\neffectiveness -- as well as to the integrity -- of the scientific process.\nRecent evidence suggests that LLMs may have already been tacitly used in peer\nreviewing, e.g., at the 2024 International Conference of Learning\nRepresentations (ICLR). Furthermore, some efforts have been undertaken in an\nattempt to explicitly integrate LLMs in peer reviewing by various editorial\nboards (including that of ICLR'25). To fully understand the utility and the\nimplications of LLMs' deployment for scientific reviewing, a comprehensive\nrelevant dataset is strongly desirable. Despite some previous research on this\ntopic, such dataset has been lacking so far. We fill in this gap by presenting\nGenReview, the hitherto largest dataset containing LLM-written reviews. Our\ndataset includes 81K reviews generated for all submissions to the 2018--2025\neditions of the ICLR by providing the LLM with three independent prompts: a\nnegative, a positive, and a neutral one. GenReview is also linked to the\nrespective papers and their original reviews, thereby enabling a broad range of\ninvestigations. To illustrate the value of GenReview, we explore a sample of\nintriguing research questions, namely: if LLMs exhibit bias in reviewing (they\ndo); if LLM-written reviews can be automatically detected (so far, they can);\nif LLMs can rigorously follow reviewing instructions (not always) and whether\nLLM-provided ratings align with decisions on paper acceptance or rejection\n(holds true only for accepted papers). GenReview can be accessed at the\nfollowing link: https://anonymous.4open.science/r/gen_review.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86GenReview\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u5305\u542bLLM\u751f\u6210\u8bc4\u5ba1\u610f\u89c1\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d6ICLR 2018-2025\u5e74\u6240\u6709\u63d0\u4ea4\u8bba\u6587\u768481K\u6761\u8bc4\u5ba1\u610f\u89c1\uff0c\u7528\u4e8e\u7814\u7a76LLM\u5728\u79d1\u5b66\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u6f5c\u5728\u4f7f\u7528\u65e5\u76ca\u589e\u591a\uff0c\u9700\u8981\u5168\u9762\u6570\u636e\u96c6\u6765\u7406\u89e3LLM\u90e8\u7f72\u7684\u6548\u7528\u548c\u5f71\u54cd\uff0c\u6b64\u524d\u7f3a\u4e4f\u8fd9\u6837\u7684\u6570\u636e\u96c6\u3002", "method": "\u521b\u5efaGenReview\u6570\u636e\u96c6\uff0c\u4e3aICLR 2018-2025\u6240\u6709\u63d0\u4ea4\u8bba\u6587\u751f\u621081K\u6761LLM\u8bc4\u5ba1\u610f\u89c1\uff0c\u4f7f\u7528\u8d1f\u9762\u3001\u6b63\u9762\u548c\u4e2d\u6027\u4e09\u79cd\u72ec\u7acb\u63d0\u793a\u8bcd\uff0c\u5e76\u5c06\u6570\u636e\u96c6\u4e0e\u539f\u59cb\u8bba\u6587\u53ca\u5176\u8bc4\u5ba1\u610f\u89c1\u5173\u8054\u3002", "result": "\u901a\u8fc7GenReview\u6570\u636e\u96c6\u7814\u7a76\u53d1\u73b0\uff1aLLM\u5728\u8bc4\u5ba1\u4e2d\u5b58\u5728\u504f\u89c1\uff1bLLM\u751f\u6210\u7684\u8bc4\u5ba1\u610f\u89c1\u76ee\u524d\u53ef\u4ee5\u81ea\u52a8\u68c0\u6d4b\uff1bLLM\u5e76\u4e0d\u603b\u662f\u4e25\u683c\u9075\u5faa\u8bc4\u5ba1\u6307\u5357\uff1bLLM\u63d0\u4f9b\u7684\u8bc4\u5206\u4ec5\u4e0e\u8bba\u6587\u63a5\u53d7\u51b3\u7b56\u4e00\u81f4\u3002", "conclusion": "GenReview\u6570\u636e\u96c6\u586b\u8865\u4e86\u76f8\u5173\u7814\u7a76\u7a7a\u767d\uff0c\u4e3a\u6df1\u5165\u63a2\u7d22LLM\u5728\u79d1\u5b66\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u4f5c\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u63ed\u793a\u4e86LLM\u8bc4\u5ba1\u7684\u5c40\u9650\u6027\u53ca\u5176\u5bf9\u79d1\u5b66\u8fc7\u7a0b\u5b8c\u6574\u6027\u7684\u5f71\u54cd\u3002"}}
{"id": "2510.21204", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21204", "abs": "https://arxiv.org/abs/2510.21204", "authors": ["Xiyuan Zhang", "Danielle C. Maddix", "Junming Yin", "Nick Erickson", "Abdul Fatir Ansari", "Boran Han", "Shuai Zhang", "Leman Akoglu", "Christos Faloutsos", "Michael W. Mahoney", "Cuixiong Hu", "Huzefa Rangwala", "George Karypis", "Bernie Wang"], "title": "Mitra: Mixed Synthetic Priors for Enhancing Tabular Foundation Models", "comment": "NeurIPS 2025. We released both classifier\n  (autogluon/mitra-classifier) and regressor (autogluon/mitra-regressor) model\n  weights on HuggingFace", "summary": "Since the seminal work of TabPFN, research on tabular foundation models\n(TFMs) based on in-context learning (ICL) has challenged long-standing\nparadigms in machine learning. Without seeing any real-world data, models\npretrained on purely synthetic datasets generalize remarkably well across\ndiverse datasets, often using only a moderate number of in-context examples.\nThis shifts the focus in tabular machine learning from model architecture\ndesign to the design of synthetic datasets, or, more precisely, to the prior\ndistributions that generate them. Yet the guiding principles for prior design\nremain poorly understood. This work marks the first attempt to address the gap.\nWe systematically investigate and identify key properties of synthetic priors\nthat allow pretrained TFMs to generalize well. Based on these insights, we\nintroduce Mitra, a TFM trained on a curated mixture of synthetic priors\nselected for their diversity, distinctiveness, and performance on real-world\ntabular data. Mitra consistently outperforms state-of-the-art TFMs, such as\nTabPFNv2 and TabICL, across both classification and regression benchmarks, with\nbetter sample efficiency.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Mitra\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u6837\u5316\u5408\u6210\u5148\u9a8c\u8bad\u7ec3\u7684\u8868\u683c\u57fa\u7840\u6a21\u578b\uff0c\u5728\u8868\u683c\u673a\u5668\u5b66\u4e60\u7684\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8868\u683c\u57fa\u7840\u6a21\u578b(TFMs)\u867d\u7136\u901a\u8fc7\u7eaf\u5408\u6210\u6570\u636e\u96c6\u9884\u8bad\u7ec3\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5408\u6210\u5148\u9a8c\u7684\u8bbe\u8ba1\u539f\u5219\u4ecd\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u5982\u4f55\u8bbe\u8ba1\u6709\u6548\u7684\u5408\u6210\u5148\u9a8c\u5206\u5e03\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u5408\u6210\u5148\u9a8c\u7684\u5173\u952e\u7279\u6027\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u6d1e\u5bdf\u5f00\u53d1Mitra\u6a21\u578b\uff0c\u901a\u8fc7\u5728\u591a\u6837\u5316\u3001\u72ec\u7279\u4e14\u5bf9\u771f\u5b9e\u8868\u683c\u6570\u636e\u8868\u73b0\u826f\u597d\u7684\u5408\u6210\u5148\u9a8c\u6df7\u5408\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "Mitra\u5728\u5206\u7c7b\u548c\u56de\u5f52\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e00\u81f4\u4f18\u4e8eTabPFNv2\u548cTabICL\u7b49\u6700\u5148\u8fdbTFMs\uff0c\u5e76\u5177\u6709\u66f4\u597d\u7684\u6837\u672c\u6548\u7387\u3002", "conclusion": "\u5408\u6210\u5148\u9a8c\u7684\u591a\u6837\u6027\u3001\u72ec\u7279\u6027\u548c\u6027\u80fd\u662f\u8bad\u7ec3\u6709\u6548\u8868\u683c\u57fa\u7840\u6a21\u578b\u7684\u5173\u952e\u56e0\u7d20\uff0cMitra\u7684\u6210\u529f\u8bc1\u660e\u4e86\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5408\u6210\u5148\u9a8c\u6df7\u5408\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.21223", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21223", "abs": "https://arxiv.org/abs/2510.21223", "authors": ["Kexuan Shi", "Yandong Wen", "Weiyang Liu"], "title": "Model Merging with Functional Dual Anchors", "comment": "Technical report (23 pages, 15 figures, project page:\n  https://spherelab.ai/fda/)", "summary": "Model merging is an efficient post-training strategy for integrating\nknowledge from multiple finetuned checkpoints of a shared foundation model.\nExisting methods operate in the parameter space, combining task vectors to\nmitigate conflicts, but remain constrained by parameter inconsistencies. We\npropose Functional Dual Anchors (FDAs), a framework that instead models the\ninput-representation space. FDAs are synthetic inputs whose induced gradients\nalign with task vectors, capturing task-specific functional shifts relative to\nthe pretrained model. This perspective bridges joint multi-task training and\npost-hoc merging, offering both robustness and flexibility. We further\nintroduce a principled initialization scheme and show that FDAs are\ncomplementary to parameter-space model merging. Comprehensive experiments\ndemonstrate the effectiveness of FDAs in model merging.", "AI": {"tldr": "\u63d0\u51faFunctional Dual Anchors (FDAs)\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u8f93\u5165\u8868\u793a\u7a7a\u95f4\u800c\u975e\u53c2\u6570\u7a7a\u95f4\u6765\u6539\u8fdb\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\uff0c\u4f7f\u7528\u5408\u6210\u8f93\u5165\u6355\u6349\u4efb\u52a1\u7279\u5b9a\u7684\u529f\u80fd\u504f\u79fb\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u5728\u53c2\u6570\u7a7a\u95f4\u64cd\u4f5c\uff0c\u53d7\u9650\u4e8e\u53c2\u6570\u4e0d\u4e00\u81f4\u6027\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u548c\u9c81\u68d2\u7684\u5408\u5e76\u7b56\u7565\u3002", "method": "\u63d0\u51faFDA\u6846\u67b6\uff0c\u4f7f\u7528\u5408\u6210\u8f93\u5165\u8bf1\u5bfc\u7684\u68af\u5ea6\u4e0e\u4efb\u52a1\u5411\u91cf\u5bf9\u9f50\uff0c\u6355\u6349\u76f8\u5bf9\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u4efb\u52a1\u7279\u5b9a\u529f\u80fd\u504f\u79fb\uff0c\u5e76\u63d0\u4f9b\u539f\u5219\u6027\u521d\u59cb\u5316\u65b9\u6848\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8bc1\u660eFDAs\u5728\u6a21\u578b\u5408\u5e76\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e14\u4e0e\u53c2\u6570\u7a7a\u95f4\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u4e92\u8865\u3002", "conclusion": "FDA\u6846\u67b6\u901a\u8fc7\u8f93\u5165\u8868\u793a\u7a7a\u95f4\u5efa\u6a21\uff0c\u4e3a\u6a21\u578b\u5408\u5e76\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u7ed3\u5408\u4e86\u8054\u5408\u591a\u4efb\u52a1\u8bad\u7ec3\u548c\u540e\u9a8c\u5408\u5e76\u7684\u4f18\u52bf\u3002"}}
{"id": "2510.21245", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.21245", "abs": "https://arxiv.org/abs/2510.21245", "authors": ["Noah Oberweis", "Semih Cayci"], "title": "Convergence of Stochastic Gradient Langevin Dynamics in the Lazy Training Regime", "comment": null, "summary": "Continuous-time models provide important insights into the training dynamics\nof optimization algorithms in deep learning. In this work, we establish a\nnon-asymptotic convergence analysis of stochastic gradient Langevin dynamics\n(SGLD), which is an It\\^o stochastic differential equation (SDE) approximation\nof stochastic gradient descent in continuous time, in the lazy training regime.\nWe show that, under regularity conditions on the Hessian of the loss function,\nSGLD with multiplicative and state-dependent noise (i) yields a non-degenerate\nkernel throughout the training process with high probability, and (ii) achieves\nexponential convergence to the empirical risk minimizer in expectation, and we\nestablish finite-time and finite-width bounds on the optimality gap. We\ncorroborate our theoretical findings with numerical examples in the regression\nsetting.", "AI": {"tldr": "\u672c\u6587\u5bf9\u968f\u673a\u68af\u5ea6Langevin\u52a8\u529b\u5b66(SGLD)\u5728\u61d2\u60f0\u8bad\u7ec3\u673a\u5236\u4e0b\u5efa\u7acb\u4e86\u975e\u6e10\u8fd1\u6536\u655b\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u5728Hessian\u77e9\u9635\u6b63\u5219\u6761\u4ef6\u4e0b\uff0cSGLD\u80fd\u4fdd\u6301\u975e\u9000\u5316\u6838\u5e76\u4ee5\u6307\u6570\u901f\u7387\u6536\u655b\u5230\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u5668\u3002", "motivation": "\u8fde\u7eed\u65f6\u95f4\u6a21\u578b\u4e3a\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u7684\u8bad\u7ec3\u52a8\u6001\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u9700\u8981\u7814\u7a76SGLD\u5728\u61d2\u60f0\u8bad\u7ec3\u673a\u5236\u4e0b\u7684\u6536\u655b\u6027\u8d28\u3002", "method": "\u4f7f\u7528\u968f\u673a\u5fae\u5206\u65b9\u7a0b(SDE)\u65b9\u6cd5\u5206\u6790SGLD\uff0c\u5728Hessian\u77e9\u9635\u6ee1\u8db3\u6b63\u5219\u6027\u6761\u4ef6\u4e0b\uff0c\u7814\u7a76\u5e26\u4e58\u6027\u548c\u72b6\u6001\u4f9d\u8d56\u566a\u58f0\u7684SGLD\u52a8\u6001\u3002", "result": "\u8bc1\u660e\u4e86SGLD\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4ee5\u9ad8\u6982\u7387\u4fdd\u6301\u975e\u9000\u5316\u6838\uff0c\u5728\u671f\u671b\u610f\u4e49\u4e0b\u4ee5\u6307\u6570\u901f\u7387\u6536\u655b\u5230\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u5668\uff0c\u5e76\u5efa\u7acb\u4e86\u6700\u4f18\u6027\u95f4\u9699\u7684\u6709\u9650\u65f6\u95f4\u548c\u6709\u9650\u5bbd\u5ea6\u754c\u9650\u3002", "conclusion": "\u7406\u8bba\u5206\u6790\u8868\u660eSGLD\u5728\u61d2\u60f0\u8bad\u7ec3\u673a\u5236\u4e0b\u5177\u6709\u826f\u597d\u7684\u6536\u655b\u6027\u8d28\uff0c\u6570\u503c\u5b9e\u9a8c\u5728\u56de\u5f52\u8bbe\u5b9a\u4e2d\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002"}}
{"id": "2510.21252", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.21252", "abs": "https://arxiv.org/abs/2510.21252", "authors": ["Francesco Martinuzzi"], "title": "Unified Implementations of Recurrent Neural Networks in Multiple Deep Learning Frameworks", "comment": null, "summary": "Recurrent neural networks (RNNs) are a cornerstone of sequence modeling\nacross various scientific and industrial applications. Owing to their\nversatility, numerous RNN variants have been proposed over the past decade,\naiming to improve the modeling of long-term dependencies and to address\nchallenges such as vanishing and exploding gradients. However, no central\nlibrary is available to test these variations, and reimplementing diverse\narchitectures can be time-consuming and error-prone, limiting reproducibility\nand exploration. Here, we introduce three open-source libraries in Julia and\nPython that centralize numerous recurrent cell implementations and higher-level\nrecurrent architectures. torchrecurrent, RecurrentLayers.jl, and\nLuxRecurrentLayers.jl offer a consistent framework for constructing and\nextending RNN models, providing built-in mechanisms for customization and\nexperimentation. All packages are available under the MIT license and actively\nmaintained on GitHub.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e09\u4e2a\u5f00\u6e90\u5e93\uff08torchrecurrent\u3001RecurrentLayers.jl\u548cLuxRecurrentLayers.jl\uff09\uff0c\u7528\u4e8e\u96c6\u4e2d\u5b9e\u73b0\u548c\u6d4b\u8bd5\u591a\u79cdRNN\u53d8\u4f53\uff0c\u89e3\u51b3\u73b0\u6709\u7f3a\u4e4f\u7edf\u4e00\u6d4b\u8bd5\u5e73\u53f0\u7684\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u7edf\u4e00\u7684\u6d4b\u8bd5\u5e93\u6765\u8bc4\u4f30\u5404\u79cdRNN\u53d8\u4f53\uff0c\u91cd\u65b0\u5b9e\u73b0\u4e0d\u540c\u67b6\u6784\u8017\u65f6\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u9650\u5236\u4e86\u53ef\u91cd\u590d\u6027\u548c\u63a2\u7d22\u6027\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u4e86\u4e09\u4e2a\u5f00\u6e90\u5e93\uff08Julia\u548cPython\u7248\u672c\uff09\uff0c\u96c6\u4e2d\u5b9e\u73b0\u4e86\u591a\u79cd\u5faa\u73af\u5355\u5143\u548c\u9ad8\u7ea7\u5faa\u73af\u67b6\u6784\uff0c\u63d0\u4f9b\u4e00\u81f4\u7684\u6846\u67b6\u6765\u6784\u5efa\u548c\u6269\u5c55RNN\u6a21\u578b\u3002", "result": "\u6210\u529f\u521b\u5efa\u4e86\u4e09\u4e2a\u6d3b\u8dc3\u7ef4\u62a4\u7684\u5f00\u6e90\u5e93\uff0c\u63d0\u4f9b\u4e86\u5185\u7f6e\u7684\u81ea\u5b9a\u4e49\u548c\u5b9e\u9a8c\u673a\u5236\uff0c\u6240\u6709\u5305\u5747\u5728GitHub\u4e0a\u4ee5MIT\u8bb8\u53ef\u8bc1\u63d0\u4f9b\u3002", "conclusion": "\u8fd9\u4e9b\u5e93\u4e3aRNN\u7814\u7a76\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4fc3\u8fdb\u4e86\u6a21\u578b\u7684\u53ef\u91cd\u590d\u6027\u548c\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2510.21267", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21267", "abs": "https://arxiv.org/abs/2510.21267", "authors": ["Junshu Sun", "Wanxing Chang", "Chenxue Yang", "Qingming Huang", "Shuhui Wang"], "title": "Relieving the Over-Aggregating Effect in Graph Transformers", "comment": "Accepted by NeurIPS 2025", "summary": "Graph attention has demonstrated superior performance in graph learning\ntasks. However, learning from global interactions can be challenging due to the\nlarge number of nodes. In this paper, we discover a new phenomenon termed\nover-aggregating. Over-aggregating arises when a large volume of messages is\naggregated into a single node with less discrimination, leading to the dilution\nof the key messages and potential information loss. To address this, we propose\nWideformer, a plug-and-play method for graph attention. Wideformer divides the\naggregation of all nodes into parallel processes and guides the model to focus\non specific subsets of these processes. The division can limit the input volume\nper aggregation, avoiding message dilution and reducing information loss. The\nguiding step sorts and weights the aggregation outputs, prioritizing the\ninformative messages. Evaluations show that Wideformer can effectively mitigate\nover-aggregating. As a result, the backbone methods can focus on the\ninformative messages, achieving superior performance compared to baseline\nmethods.", "AI": {"tldr": "Wideformer\u662f\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u56fe\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e76\u884c\u5904\u7406\u673a\u5236\u89e3\u51b3\u56fe\u6ce8\u610f\u529b\u4e2d\u7684\u8fc7\u5ea6\u805a\u5408\u95ee\u9898\uff0c\u907f\u514d\u5173\u952e\u4fe1\u606f\u88ab\u7a00\u91ca\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u56fe\u6ce8\u610f\u529b\u5728\u5168\u5c40\u4ea4\u4e92\u5b66\u4e60\u4e2d\u9762\u4e34\u8fc7\u5ea6\u805a\u5408\u95ee\u9898\uff0c\u5f53\u5927\u91cf\u8282\u70b9\u4fe1\u606f\u88ab\u805a\u5408\u5230\u5355\u4e2a\u8282\u70b9\u65f6\uff0c\u5173\u952e\u4fe1\u606f\u53ef\u80fd\u88ab\u7a00\u91ca\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\u3002", "method": "\u5c06\u8282\u70b9\u805a\u5408\u5212\u5206\u4e3a\u5e76\u884c\u8fc7\u7a0b\uff0c\u5f15\u5bfc\u6a21\u578b\u5173\u6ce8\u7279\u5b9a\u5b50\u96c6\uff0c\u9650\u5236\u6bcf\u6b21\u805a\u5408\u7684\u8f93\u5165\u91cf\uff0c\u5e76\u901a\u8fc7\u6392\u5e8f\u548c\u52a0\u6743\u673a\u5236\u4f18\u5148\u5904\u7406\u4fe1\u606f\u91cf\u5927\u7684\u805a\u5408\u8f93\u51fa\u3002", "result": "\u8bc4\u4f30\u8868\u660eWideformer\u80fd\u6709\u6548\u7f13\u89e3\u8fc7\u5ea6\u805a\u5408\u95ee\u9898\uff0c\u4f7f\u9aa8\u5e72\u65b9\u6cd5\u80fd\u591f\u4e13\u6ce8\u4e8e\u4fe1\u606f\u91cf\u5927\u7684\u6d88\u606f\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u66f4\u4f18\u6027\u80fd\u3002", "conclusion": "Wideformer\u901a\u8fc7\u5e76\u884c\u805a\u5408\u548c\u5f15\u5bfc\u673a\u5236\u6210\u529f\u89e3\u51b3\u4e86\u56fe\u6ce8\u610f\u529b\u4e2d\u7684\u8fc7\u5ea6\u805a\u5408\u95ee\u9898\uff0c\u4e3a\u56fe\u5b66\u4e60\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.21296", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21296", "abs": "https://arxiv.org/abs/2510.21296", "authors": ["Sukanya Patra", "Souhaib Ben Taieb"], "title": "An Evidence-Based Post-Hoc Adjustment Framework for Anomaly Detection Under Data Contamination", "comment": "Accepted in the Thirty-ninth Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2025)", "summary": "Unsupervised anomaly detection (AD) methods typically assume clean training\ndata, yet real-world datasets often contain undetected or mislabeled anomalies,\nleading to significant performance degradation. Existing solutions require\naccess to the training pipelines, data or prior knowledge of the proportions of\nanomalies in the data, limiting their real-world applicability. To address this\nchallenge, we propose EPHAD, a simple yet effective test-time adaptation\nframework that updates the outputs of AD models trained on contaminated\ndatasets using evidence gathered at test time. Our approach integrates the\nprior knowledge captured by the AD model trained on contaminated datasets with\nevidence derived from multimodal foundation models like Contrastive\nLanguage-Image Pre-training (CLIP), classical AD methods like the Latent\nOutlier Factor or domain-specific knowledge. We illustrate the intuition behind\nEPHAD using a synthetic toy example and validate its effectiveness through\ncomprehensive experiments across eight visual AD datasets, twenty-six tabular\nAD datasets, and a real-world industrial AD dataset. Additionally, we conduct\nan ablation study to analyse hyperparameter influence and robustness to varying\ncontamination levels, demonstrating the versatility and robustness of EPHAD\nacross diverse AD models and evidence pairs. To ensure reproducibility, our\ncode is publicly available at https://github.com/sukanyapatra1997/EPHAD.", "AI": {"tldr": "EPHAD\u662f\u4e00\u4e2a\u7b80\u5355\u6709\u6548\u7684\u6d4b\u8bd5\u65f6\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u8bad\u7ec3\u6570\u636e\u88ab\u6c61\u67d3\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u5408\u9884\u8bad\u7ec3AD\u6a21\u578b\u548c\u6765\u81ea\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7684\u8bc1\u636e\u6765\u66f4\u65b0\u6a21\u578b\u8f93\u51fa\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u6570\u636e\u96c6\u901a\u5e38\u5305\u542b\u672a\u88ab\u68c0\u6d4b\u5230\u6216\u9519\u8bef\u6807\u8bb0\u7684\u5f02\u5e38\uff0c\u5bfc\u81f4\u73b0\u6709\u65b9\u6cd5\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u800c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u9700\u8981\u8bbf\u95ee\u8bad\u7ec3\u7ba1\u9053\u3001\u6570\u636e\u6216\u5f02\u5e38\u6bd4\u4f8b\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faEPHAD\u6d4b\u8bd5\u65f6\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5728\u6c61\u67d3\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684AD\u6a21\u578b\u7684\u5148\u9a8c\u77e5\u8bc6\u4e0e\u6765\u81ea\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\uff08\u5982CLIP\uff09\u3001\u7ecf\u5178AD\u65b9\u6cd5\u6216\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u7684\u8bc1\u636e\u6765\u66f4\u65b0\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u57288\u4e2a\u89c6\u89c9AD\u6570\u636e\u96c6\u300126\u4e2a\u8868\u683cAD\u6570\u636e\u96c6\u548c1\u4e2a\u771f\u5b9e\u5de5\u4e1aAD\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u9a8c\u8bc1\u4e86EPHAD\u7684\u6709\u6548\u6027\uff0c\u6d88\u878d\u7814\u7a76\u5206\u6790\u4e86\u8d85\u53c2\u6570\u5f71\u54cd\u548c\u5bf9\u4e0d\u540c\u6c61\u67d3\u6c34\u5e73\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "EPHAD\u5c55\u793a\u4e86\u5728\u4e0d\u540cAD\u6a21\u578b\u548c\u8bc1\u636e\u5bf9\u4e2d\u7684\u591a\u529f\u80fd\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u89e3\u51b3\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.21303", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21303", "abs": "https://arxiv.org/abs/2510.21303", "authors": ["Prakhar Ganesh", "Hsiang Hsu", "Golnoosh Farnadi"], "title": "Data as a Lever: A Neighbouring Datasets Perspective on Predictive Multiplicity", "comment": null, "summary": "Multiplicity -- the existence of distinct models with comparable performance\n-- has received growing attention in recent years. While prior work has largely\nemphasized modelling choices, the critical role of data in shaping multiplicity\nhas been comparatively overlooked. In this work, we introduce a neighbouring\ndatasets framework to examine the most granular case: the impact of a\nsingle-data-point difference on multiplicity. Our analysis yields a seemingly\ncounterintuitive finding: neighbouring datasets with greater inter-class\ndistribution overlap exhibit lower multiplicity. This reversal of conventional\nexpectations arises from a shared Rashomon parameter, and we substantiate it\nwith rigorous proofs.\n  Building on this foundation, we extend our framework to two practical\ndomains: active learning and data imputation. For each, we establish natural\nextensions of the neighbouring datasets perspective, conduct the first\nsystematic study of multiplicity in existing algorithms, and finally, propose\nnovel multiplicity-aware methods, namely, multiplicity-aware data acquisition\nstrategies for active learning and multiplicity-aware data imputation\ntechniques.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u90bb\u63a5\u6570\u636e\u96c6\u6846\u67b6\u6765\u7814\u7a76\u6570\u636e\u5bf9\u6a21\u578b\u591a\u6837\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7c7b\u95f4\u5206\u5e03\u91cd\u53e0\u66f4\u5927\u7684\u90bb\u63a5\u6570\u636e\u96c6\u53cd\u800c\u8868\u73b0\u51fa\u66f4\u4f4e\u7684\u6a21\u578b\u591a\u6837\u6027\u3002\u57fa\u4e8e\u6b64\uff0c\u4f5c\u8005\u5c06\u6846\u67b6\u6269\u5c55\u5230\u4e3b\u52a8\u5b66\u4e60\u548c\u6570\u636e\u63d2\u8865\u4e24\u4e2a\u5b9e\u9645\u9886\u57df\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u591a\u6837\u6027\u611f\u77e5\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5efa\u6a21\u9009\u62e9\u5bf9\u6a21\u578b\u591a\u6837\u6027\u7684\u5f71\u54cd\uff0c\u800c\u6570\u636e\u5728\u5851\u9020\u591a\u6837\u6027\u65b9\u9762\u7684\u5173\u952e\u4f5c\u7528\u88ab\u76f8\u5bf9\u5ffd\u89c6\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u901a\u8fc7\u90bb\u63a5\u6570\u636e\u96c6\u6846\u67b6\u7814\u7a76\u5355\u4e2a\u6570\u636e\u70b9\u5dee\u5f02\u5bf9\u591a\u6837\u6027\u7684\u5f71\u54cd\u3002", "method": "\u5f15\u5165\u90bb\u63a5\u6570\u636e\u96c6\u6846\u67b6\u5206\u6790\u5355\u4e2a\u6570\u636e\u70b9\u5dee\u5f02\u5bf9\u6a21\u578b\u591a\u6837\u6027\u7684\u5f71\u54cd\uff1b\u5efa\u7acb\u5171\u4eabRashomon\u53c2\u6570\u7684\u7406\u8bba\u57fa\u7840\uff1b\u5c06\u6846\u67b6\u6269\u5c55\u5230\u4e3b\u52a8\u5b66\u4e60\u548c\u6570\u636e\u63d2\u8865\u9886\u57df\uff0c\u63d0\u51fa\u591a\u6837\u6027\u611f\u77e5\u7684\u6570\u636e\u83b7\u53d6\u7b56\u7565\u548c\u63d2\u8865\u6280\u672f\u3002", "result": "\u53d1\u73b0\u4e86\u4e00\u4e2a\u53cd\u76f4\u89c9\u7684\u7ed3\u679c\uff1a\u7c7b\u95f4\u5206\u5e03\u91cd\u53e0\u66f4\u5927\u7684\u90bb\u63a5\u6570\u636e\u96c6\u53cd\u800c\u8868\u73b0\u51fa\u66f4\u4f4e\u7684\u6a21\u578b\u591a\u6837\u6027\uff1b\u901a\u8fc7\u4e25\u683c\u8bc1\u660e\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u53d1\u73b0\uff1b\u5728\u4e3b\u52a8\u5b66\u4e60\u548c\u6570\u636e\u63d2\u8865\u9886\u57df\u5f00\u53d1\u4e86\u65b0\u7684\u591a\u6837\u6027\u611f\u77e5\u7b97\u6cd5\u3002", "conclusion": "\u6570\u636e\u5728\u6a21\u578b\u591a\u6837\u6027\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u7c7b\u95f4\u5206\u5e03\u91cd\u53e0\u53ef\u4ee5\u964d\u4f4e\u591a\u6837\u6027\uff1b\u63d0\u51fa\u7684\u90bb\u63a5\u6570\u636e\u96c6\u6846\u67b6\u4e3a\u7406\u89e3\u6570\u636e\u5bf9\u591a\u6837\u6027\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff1b\u591a\u6837\u6027\u611f\u77e5\u65b9\u6cd5\u5728\u4e3b\u52a8\u5b66\u4e60\u548c\u6570\u636e\u63d2\u8865\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.21312", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21312", "abs": "https://arxiv.org/abs/2510.21312", "authors": ["Dhruv Sarkar", "Nishant Pandey", "Sayak Ray Chowdhury"], "title": "Revisiting Social Welfare in Bandits: UCB is (Nearly) All You Need", "comment": null, "summary": "Regret in stochastic multi-armed bandits traditionally measures the\ndifference between the highest reward and either the arithmetic mean of\naccumulated rewards or the final reward. These conventional metrics often fail\nto address fairness among agents receiving rewards, particularly in settings\nwhere rewards are distributed across a population, such as patients in clinical\ntrials. To address this, a recent body of work has introduced Nash regret,\nwhich evaluates performance via the geometric mean of accumulated rewards,\naligning with the Nash social welfare function known for satisfying fairness\naxioms.\n  To minimize Nash regret, existing approaches require specialized algorithm\ndesigns and strong assumptions, such as multiplicative concentration\ninequalities and bounded, non-negative rewards, making them unsuitable for even\nGaussian reward distributions. We demonstrate that an initial uniform\nexploration phase followed by a standard Upper Confidence Bound (UCB) algorithm\nachieves near-optimal Nash regret, while relying only on additive Hoeffding\nbounds, and naturally extending to sub-Gaussian rewards. Furthermore, we\ngeneralize the algorithm to a broad class of fairness metrics called the\n$p$-mean regret, proving (nearly) optimal regret bounds uniformly across all\n$p$ values. This is in contrast to prior work, which made extremely restrictive\nassumptions on the bandit instances and even then achieved suboptimal regret\nbounds.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u521d\u59cb\u5747\u5300\u63a2\u7d22\u9636\u6bb5\u540e\u63a5\u6807\u51c6UCB\u7b97\u6cd5\u6765\u6700\u5c0f\u5316Nash\u9057\u61be\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u52a0\u6027Hoeffding\u8fb9\u754c\uff0c\u53ef\u81ea\u7136\u6269\u5c55\u5230\u4e9a\u9ad8\u65af\u5956\u52b1\u5206\u5e03\uff0c\u5e76\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684p-\u5747\u503c\u9057\u61be\u516c\u5e73\u6027\u5ea6\u91cf\u3002", "motivation": "\u4f20\u7edf\u968f\u673a\u591a\u81c2\u8001\u864e\u673a\u4e2d\u7684\u9057\u61be\u5ea6\u91cf\u65e0\u6cd5\u89e3\u51b3\u5956\u52b1\u5206\u914d\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u4e34\u5e8a\u5b9e\u9a8c\u7b49\u9700\u8981\u8de8\u7fa4\u4f53\u5206\u914d\u5956\u52b1\u7684\u573a\u666f\u4e2d\u3002\u73b0\u6709\u7684Nash\u9057\u61be\u6700\u5c0f\u5316\u65b9\u6cd5\u9700\u8981\u4e13\u95e8\u7b97\u6cd5\u8bbe\u8ba1\u548c\u5f3a\u5047\u8bbe\u6761\u4ef6\u3002", "method": "\u91c7\u7528\u521d\u59cb\u5747\u5300\u63a2\u7d22\u9636\u6bb5\u540e\u63a5\u6807\u51c6\u4e0a\u7f6e\u4fe1\u754c(UCB)\u7b97\u6cd5\uff0c\u4ec5\u4f9d\u8d56\u52a0\u6027Hoeffding\u8fb9\u754c\uff0c\u53ef\u6269\u5c55\u5230\u4e9a\u9ad8\u65af\u5956\u52b1\u5206\u5e03\uff0c\u5e76\u63a8\u5e7f\u5230p-\u5747\u503c\u9057\u61be\u516c\u5e73\u6027\u5ea6\u91cf\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684Nash\u9057\u61be\uff0c\u76f8\u6bd4\u4e4b\u524d\u5de5\u4f5c\uff0c\u5728\u66f4\u5f31\u7684\u5047\u8bbe\u6761\u4ef6\u4e0b\u83b7\u5f97\u4e86\u66f4\u597d\u7684\u9057\u61be\u8fb9\u754c\uff0c\u4e14\u80fd\u7edf\u4e00\u9002\u7528\u4e8e\u6240\u6709p\u503c\u7684\u516c\u5e73\u6027\u5ea6\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6700\u5c0f\u5316\u516c\u5e73\u6027\u9057\u61be\u65b9\u9762\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u6709\u6548\uff0c\u65e0\u9700\u5f3a\u5047\u8bbe\u6761\u4ef6\uff0c\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u5956\u52b1\u5206\u5e03\u548c\u516c\u5e73\u6027\u5ea6\u91cf\u3002"}}
{"id": "2510.21330", "categories": ["cs.LG", "hep-lat", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.21330", "abs": "https://arxiv.org/abs/2510.21330", "authors": ["Vikas Kanaujia", "Vipul Arora"], "title": "SCORENF: Score-based Normalizing Flows for Sampling Unnormalized distributions", "comment": "\\c{opyright} 20XX IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Unnormalized probability distributions are central to modeling complex\nphysical systems across various scientific domains. Traditional sampling\nmethods, such as Markov Chain Monte Carlo (MCMC), often suffer from slow\nconvergence, critical slowing down, poor mode mixing, and high autocorrelation.\nIn contrast, likelihood-based and adversarial machine learning models, though\neffective, are heavily data-driven, requiring large datasets and often\nencountering mode covering and mode collapse. In this work, we propose ScoreNF,\na score-based learning framework built on the Normalizing Flow (NF)\narchitecture, integrated with an Independent Metropolis-Hastings (IMH) module,\nenabling efficient and unbiased sampling from unnormalized target\ndistributions. We show that ScoreNF maintains high performance even with small\ntraining ensembles, thereby reducing reliance on computationally expensive\nMCMC-generated training data. We also present a method for assessing\nmode-covering and mode-collapse behaviours. We validate our method on synthetic\n2D distributions (MOG-4 and MOG-8) and the high-dimensional $\\phi^4$ lattice\nfield theory distribution, demonstrating its effectiveness for sampling tasks.", "AI": {"tldr": "ScoreNF\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f52\u4e00\u5316\u6d41\u67b6\u6784\u7684\u5f97\u5206\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u72ec\u7acbMetropolis-Hastings\u6a21\u5757\uff0c\u80fd\u591f\u4ece\u975e\u5f52\u4e00\u5316\u76ee\u6807\u5206\u5e03\u4e2d\u8fdb\u884c\u9ad8\u6548\u65e0\u504f\u91c7\u6837\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfMCMC\u65b9\u6cd5\u6536\u655b\u6162\u3001\u6a21\u5f0f\u6df7\u5408\u5dee\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfMCMC\u91c7\u6837\u65b9\u6cd5\u5b58\u5728\u6536\u655b\u6162\u3001\u4e34\u754c\u51cf\u901f\u3001\u6a21\u5f0f\u6df7\u5408\u5dee\u548c\u9ad8\u81ea\u76f8\u5173\u7b49\u95ee\u9898\uff0c\u800c\u57fa\u4e8e\u4f3c\u7136\u548c\u5bf9\u6297\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9700\u8981\u5927\u91cf\u6570\u636e\u4e14\u5bb9\u6613\u51fa\u73b0\u6a21\u5f0f\u8986\u76d6\u548c\u6a21\u5f0f\u5d29\u6e83\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9ad8\u6548\u91c7\u6837\u975e\u5f52\u4e00\u5316\u6982\u7387\u5206\u5e03\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faScoreNF\u6846\u67b6\uff0c\u57fa\u4e8e\u5f52\u4e00\u5316\u6d41\u67b6\u6784\u6784\u5efa\u5f97\u5206\u5b66\u4e60\uff0c\u96c6\u6210\u72ec\u7acbMetropolis-Hastings\u6a21\u5757\uff0c\u80fd\u591f\u5728\u8bad\u7ec3\u96c6\u8f83\u5c0f\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u9ad8\u6027\u80fd\uff0c\u51cf\u5c11\u5bf9\u8ba1\u7b97\u6602\u8d35\u7684MCMC\u751f\u6210\u8bad\u7ec3\u6570\u636e\u7684\u4f9d\u8d56\u3002", "result": "\u5728\u5408\u62102D\u5206\u5e03\uff08MOG-4\u548cMOG-8\uff09\u548c\u9ad8\u7ef4\u03c6\u2074\u6676\u683c\u573a\u8bba\u5206\u5e03\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u91c7\u6837\u4efb\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "ScoreNF\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u65e0\u504f\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u975e\u5f52\u4e00\u5316\u6982\u7387\u5206\u5e03\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u91c7\u6837\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u79d1\u5b66\u8ba1\u7b97\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.21361", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21361", "abs": "https://arxiv.org/abs/2510.21361", "authors": ["Jaesik Yoon", "Hyeonseo Cho", "Sungjin Ahn"], "title": "Compositional Monte Carlo Tree Diffusion for Extendable Planning", "comment": "24 pages, 4 figures, NeurIPS 25 Spotlight", "summary": "Monte Carlo Tree Diffusion (MCTD) integrates diffusion models with structured\ntree search to enable effective trajectory exploration through stepwise\nreasoning. However, MCTD remains fundamentally limited by training trajectory\nlengths. While periodic replanning allows plan concatenation for longer plan\ngeneration, the planning process remains locally confined, as MCTD searches\nwithin individual trajectories without access to global context. We propose\nCompositional Monte Carlo Tree Diffusion (C-MCTD), a framework that elevates\nplanning from individual trajectory optimization to reasoning over complete\nplan compositions. C-MCTD introduces three complementary components: (1) Online\nComposer, which performs globally-aware planning by searching across entire\nplan compositions; (2) Distributed Composer, which reduces search complexity\nthrough parallel exploration from multiple starting points; and (3) Preplan\nComposer, which accelerates inference by leveraging cached plan graphs.", "AI": {"tldr": "C-MCTD\u901a\u8fc7\u5f15\u5165\u4e09\u4e2a\u7ec4\u4ef6\uff08\u5728\u7ebf\u7ec4\u5408\u5668\u3001\u5206\u5e03\u5f0f\u7ec4\u5408\u5668\u548c\u9884\u8ba1\u5212\u7ec4\u5408\u5668\uff09\u5c06\u89c4\u5212\u4ece\u5355\u4e2a\u8f68\u8ff9\u4f18\u5316\u63d0\u5347\u5230\u5b8c\u6574\u8ba1\u5212\u7ec4\u5408\u7684\u63a8\u7406\uff0c\u89e3\u51b3\u4e86MCTD\u5728\u8bad\u7ec3\u8f68\u8ff9\u957f\u5ea6\u548c\u5168\u5c40\u4e0a\u4e0b\u6587\u8bbf\u95ee\u65b9\u9762\u7684\u9650\u5236\u3002", "motivation": "MCTD\u5728\u8bad\u7ec3\u8f68\u8ff9\u957f\u5ea6\u4e0a\u5b58\u5728\u6839\u672c\u9650\u5236\uff0c\u4e14\u89c4\u5212\u8fc7\u7a0b\u5c40\u9650\u4e8e\u5c40\u90e8\uff0c\u65e0\u6cd5\u8bbf\u95ee\u5168\u5c40\u4e0a\u4e0b\u6587\u3002\u867d\u7136\u5468\u671f\u6027\u91cd\u65b0\u89c4\u5212\u5141\u8bb8\u8ba1\u5212\u8fde\u63a5\u4ee5\u751f\u6210\u957f\u8ba1\u5212\uff0c\u4f46\u641c\u7d22\u4ecd\u5c40\u9650\u4e8e\u5355\u4e2a\u8f68\u8ff9\u5185\u3002", "method": "C-MCTD\u5305\u542b\u4e09\u4e2a\u4e92\u8865\u7ec4\u4ef6\uff1a\u5728\u7ebf\u7ec4\u5408\u5668\u6267\u884c\u5168\u5c40\u611f\u77e5\u89c4\u5212\uff0c\u5728\u6574\u4e2a\u8ba1\u5212\u7ec4\u5408\u4e0a\u8fdb\u884c\u641c\u7d22\uff1b\u5206\u5e03\u5f0f\u7ec4\u5408\u5668\u901a\u8fc7\u4ece\u591a\u4e2a\u8d77\u70b9\u5e76\u884c\u63a2\u7d22\u6765\u964d\u4f4e\u641c\u7d22\u590d\u6742\u5ea6\uff1b\u9884\u8ba1\u5212\u7ec4\u5408\u5668\u901a\u8fc7\u5229\u7528\u7f13\u5b58\u7684\u8ba1\u5212\u56fe\u6765\u52a0\u901f\u63a8\u7406\u3002", "result": "\u8be5\u65b9\u6cd5\u5c06\u89c4\u5212\u4ece\u4e2a\u4f53\u8f68\u8ff9\u4f18\u5316\u63d0\u5347\u5230\u5b8c\u6574\u8ba1\u5212\u7ec4\u5408\u7684\u63a8\u7406\uff0c\u5b9e\u73b0\u4e86\u5168\u5c40\u611f\u77e5\u7684\u89c4\u5212\u80fd\u529b\u3002", "conclusion": "C-MCTD\u6846\u67b6\u901a\u8fc7\u7ec4\u5408\u5f0f\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86MCTD\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u8f68\u8ff9\u63a2\u7d22\u548c\u89c4\u5212\u80fd\u529b\u3002"}}
{"id": "2510.21379", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21379", "abs": "https://arxiv.org/abs/2510.21379", "authors": ["Dong Bok Lee", "Aoxuan Silvia Zhang", "Byungjoo Kim", "Junhyeon Park", "Steven Adriaensen", "Juho Lee", "Sung Ju Hwang", "Hae Beom Lee"], "title": "Cost-Sensitive Freeze-thaw Bayesian Optimization for Efficient Hyperparameter Tuning", "comment": "Published at NeurIPS 2025", "summary": "In this paper, we address the problem of \\emph{cost-sensitive} hyperparameter\noptimization (HPO) built upon freeze-thaw Bayesian optimization (BO).\nSpecifically, we assume a scenario where users want to early-stop the HPO\nprocess when the expected performance improvement is not satisfactory with\nrespect to the additional computational cost. Motivated by this scenario, we\nintroduce \\emph{utility} in the freeze-thaw framework, a function describing\nthe trade-off between the cost and performance that can be estimated from the\nuser's preference data. This utility function, combined with our novel\nacquisition function and stopping criterion, allows us to dynamically continue\ntraining the configuration that we expect to maximally improve the utility in\nthe future, and also automatically stop the HPO process around the maximum\nutility. Further, we improve the sample efficiency of existing freeze-thaw\nmethods with transfer learning to develop a specialized surrogate model for the\ncost-sensitive HPO problem. We validate our algorithm on established\nmulti-fidelity HPO benchmarks and show that it outperforms all the previous\nfreeze-thaw BO and transfer-BO baselines we consider, while achieving a\nsignificantly better trade-off between the cost and performance. Our code is\npublicly available at https://github.com/db-Lee/CFBO.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51bb\u7ed3-\u89e3\u51bb\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u6210\u672c\u654f\u611f\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u6548\u7528\u51fd\u6570\u3001\u65b0\u9896\u7684\u91c7\u96c6\u51fd\u6570\u548c\u505c\u6b62\u51c6\u5219\uff0c\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u5b9e\u73b0\u66f4\u597d\u7684\u6743\u8861\u3002", "motivation": "\u89e3\u51b3\u7528\u6237\u5e0c\u671b\u5728\u9884\u671f\u6027\u80fd\u6539\u8fdb\u4e0d\u4ee4\u4eba\u6ee1\u610f\u65f6\u80fd\u591f\u63d0\u524d\u505c\u6b62\u8d85\u53c2\u6570\u4f18\u5316\u8fc7\u7a0b\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u8003\u8651\u989d\u5916\u8ba1\u7b97\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u5728\u51bb\u7ed3-\u89e3\u51bb\u6846\u67b6\u4e2d\u5f15\u5165\u6548\u7528\u51fd\u6570\u63cf\u8ff0\u6210\u672c\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u7ed3\u5408\u65b0\u7684\u91c7\u96c6\u51fd\u6570\u548c\u505c\u6b62\u51c6\u5219\uff0c\u52a8\u6001\u9009\u62e9\u6700\u6709\u6f5c\u529b\u7684\u914d\u7f6e\u7ee7\u7eed\u8bad\u7ec3\uff0c\u5e76\u81ea\u52a8\u5728\u6700\u5927\u6548\u7528\u9644\u8fd1\u505c\u6b62\u4f18\u5316\u8fc7\u7a0b\u3002\u540c\u65f6\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3002", "result": "\u5728\u5df2\u5efa\u7acb\u7684\u591a\u4fdd\u771f\u5ea6\u8d85\u53c2\u6570\u4f18\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u6240\u6709\u5148\u524d\u8003\u8651\u7684\u51bb\u7ed3-\u89e3\u51bb\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u8fc1\u79fb\u8d1d\u53f6\u65af\u4f18\u5316\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u6210\u672c\u4e0e\u6027\u80fd\u4e4b\u95f4\u663e\u8457\u66f4\u597d\u7684\u6743\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684\u6210\u672c\u654f\u611f\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e73\u8861\u8ba1\u7b97\u6210\u672c\u548c\u6a21\u578b\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8d85\u53c2\u6570\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.21448", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21448", "abs": "https://arxiv.org/abs/2510.21448", "authors": ["Zhuojing Tian", "Yushu Chen"], "title": "Unified token representations for sequential decision models", "comment": null, "summary": "Transformers have demonstrated strong potential in offline reinforcement\nlearning (RL) by modeling trajectories as sequences of return-to-go, states,\nand actions. However, existing approaches such as the Decision Transformer(DT)\nand its variants suffer from redundant tokenization and quadratic attention\ncomplexity, limiting their scalability in real-time or resource-constrained\nsettings. To address this, we propose a Unified Token Representation (UTR) that\nmerges return-to-go, state, and action into a single token, substantially\nreducing sequence length and model complexity. Theoretical analysis shows that\nUTR leads to a tighter Rademacher complexity bound, suggesting improved\ngeneralization. We further develop two variants: UDT and UDC, built upon\ntransformer and gated CNN backbones, respectively. Both achieve comparable or\nsuperior performance to state-of-the-art methods with markedly lower\ncomputation. These findings demonstrate that UTR generalizes well across\narchitectures and may provide an efficient foundation for scalable control in\nfuture large decision models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7edf\u4e00\u4ee4\u724c\u8868\u793a(UTR)\u65b9\u6cd5\uff0c\u5c06\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u56de\u62a5\u76ee\u6807\u3001\u72b6\u6001\u548c\u52a8\u4f5c\u5408\u5e76\u4e3a\u5355\u4e2a\u4ee4\u724c\uff0c\u663e\u8457\u51cf\u5c11\u5e8f\u5217\u957f\u5ea6\u548c\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5982\u51b3\u7b56\u53d8\u6362\u5668(DT)\u53ca\u5176\u53d8\u4f53\u5b58\u5728\u4ee4\u724c\u5197\u4f59\u548c\u4e8c\u6b21\u6ce8\u610f\u529b\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5728\u5b9e\u65f6\u6216\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51faUTR\u65b9\u6cd5\u5408\u5e76\u56de\u62a5\u76ee\u6807\u3001\u72b6\u6001\u548c\u52a8\u4f5c\u4e3a\u5355\u4e00\u4ee4\u724c\uff0c\u5e76\u57fa\u4e8e\u53d8\u6362\u5668\u548c\u95e8\u63a7CNN\u5206\u522b\u5f00\u53d1UDT\u548cUDC\u4e24\u4e2a\u53d8\u4f53\u3002", "result": "UTR\u65b9\u6cd5\u5728\u4fdd\u6301\u6216\u8d85\u8d8a\u6700\u5148\u8fdb\u65b9\u6cd5\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u7406\u8bba\u5206\u6790\u663e\u793a\u5176\u5177\u6709\u66f4\u7d27\u7684Rademacher\u590d\u6742\u5ea6\u8fb9\u754c\u3002", "conclusion": "UTR\u65b9\u6cd5\u5728\u4e0d\u540c\u67b6\u6784\u4e0a\u6cdb\u5316\u826f\u597d\uff0c\u4e3a\u672a\u6765\u5927\u89c4\u6a21\u51b3\u7b56\u6a21\u578b\u7684\u53ef\u6269\u5c55\u63a7\u5236\u63d0\u4f9b\u4e86\u9ad8\u6548\u57fa\u7840\u3002"}}
{"id": "2510.21455", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21455", "abs": "https://arxiv.org/abs/2510.21455", "authors": ["Jorge D\u00edez", "Pablo P\u00e9rez-N\u00fa\u00f1ez", "Oscar Luaces", "Beatriz Remeseiro", "Antonio Bahamonde"], "title": "Towards Explainable Personalized Recommendations by Learning from Users' Photos", "comment": null, "summary": "Explaining the output of a complex system, such as a Recommender System (RS),\nis becoming of utmost importance for both users and companies. In this paper we\nexplore the idea that personalized explanations can be learned as\nrecommendation themselves. There are plenty of online services where users can\nupload some photos, in addition to rating items. We assume that users take\nthese photos to reinforce or justify their opinions about the items. For this\nreason we try to predict what photo a user would take of an item, because that\nimage is the argument that can best convince her of the qualities of the item.\nIn this sense, an RS can explain its results and, therefore, increase its\nreliability. Furthermore, once we have a model to predict attractive images for\nusers, we can estimate their distribution. Thus, the companies acquire a vivid\nknowledge about the aspects that the clients highlight of their products. The\npaper includes a formal framework that estimates the authorship probability for\na given pair (user, photo). To illustrate the proposal, we use data gathered\nfrom TripAdvisor containing the reviews (with photos) of restaurants in six\ncities of different sizes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u4e2a\u6027\u5316\u89e3\u91ca\u4f5c\u4e3a\u63a8\u8350\u672c\u8eab\u6765\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u6d4b\u7528\u6237\u4f1a\u4e3a\u7269\u54c1\u62cd\u6444\u4ec0\u4e48\u7167\u7247\u6765\u751f\u6210\u6709\u8bf4\u670d\u529b\u7684\u63a8\u8350\u89e3\u91ca\uff0c\u4ece\u800c\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u91ca\u590d\u6742\u7cfb\u7edf\uff08\u5982\u63a8\u8350\u7cfb\u7edf\uff09\u7684\u8f93\u51fa\u5bf9\u7528\u6237\u548c\u516c\u53f8\u90fd\u81f3\u5173\u91cd\u8981\u3002\u7528\u6237\u4e0a\u4f20\u7684\u7167\u7247\u53ef\u4ee5\u5f3a\u5316\u6216\u8bc1\u660e\u4ed6\u4eec\u5bf9\u7269\u54c1\u7684\u8bc4\u4ef7\uff0c\u56e0\u6b64\u9884\u6d4b\u7528\u6237\u4f1a\u4e3a\u7269\u54c1\u62cd\u6444\u4ec0\u4e48\u7167\u7247\u53ef\u4ee5\u4f5c\u4e3a\u6700\u6709\u8bf4\u670d\u529b\u7684\u63a8\u8350\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6b63\u5f0f\u6846\u67b6\u6765\u4f30\u8ba1\u7ed9\u5b9a\uff08\u7528\u6237\uff0c\u7167\u7247\uff09\u5bf9\u7684\u4f5c\u8005\u6982\u7387\u3002\u4f7f\u7528TripAdvisor\u6536\u96c6\u7684\u9910\u5385\u8bc4\u8bba\uff08\u5305\u542b\u7167\u7247\uff09\u6570\u636e\u6765\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u6db5\u76d6\u516d\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684\u57ce\u5e02\u3002", "result": "\u901a\u8fc7\u9884\u6d4b\u7528\u6237\u53ef\u80fd\u62cd\u6444\u7684\u7167\u7247\uff0c\u63a8\u8350\u7cfb\u7edf\u80fd\u591f\u4e3a\u5176\u7ed3\u679c\u63d0\u4f9b\u6709\u8bf4\u670d\u529b\u7684\u89e3\u91ca\uff0c\u4ece\u800c\u589e\u52a0\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002\u540c\u65f6\uff0c\u516c\u53f8\u53ef\u4ee5\u83b7\u5f97\u5173\u4e8e\u5ba2\u6237\u5f3a\u8c03\u4ea7\u54c1\u65b9\u9762\u7684\u751f\u52a8\u77e5\u8bc6\u3002", "conclusion": "\u5c06\u4e2a\u6027\u5316\u89e3\u91ca\u4f5c\u4e3a\u63a8\u8350\u672c\u8eab\u5b66\u4e60\u662f\u53ef\u884c\u7684\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\uff0c\u8fd8\u80fd\u4e3a\u4f01\u4e1a\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u5ba2\u6237\u6d1e\u5bdf\u3002"}}
{"id": "2510.21506", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21506", "abs": "https://arxiv.org/abs/2510.21506", "authors": ["Tanmay Devale", "Pramith Devulapalli", "Steve Hanneke"], "title": "Uniform Convergence Beyond Glivenko-Cantelli", "comment": null, "summary": "We characterize conditions under which collections of distributions on\n$\\{0,1\\}^\\mathbb{N}$ admit uniform estimation of their mean. Prior work from\nVapnik and Chervonenkis (1971) has focused on uniform convergence using the\nempirical mean estimator, leading to the principle known as $P-$\nGlivenko-Cantelli. We extend this framework by moving beyond the empirical mean\nestimator and introducing Uniform Mean Estimability, also called $UME-$\nlearnability, which captures when a collection permits uniform mean estimation\nby any arbitrary estimator. We work on the space created by the mean vectors of\nthe collection of distributions. For each distribution, the mean vector records\nthe expected value in each coordinate. We show that separability of the mean\nvectors is a sufficient condition for $UME-$ learnability. However, we show\nthat separability of the mean vectors is not necessary for $UME-$ learnability\nby constructing a collection of distributions whose mean vectors are\nnon-separable yet $UME-$ learnable using techniques fundamentally different\nfrom those used in our separability-based analysis. Finally, we establish that\ncountable unions of $UME-$ learnable collections are also $UME-$ learnable,\nsolving a conjecture posed in Cohen et al. (2025).", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Vapnik\u548cChervonenkis\u7684\u7ecf\u5178\u6846\u67b6\uff0c\u5f15\u5165\u4e86Uniform Mean Estimability\uff08UME-learnability\uff09\u6982\u5ff5\uff0c\u7814\u7a76\u5206\u5e03\u96c6\u5408\u5728\u4efb\u610f\u4f30\u8ba1\u5668\u4e0b\u7684\u5747\u5300\u5747\u503c\u4f30\u8ba1\u80fd\u529b\u3002\u8bc1\u660e\u4e86\u5747\u503c\u5411\u91cf\u53ef\u5206\u6027\u662fUME-learnability\u7684\u5145\u5206\u6761\u4ef6\uff0c\u4f46\u975e\u5fc5\u8981\u6761\u4ef6\uff0c\u5e76\u89e3\u51b3\u4e86Cohen\u7b49\u4eba\u7684\u731c\u60f3\u3002", "motivation": "\u4f20\u7edfVapnik-Chervonenkis\u7406\u8bba\u4e3b\u8981\u5173\u6ce8\u7ecf\u9a8c\u5747\u503c\u4f30\u8ba1\u5668\u7684\u5747\u5300\u6536\u655b\u6027\uff08P-Glivenko-Cantelli\u539f\u5219\uff09\u3002\u672c\u6587\u65e8\u5728\u8d85\u8d8a\u7ecf\u9a8c\u5747\u503c\u4f30\u8ba1\u5668\uff0c\u7814\u7a76\u5206\u5e03\u96c6\u5408\u662f\u5426\u5141\u8bb8\u901a\u8fc7\u4efb\u610f\u4f30\u8ba1\u5668\u8fdb\u884c\u5747\u5300\u5747\u503c\u4f30\u8ba1\u3002", "method": "\u5728\u5206\u5e03\u96c6\u5408\u7684\u5747\u503c\u5411\u91cf\u7a7a\u95f4\u4e0a\u5de5\u4f5c\uff0c\u5206\u6790\u5747\u503c\u5411\u91cf\u7684\u53ef\u5206\u6027\u6761\u4ef6\u3002\u901a\u8fc7\u6784\u9020\u975e\u53ef\u5206\u4f46UME-learnable\u7684\u5206\u5e03\u96c6\u5408\uff0c\u5c55\u793a\u4e86\u4e0e\u53ef\u5206\u6027\u5206\u6790\u4e0d\u540c\u7684\u6280\u672f\u65b9\u6cd5\u3002", "result": "1\uff09\u5747\u503c\u5411\u91cf\u53ef\u5206\u6027\u662fUME-learnability\u7684\u5145\u5206\u6761\u4ef6\uff1b2\uff09\u5747\u503c\u5411\u91cf\u53ef\u5206\u6027\u4e0d\u662fUME-learnability\u7684\u5fc5\u8981\u6761\u4ef6\uff1b3\uff09UME-learnable\u96c6\u5408\u7684\u53ef\u6570\u5e76\u96c6\u4e5f\u662fUME-learnable\u7684\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86Uniform Mean Estimability\u7684\u5b8c\u6574\u7406\u8bba\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u7ecf\u5178\u5b66\u4e60\u7406\u8bba\uff0c\u8bc1\u660e\u4e86\u53ef\u5206\u6027\u6761\u4ef6\u4e0eUME-learnability\u7684\u5173\u7cfb\uff0c\u5e76\u89e3\u51b3\u4e86\u76f8\u5173\u731c\u60f3\u3002"}}
{"id": "2510.21531", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21531", "abs": "https://arxiv.org/abs/2510.21531", "authors": ["Jan Wehner", "Mario Fritz"], "title": "Probe-based Fine-tuning for Reducing Toxicity", "comment": null, "summary": "Probes trained on model activations can detect undesirable behaviors like\ndeception or biases that are difficult to identify from outputs alone. This\nmakes them useful detectors to identify misbehavior. Furthermore, they are also\nvaluable training signals, since they not only reward outputs, but also good\ninternal processes for arriving at that output. However, training against\ninterpretability tools raises a fundamental concern: when a monitor becomes a\ntraining target, it may cease to be reliable (Goodhart's Law). We propose two\nmethods for training against probes based on Supervised Fine-tuning and Direct\nPreference Optimization. We conduct an initial exploration of these methods in\na testbed for reducing toxicity and evaluate the amount by which probe accuracy\ndrops when training against them. To retain the accuracy of probe-detectors\nafter training, we attempt (1) to train against an ensemble of probes, (2)\nretain held-out probes that aren't used for training, and (3) retrain new\nprobes after training.\n  First, probe-based preference optimization unexpectedly preserves probe\ndetectability better than classifier-based methods, suggesting the preference\nlearning objective incentivizes maintaining rather than obfuscating relevant\nrepresentations. Second, probe diversity provides minimal practical benefit -\nsimply retraining probes after optimization recovers high detection accuracy.\nOur findings suggest probe-based training can be viable for certain alignment\nmethods, though probe ensembles are largely unnecessary when retraining is\nfeasible.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u63a2\u9488\u68c0\u6d4b\u5668\u65f6\u5982\u4f55\u907f\u514dGoodhart\u5b9a\u5f8b\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u76d1\u7763\u5fae\u8c03\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u5728\u504f\u597d\u5b66\u4e60\u76ee\u6807\u4e0b\u63a2\u9488\u68c0\u6d4b\u80fd\u529b\u5f97\u5230\u66f4\u597d\u4fdd\u6301\uff0c\u4e14\u91cd\u65b0\u8bad\u7ec3\u63a2\u9488\u6bd4\u4f7f\u7528\u63a2\u9488\u96c6\u6210\u66f4\u6709\u6548\u3002", "motivation": "\u63a2\u9488\u53ef\u7528\u4e8e\u68c0\u6d4b\u6a21\u578b\u5185\u90e8\u7684\u4e0d\u826f\u884c\u4e3a\uff0c\u5982\u6b3a\u9a97\u6216\u504f\u89c1\uff0c\u4f46\u5c06\u63a2\u9488\u4f5c\u4e3a\u8bad\u7ec3\u76ee\u6807\u53ef\u80fd\u5bfc\u81f4\u5176\u53ef\u9760\u6027\u4e0b\u964d\uff08Goodhart\u5b9a\u5f8b\uff09\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u5728\u8bad\u7ec3\u4e2d\u4fdd\u6301\u63a2\u9488\u7684\u68c0\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u76d1\u7763\u5fae\u8c03\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5728\u6bd2\u6027\u51cf\u5c11\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u8bad\u7ec3\u540e\u63a2\u9488\u51c6\u786e\u6027\u7684\u4e0b\u964d\u7a0b\u5ea6\uff0c\u5e76\u5c1d\u8bd5\u4f7f\u7528\u63a2\u9488\u96c6\u6210\u3001\u4fdd\u7559\u672a\u8bad\u7ec3\u63a2\u9488\u548c\u8bad\u7ec3\u540e\u91cd\u65b0\u8bad\u7ec3\u63a2\u9488\u4e09\u79cd\u7b56\u7565\u3002", "result": "\u57fa\u4e8e\u63a2\u9488\u7684\u504f\u597d\u4f18\u5316\u6bd4\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u65b9\u6cd5\u66f4\u597d\u5730\u4fdd\u6301\u4e86\u63a2\u9488\u68c0\u6d4b\u80fd\u529b\uff0c\u504f\u597d\u5b66\u4e60\u76ee\u6807\u6fc0\u52b1\u6a21\u578b\u4fdd\u6301\u800c\u975e\u6a21\u7cca\u76f8\u5173\u8868\u793a\uff1b\u63a2\u9488\u591a\u6837\u6027\u5e26\u6765\u7684\u5b9e\u9645\u76ca\u5904\u6709\u9650\uff0c\u8bad\u7ec3\u540e\u91cd\u65b0\u8bad\u7ec3\u63a2\u9488\u5373\u53ef\u6062\u590d\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u3002", "conclusion": "\u57fa\u4e8e\u63a2\u9488\u7684\u8bad\u7ec3\u5bf9\u4e8e\u67d0\u4e9b\u5bf9\u9f50\u65b9\u6cd5\u662f\u53ef\u884c\u7684\uff0c\u5f53\u91cd\u65b0\u8bad\u7ec3\u53ef\u884c\u65f6\uff0c\u63a2\u9488\u96c6\u6210\u57fa\u672c\u4e0a\u662f\u4e0d\u5fc5\u8981\u7684\u3002"}}
{"id": "2510.21532", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21532", "abs": "https://arxiv.org/abs/2510.21532", "authors": ["Mojtaba Nafez", "Mobina Poulaei", "Nikan Vasei", "Bardia Soltani Moakhar", "Mohammad Sabokrou", "MohammadHossein Rohban"], "title": "FrameShield: Adversarially Robust Video Anomaly Detection", "comment": "28 page, 5 figures", "summary": "Weakly Supervised Video Anomaly Detection (WSVAD) has achieved notable\nadvancements, yet existing models remain vulnerable to adversarial attacks,\nlimiting their reliability. Due to the inherent constraints of weak\nsupervision, where only video-level labels are provided despite the need for\nframe-level predictions, traditional adversarial defense mechanisms, such as\nadversarial training, are not effective since video-level adversarial\nperturbations are typically weak and inadequate. To address this limitation,\npseudo-labels generated directly from the model can enable frame-level\nadversarial training; however, these pseudo-labels are inherently noisy,\nsignificantly degrading performance. We therefore introduce a novel\nPseudo-Anomaly Generation method called Spatiotemporal Region Distortion (SRD),\nwhich creates synthetic anomalies by applying severe augmentations to localized\nregions in normal videos while preserving temporal consistency. Integrating\nthese precisely annotated synthetic anomalies with the noisy pseudo-labels\nsubstantially reduces label noise, enabling effective adversarial training.\nExtensive experiments demonstrate that our method significantly enhances the\nrobustness of WSVAD models against adversarial attacks, outperforming\nstate-of-the-art methods by an average of 71.0\\% in overall AUROC performance\nacross multiple benchmarks. The implementation and code are publicly available\nat https://github.com/rohban-lab/FrameShield.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u65f6\u7a7a\u533a\u57df\u626d\u66f2\uff08SRD\uff09\u7684\u4f2a\u5f02\u5e38\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6b63\u5e38\u89c6\u9891\u7684\u5c40\u90e8\u533a\u57df\u5e94\u7528\u4e25\u91cd\u589e\u5f3a\u6765\u521b\u5efa\u5408\u6210\u5f02\u5e38\uff0c\u540c\u65f6\u4fdd\u6301\u65f6\u95f4\u4e00\u81f4\u6027\u3002\u7ed3\u5408\u8fd9\u4e9b\u7cbe\u786e\u6807\u6ce8\u7684\u5408\u6210\u5f02\u5e38\u4e0e\u566a\u58f0\u4f2a\u6807\u7b7e\uff0c\u663e\u8457\u51cf\u5c11\u6807\u7b7e\u566a\u58f0\uff0c\u5b9e\u73b0\u6709\u6548\u7684\u5bf9\u6297\u8bad\u7ec3\u3002", "motivation": "\u5f31\u76d1\u7763\u89c6\u9891\u5f02\u5e38\u68c0\u6d4b\uff08WSVAD\uff09\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u653b\u51fb\uff0c\u4f46\u7531\u4e8e\u5f31\u76d1\u7763\u7684\u56fa\u6709\u7ea6\u675f\uff08\u4ec5\u63d0\u4f9b\u89c6\u9891\u7ea7\u6807\u7b7e\u4f46\u9700\u8981\u5e27\u7ea7\u9884\u6d4b\uff09\uff0c\u4f20\u7edf\u5bf9\u6297\u9632\u5fa1\u673a\u5236\u5982\u5bf9\u6297\u8bad\u7ec3\u6548\u679c\u4e0d\u4f73\u3002\u89c6\u9891\u7ea7\u5bf9\u6297\u6270\u52a8\u901a\u5e38\u8f83\u5f31\u4e14\u4e0d\u8db3\uff0c\u800c\u76f4\u63a5\u4f7f\u7528\u6a21\u578b\u751f\u6210\u7684\u4f2a\u6807\u7b7e\u8fdb\u884c\u5e27\u7ea7\u5bf9\u6297\u8bad\u7ec3\u4f1a\u56e0\u6807\u7b7e\u566a\u58f0\u663e\u8457\u964d\u4f4e\u6027\u80fd\u3002", "method": "\u5f15\u5165\u65f6\u7a7a\u533a\u57df\u626d\u66f2\uff08SRD\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6b63\u5e38\u89c6\u9891\u7684\u5c40\u90e8\u533a\u57df\u5e94\u7528\u4e25\u91cd\u589e\u5f3a\u6765\u521b\u5efa\u5408\u6210\u5f02\u5e38\uff0c\u540c\u65f6\u4fdd\u6301\u65f6\u95f4\u4e00\u81f4\u6027\u3002\u5c06\u8fd9\u4e9b\u7cbe\u786e\u6807\u6ce8\u7684\u5408\u6210\u5f02\u5e38\u4e0e\u566a\u58f0\u4f2a\u6807\u7b7e\u7ed3\u5408\uff0c\u663e\u8457\u51cf\u5c11\u6807\u7b7e\u566a\u58f0\uff0c\u5b9e\u73b0\u6709\u6548\u7684\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u589e\u5f3a\u4e86WSVAD\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6574\u4f53AUROC\u6027\u80fd\u5e73\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd571.0%\u3002", "conclusion": "\u63d0\u51fa\u7684SRD\u65b9\u6cd5\u901a\u8fc7\u751f\u6210\u7cbe\u786e\u6807\u6ce8\u7684\u5408\u6210\u5f02\u5e38\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f31\u76d1\u7763\u89c6\u9891\u5f02\u5e38\u68c0\u6d4b\u4e2d\u5bf9\u6297\u8bad\u7ec3\u7684\u6807\u7b7e\u566a\u58f0\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.21537", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21537", "abs": "https://arxiv.org/abs/2510.21537", "authors": ["Nikolai Gruzinov", "Ksenia Sycheva", "Earl T. Barr", "Alex Bezzubov"], "title": "Excision Score: Evaluating Edits with Surgical Precision", "comment": "Code is available at\n  https://anonymous.4open.science/r/excision-score-eval-B9AF/", "summary": "Many tasks revolve around editing a document, whether code or text. We\nformulate the revision similarity problem to unify a wide range of machine\nlearning evaluation problems whose goal is to assess a revision to an existing\ndocument. We observe that revisions usually change only a small portion of an\nexisting document, so the existing document and its immediate revisions share a\nmajority of their content. We formulate five adequacy criteria for revision\nsimilarity measures, designed to align them with human judgement. We show that\npopular pairwise measures, like BLEU, fail to meet these criteria, because\ntheir scores are dominated by the shared content. They report high similarity\nbetween two revisions when humans would assess them as quite different. This is\na fundamental flaw we address. We propose a novel static measure, Excision\nScore (ES), which computes longest common subsequence (LCS) to remove content\nshared by an existing document with the ground truth and predicted revisions,\nbefore comparing only the remaining divergent regions. This is analogous to a\nsurgeon creating a sterile field to focus on the work area. We use\napproximation to speed the standard cubic LCS computation to quadratic. In\ncode-editing evaluation, where static measures are often used as a cheap proxy\nfor passing tests, we demonstrate that ES surpasses existing measures. When\naligned with test execution on HumanEvalFix, ES improves over its nearest\ncompetitor, SARI, by 12% Pearson correlation and by >21% over standard measures\nlike BLEU. The key criterion is invariance to shared context; when we perturb\nHumanEvalFix with increased shared context, ES' improvement over SARI increases\nto 20% and >30% over standard measures. ES also handles other corner cases that\nother measures do not, such as correctly aligning moved code blocks, and\nappropriately rewarding matching insertions or deletions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4fee\u8ba2\u76f8\u4f3c\u6027\u95ee\u9898\uff0c\u5e76\u6307\u51fa\u4f20\u7edf\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\uff08\u5982BLEU\uff09\u56e0\u8fc7\u5206\u5173\u6ce8\u5171\u4eab\u5185\u5bb9\u800c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u6587\u6863\u4fee\u8ba2\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9759\u6001\u5ea6\u91cf\u65b9\u6cd5\u2014\u2014\u5207\u9664\u5206\u6570\uff08ES\uff09\uff0c\u901a\u8fc7\u79fb\u9664\u73b0\u6709\u6587\u6863\u4e0e\u4fee\u8ba2\u7248\u672c\u4e4b\u95f4\u7684\u5171\u4eab\u5185\u5bb9\uff0c\u4e13\u6ce8\u4e8e\u6bd4\u8f83\u5dee\u5f02\u533a\u57df\uff0c\u4ece\u800c\u66f4\u597d\u5730\u4e0e\u4eba\u7c7b\u5224\u65ad\u4fdd\u6301\u4e00\u81f4\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u6863\u4fee\u8ba2\u8bc4\u4f30\u65b9\u6cd5\uff08\u5982BLEU\uff09\u5b58\u5728\u6839\u672c\u6027\u7f3a\u9677\uff0c\u5b83\u4eec\u8fc7\u5206\u5173\u6ce8\u5171\u4eab\u5185\u5bb9\uff0c\u5bfc\u81f4\u5728\u4eba\u7c7b\u8ba4\u4e3a\u5dee\u5f02\u5f88\u5927\u7684\u4fee\u8ba2\u4e4b\u95f4\u4ecd\u62a5\u544a\u9ad8\u76f8\u4f3c\u6027\u3002\u8fd9\u4fc3\u4f7f\u4f5c\u8005\u5f00\u53d1\u4e00\u79cd\u80fd\u66f4\u597d\u53cd\u6620\u4eba\u7c7b\u5224\u65ad\u7684\u4fee\u8ba2\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5207\u9664\u5206\u6570\uff08ES\uff09\u65b9\u6cd5\uff0c\u4f7f\u7528\u6700\u957f\u516c\u5171\u5b50\u5e8f\u5217\uff08LCS\uff09\u6765\u8bc6\u522b\u5e76\u79fb\u9664\u73b0\u6709\u6587\u6863\u4e0e\u4fee\u8ba2\u7248\u672c\u4e4b\u95f4\u7684\u5171\u4eab\u5185\u5bb9\uff0c\u7136\u540e\u4ec5\u6bd4\u8f83\u5269\u4f59\u7684\u4e0d\u540c\u533a\u57df\u3002\u901a\u8fc7\u8fd1\u4f3c\u7b97\u6cd5\u5c06\u6807\u51c6\u7acb\u65b9LCS\u8ba1\u7b97\u52a0\u901f\u5230\u4e8c\u6b21\u590d\u6742\u5ea6\u3002", "result": "\u5728\u4ee3\u7801\u7f16\u8f91\u8bc4\u4f30\u4e2d\uff0cES\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5ea6\u91cf\u65b9\u6cd5\u3002\u5728HumanEvalFix\u6570\u636e\u96c6\u4e0a\uff0cES\u4e0e\u6d4b\u8bd5\u6267\u884c\u7684Pearson\u76f8\u5173\u6027\u6bd4\u6700\u63a5\u8fd1\u7684\u7ade\u4e89\u5bf9\u624bSARI\u63d0\u9ad8\u4e8612%\uff0c\u6bd4\u6807\u51c6\u5ea6\u91cf\u65b9\u6cd5\uff08\u5982BLEU\uff09\u63d0\u9ad8\u4e86\u8d85\u8fc721%\u3002\u5f53\u589e\u52a0\u5171\u4eab\u4e0a\u4e0b\u6587\u65f6\uff0cES\u7684\u6539\u8fdb\u8fdb\u4e00\u6b65\u589e\u52a0\u523020%\uff08\u76f8\u6bd4SARI\uff09\u548c\u8d85\u8fc730%\uff08\u76f8\u6bd4\u6807\u51c6\u5ea6\u91cf\uff09\u3002", "conclusion": "ES\u65b9\u6cd5\u901a\u8fc7\u4e13\u6ce8\u4e8e\u4fee\u8ba2\u4e2d\u7684\u5dee\u5f02\u533a\u57df\u800c\u975e\u5171\u4eab\u5185\u5bb9\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u6587\u6863\u4fee\u8ba2\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728\u4ee3\u7801\u7f16\u8f91\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u4fee\u8ba2\u76f8\u4f3c\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u5ea6\u91cf\u6807\u51c6\u3002"}}
{"id": "2510.21551", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21551", "abs": "https://arxiv.org/abs/2510.21551", "authors": ["Jialu Tang", "Hung Manh Pham", "Ignace De Lathauwer", "Henk S. Schipper", "Yuan Lu", "Dong Ma", "Aaqib Saeed"], "title": "Interpretable Multimodal Zero-Shot ECG Diagnosis via Structured Clinical Knowledge Alignment", "comment": null, "summary": "Electrocardiogram (ECG) interpretation is essential for cardiovascular\ndisease diagnosis, but current automated systems often struggle with\ntransparency and generalization to unseen conditions. To address this, we\nintroduce ZETA, a zero-shot multimodal framework designed for interpretable ECG\ndiagnosis aligned with clinical workflows. ZETA uniquely compares ECG signals\nagainst structured positive and negative clinical observations, which are\ncurated through an LLM-assisted, expert-validated process, thereby mimicking\ndifferential diagnosis. Our approach leverages a pre-trained multimodal model\nto align ECG and text embeddings without disease-specific fine-tuning.\nEmpirical evaluations demonstrate ZETA's competitive zero-shot classification\nperformance and, importantly, provide qualitative and quantitative evidence of\nenhanced interpretability, grounding predictions in specific, clinically\nrelevant positive and negative diagnostic features. ZETA underscores the\npotential of aligning ECG analysis with structured clinical knowledge for\nbuilding more transparent, generalizable, and trustworthy AI diagnostic\nsystems. We will release the curated observation dataset and code to facilitate\nfuture research.", "AI": {"tldr": "ZETA\u662f\u4e00\u4e2a\u96f6\u6837\u672c\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u89e3\u91ca\u7684\u5fc3\u7535\u56fe\u8bca\u65ad\uff0c\u901a\u8fc7\u5bf9\u6bd4ECG\u4fe1\u53f7\u4e0e\u7ed3\u6784\u5316\u4e34\u5e8a\u89c2\u5bdf\u6765\u6a21\u62df\u4e34\u5e8a\u9274\u522b\u8bca\u65ad\u6d41\u7a0b\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8ECG\u8bca\u65ad\u7cfb\u7edf\u5728\u900f\u660e\u6027\u548c\u6cdb\u5316\u5230\u672a\u89c1\u75c5\u75c7\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7b26\u5408\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u7684\u53ef\u89e3\u91caAI\u8bca\u65ad\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528LLM\u8f85\u52a9\u3001\u4e13\u5bb6\u9a8c\u8bc1\u7684\u8fc7\u7a0b\u6784\u5efa\u7ed3\u6784\u5316\u6b63\u8d1f\u4e34\u5e8a\u89c2\u5bdf\u6570\u636e\u96c6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u6a21\u578b\u5bf9\u9f50ECG\u548c\u6587\u672c\u5d4c\u5165\uff0c\u65e0\u9700\u75be\u75c5\u7279\u5b9a\u5fae\u8c03\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793aZETA\u5728\u96f6\u6837\u672c\u5206\u7c7b\u6027\u80fd\u4e0a\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u7684\u5b9a\u6027\u548c\u5b9a\u91cf\u8bc1\u636e\uff0c\u5c06\u9884\u6d4b\u57fa\u4e8e\u5177\u4f53\u7684\u4e34\u5e8a\u76f8\u5173\u8bca\u65ad\u7279\u5f81\u3002", "conclusion": "ZETA\u5c55\u793a\u4e86\u5c06ECG\u5206\u6790\u4e0e\u7ed3\u6784\u5316\u4e34\u5e8a\u77e5\u8bc6\u5bf9\u9f50\u7684\u6f5c\u529b\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u900f\u660e\u3001\u53ef\u6cdb\u5316\u548c\u53ef\u4fe1\u8d56\u7684AI\u8bca\u65ad\u7cfb\u7edf\u3002"}}
{"id": "2510.21585", "categories": ["cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.21585", "abs": "https://arxiv.org/abs/2510.21585", "authors": ["Yassine El Ouahidi", "Jonathan Lys", "Philipp Th\u00f6lke", "Nicolas Farrugia", "Bastien Pasdeloup", "Vincent Gripon", "Karim Jerbi", "Giulia Lioi"], "title": "REVE: A Foundation Model for EEG -- Adapting to Any Setup with Large-Scale Pretraining on 25,000 Subjects", "comment": "Code available at: https://brain-bzh.github.io/reve/", "summary": "Foundation models have transformed AI by reducing reliance on task-specific\ndata through large-scale pretraining. While successful in language and vision,\ntheir adoption in EEG has lagged due to the heterogeneity of public datasets,\nwhich are collected under varying protocols, devices, and electrode\nconfigurations. Existing EEG foundation models struggle to generalize across\nthese variations, often restricting pretraining to a single setup, resulting in\nsuboptimal performance, in particular under linear probing. We present REVE\n(Representation for EEG with Versatile Embeddings), a pretrained model\nexplicitly designed to generalize across diverse EEG signals. REVE introduces a\nnovel 4D positional encoding scheme that enables it to process signals of\narbitrary length and electrode arrangement. Using a masked autoencoding\nobjective, we pretrain REVE on over 60,000 hours of EEG data from 92 datasets\nspanning 25,000 subjects, representing the largest EEG pretraining effort to\ndate. REVE achieves state-of-the-art results on 10 downstream EEG tasks,\nincluding motor imagery classification, seizure detection, sleep staging,\ncognitive load estimation, and emotion recognition. With little to no\nfine-tuning, it demonstrates strong generalization, and nuanced spatio-temporal\nmodeling. We release code, pretrained weights, and tutorials to support\nstandardized EEG research and accelerate progress in clinical neuroscience.", "AI": {"tldr": "REVE\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u5904\u7406\u591a\u6837\u5316EEG\u4fe1\u53f7\u8bbe\u8ba1\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u901a\u8fc74D\u4f4d\u7f6e\u7f16\u7801\u65b9\u6848\u5904\u7406\u4efb\u610f\u957f\u5ea6\u548c\u7535\u6781\u6392\u5217\u7684\u4fe1\u53f7\uff0c\u572892\u4e2a\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u8d85\u8fc760,000\u5c0f\u65f6\uff0c\u572810\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u53d6\u5f97\u6700\u5148\u8fdb\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709EEG\u57fa\u7840\u6a21\u578b\u96be\u4ee5\u6cdb\u5316\u5230\u4e0d\u540c\u534f\u8bae\u3001\u8bbe\u5907\u548c\u7535\u6781\u914d\u7f6e\u7684\u5f02\u6784\u516c\u5171\u6570\u636e\u96c6\uff0c\u901a\u5e38\u9650\u5236\u5728\u5355\u4e00\u8bbe\u7f6e\u4e0b\u9884\u8bad\u7ec3\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u7ebf\u6027\u63a2\u6d4b\u65b9\u9762\u3002", "method": "\u5f15\u5165\u65b0\u9896\u76844D\u4f4d\u7f6e\u7f16\u7801\u65b9\u6848\uff0c\u4f7f\u7528\u63a9\u7801\u81ea\u7f16\u7801\u76ee\u6807\u572892\u4e2a\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u8d85\u8fc760,000\u5c0f\u65f6EEG\u6570\u636e\uff0c\u6db5\u76d625,000\u540d\u53d7\u8bd5\u8005\u3002", "result": "\u572810\u4e2a\u4e0b\u6e38EEG\u4efb\u52a1\u4e2d\u53d6\u5f97\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u5305\u62ec\u8fd0\u52a8\u60f3\u8c61\u5206\u7c7b\u3001\u766b\u75eb\u68c0\u6d4b\u3001\u7761\u7720\u5206\u671f\u3001\u8ba4\u77e5\u8d1f\u8377\u4f30\u8ba1\u548c\u60c5\u7eea\u8bc6\u522b\uff0c\u5c55\u793a\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u7cbe\u7ec6\u7684\u65f6\u7a7a\u5efa\u6a21\u80fd\u529b\u3002", "conclusion": "REVE\u652f\u6301\u6807\u51c6\u5316EEG\u7814\u7a76\u5e76\u52a0\u901f\u4e34\u5e8a\u795e\u7ecf\u79d1\u5b66\u8fdb\u5c55\uff0c\u901a\u8fc7\u53d1\u5e03\u4ee3\u7801\u3001\u9884\u8bad\u7ec3\u6743\u91cd\u548c\u6559\u7a0b\u4fc3\u8fdb\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2510.21592", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21592", "abs": "https://arxiv.org/abs/2510.21592", "authors": ["Lei Liu", "Zhenxin Huang", "Hong Wang", "huanshuo dong", "Haiyang Xin", "Hongwei Zhao", "Bin Li"], "title": "Accelerating Data Generation for Nonlinear temporal PDEs via homologous perturbation in solution space", "comment": null, "summary": "Data-driven deep learning methods like neural operators have advanced in\nsolving nonlinear temporal partial differential equations (PDEs). However,\nthese methods require large quantities of solution pairs\\u2014the solution\nfunctions and right-hand sides (RHS) of the equations. These pairs are\ntypically generated via traditional numerical methods, which need thousands of\ntime steps iterations far more than the dozens required for training, creating\nheavy computational and temporal overheads. To address these challenges, we\npropose a novel data generation algorithm, called HOmologous Perturbation in\nSolution Space (HOPSS), which directly generates training datasets with fewer\ntime steps rather than following the traditional approach of generating large\ntime steps datasets. This algorithm simultaneously accelerates dataset\ngeneration and preserves the approximate precision required for model training.\nSpecifically, we first obtain a set of base solution functions from a reliable\nsolver, usually with thousands of time steps, and then align them in time steps\nwith training datasets by downsampling. Subsequently, we propose a \"homologous\nperturbation\" approach: by combining two solution functions (one as the primary\nfunction, the other as a homologous perturbation term scaled by a small scalar)\nwith random noise, we efficiently generate comparable-precision PDE data\npoints. Finally, using these data points, we compute the variation in the\noriginal equation's RHS to form new solution pairs. Theoretical and\nexperimental results show HOPSS lowers time complexity. For example, on the\nNavier-Stokes equation, it generates 10,000 samples in approximately 10% of\ntraditional methods' time, with comparable model training performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHOPSS\u7684\u65b0\u6570\u636e\u751f\u6210\u7b97\u6cd5\uff0c\u901a\u8fc7\u540c\u6e90\u6270\u52a8\u65b9\u6cd5\u76f4\u63a5\u751f\u6210\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u663e\u8457\u51cf\u5c11\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u751f\u6210\u6570\u636e\u6240\u9700\u7684\u65f6\u95f4\u6b65\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8bad\u7ec3\u6240\u9700\u7684\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u9a71\u52a8\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u89e3\u51fd\u6570\u5bf9\uff0c\u8fd9\u4e9b\u6570\u636e\u901a\u5e38\u901a\u8fc7\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u751f\u6210\uff0c\u9700\u8981\u6570\u5343\u4e2a\u65f6\u95f4\u6b65\u8fed\u4ee3\uff0c\u8fdc\u591a\u4e8e\u8bad\u7ec3\u6240\u9700\u7684\u51e0\u5341\u4e2a\u65f6\u95f4\u6b65\uff0c\u9020\u6210\u6c89\u91cd\u7684\u8ba1\u7b97\u548c\u65f6\u95f4\u5f00\u9500\u3002", "method": "\u9996\u5148\u4ece\u53ef\u9760\u6c42\u89e3\u5668\u83b7\u53d6\u57fa\u7840\u89e3\u51fd\u6570\u96c6\uff0c\u901a\u8fc7\u4e0b\u91c7\u6837\u4e0e\u8bad\u7ec3\u6570\u636e\u96c6\u5bf9\u9f50\u65f6\u95f4\u6b65\uff1b\u7136\u540e\u63d0\u51fa\"\u540c\u6e90\u6270\u52a8\"\u65b9\u6cd5\uff1a\u5c06\u4e24\u4e2a\u89e3\u51fd\u6570\uff08\u4e00\u4e2a\u4f5c\u4e3a\u4e3b\u51fd\u6570\uff0c\u53e6\u4e00\u4e2a\u4f5c\u4e3a\u540c\u6e90\u6270\u52a8\u9879\uff09\u4e0e\u968f\u673a\u566a\u58f0\u7ed3\u5408\uff0c\u9ad8\u6548\u751f\u6210\u7cbe\u5ea6\u76f8\u5f53\u7684PDE\u6570\u636e\u70b9\uff1b\u6700\u540e\u7528\u8fd9\u4e9b\u6570\u636e\u70b9\u8ba1\u7b97\u539f\u59cb\u65b9\u7a0b\u53f3\u7aef\u9879\u7684\u53d8\u5316\u5f62\u6210\u65b0\u7684\u89e3\u5bf9\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eHOPSS\u964d\u4f4e\u4e86\u65f6\u95f4\u590d\u6742\u5ea6\u3002\u4f8b\u5982\u5728Navier-Stokes\u65b9\u7a0b\u4e0a\uff0c\u751f\u621010,000\u4e2a\u6837\u672c\u4ec5\u9700\u4f20\u7edf\u65b9\u6cd5\u7ea610%\u7684\u65f6\u95f4\uff0c\u4e14\u6a21\u578b\u8bad\u7ec3\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "HOPSS\u7b97\u6cd5\u80fd\u591f\u663e\u8457\u52a0\u901fPDE\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u751f\u6210\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u636e\u7cbe\u5ea6\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u6570\u636e\u751f\u6210\u65b9\u6848\u3002"}}
{"id": "2510.21608", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21608", "abs": "https://arxiv.org/abs/2510.21608", "authors": ["Oscar Davis", "Michael S. Albergo", "Nicholas M. Boffi", "Michael M. Bronstein", "Avishek Joey Bose"], "title": "Generalised Flow Maps for Few-Step Generative Modelling on Riemannian Manifolds", "comment": "Under review", "summary": "Geometric data and purpose-built generative models on them have become\nubiquitous in high-impact deep learning application domains, ranging from\nprotein backbone generation and computational chemistry to geospatial data.\nCurrent geometric generative models remain computationally expensive at\ninference -- requiring many steps of complex numerical simulation -- as they\nare derived from dynamical measure transport frameworks such as diffusion and\nflow-matching on Riemannian manifolds. In this paper, we propose Generalised\nFlow Maps (GFM), a new class of few-step generative models that generalises the\nFlow Map framework in Euclidean spaces to arbitrary Riemannian manifolds. We\ninstantiate GFMs with three self-distillation-based training methods:\nGeneralised Lagrangian Flow Maps, Generalised Eulerian Flow Maps, and\nGeneralised Progressive Flow Maps. We theoretically show that GFMs, under\nspecific design decisions, unify and elevate existing Euclidean few-step\ngenerative models, such as consistency models, shortcut models, and meanflows,\nto the Riemannian setting. We benchmark GFMs against other geometric generative\nmodels on a suite of geometric datasets, including geospatial data, RNA torsion\nangles, and hyperbolic manifolds, and achieve state-of-the-art sample quality\nfor single- and few-step evaluations, and superior or competitive\nlog-likelihoods using the implicit probability flow.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5e7f\u4e49\u6d41\u6620\u5c04\uff08GFM\uff09\uff0c\u4e00\u79cd\u65b0\u7684\u5c11\u6b65\u751f\u6210\u6a21\u578b\uff0c\u5c06\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u7684\u6d41\u6620\u5c04\u6846\u67b6\u63a8\u5e7f\u5230\u4efb\u610f\u9ece\u66fc\u6d41\u5f62\u4e0a\u3002GFM\u901a\u8fc7\u4e09\u79cd\u81ea\u84b8\u998f\u8bad\u7ec3\u65b9\u6cd5\u5b9e\u73b0\uff0c\u5728\u591a\u4e2a\u51e0\u4f55\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6837\u672c\u8d28\u91cf\u548c\u7ade\u4e89\u6027\u7684\u5bf9\u6570\u4f3c\u7136\u3002", "motivation": "\u5f53\u524d\u51e0\u4f55\u751f\u6210\u6a21\u578b\u5728\u63a8\u7406\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u590d\u6742\u7684\u6570\u503c\u6a21\u62df\u6b65\u9aa4\uff0c\u56e0\u4e3a\u5b83\u4eec\u57fa\u4e8e\u9ece\u66fc\u6d41\u5f62\u4e0a\u7684\u6269\u6563\u548c\u6d41\u5339\u914d\u7b49\u52a8\u6001\u6d4b\u5ea6\u4f20\u8f93\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u5e7f\u4e49\u6d41\u6620\u5c04\uff08GFM\uff09\u6846\u67b6\uff0c\u5305\u542b\u4e09\u79cd\u81ea\u84b8\u998f\u8bad\u7ec3\u65b9\u6cd5\uff1a\u5e7f\u4e49\u62c9\u683c\u6717\u65e5\u6d41\u6620\u5c04\u3001\u5e7f\u4e49\u6b27\u62c9\u6d41\u6620\u5c04\u548c\u5e7f\u4e49\u6e10\u8fdb\u6d41\u6620\u5c04\u3002", "result": "\u5728\u5305\u62ec\u5730\u7406\u7a7a\u95f4\u6570\u636e\u3001RNA\u626d\u8f6c\u89d2\u548c\u53cc\u66f2\u6d41\u5f62\u5728\u5185\u7684\u51e0\u4f55\u6570\u636e\u96c6\u4e0a\uff0cGFM\u5728\u5355\u6b65\u548c\u5c11\u6b65\u8bc4\u4f30\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6837\u672c\u8d28\u91cf\uff0c\u5e76\u4f7f\u7528\u9690\u5f0f\u6982\u7387\u6d41\u83b7\u5f97\u4e86\u4f18\u8d8a\u6216\u7ade\u4e89\u6027\u7684\u5bf9\u6570\u4f3c\u7136\u3002", "conclusion": "GFM\u7edf\u4e00\u5e76\u63d0\u5347\u4e86\u73b0\u6709\u7684\u6b27\u51e0\u91cc\u5f97\u5c11\u6b65\u751f\u6210\u6a21\u578b\u5230\u9ece\u66fc\u8bbe\u7f6e\uff0c\u4e3a\u51e0\u4f55\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
