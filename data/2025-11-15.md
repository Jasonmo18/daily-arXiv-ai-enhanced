<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 2]
- [cs.CL](#cs.CL) [Total: 5]
- [cs.MM](#cs.MM) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals](https://arxiv.org/abs/2511.10615)
*Shruti Singh Baghel,Yash Pratap Singh Rathore,Sushovan Jena,Anurag Pradhan,Amit Shukla,Arnav Bhavsar,Pawan Goyal*

Main category: cs.CV

TL;DR: 本文研究了不同参数规模的SmolVLM2模型在盲人和低视力用户视频描述任务上的性能，提出了专门针对BLV可访问性评估的新框架，并评估了不同提示策略和移动设备部署方案。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型虽然能生成高质量视频描述，但其高内存、计算和部署需求限制了实际应用，特别是对依赖详细上下文感知描述的盲人和低视力用户。

Method: 评估500M和2.2B参数的SmolVLM2变体在两个数据集上，引入了多上下文BLV框架和导航辅助框架，系统评估了四种提示设计策略，并在智能手机上部署FP32和INT8精度变体。

Result: 通过专门设计的评估框架对模型性能进行了全面评估，重点关注空间导向、社交互动、动作事件和环境背景等关键上下文信息。

Conclusion: 研究为资源受限移动设备上的视觉语言模型部署提供了实用指导，特别关注了BLV用户的可访问性需求。

Abstract: Large Vision-Language Models (VLMs) excel at understanding and generating video descriptions but their high memory, computation, and deployment demands hinder practical use particularly for blind and low-vision (BLV) users who depend on detailed, context-aware descriptions. To study the effect of model size on accessibility-focused description quality, we evaluate SmolVLM2 variants with 500M and 2.2B parameters across two diverse datasets: AVCaps (outdoor), and Charades (indoor). In this work, we introduce two novel evaluation frameworks specifically designed for BLV accessibility assessment: the Multi-Context BLV Framework evaluating spatial orientation, social interaction, action events, and ambience contexts; and the Navigational Assistance Framework focusing on mobility-critical information. Additionally, we conduct a systematic evaluation of four different prompt design strategies and deploy both models on a smartphone, evaluating FP32 and INT8 precision variants to assess real-world performance constraints on resource-limited mobile devices.

</details>


### [2] [Enhancing the Outcome Reward-based RL Training of MLLMs with Self-Consistency Sampling](https://arxiv.org/abs/2511.10648)
*Jiahao Wang,Weiye Xu,Aijun Yang,Wengang Zhou,Lewei Lu,Houqiang Li,Xiaohua Wang,Jinguo Zhu*

Main category: cs.CV

TL;DR: 本文提出自一致性采样（SCS）方法，解决多模态大语言模型在结果奖励强化学习中存在的不可靠轨迹问题，通过在推理过程中引入视觉扰动和重复截断重采样来提高推理的可靠性。


<details>
  <summary>Details</summary>
Motivation: 在多模态推理基准测试中，结果奖励强化学习面临一个被忽视的障碍：即使推理链存在错误，只要最终猜对正确答案，就会获得与正确推理相同的奖励，这影响了模型的学习效果。

Method: 提出自一致性采样（SCS）方法：对每个问题（i）引入小的视觉扰动，（ii）对初始轨迹进行重复截断和重采样，通过结果轨迹的一致性产生可微的一致性分数，在策略更新时降低不可靠轨迹的权重。

Result: 在Qwen2.5-VL-7B-Instruct模型上，将SCS集成到RLOO、GRPO和REINFORCE++系列中，在六个多模态基准测试上准确率最高提升7.7个百分点，计算开销可忽略不计。在Qwen2.5-VL-3B-Instruct和InternVL3-8B模型上也取得了显著提升。

Conclusion: SCS为多模态大语言模型中的结果奖励强化学习提供了一个简单通用的解决方案，能够有效提高推理的可靠性和准确性。

Abstract: Outcome-reward reinforcement learning (RL) is a common and increasingly significant way to refine the step-by-step reasoning of multimodal large language models (MLLMs). In the multiple-choice setting - a dominant format for multimodal reasoning benchmarks - the paradigm faces a significant yet often overlooked obstacle: unfaithful trajectories that guess the correct option after a faulty chain of thought receive the same reward as genuine reasoning, which is a flaw that cannot be ignored. We propose Self-Consistency Sampling (SCS) to correct this issue. For each question, SCS (i) introduces small visual perturbations and (ii) performs repeated truncation and resampling of an initial trajectory; agreement among the resulting trajectories yields a differentiable consistency score that down-weights unreliable traces during policy updates. Based on Qwen2.5-VL-7B-Instruct, plugging SCS into RLOO, GRPO, and REINFORCE++ series improves accuracy by up to 7.7 percentage points on six multimodal benchmarks with negligible extra computation. SCS also yields notable gains on both Qwen2.5-VL-3B-Instruct and InternVL3-8B, offering a simple, general remedy for outcome-reward RL in MLLMs.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [3] [Know Your Limits: Entropy Estimation Modeling for Compression and Generalization](https://arxiv.org/abs/2511.10618)
*Benjamin L. Badger,Matthew Neligeorge*

Main category: cs.CL

TL;DR: 本文提出了编码器增强的因果解码器模型架构，该架构在训练效率上优于因果变换器，并能实现更高的压缩率。研究表明，当模型训练接近但不超出估计的每标记熵时，其泛化能力更强。


<details>
  <summary>Details</summary>
Motivation: 语言预测受到语言内在信息熵的限制，当前最有效的语言压缩算法是因果大语言模型，但使用这些模型准确估计语言熵在计算上不可行。

Method: 引入编码器增强的因果解码器模型架构，展示如何基于每标记获得熵估计，并证明训练接近训练数据熵的模型必然比训练超出该值的模型具有更好的泛化能力。

Result: 编码器增强架构在适度硬件上训练时表现出更高的压缩率，经验证明考虑熵训练的因果模型比不考虑熵的模型具有更好的泛化能力。

Conclusion: 通过编码器增强的因果解码器架构可以更有效地估计语言熵，训练接近但不超出估计熵的模型能获得更好的泛化性能。

Abstract: Language prediction is constrained by informational entropy intrinsic to language, such that there exists a limit to how accurate any language model can become and equivalently a lower bound to language compression. The most efficient language compression algorithms today are causal (next token prediction) large language models, but the use of these models to form accurate estimates of language entropy is currently computationally infeasible. We introduce encoder-augmented causal decoder model architectures that exhibit superior training efficiency characteristics and achieve higher compression than causal transformers even when trained on modest hardware. We demonstrate how entropy estimates can be obtained on a per-token basis, and show that the generalization of models trained to approach the entropy of their training data necessarily exceeds the generalization of models trained to minimize loss beyond this value. We show empirically that causal models trained to approach but not exceed estimated per-token entropies exhibit greater generalization than models trained without taking entropy into account.

</details>


### [4] [SSR: Socratic Self-Refine for Large Language Model Reasoning](https://arxiv.org/abs/2511.10621)
*Haizhou Shi,Ye Liu,Bo Pang,Zeyu Leo Liu,Hao Wang,Silvio Savarese,Caiming Xiong,Yingbo Zhou,Semih Yavuz*

Main category: cs.CL

TL;DR: SSR是一个新颖的LLM推理框架，通过将模型响应分解为可验证的子问题-子答案对，实现细粒度评估和精确优化，在多个推理基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有测试时框架依赖粗粒度的自我验证和自我修正，限制了在复杂任务上的有效性，需要更精细的评估和优化方法。

Method: 将模型响应分解为可验证的子问题-子答案对，通过受控重解和自一致性检查进行步骤级置信度估计，精确定位不可靠步骤并迭代优化。

Result: 在五个推理基准测试和三个LLM上的实证结果显示，SSR始终优于最先进的迭代自优化基线方法。

Conclusion: SSR不仅提升了性能，还提供了一种原则性的黑盒方法来评估和理解LLM的内部推理过程。

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, yet existing test-time frameworks often rely on coarse self-verification and self-correction, limiting their effectiveness on complex tasks. In this paper, we propose Socratic Self-Refine (SSR), a novel framework for fine-grained evaluation and precise refinement of LLM reasoning. Our proposed SSR decomposes model responses into verifiable (sub-question, sub-answer) pairs, enabling step-level confidence estimation through controlled re-solving and self-consistency checks. By pinpointing unreliable steps and iteratively refining them, SSR produces more accurate and interpretable reasoning chains. Empirical results across five reasoning benchmarks and three LLMs show that SSR consistently outperforms state-of-the-art iterative self-refinement baselines. Beyond performance gains, SSR provides a principled black-box approach for evaluating and understanding the internal reasoning processes of LLMs. Code is available at https://github.com/SalesforceAIResearch/socratic-self-refine-reasoning.

</details>


### [5] [Instella: Fully Open Language Models with Stellar Performance](https://arxiv.org/abs/2511.10628)
*Jiang Liu,Jialian Wu,Xiaodong Yu,Yusheng Su,Prakamya Mishra,Gowtham Ramesh,Sudhanshu Ranjan,Chaitanya Manem,Ximeng Sun,Ze Wang,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: Instella是一个完全开源的30亿参数语言模型家族，使用公开可用数据和代码库训练，在AMD Instinct MI300X GPU上开发，包括预训练、指令微调和人类偏好对齐。尽管预训练token数量较少，但在完全开源模型中达到最先进水平，并发布两个专业变体：Instella-Long（支持128K上下文长度）和Instella-Math（数学推理增强模型）。


<details>
  <summary>Details</summary>
Motivation: 当前高性能语言模型大多为闭源或部分开源，限制了透明度和可复现性。本研究旨在开发完全开源的语言模型，推动开放和可复现的语言建模研究。

Method: 使用AMD Instinct MI300X GPU进行大规模预训练、通用指令微调以及与人类偏好的对齐。开发了两个专业变体：Instella-Long通过技术处理支持长上下文，Instella-Math通过监督微调和强化学习在数学任务上增强推理能力。

Result: Instella在完全开源模型中达到最先进水平，与同规模领先的开源权重模型具有竞争力。Instella-Long支持128K token上下文长度，Instella-Math在数学推理任务上表现优异。

Conclusion: Instella系列模型为社区提供了透明、高性能且多功能的替代方案，推进了开放和可复现语言建模研究的目标。

Abstract: Large language models (LLMs) have demonstrated remarkable performance across a wide range of tasks, yet the majority of high-performing models remain closed-source or partially open, limiting transparency and reproducibility. In this work, we introduce Instella, a family of fully open three billion parameter language models trained entirely on openly available data and codebase. Powered by AMD Instinct MI300X GPUs, Instella is developed through large-scale pre-training, general-purpose instruction tuning, and alignment with human preferences. Despite using substantially fewer pre-training tokens than many contemporaries, Instella achieves state-of-the-art results among fully open models and is competitive with leading open-weight models of comparable size. We further release two specialized variants: Instella-Long, capable of handling context lengths up to 128K tokens, and Instella-Math, a reasoning-focused model enhanced through supervised fine-tuning and reinforcement learning on mathematical tasks. Together, these contributions establish Instella as a transparent, performant, and versatile alternative for the community, advancing the goal of open and reproducible language modeling research.

</details>


### [6] [Black-Box On-Policy Distillation of Large Language Models](https://arxiv.org/abs/2511.10643)
*Tianzhu Ye,Li Dong,Zewen Chi,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.CL

TL;DR: 本文提出生成对抗蒸馏（GAD）方法，通过将学生LLM作为生成器、训练判别器区分师生模型响应，实现黑盒蒸馏。该方法在LMSYS-Chat评估中使Qwen2.5-14B-Instruct学生模型达到与GPT-5-Chat教师模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 解决黑盒蒸馏中学生模型只能从教师模型的文本输出学习，无法访问内部logits或参数的问题，实现更有效的知识迁移。

Method: 将学生LLM作为生成器，训练判别器区分师生模型响应，形成极小极大博弈。判别器作为在线奖励模型与学生共同进化，提供稳定自适应反馈。

Result: GAD在实验中持续优于常用的序列级知识蒸馏方法。Qwen2.5-14B-Instruct学生模型通过GAD训练后，在LMSYS-Chat自动评估中与GPT-5-Chat教师模型表现相当。

Conclusion: GAD被确立为黑盒LLM蒸馏的有前景且有效的范式，为无法访问教师模型内部信息的场景提供了可行的蒸馏方案。

Abstract: Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work, we introduce Generative Adversarial Distillation (GAD), which enables on-policy and black-box distillation. GAD frames the student LLM as a generator and trains a discriminator to distinguish its responses from the teacher LLM's, creating a minimax game. The discriminator acts as an on-policy reward model that co-evolves with the student, providing stable, adaptive feedback. Experimental results show that GAD consistently surpasses the commonly used sequence-level knowledge distillation. In particular, Qwen2.5-14B-Instruct (student) trained with GAD becomes comparable to its teacher, GPT-5-Chat, on the LMSYS-Chat automatic evaluation. The results establish GAD as a promising and effective paradigm for black-box LLM distillation.

</details>


### [7] [ParoQuant: Pairwise Rotation Quantization for Efficient Reasoning LLM Inference](https://arxiv.org/abs/2511.10645)
*Yesheng Liang,Haisheng Chen,Song Han,Zhijian Liu*

Main category: cs.CL

TL;DR: ParoQuant是一种仅权重的后训练量化方法，通过成对旋转量化和通道级缩放来减少大语言模型中的异常值影响，在推理任务上比AWQ平均提升2.4%准确率，且开销低于10%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型权重和激活中的异常值会导致量化误差和精度下降，特别是在推理任务中误差会在长思维链中累积。现有方法要么无法充分抑制异常值，要么在推理时引入显著开销。

Method: 结合硬件高效的独立Givens旋转和通道级缩放，均衡通道间幅度并缩小每个量化组内的动态范围，同时协同设计推理内核以充分利用GPU并行性。

Result: 在推理任务上比AWQ平均提升2.4%准确率，推理开销低于10%。

Conclusion: 为更高效和准确部署推理大语言模型铺平了道路。

Abstract: Weight-only post-training quantization (PTQ) compresses the weights of Large Language Models (LLMs) into low-precision representations to reduce memory footprint and accelerate inference. However, the presence of outliers in weights and activations often leads to large quantization errors and severe accuracy degradation, especially in recent reasoning LLMs where errors accumulate across long chains of thought. Existing PTQ methods either fail to sufficiently suppress outliers or introduce significant overhead during inference. In this paper, we propose Pairwise Rotation Quantization (ParoQuant), a weight-only PTQ method that combines hardware-efficient and optimizable independent Givens rotations with channel-wise scaling to even out the magnitude across channels and narrow the dynamic range within each quantization group. We further co-design the inference kernel to fully exploit GPU parallelism and keep the rotations and scaling lightweight at runtime. ParoQuant achieves an average 2.4% accuracy improvement over AWQ on reasoning tasks with less than 10% overhead. This paves the way for more efficient and accurate deployment of reasoning LLMs.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [8] [Robustness and Imperceptibility Analysis of Hybrid Spatial-Frequency Domain Image Watermarking](https://arxiv.org/abs/2511.10245)
*Rizal Khoirul Anam*

Main category: cs.MM

TL;DR: 本文比较了三种数字图像水印技术：空间域LSB、频域DFT和新型混合LSB+DFT方法，评估了不可感知性（PSNR）与鲁棒性（NC和BER）之间的权衡。实验表明混合方法在保持高视觉质量的同时具有最佳抗攻击能力。


<details>
  <summary>Details</summary>
Motivation: 数字媒体的普及需要强大的版权保护和内容认证方法，因此需要评估不同水印技术在不可感知性和鲁棒性之间的平衡。

Method: 在统一的MATLAB实验框架中实现了三种水印技术：空间域LSB、频域DFT和混合LSB+DFT方法，并对水印图像进行JPEG压缩、高斯噪声和椒盐噪声等常见图像处理攻击测试。

Result: 实验结果显示LSB方法具有最佳不可感知性但极其脆弱，DFT方法鲁棒性强但视觉质量较差，而混合LSB+DFT方法通过冗余嵌入和回退提取机制实现了最佳平衡。

Conclusion: 提出的混合LSB+DFT水印技术能够保持高视觉保真度，同时对所有测试攻击表现出优异的鲁棒性，是数字图像版权保护的理想解决方案。

Abstract: The proliferation of digital media necessitates robust methods for copyright protection and content authentication. This paper presents a comprehensive comparative study of digital image watermarking techniques implemented using the spatial domain (Least Significant Bit - LSB), the frequency domain (Discrete Fourier Transform - DFT), and a novel hybrid (LSB+DFT) approach. The core objective is to evaluate the trade-offs between imperceptibility (measured by Peak Signal-to-Noise Ratio - PSNR) and robustness (measured by Normalized Correlation - NC and Bit Error Rate - BER). We implemented these three techniques within a unified MATLAB-based experimental framework. The watermarked images were subjected to a battery of common image processing attacks, including JPEG compression, Gaussian noise, and salt-and-pepper noise, at varying intensities. Experimental results generated from standard image datasets (USC-SIPI) demonstrate that while LSB provides superior imperceptibility, it is extremely fragile. The DFT method offers significant robustness at the cost of visual quality. The proposed hybrid LSB+DFT technique, which leverages redundant embedding and a fallback extraction mechanism, is shown to provide the optimal balance, maintaining high visual fidelity while exhibiting superior resilience to all tested attacks.

</details>


### [9] [TMDC: A Two-Stage Modality Denoising and Complementation Framework for Multimodal Sentiment Analysis with Missing and Noisy Modalities](https://arxiv.org/abs/2511.10325)
*Yan Zhuang,Minhao Liu,Yanru Zhang,Jiawen Deng,Fuji Ren*

Main category: cs.MM

TL;DR: 提出了TMDC框架，通过两阶段训练联合解决多模态情感分析中的模态缺失和噪声问题，在多个数据集上达到最优性能


<details>
  <summary>Details</summary>
Motivation: 现实场景中多模态情感分析面临模态缺失和噪声信号的挑战，现有方法通常单独处理这些问题，限制了实际应用效果

Method: TMDC框架包含两个顺序训练阶段：模态内去噪阶段提取去噪后的模态特定和模态共享表示；模态间互补阶段利用这些表示补偿缺失模态

Result: 在MOSI、MOSEI和IEMOCAP数据集上的广泛评估表明，TMDC相比现有方法持续实现更优性能，建立了新的最先进结果

Conclusion: TMDC框架能有效联合缓解模态缺失和噪声问题，增强多模态情感分析模型的鲁棒性和准确性

Abstract: Multimodal Sentiment Analysis (MSA) aims to infer human sentiment by integrating information from multiple modalities such as text, audio, and video. In real-world scenarios, however, the presence of missing modalities and noisy signals significantly hinders the robustness and accuracy of existing models. While prior works have made progress on these issues, they are typically addressed in isolation, limiting overall effectiveness in practical settings. To jointly mitigate the challenges posed by missing and noisy modalities, we propose a framework called Two-stage Modality Denoising and Complementation (TMDC). TMDC comprises two sequential training stages. In the Intra-Modality Denoising Stage, denoised modality-specific and modality-shared representations are extracted from complete data using dedicated denoising modules, reducing the impact of noise and enhancing representational robustness. In the Inter-Modality Complementation Stage, these representations are leveraged to compensate for missing modalities, thereby enriching the available information and further improving robustness. Extensive evaluations on MOSI, MOSEI, and IEMOCAP demonstrate that TMDC consistently achieves superior performance compared to existing methods, establishing new state-of-the-art results.

</details>
