<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 141]
- [cs.CL](#cs.CL) [Total: 90]
- [cs.LG](#cs.LG) [Total: 147]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [eess.IV](#eess.IV) [Total: 7]
- [cs.NE](#cs.NE) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 5]
- [cs.AI](#cs.AI) [Total: 42]
- [stat.ML](#stat.ML) [Total: 14]
- [cs.MA](#cs.MA) [Total: 7]
- [cs.HC](#cs.HC) [Total: 19]
- [physics.med-ph](#physics.med-ph) [Total: 6]
- [math.NA](#math.NA) [Total: 27]
- [eess.SP](#eess.SP) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [ESCA: Contextualizing Embodied Agents via Scene-Graph Generation](https://arxiv.org/abs/2510.15963)
*Jiani Huang,Amish Sethi,Matthew Kuo,Mayank Keoliya,Neelay Velingker,JungHo Jung,Ser-Nam Lim,Ziyang Li,Mayur Naik*

Main category: cs.CV

TL;DR: 本文提出ESCA框架和SGClip模型，通过结构化时空理解来情境化具身智能体。SGClip是一种基于CLIP的开放域可提示场景图生成模型，在无需人工标注的情况下训练，显著提升了多模态大语言模型在具身环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型主要依赖高级视觉-声音-文本对，缺乏像素级视觉内容与文本语义之间的细粒度结构化对齐，这限制了具身智能体的发展。

Method: 提出ESCA框架，核心是SGClip模型——基于CLIP的开放域可提示场景图生成模型。通过神经符号学习管道在87K+开放域视频上训练，利用视频-字幕对进行模型驱动的自监督学习和结构化推理。

Result: SGClip在场景图生成和动作定位基准测试中表现出色。ESCA框架持续改进开源和商业MLLMs，在两个具身环境中实现最先进性能，显著减少智能体感知错误，并使开源模型超越专有基线。

Conclusion: ESCA框架通过结构化时空理解有效提升了具身智能体的性能，SGClip模型在无需人工标注的情况下实现了高质量的开放域场景图生成，为通用具身智能体的发展提供了重要支持。

Abstract: Multi-modal large language models (MLLMs) are making rapid progress toward
general-purpose embodied agents. However, current training pipelines primarily
rely on high-level vision-sound-text pairs and lack fine-grained, structured
alignment between pixel-level visual content and textual semantics. To overcome
this challenge, we propose ESCA, a new framework for contextualizing embodied
agents through structured spatial-temporal understanding. At its core is
SGClip, a novel CLIP-based, open-domain, and promptable model for generating
scene graphs. SGClip is trained on 87K+ open-domain videos via a neurosymbolic
learning pipeline, which harnesses model-driven self-supervision from
video-caption pairs and structured reasoning, thereby eliminating the need for
human-labeled scene graph annotations. We demonstrate that SGClip supports both
prompt-based inference and task-specific fine-tuning, excelling in scene graph
generation and action localization benchmarks. ESCA with SGClip consistently
improves both open-source and commercial MLLMs, achieving state-of-the-art
performance across two embodied environments. Notably, it significantly reduces
agent perception errors and enables open-source models to surpass proprietary
baselines.

</details>


### [2] [CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection](https://arxiv.org/abs/2510.15991)
*Huiming Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为CrossRay3D的稀疏跨模态3D检测器，通过引入Sparse Selector模块（包括Ray-Aware Supervision和Class-Balanced Supervision）以及Ray Positional Encoding，显著提升了稀疏检测器的性能，在nuScenes基准测试中达到72.4 mAP和74.7 NDS的SOTA性能，且运行速度比现有方法快1.84倍。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏检测器忽略了token表示的质量，导致前景质量不理想且性能受限。本文发现几何结构保持和类别分布是提升稀疏检测器性能的关键。

Method: 提出Sparse Selector模块，包含：Ray-Aware Supervision在训练阶段保持丰富的几何信息；Class-Balanced Supervision自适应重新加权类别语义的显著性；Ray Positional Encoding解决LiDAR和图像模态间的分布差异。将这些模块集成到端到端的CrossRay3D稀疏多模态检测器中。

Result: 在nuScenes基准测试中，CrossRay3D达到72.4 mAP和74.7 NDS的SOTA性能，运行速度比其他领先方法快1.84倍。在LiDAR或相机数据部分或完全缺失的场景下也表现出强鲁棒性。

Conclusion: CrossRay3D通过改进token表示质量，在保持稀疏检测器计算效率优势的同时，显著提升了检测性能，为下游任务提供了更好的适应性。

Abstract: The sparse cross-modality detector offers more advantages than its
counterpart, the Bird's-Eye-View (BEV) detector, particularly in terms of
adaptability for downstream tasks and computational cost savings. However,
existing sparse detectors overlook the quality of token representation, leaving
it with a sub-optimal foreground quality and limited performance. In this
paper, we identify that the geometric structure preserved and the class
distribution are the key to improving the performance of the sparse detector,
and propose a Sparse Selector (SS). The core module of SS is Ray-Aware
Supervision (RAS), which preserves rich geometric information during the
training stage, and Class-Balanced Supervision, which adaptively reweights the
salience of class semantics, ensuring that tokens associated with small objects
are retained during token sampling. Thereby, outperforming other sparse
multi-modal detectors in the representation of tokens. Additionally, we design
Ray Positional Encoding (Ray PE) to address the distribution differences
between the LiDAR modality and the image. Finally, we integrate the
aforementioned module into an end-to-end sparse multi-modality detector, dubbed
CrossRay3D. Experiments show that, on the challenging nuScenes benchmark,
CrossRay3D achieves state-of-the-art performance with 72.4 mAP and 74.7 NDS,
while running 1.84 faster than other leading methods. Moreover, CrossRay3D
demonstrates strong robustness even in scenarios where LiDAR or camera data are
partially or entirely missing.

</details>


### [3] [IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection](https://arxiv.org/abs/2510.16036)
*Zewen Li,Zitong Yu,Qilang Ye,Weicheng Xie,Wei Zhuo,Linlin Shen*

Main category: cs.CV

TL;DR: IAD-GPT是一个基于多模态大语言模型的工业异常检测新范式，通过异常提示生成器、文本引导增强器和多掩码融合模块，结合文本语义与图像信息实现先进的异常检测和分割。


<details>
  <summary>Details</summary>
Motivation: 传统工业异常检测方法缺乏多轮人机对话和详细描述能力，而基于大预训练模型的方法尚未充分激发大模型在异常检测任务中的潜力。

Method: 使用异常提示生成器生成详细异常提示，通过文本引导增强器增强视觉定位能力，设计多掩码融合模块将掩码作为专家知识增强像素级异常感知。

Result: 在MVTec-AD和VisA数据集上的实验表明，该方法在自监督和少样本异常检测与分割任务中达到了最先进的性能。

Conclusion: IAD-GPT成功将多模态大语言模型应用于工业异常检测，实现了结合文本语义与图像信息的有效异常检测框架。

Abstract: The robust causal capability of Multimodal Large Language Models (MLLMs) hold
the potential of detecting defective objects in Industrial Anomaly Detection
(IAD). However, most traditional IAD methods lack the ability to provide
multi-turn human-machine dialogues and detailed descriptions, such as the color
of objects, the shape of an anomaly, or specific types of anomalies. At the
same time, methods based on large pre-trained models have not fully stimulated
the ability of large models in anomaly detection tasks. In this paper, we
explore the combination of rich text semantics with both image-level and
pixel-level information from images and propose IAD-GPT, a novel paradigm based
on MLLMs for IAD. We employ Abnormal Prompt Generator (APG) to generate
detailed anomaly prompts for specific objects. These specific prompts from the
large language model (LLM) are used to activate the detection and segmentation
functions of the pre-trained visual-language model (i.e., CLIP). To enhance the
visual grounding ability of MLLMs, we propose Text-Guided Enhancer, wherein
image features interact with normal and abnormal text prompts to dynamically
select enhancement pathways, which enables language models to focus on specific
aspects of visual data, enhancing their ability to accurately interpret and
respond to anomalies within images. Moreover, we design a Multi-Mask Fusion
module to incorporate mask as expert knowledge, which enhances the LLM's
perception of pixel-level anomalies. Extensive experiments on MVTec-AD and VisA
datasets demonstrate our state-of-the-art performance on self-supervised and
few-shot anomaly detection and segmentation tasks, such as MVTec-AD and VisA
datasets. The codes are available at
\href{https://github.com/LiZeWen1225/IAD-GPT}{https://github.com/LiZeWen1225/IAD-GPT}.

</details>


### [4] [Effect of Reporting Mode and Clinical Experience on Radiologists' Gaze and Image Analysis Behavior in Chest Radiography](https://arxiv.org/abs/2510.16070)
*Mahta Khoobi,Marc Sebastian von der Stueck,Felix Barajas Ordonez,Anca-Maria Iancu,Eric Corban,Julia Nowak,Aleksandar Kargaliev,Valeria Perelygina,Anna-Sophie Schott,Daniel Pinto dos Santos,Christiane Kuhl,Daniel Truhn,Sven Nebelung,Robert Siepmann*

Main category: cs.CV

TL;DR: 本研究评估了自由文本、结构化报告和AI辅助结构化报告三种报告模式对放射科医生分析床边胸片的影响，发现AI辅助结构化报告能显著提高诊断准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 结构化报告和人工智能可能改变放射科医生与影像研究的交互方式，需要评估不同报告模式对图像分析行为、诊断准确性、效率和用户体验的影响。

Method: 前瞻性研究（2024年7月至12月），8名读者（4名新手和4名非新手）每人分析35张床边胸片，使用定制查看器和眼动追踪系统，比较三种报告模式：自由文本、结构化报告和AI辅助结构化报告。

Result: AI辅助结构化报告的诊断准确性最高（κ=0.71），报告时间最短（25±9秒），眼动指标显示视觉注意力更集中于图像区域，且是用户偏好的模式。

Conclusion: 结构化报告通过引导视觉注意力朝向图像来提高效率，而AI预填充的结构化报告进一步增强了诊断准确性和用户满意度。

Abstract: Structured reporting (SR) and artificial intelligence (AI) may transform how
radiologists interact with imaging studies. This prospective study (July to
December 2024) evaluated the impact of three reporting modes: free-text (FT),
structured reporting (SR), and AI-assisted structured reporting (AI-SR), on
image analysis behavior, diagnostic accuracy, efficiency, and user experience.
Four novice and four non-novice readers (radiologists and medical students)
each analyzed 35 bedside chest radiographs per session using a customized
viewer and an eye-tracking system. Outcomes included diagnostic accuracy
(compared with expert consensus using Cohen's $\kappa$), reporting time per
radiograph, eye-tracking metrics, and questionnaire-based user experience.
Statistical analysis used generalized linear mixed models with Bonferroni
post-hoc tests with a significance level of ($P \le .01$). Diagnostic accuracy
was similar in FT ($\kappa = 0.58$) and SR ($\kappa = 0.60$) but higher in
AI-SR ($\kappa = 0.71$, $P < .001$). Reporting times decreased from $88 \pm 38$
s (FT) to $37 \pm 18$ s (SR) and $25 \pm 9$ s (AI-SR) ($P < .001$). Saccade
counts for the radiograph field ($205 \pm 135$ (FT), $123 \pm 88$ (SR), $97 \pm
58$ (AI-SR)) and total fixation duration for the report field ($11 \pm 5$ s
(FT), $5 \pm 3$ s (SR), $4 \pm 1$ s (AI-SR)) were lower with SR and AI-SR ($P <
.001$ each). Novice readers shifted gaze towards the radiograph in SR, while
non-novice readers maintained their focus on the radiograph. AI-SR was the
preferred mode. In conclusion, SR improves efficiency by guiding visual
attention toward the image, and AI-prefilled SR further enhances diagnostic
accuracy and user satisfaction.

</details>


### [5] [Data-Driven Analysis of Intersectional Bias in Image Classification: A Framework with Bias-Weighted Augmentation](https://arxiv.org/abs/2510.16072)
*Farjana Yesmin*

Main category: cs.CV

TL;DR: 本文提出了一种数据驱动框架IFEF来分析图像分类中的交叉偏见，并开发了BWA数据增强方法来缓解偏见，在Open Images V7数据集上显著提升了少数群体准确率并减少了公平性差距。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在非平衡数据集上训练时经常表现出交叉偏见——由对象类别和环境条件等多个属性相互作用产生的系统性错误，需要系统性地分析和缓解这种偏见。

Method: 提出了交叉公平性评估框架(IFEF)结合定量公平性指标和可解释性工具来识别偏见模式，并开发了基于子群分布统计的自适应变换强度的偏见加权增强(BWA)数据增强策略。

Result: 在Open Images V7数据集上，BWA将代表性不足的类别-环境交叉组的准确率提高了最多24个百分点，同时将公平性指标差异减少了35%，统计检验证实了改进的显著性(p < 0.05)。

Conclusion: 该方法为分析和解决图像分类系统中的交叉偏见提供了一个可复现的途径。

Abstract: Machine learning models trained on imbalanced datasets often exhibit
intersectional biases-systematic errors arising from the interaction of
multiple attributes such as object class and environmental conditions. This
paper presents a data-driven framework for analyzing and mitigating such biases
in image classification. We introduce the Intersectional Fairness Evaluation
Framework (IFEF), which combines quantitative fairness metrics with
interpretability tools to systematically identify bias patterns in model
predictions. Building on this analysis, we propose Bias-Weighted Augmentation
(BWA), a novel data augmentation strategy that adapts transformation
intensities based on subgroup distribution statistics. Experiments on the Open
Images V7 dataset with five object classes demonstrate that BWA improves
accuracy for underrepresented class-environment intersections by up to 24
percentage points while reducing fairness metric disparities by 35%.
Statistical analysis across multiple independent runs confirms the significance
of improvements (p < 0.05). Our methodology provides a replicable approach for
analyzing and addressing intersectional biases in image classification systems.

</details>


### [6] [RefAtomNet++: Advancing Referring Atomic Video Action Recognition using Semantic Retrieval based Multi-Trajectory Mamba](https://arxiv.org/abs/2510.16444)
*Kunyu Peng,Di Wen,Jia Fu,Jiamin Wu,Kailun Yang,Junwei Zheng,Ruiping Liu,Yufan Chen,Yuqian Fu,Danda Pani Paudel,Luc Van Gool,Rainer Stiefelhagen*

Main category: cs.CV

TL;DR: 本文介绍了RefAVA++数据集和RefAtomNet++框架，用于指代原子视频动作识别任务。该任务旨在根据自然语言描述识别特定人物的细粒度原子级动作。


<details>
  <summary>Details</summary>
Motivation: 现有的动作识别和检测方法在复杂多人场景中难以实现精确的语言引导动作理解，特别是在定位目标人物和预测细粒度动作方面存在局限性。

Method: 提出RefAtomNet++框架，采用多层次语义对齐交叉注意力机制，结合部分关键词、场景属性和整体句子级别的多轨迹Mamba建模，动态选择最近的视觉空间标记构建扫描轨迹。

Result: 实验表明RefAtomNet++在RefAVA++数据集上取得了最先进的结果，该数据集包含超过290万帧和75.1k个标注人物。

Conclusion: RefAtomNet++通过改进的跨模态标记聚合机制，显著提升了在复杂多人场景中定位目标人物和识别细粒度动作的能力。

Abstract: Referring Atomic Video Action Recognition (RAVAR) aims to recognize
fine-grained, atomic-level actions of a specific person of interest conditioned
on natural language descriptions. Distinct from conventional action recognition
and detection tasks, RAVAR emphasizes precise language-guided action
understanding, which is particularly critical for interactive human action
analysis in complex multi-person scenarios. In this work, we extend our
previously introduced RefAVA dataset to RefAVA++, which comprises >2.9 million
frames and >75.1k annotated persons in total. We benchmark this dataset using
baselines from multiple related domains, including atomic action localization,
video question answering, and text-video retrieval, as well as our earlier
model, RefAtomNet. Although RefAtomNet surpasses other baselines by
incorporating agent attention to highlight salient features, its ability to
align and retrieve cross-modal information remains limited, leading to
suboptimal performance in localizing the target person and predicting
fine-grained actions. To overcome the aforementioned limitations, we introduce
RefAtomNet++, a novel framework that advances cross-modal token aggregation
through a multi-hierarchical semantic-aligned cross-attention mechanism
combined with multi-trajectory Mamba modeling at the partial-keyword,
scene-attribute, and holistic-sentence levels. In particular, scanning
trajectories are constructed by dynamically selecting the nearest visual
spatial tokens at each timestep for both partial-keyword and scene-attribute
levels. Moreover, we design a multi-hierarchical semantic-aligned
cross-attention strategy, enabling more effective aggregation of spatial and
temporal tokens across different semantic hierarchies. Experiments show that
RefAtomNet++ establishes new state-of-the-art results. The dataset and code are
released at https://github.com/KPeng9510/refAVA2.

</details>


### [7] [GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer](https://arxiv.org/abs/2510.16136)
*Sayan Deb Sarkar,Sinisa Stekovic,Vincent Lepetit,Iro Armeni*

Main category: cs.CV

TL;DR: 提出了一种基于通用引导的训练无关方法，通过周期性添加引导来将外观（图像或文本）转移到3D资产上，解决了输入和外观对象几何差异较大时的纹理和几何细节转移问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法在输入和外观对象的几何差异较大时效果不佳，直接应用3D生成模型无法产生有吸引力的结果，需要一种更原则性的方法来实现外观转移。

Method: 使用预训练的整流流模型，在采样过程中周期性添加可微损失函数作为引导，包括部分感知损失和自相似性损失，无需训练即可实现外观转移。

Result: 方法成功将纹理和几何细节转移到输入3D资产，在定性和定量评估中均优于基线方法，并通过GPT-based系统和用户研究验证了评估效果。

Conclusion: 该方法具有通用性，可扩展到不同类型的扩散模型和引导函数，为外观转移任务提供了有效的解决方案。

Abstract: Transferring appearance to 3D assets using different representations of the
appearance object - such as images or text - has garnered interest due to its
wide range of applications in industries like gaming, augmented reality, and
digital content creation. However, state-of-the-art methods still fail when the
geometry between the input and appearance objects is significantly different. A
straightforward approach is to directly apply a 3D generative model, but we
show that this ultimately fails to produce appealing results. Instead, we
propose a principled approach inspired by universal guidance. Given a
pretrained rectified flow model conditioned on image or text, our training-free
method interacts with the sampling process by periodically adding guidance.
This guidance can be modeled as a differentiable loss function, and we
experiment with two different types of guidance including part-aware losses for
appearance and self-similarity. Our experiments show that our approach
successfully transfers texture and geometric details to the input 3D asset,
outperforming baselines both qualitatively and quantitatively. We also show
that traditional metrics are not suitable for evaluating the task due to their
inability of focusing on local details and comparing dissimilar inputs, in
absence of ground truth data. We thus evaluate appearance transfer quality with
a GPT-based system objectively ranking outputs, ensuring robust and human-like
assessment, as further confirmed by our user study. Beyond showcased scenarios,
our method is general and could be extended to different types of diffusion
models and guidance functions.

</details>


### [8] [Person Re-Identification via Generalized Class Prototypes](https://arxiv.org/abs/2510.17043)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 本文提出了一种改进行人重识别性能的广义选择方法，通过选择不限于类别质心的表示来平衡准确率和平均精度均值，在各种重识别嵌入上都显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 虽然先进的特征提取方法和目标函数改进已经显著提升了行人重识别性能，但选择更好的类别代表是一个研究不足的领域。现有方法主要使用图库图像类别的质心，但在检索阶段使用替代表示的研究较少。

Method: 提出了一种广义选择方法，选择不限于类别质心的表示。该方法可以调整每个类别的实际表示数量以满足特定应用需求，并在多种重识别嵌入上应用。

Result: 该方法在准确率和平均精度均值之间取得了平衡，超越了现有技术水平。在各种重识别嵌入上都显著改进了当代结果。

Conclusion: 广义选择方法通过优化类别表示选择，为行人重识别任务提供了有效的性能提升方案，能够适应不同的应用需求。

Abstract: Advanced feature extraction methods have significantly contributed to
enhancing the task of person re-identification. In addition, modifications to
objective functions have been developed to further improve performance.
Nonetheless, selecting better class representatives is an underexplored area of
research that can also lead to advancements in re-identification performance.
Although past works have experimented with using the centroid of a gallery
image class during training, only a few have investigated alternative
representations during the retrieval stage. In this paper, we demonstrate that
these prior techniques yield suboptimal results in terms of re-identification
metrics. To address the re-identification problem, we propose a generalized
selection method that involves choosing representations that are not limited to
class centroids. Our approach strikes a balance between accuracy and mean
average precision, leading to improvements beyond the state of the art. For
example, the actual number of representations per class can be adjusted to meet
specific application requirements. We apply our methodology on top of multiple
re-identification embeddings, and in all cases it substantially improves upon
contemporary results

</details>


### [9] [Universal and Transferable Attacks on Pathology Foundation Models](https://arxiv.org/abs/2510.16660)
*Yuntian Wang,Xilin Yang,Che-Yung Shen,Nir Pillar,Aydogan Ozcan*

Main category: cs.CV

TL;DR: 本文提出了针对病理学基础模型的通用可迁移对抗扰动（UTAP），这是一种固定的弱噪声模式，能够系统性地破坏多个病理学基础模型的特征表示能力，导致下游任务性能下降。


<details>
  <summary>Details</summary>
Motivation: 揭示病理学基础模型的关键脆弱性，为模型鲁棒性评估建立高标准基准，推动防御机制发展，确保AI在病理学中的安全可靠部署。

Method: 使用深度学习优化生成固定的弱噪声模式（UTAP），将其添加到病理图像中，系统性地破坏多个病理学基础模型的特征表示能力。

Result: UTAP能够在多种最先进的病理学基础模型上引起显著性能下降，且对输入图像的视觉修改难以察觉，具有跨数据集和跨模型的通用性和可迁移性。

Conclusion: UTAP构成了对各种新兴病理学基础模型及其应用的广泛威胁，强调了推进防御机制和对抗训练的必要性，为模型鲁棒性评估提供了关键基准。

Abstract: We introduce Universal and Transferable Adversarial Perturbations (UTAP) for
pathology foundation models that reveal critical vulnerabilities in their
capabilities. Optimized using deep learning, UTAP comprises a fixed and weak
noise pattern that, when added to a pathology image, systematically disrupts
the feature representation capabilities of multiple pathology foundation
models. Therefore, UTAP induces performance drops in downstream tasks that
utilize foundation models, including misclassification across a wide range of
unseen data distributions. In addition to compromising the model performance,
we demonstrate two key features of UTAP: (1) universality: its perturbation can
be applied across diverse field-of-views independent of the dataset that UTAP
was developed on, and (2) transferability: its perturbation can successfully
degrade the performance of various external, black-box pathology foundation
models - never seen before. These two features indicate that UTAP is not a
dedicated attack associated with a specific foundation model or image dataset,
but rather constitutes a broad threat to various emerging pathology foundation
models and their applications. We systematically evaluated UTAP across various
state-of-the-art pathology foundation models on multiple datasets, causing a
significant drop in their performance with visually imperceptible modifications
to the input images using a fixed noise pattern. The development of these
potent attacks establishes a critical, high-standard benchmark for model
robustness evaluation, highlighting a need for advancing defense mechanisms and
potentially providing the necessary assets for adversarial training to ensure
the safe and reliable deployment of AI in pathology.

</details>


### [10] [C-arm Guidance: A Self-supervised Approach To Automated Positioning During Stroke Thrombectomy](https://arxiv.org/abs/2510.16145)
*Ahmad Arrabi,Jay hwasung Jung,J Le,A Nguyen,J Reed,E Stahl,Nathan Franssen,Scott Raymond,Safwan Wshah*

Main category: cs.CV

TL;DR: 提出一种用于血栓切除术的自监督深度学习框架，通过回归任务分类骨骼标志点，显著提升下游分类性能，旨在实现C臂自主控制以优化手术轨迹。


<details>
  <summary>Details</summary>
Motivation: 血栓切除术是缺血性中风最有效的治疗方法之一，但资源密集且人员需求高。通过深度学习自动化关键环节可提高效率和安全性。

Method: 引入自监督框架，使用基于回归的前置任务分类各种骨骼标志点。

Result: 实验表明该模型在回归和分类任务中均优于现有方法，位置前置任务显著提升下游分类性能。

Conclusion: 未来工作将扩展该框架实现完全自主的C臂控制，优化从中风血栓切除术中从骨盆到头部的轨迹。

Abstract: Thrombectomy is one of the most effective treatments for ischemic stroke, but
it is resource and personnel-intensive. We propose employing deep learning to
automate critical aspects of thrombectomy, thereby enhancing efficiency and
safety. In this work, we introduce a self-supervised framework that classifies
various skeletal landmarks using a regression-based pretext task. Our
experiments demonstrate that our model outperforms existing methods in both
regression and classification tasks. Notably, our results indicate that the
positional pretext task significantly enhances downstream classification
performance. Future work will focus on extending this framework toward fully
autonomous C-arm control, aiming to optimize trajectories from the pelvis to
the head during stroke thrombectomy procedures. All code used is available at
https://github.com/AhmadArrabi/C_arm_guidance

</details>


### [11] [Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis](https://arxiv.org/abs/2510.16973)
*Praveenbalaji Rajendran,Mojtaba Safari,Wenfeng He,Mingzhe Hu,Shansong Wang,Jun Zhou,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 本文综述了医学图像分析中基础模型的研究现状，系统分类了视觉专用和视觉语言基础模型，分析了架构、训练策略和临床应用，并讨论了领域适应、高效微调等挑战及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在医学图像分析中快速发展，但该领域仍缺乏对架构演变、训练范式和临床应用的系统性综合，需要统一的分析框架来指导未来研究。

Method: 采用系统分类方法将研究分为视觉专用和视觉语言基础模型，基于架构基础、训练策略和下游临床任务进行结构化分析，并进行定量元分析以表征数据集利用和应用领域的时间趋势。

Result: 揭示了基础模型在医学图像分析中的多样化应用，从分割到报告生成等任务，展示了强大的零样本和少样本性能，同时识别了领域适应、计算约束等关键挑战。

Conclusion: 基础模型在医学图像分析中具有巨大潜力，但需要解决鲁棒性、可解释性和临床集成等关键问题，通过联邦学习、知识蒸馏等新兴解决方案加速其向实际医疗实践的转化。

Abstract: Recent advancements in artificial intelligence (AI), particularly foundation
models (FMs), have revolutionized medical image analysis, demonstrating strong
zero- and few-shot performance across diverse medical imaging tasks, from
segmentation to report generation. Unlike traditional task-specific AI models,
FMs leverage large corpora of labeled and unlabeled multimodal datasets to
learn generalized representations that can be adapted to various downstream
clinical applications with minimal fine-tuning. However, despite the rapid
proliferation of FM research in medical imaging, the field remains fragmented,
lacking a unified synthesis that systematically maps the evolution of
architectures, training paradigms, and clinical applications across modalities.
To address this gap, this review article provides a comprehensive and
structured analysis of FMs in medical image analysis. We systematically
categorize studies into vision-only and vision-language FMs based on their
architectural foundations, training strategies, and downstream clinical tasks.
Additionally, a quantitative meta-analysis of the studies was conducted to
characterize temporal trends in dataset utilization and application domains. We
also critically discuss persistent challenges, including domain adaptation,
efficient fine-tuning, computational constraints, and interpretability along
with emerging solutions such as federated learning, knowledge distillation, and
advanced prompting. Finally, we identify key future research directions aimed
at enhancing the robustness, explainability, and clinical integration of FMs,
thereby accelerating their translation into real-world medical practice.

</details>


### [12] [Automated C-Arm Positioning via Conformal Landmark Localization](https://arxiv.org/abs/2510.16160)
*Ahmad Arrabi,Jay Hwasung Jung,Jax Luo,Nathan Franssen,Scott Raymond,Safwan Wshah*

Main category: cs.CV

TL;DR: 提出了一种自主导航C臂到预定义解剖标志的管道，利用X射线图像预测3D位移向量，结合不确定性估计和保形预测确保可靠性。


<details>
  <summary>Details</summary>
Motivation: C臂精确定位对荧光引导介入至关重要，但临床工作流程依赖手动对齐，会增加辐射暴露和手术延迟。

Method: 使用X射线图像预测3D位移向量，捕获预测中的不确定度，通过保形预测校准，结合概率损失和骨骼姿态正则化训练。

Result: 在DeepDRR生成的合成X射线数据集上验证，显示强定位精度和良好校准的预测边界。

Conclusion: 该管道有潜力作为安全可靠自主C臂系统的组成部分。

Abstract: Accurate and reliable C-arm positioning is essential for fluoroscopy-guided
interventions. However, clinical workflows rely on manual alignment that
increases radiation exposure and procedural delays. In this work, we present a
pipeline that autonomously navigates the C-arm to predefined anatomical
landmarks utilizing X-ray images. Given an input X-ray image from an arbitrary
starting location on the operating table, the model predicts a 3D displacement
vector toward each target landmark along the body. To ensure reliable
deployment, we capture both aleatoric and epistemic uncertainties in the
model's predictions and further calibrate them using conformal prediction. The
derived prediction regions are interpreted as 3D confidence regions around the
predicted landmark locations. The training framework combines a probabilistic
loss with skeletal pose regularization to encourage anatomically plausible
outputs. We validate our approach on a synthetic X-ray dataset generated from
DeepDRR. Results show not only strong localization accuracy across multiple
architectures but also well-calibrated prediction bounds. These findings
highlight the pipeline's potential as a component in safe and reliable
autonomous C-arm systems. Code is available at
https://github.com/AhmadArrabi/C_arm_guidance_APAH

</details>


### [13] [Cost Savings from Automatic Quality Assessment of Generated Images](https://arxiv.org/abs/2510.16179)
*Xavier Giro-i-Nieto,Nefeli Andreou,Anqi Liang,Manel Baradad,Francesc Moreno-Noguer,Aleix Martinez*

Main category: cs.CV

TL;DR: 本文提出了一种自动图像质量评估预过滤方法，通过公式估算成本节约，在背景修复用例中实现了51.61%的成本节约。


<details>
  <summary>Details</summary>
Motivation: 当前深度生成模型生成的图像质量尚未达到传统摄影方法的标准，生产流程中需要手动图像质量评估，这个过程既缓慢又昂贵，特别是由于自动生成图像通过质量标准的比例较低。

Method: 引入自动预过滤阶段来减少图像质量评估工作量，提出了一个估算通用IQA引擎精度和通过率相关成本节约的公式，并应用了简单的AutoML解决方案。

Result: 在背景修复用例中，通过简单的AutoML解决方案实现了51.61%的显著成本节约。

Conclusion: 自动预过滤方法可以有效提高发送审核图像的整体质量，从而降低获得高质量图像的平均成本，为生产流程带来显著的经济效益。

Abstract: Deep generative models have shown impressive progress in recent years, making
it possible to produce high quality images with a simple text prompt or a
reference image. However, state of the art technology does not yet meet the
quality standards offered by traditional photographic methods. For this reason,
production pipelines that use generated images often include a manual stage of
image quality assessment (IQA). This process is slow and expensive, especially
because of the low yield of automatically generated images that pass the
quality bar. The IQA workload can be reduced by introducing an automatic
pre-filtering stage, that will increase the overall quality of the images sent
to review and, therefore, reduce the average cost required to obtain a high
quality image. We present a formula that estimates the cost savings depending
on the precision and pass yield of a generic IQA engine. This formula is
applied in a use case of background inpainting, showcasing a significant cost
saving of 51.61% obtained with a simple AutoML solution.

</details>


### [14] [Data-Centric AI for Tropical Agricultural Mapping: Challenges, Strategies and Scalable Solutions](https://arxiv.org/abs/2510.16207)
*Mateus Pinto da Silva,Sabrina P. L. P. Correa,Hugo N. Oliveira,Ian M. Nunes,Jefersson A. dos Santos*

Main category: cs.CV

TL;DR: 本文提出了一种数据为中心的人工智能方法来解决热带农业遥感制图面临的挑战，包括数据质量差、标注成本高、数据变异性和区域泛化问题。


<details>
  <summary>Details</summary>
Motivation: 热带地区农业遥感制图面临独特挑战：缺乏高质量标注数据、标注成本高、数据变异性大、区域泛化困难。传统以模型为中心的方法受到高云量、多样化作物日历和有限数据集的限制。

Method: 采用数据为中心的人工智能视角和流程，强调数据质量和整理作为模型鲁棒性和可扩展性的关键驱动因素。重点技术包括置信学习、核心集选择、数据增强和主动学习。

Result: 确定了25种适用于大规模农业制图流程的策略，并提出了使用9种最成熟和直接方法的实用流程。

Conclusion: 数据为中心的方法能够更好地适应热带农业的动态现实，为大规模热带农业制图项目提供了实用的解决方案。

Abstract: Mapping agriculture in tropical areas through remote sensing presents unique
challenges, including the lack of high-quality annotated data, the elevated
costs of labeling, data variability, and regional generalisation. This paper
advocates a Data-Centric Artificial Intelligence (DCAI) perspective and
pipeline, emphasizing data quality and curation as key drivers for model
robustness and scalability. It reviews and prioritizes techniques such as
confident learning, core-set selection, data augmentation, and active learning.
The paper highlights the readiness and suitability of 25 distinct strategies in
large-scale agricultural mapping pipelines. The tropical context is of high
interest, since high cloudiness, diverse crop calendars, and limited datasets
limit traditional model-centric approaches. This tutorial outlines practical
solutions as a data-centric approach for curating and training AI models better
suited to the dynamic realities of tropical agriculture. Finally, we propose a
practical pipeline using the 9 most mature and straightforward methods that can
be applied to a large-scale tropical agricultural mapping project.

</details>


### [15] [Embody 3D: A Large-scale Multimodal Motion and Behavior Dataset](https://arxiv.org/abs/2510.16258)
*Claire McLean,Makenzie Meendering,Tristan Swartz,Orri Gabbay,Alexandra Olsen,Rachel Jacobs,Nicholas Rosen,Philippe de Bree,Tony Garcia,Gadsden Merrill,Jake Sandakly,Julia Buffalini,Neham Jain,Steven Krenn,Moneish Kumar,Dejan Markovic,Evonne Ng,Fabian Prada,Andrew Saba,Siwei Zhang,Vasu Agrawal,Tim Godisart,Alexander Richard,Michael Zollhoefer*

Main category: cs.CV

TL;DR: Embody 3D是一个包含500小时3D运动数据的多模态数据集，涵盖439名参与者的单人和多人行为数据，包括手势、运动、对话和协作活动。


<details>
  <summary>Details</summary>
Motivation: 创建大规模、高质量的3D人体运动数据集，支持多模态行为分析和人机交互研究。

Method: 在多摄像头采集环境中收集439名参与者的运动数据，包括身体追踪、手部追踪、身体形状、文本标注和独立音频轨道。

Result: 构建了包含54百万帧3D运动追踪数据的数据集，涵盖广泛的单人和多人行为场景。

Conclusion: Embody 3D为研究社区提供了丰富的3D人体运动数据资源，支持多模态行为分析和人机交互应用开发。

Abstract: The Codec Avatars Lab at Meta introduces Embody 3D, a multimodal dataset of
500 individual hours of 3D motion data from 439 participants collected in a
multi-camera collection stage, amounting to over 54 million frames of tracked
3D motion. The dataset features a wide range of single-person motion data,
including prompted motions, hand gestures, and locomotion; as well as
multi-person behavioral and conversational data like discussions, conversations
in different emotional states, collaborative activities, and co-living
scenarios in an apartment-like space. We provide tracked human motion including
hand tracking and body shape, text annotations, and a separate audio track for
each participant.

</details>


### [16] [Proactive Scene Decomposition and Reconstruction](https://arxiv.org/abs/2510.16272)
*Baicheng Li,Zike Yan,Dong Wu,Hongbin Zha*

Main category: cs.CV

TL;DR: 提出了一种主动场景分解与重建的新任务，利用人-物交互在线迭代地分解和重建动态环境，通过高斯泼溅技术实现逼真高效渲染。


<details>
  <summary>Details</summary>
Motivation: 人类行为是场景动态的主要来源，包含丰富的动态线索。静态物体级重建存在固有模糊性，需要利用人类意图交互来解决这些模糊性。

Method: 提出在线方法，通过观察人-物交互迭代分解和重建环境，整合相机和物体姿态估计、实例分解、在线地图更新等多个任务，使用高斯泼溅技术进行动态场景建模。

Result: 在多个真实场景中验证了有效性，实现了准确一致的动态场景建模，具有逼真高效的渲染效果。

Conclusion: 该方法为传统物体级重建方法提供了灵活渐进的替代方案，能够利用第一人称视角直播中的人-物交互线索，有效解决动态环境中的重建问题。

Abstract: Human behaviors are the major causes of scene dynamics and inherently contain
rich cues regarding the dynamics. This paper formalizes a new task of proactive
scene decomposition and reconstruction, an online approach that leverages
human-object interactions to iteratively disassemble and reconstruct the
environment. By observing these intentional interactions, we can dynamically
refine the decomposition and reconstruction process, addressing inherent
ambiguities in static object-level reconstruction. The proposed system
effectively integrates multiple tasks in dynamic environments such as accurate
camera and object pose estimation, instance decomposition, and online map
updating, capitalizing on cues from human-object interactions in egocentric
live streams for a flexible, progressive alternative to conventional
object-level reconstruction methods. Aided by the Gaussian splatting technique,
accurate and consistent dynamic scene modeling is achieved with photorealistic
and efficient rendering. The efficacy is validated in multiple real-world
scenarios with promising advantages.

</details>


### [17] [Cerberus: Real-Time Video Anomaly Detection via Cascaded Vision-Language Models](https://arxiv.org/abs/2510.16290)
*Yue Zheng,Xiufang Shi,Jiming Chen,Yuanchao Shu*

Main category: cs.CV

TL;DR: Cerberus是一个用于实时视频异常检测的两级级联系统，通过离线学习正常行为规则，结合轻量级过滤和细粒度视觉语言模型推理，在保持高精度的同时实现57.68 fps的实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的视频异常检测方法虽然具有优秀的零样本检测能力，但计算成本巨大且视觉定位性能不稳定，阻碍了实时部署。

Method: 采用两级级联系统：离线学习正常行为规则，在线推理时结合轻量级过滤和细粒度VLM推理。关键创新包括运动掩码提示和基于规则的偏差检测。

Result: 在四个数据集上的评估显示，Cerberus在NVIDIA L40S GPU上平均达到57.68 fps，速度提升151.79倍，准确率达到97.2%，与最先进的VLM-based VAD方法相当。

Conclusion: Cerberus为实时视频分析提供了一个实用的解决方案，在保持高精度的同时实现了显著的性能提升。

Abstract: Video anomaly detection (VAD) has rapidly advanced by recent development of
Vision-Language Models (VLMs). While these models offer superior zero-shot
detection capabilities, their immense computational cost and unstable visual
grounding performance hinder real-time deployment. To overcome these
challenges, we introduce Cerberus, a two-stage cascaded system designed for
efficient yet accurate real-time VAD. Cerberus learns normal behavioral rules
offline, and combines lightweight filtering with fine-grained VLM reasoning
during online inference. The performance gains of Cerberus come from two key
innovations: motion mask prompting and rule-based deviation detection. The
former directs the VLM's attention to regions relevant to motion, while the
latter identifies anomalies as deviations from learned norms rather than
enumerating possible anomalies. Extensive evaluations on four datasets show
that Cerberus on average achieves 57.68 fps on an NVIDIA L40S GPU, a
151.79$\times$ speedup, and 97.2\% accuracy comparable to the state-of-the-art
VLM-based VAD methods, establishing it as a practical solution for real-time
video analytics.

</details>


### [18] [OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models](https://arxiv.org/abs/2510.16295)
*Ryoto Miyamoto,Xin Fan,Fuyuko Kido,Tsuneo Matsumoto,Hayato Yamana*

Main category: cs.CV

TL;DR: OpenLVLM-MIA是一个新的基准测试，揭示了评估大型视觉语言模型成员推理攻击的基本挑战，指出先前高攻击成功率主要源于检测数据集构建中的分布偏差而非真实成员状态识别。


<details>
  <summary>Details</summary>
Motivation: 现有研究报道的成员推理攻击高成功率可能源于数据集构建中的分布偏差，而非真实识别成员状态，需要建立一个无偏基准来准确评估攻击性能。

Method: 引入包含6,000张图像的受控基准，其中成员和非成员样本分布经过仔细平衡，并提供三个不同训练阶段的真实成员标签。

Result: 在无偏条件下，最先进的成员推理攻击方法性能收敛到随机猜测水平，表明先前的高成功率主要源于分布偏差。

Conclusion: OpenLVLM-MIA为LVLMs成员推理攻击研究提供了透明无偏的基准，明确了当前方法的局限性，并为开发更强的隐私保护技术奠定了基础。

Abstract: OpenLVLM-MIA is a new benchmark that highlights fundamental challenges in
evaluating membership inference attacks (MIA) against large vision-language
models (LVLMs). While prior work has reported high attack success rates, our
analysis suggests that these results often arise from detecting distributional
bias introduced during dataset construction rather than from identifying true
membership status. To address this issue, we introduce a controlled benchmark
of 6{,}000 images where the distributions of member and non-member samples are
carefully balanced, and ground-truth membership labels are provided across
three distinct training stages. Experiments using OpenLVLM-MIA demonstrated
that the performance of state-of-the-art MIA methods converged to random chance
under unbiased conditions. By offering a transparent and unbiased benchmark,
OpenLVLM-MIA clarifies the current limitations of MIA research on LVLMs and
provides a solid foundation for developing stronger privacy-preserving
techniques.

</details>


### [19] [Stroke2Sketch: Harnessing Stroke Attributes for Training-Free Sketch Generation](https://arxiv.org/abs/2510.16319)
*Rui Yang,Huining Li,Yiyi Long,Xiaojun Wu,Shengfeng He*

Main category: cs.CV

TL;DR: Stroke2Sketch是一个无需训练的新框架，通过跨图像笔画注意机制实现参考风格的笔画属性精确转移，同时保持语义结构和内容保真度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成参考风格引导的草图时，难以精确传递笔画属性（如线条粗细、变形和纹理稀疏度），同时保持语义结构和内容保真度。

Method: 提出跨图像笔画注意力机制，嵌入自注意力层中建立细粒度语义对应关系；开发自适应对比度增强和语义聚焦注意力来加强内容保存和前景强调。

Result: Stroke2Sketch能够有效合成风格忠实的草图，与手工制作结果高度相似，在表达性笔画控制和语义连贯性方面优于现有方法。

Conclusion: 该框架通过创新的注意力机制实现了精确的笔画属性转移，为风格化草图生成提供了有效的解决方案。

Abstract: Generating sketches guided by reference styles requires precise transfer of
stroke attributes, such as line thickness, deformation, and texture sparsity,
while preserving semantic structure and content fidelity. To this end, we
propose Stroke2Sketch, a novel training-free framework that introduces
cross-image stroke attention, a mechanism embedded within self-attention layers
to establish fine-grained semantic correspondences and enable accurate stroke
attribute transfer. This allows our method to adaptively integrate reference
stroke characteristics into content images while maintaining structural
integrity. Additionally, we develop adaptive contrast enhancement and
semantic-focused attention to reinforce content preservation and foreground
emphasis. Stroke2Sketch effectively synthesizes stylistically faithful sketches
that closely resemble handcrafted results, outperforming existing methods in
expressive stroke control and semantic coherence. Codes are available at
https://github.com/rane7/Stroke2Sketch.

</details>


### [20] [Scaling Laws for Deepfake Detection](https://arxiv.org/abs/2510.16320)
*Wenhao Wang,Longqi Cai,Taihong Xiao,Yuxiao Wang,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 本文系统研究了深度伪造检测任务的缩放规律，发现检测误差随真实图像域数量和深度伪造方法数量呈幂律衰减，类似于大语言模型的缩放规律。


<details>
  <summary>Details</summary>
Motivation: 由于现有数据集规模不足以研究深度伪造检测的缩放规律，作者构建了ScaleDF数据集来系统分析模型性能与真实图像域数量、深度伪造生成方法和训练图像数量之间的关系。

Method: 构建了ScaleDF数据集（包含51个真实图像域的580万张真实图像和102种深度伪造方法生成的880万张伪造图像），通过该数据集分析检测误差与真实域数量、伪造方法数量之间的幂律关系。

Result: 观察到检测平均误差随真实图像域数量或深度伪造方法数量的增加呈可预测的幂律衰减，可以据此预测达到目标性能所需的额外真实域或伪造方法数量。

Conclusion: 深度伪造检测任务存在类似大语言模型的幂律缩放规律，这为以数据为中心的方式对抗不断演进的深度伪造技术提供了新思路，同时研究了预训练和数据增强在缩放中的作用以及缩放本身的局限性。

Abstract: This paper presents a systematic study of scaling laws for the deepfake
detection task. Specifically, we analyze the model performance against the
number of real image domains, deepfake generation methods, and training images.
Since no existing dataset meets the scale requirements for this research, we
construct ScaleDF, the largest dataset to date in this field, which contains
over 5.8 million real images from 51 different datasets (domains) and more than
8.8 million fake images generated by 102 deepfake methods. Using ScaleDF, we
observe power-law scaling similar to that shown in large language models
(LLMs). Specifically, the average detection error follows a predictable
power-law decay as either the number of real domains or the number of deepfake
methods increases. This key observation not only allows us to forecast the
number of additional real domains or deepfake methods required to reach a
target performance, but also inspires us to counter the evolving deepfake
technology in a data-centric manner. Beyond this, we examine the role of
pre-training and data augmentations in deepfake detection under scaling, as
well as the limitations of scaling itself.

</details>


### [21] [Scale-DiT: Ultra-High-Resolution Image Generation with Hierarchical Local Attention](https://arxiv.org/abs/2510.16325)
*Yuyao Zhang,Yu-Wing Tai*

Main category: cs.CV

TL;DR: Scale-DiT是一个用于超高分辨率文本到图像生成的扩散框架，通过分层局部注意力和低分辨率全局引导，实现了4K分辨率的高效、可扩展图像合成，无需额外高分辨率训练数据。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型受限于注意力机制的二次复杂性和缺乏原生4K训练数据，无法实现超高分辨率图像生成，需要开发更高效的架构。

Method: 采用分层局部注意力机制，将高分辨率潜在空间划分为固定大小的局部窗口以降低计算复杂度；使用低分辨率潜在空间注入全局语义；通过LoRA适应桥接全局和局部路径；采用Hilbert曲线重新排列令牌序列和融合内核优化推理效率。

Result: Scale-DiT相比密集注意力基线实现了2倍以上的推理速度提升和更低的内存使用，能够可靠扩展到4K×4K分辨率，在定量指标（FID、IS、CLIP Score）和定性比较中均表现出优越的全局一致性和更锐利的局部细节。

Conclusion: 分层局部注意力与引导低分辨率锚点相结合是推进超高分辨率图像生成的有效方法，Scale-DiT框架在不依赖原生4K训练数据的情况下实现了与最先进方法相当或更优的性能。

Abstract: Ultra-high-resolution text-to-image generation demands both fine-grained
texture synthesis and globally coherent structure, yet current diffusion models
remain constrained to sub-$1K \times 1K$ resolutions due to the prohibitive
quadratic complexity of attention and the scarcity of native $4K$ training
data. We present \textbf{Scale-DiT}, a new diffusion framework that introduces
hierarchical local attention with low-resolution global guidance, enabling
efficient, scalable, and semantically coherent image synthesis at ultra-high
resolutions. Specifically, high-resolution latents are divided into fixed-size
local windows to reduce attention complexity from quadratic to near-linear,
while a low-resolution latent equipped with scaled positional anchors injects
global semantics. A lightweight LoRA adaptation bridges global and local
pathways during denoising, ensuring consistency across structure and detail. To
maximize inference efficiency, we repermute token sequence in Hilbert curve
order and implement a fused-kernel for skipping masked operations, resulting in
a GPU-friendly design. Extensive experiments demonstrate that Scale-DiT
achieves more than $2\times$ faster inference and lower memory usage compared
to dense attention baselines, while reliably scaling to $4K \times 4K$
resolution without requiring additional high-resolution training data. On both
quantitative benchmarks (FID, IS, CLIP Score) and qualitative comparisons,
Scale-DiT delivers superior global coherence and sharper local detail, matching
or outperforming state-of-the-art methods that rely on native 4K training.
Taken together, these results highlight hierarchical local attention with
guided low-resolution anchors as a promising and effective approach for
advancing ultra-high-resolution image generation.

</details>


### [22] [DiffusionX: Efficient Edge-Cloud Collaborative Image Generation with Multi-Round Prompt Evolution](https://arxiv.org/abs/2510.16326)
*Yi Wei,Shunpu Tang,Liang Zhao,Qiangian Yang*

Main category: cs.CV

TL;DR: DiffusionX是一个云边协同框架，通过轻量级设备端扩散模型快速生成预览图像，云端大模型进行最终优化，结合噪声水平预测器动态平衡计算负载，在保持图像质量的同时显著降低生成时间。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型生成过程计算密集、用户需要多次迭代优化提示词导致延迟增加和云资源负担重的问题。

Method: 提出云边协同框架，设备端轻量扩散模型与用户交互生成预览，云端大模型进行最终优化；引入噪声水平预测器动态平衡计算负载。

Result: 与Stable Diffusion v1.5相比平均生成时间减少15.8%，图像质量相当；比Tiny-SD仅慢0.9%但图像质量显著提升。

Conclusion: DiffusionX在保持图像质量的同时显著提升了生成效率，具有高效性和可扩展性，且额外开销极小。

Abstract: Recent advances in diffusion models have driven remarkable progress in image
generation. However, the generation process remains computationally intensive,
and users often need to iteratively refine prompts to achieve the desired
results, further increasing latency and placing a heavy burden on cloud
resources. To address this challenge, we propose DiffusionX, a cloud-edge
collaborative framework for efficient multi-round, prompt-based generation. In
this system, a lightweight on-device diffusion model interacts with users by
rapidly producing preview images, while a high-capacity cloud model performs
final refinements after the prompt is finalized. We further introduce a noise
level predictor that dynamically balances the computation load, optimizing the
trade-off between latency and cloud workload. Experiments show that DiffusionX
reduces average generation time by 15.8% compared with Stable Diffusion v1.5,
while maintaining comparable image quality. Moreover, it is only 0.9% slower
than Tiny-SD with significantly improved image quality, thereby demonstrating
efficiency and scalability with minimal overhead.

</details>


### [23] [TokenAR: Multiple Subject Generation via Autoregressive Token-level enhancement](https://arxiv.org/abs/2510.16332)
*Haiyue Sun,Qingdong He,Jinlong Peng,Peng Tang,Jiangning Zhang,Junwei Zhu,Xiaobin Hu,Shuicheng Yan*

Main category: cs.CV

TL;DR: TokenAR框架通过token级增强机制解决多参考图像生成中的身份混淆问题，包含Token索引嵌入、指令token注入和身份token解缠策略，显著提升身份一致性和背景重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归模型在多参考图像生成中存在身份解耦困难的问题，导致参考身份混淆。

Method: 提出TokenAR框架，包含三个token级增强组件：Token索引嵌入、指令token注入和身份token解缠策略，通过改进token表示来独立表示每个身份特征。

Result: 在多个参考图像生成任务中超越了当前最先进模型，实现了良好的身份一致性和高质量的背景重建。

Conclusion: TokenAR框架有效解决了多参考图像生成中的身份混淆问题，为高质量、高多样性的多主体生成提供了有效解决方案。

Abstract: Autoregressive Model (AR) has shown remarkable success in conditional image
generation. However, these approaches for multiple reference generation
struggle with decoupling different reference identities. In this work, we
propose the TokenAR framework, specifically focused on a simple but effective
token-level enhancement mechanism to address reference identity confusion
problem. Such token-level enhancement consists of three parts, 1). Token Index
Embedding clusters the tokens index for better representing the same reference
images; 2). Instruct Token Injection plays as a role of extra visual feature
container to inject detailed and complementary priors for reference tokens; 3).
The identity-token disentanglement strategy (ITD) explicitly guides the token
representations toward independently representing the features of each
identity.This token-enhancement framework significantly augments the
capabilities of existing AR based methods in conditional image generation,
enabling good identity consistency while preserving high quality background
reconstruction. Driven by the goal of high-quality and high-diversity in
multi-subject generation, we introduce the InstructAR Dataset, the first
open-source, large-scale, multi-reference input, open domain image generation
dataset that includes 28K training pairs, each example has two reference
subjects, a relative prompt and a background with mask annotation, curated for
multiple reference image generation training and evaluating. Comprehensive
experiments validate that our approach surpasses current state-of-the-art
models in multiple reference image generation task. The implementation code and
datasets will be made publicly. Codes are available, see
https://github.com/lyrig/TokenAR

</details>


### [24] [On the Provable Importance of Gradients for Language-Assisted Image Clustering](https://arxiv.org/abs/2510.16335)
*Bo Peng,Jie Lu,Guangquan Zhang,Zhen Fang*

Main category: cs.CV

TL;DR: 本文提出了一种基于梯度的框架GradNorm，用于解决语言辅助图像聚类中的正名词过滤问题，通过理论保证和实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的语言辅助图像聚类方法主要依赖CLIP学习的特征空间来过滤正名词，但这些策略缺乏严格的理论基础。

Method: 提出GradNorm框架，通过反向传播交叉熵损失的梯度幅度来度量名词的积极性，并提供了严格的理论误差界。

Result: 理论证明GradNorm自然包含现有过滤策略作为特例，实验表明在各种基准测试中达到最先进的聚类性能。

Conclusion: GradNorm为语言辅助图像聚类提供了理论基础和有效的正名词过滤方法，显著提升了聚类性能。

Abstract: This paper investigates the recently emerged problem of Language-assisted
Image Clustering (LaIC), where textual semantics are leveraged to improve the
discriminability of visual representations to facilitate image clustering. Due
to the unavailability of true class names, one of core challenges of LaIC lies
in how to filter positive nouns, i.e., those semantically close to the images
of interest, from unlabeled wild corpus data. Existing filtering strategies are
predominantly based on the off-the-shelf feature space learned by CLIP;
however, despite being intuitive, these strategies lack a rigorous theoretical
foundation. To fill this gap, we propose a novel gradient-based framework,
termed as GradNorm, which is theoretically guaranteed and shows strong
empirical performance. In particular, we measure the positiveness of each noun
based on the magnitude of gradients back-propagated from the cross-entropy
between the predicted target distribution and the softmax output.
Theoretically, we provide a rigorous error bound to quantify the separability
of positive nouns by GradNorm and prove that GradNorm naturally subsumes
existing filtering strategies as extremely special cases of itself.
Empirically, extensive experiments show that GradNorm achieves the
state-of-the-art clustering performance on various benchmarks.

</details>


### [25] [MIRAD - A comprehensive real-world robust anomaly detection dataset for Mass Individualization](https://arxiv.org/abs/2510.16370)
*Pulin Li,Guocheng Wu,Li Yin,Yuxin Zheng,Wei Zhang,Yanjie Zhou*

Main category: cs.CV

TL;DR: 提出了首个专门针对社会化制造场景的异常检测基准数据集MIRAD，该数据集捕捉了个性化产品、分布式生产节点和成像异质性三个关键维度，评估显示现有SOTA方法在该数据集上性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 社会化制造通过社区协作和分散资源实现大规模个性化生产，但这一范式转变在质量控制特别是缺陷检测方面带来了重大挑战，主要困难包括高度定制化配置、碎片化小批量订单以及分布式站点成像环境差异。

Method: 引入MIRAD数据集，该数据集包含：(1)具有大类内变异的多样化个性化产品；(2)来自六个地理分散制造节点的数据；(3)显著的成像异质性，包括光照、背景和运动条件变化。在MIRAD上对单类、多类和零样本等SOTA异常检测方法进行了广泛评估。

Result: 与传统基准相比，所有模型在MIRAD数据集上都表现出显著的性能下降，突显了现实世界个性化生产中缺陷检测尚未解决的复杂性。

Conclusion: MIRAD通过弥合工业需求和学术研究，为开发工业5.0所需的稳健质量控制解决方案提供了现实基础，该数据集已在GitHub上公开。

Abstract: Social manufacturing leverages community collaboration and scattered
resources to realize mass individualization in modern industry. However, this
paradigm shift also introduces substantial challenges in quality control,
particularly in defect detection. The main difficulties stem from three
aspects. First, products often have highly customized configurations. Second,
production typically involves fragmented, small-batch orders. Third, imaging
environments vary considerably across distributed sites. To overcome the
scarcity of real-world datasets and tailored algorithms, we introduce the Mass
Individualization Robust Anomaly Detection (MIRAD) dataset. As the first
benchmark explicitly designed for anomaly detection in social manufacturing,
MIRAD captures three critical dimensions of this domain: (1) diverse
individualized products with large intra-class variation, (2) data collected
from six geographically dispersed manufacturing nodes, and (3) substantial
imaging heterogeneity, including variations in lighting, background, and motion
conditions. We then conduct extensive evaluations of state-of-the-art (SOTA)
anomaly detection methods on MIRAD, covering one-class, multi-class, and
zero-shot approaches. Results show a significant performance drop across all
models compared with conventional benchmarks, highlighting the unresolved
complexities of defect detection in real-world individualized production. By
bridging industrial requirements and academic research, MIRAD provides a
realistic foundation for developing robust quality control solutions essential
for Industry 5.0. The dataset is publicly available at
https://github.com/wu33learn/MIRAD.

</details>


### [26] [Cataract-LMM: Large-Scale, Multi-Source, Multi-Task Benchmark for Deep Learning in Surgical Video Analysis](https://arxiv.org/abs/2510.16371)
*Mohammad Javad Ahmadi,Iman Gandomi,Parisa Abdi,Seyed-Farzad Mohammadi,Amirhossein Taslimi,Mehdi Khodaparast,Hassan Hashemi,Mahdi Tavakoli,Hamid D. Taghirad*

Main category: cs.CV

TL;DR: 提出了一个包含3000个白内障超声乳化手术视频的数据集，来自两个手术中心，包含四个注释层：手术阶段、实例分割、器械-组织交互追踪和技能评分。


<details>
  <summary>Details</summary>
Motivation: 现有白内障手术数据集缺乏多样性和注释深度，无法训练泛化性强的深度学习模型。

Method: 收集3000个手术视频，添加四个注释层，并进行基准实验验证数据集质量，包括工作流识别、场景分割和自动技能评估。

Result: 数据集支持关键手术AI任务的基准实验，并建立了领域适应基线。

Conclusion: 该数据集为白内障手术AI研究提供了高质量、多样化的资源，支持多种计算机辅助手术应用。

Abstract: The development of computer-assisted surgery systems depends on large-scale,
annotated datasets. Current resources for cataract surgery often lack the
diversity and annotation depth needed to train generalizable deep-learning
models. To address this gap, we present a dataset of 3,000 phacoemulsification
cataract surgery videos from two surgical centers, performed by surgeons with a
range of experience levels. This resource is enriched with four annotation
layers: temporal surgical phases, instance segmentation of instruments and
anatomical structures, instrument-tissue interaction tracking, and quantitative
skill scores based on the established competency rubrics like the ICO-OSCAR.
The technical quality of the dataset is supported by a series of benchmarking
experiments for key surgical AI tasks, including workflow recognition, scene
segmentation, and automated skill assessment. Furthermore, we establish a
domain adaptation baseline for the phase recognition task by training a model
on a subset of surgical centers and evaluating its performance on a held-out
center. The dataset and annotations are available in Google Form
(https://docs.google.com/forms/d/e/1FAIpQLSfmyMAPSTGrIy2sTnz0-TMw08ZagTimRulbAQcWdaPwDy187A/viewform?usp=dialog).

</details>


### [27] [Demeter: A Parametric Model of Crop Plant Morphology from the Real World](https://arxiv.org/abs/2510.16377)
*Tianhang Cheng,Albert J. Zhai,Evan Z. Chen,Rui Zhou,Yawen Deng,Zitong Li,Kejie Zhao,Janice Shiu,Qianyu Zhao,Yide Xu,Xinlei Wang,Yuan Shen,Sheng Wang,Lisa Ainsworth,Kaiyu Guan,Shenlong Wang*

Main category: cs.CV

TL;DR: 本文提出了Demeter，一种数据驱动的参数化植物形态模型，能够编码植物的拓扑结构、形状、关节和变形等关键因素，支持不同物种的拓扑变化，并模拟三种形状变化来源。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对植物建模的同等表达能力模型，而现有的参数化模型主要针对人类和动物。植物建模在3D重建、生成、理解和仿真方面具有广泛的应用价值。

Method: 开发了Demeter参数化模型，通过数据驱动方法学习植物形态的紧凑表示，处理不同物种的拓扑变化，并建模三种形状变化：关节运动、子组件形状变化和非刚性变形。

Result: 在大规模大豆农场数据集上的实验表明，Demeter能够有效合成形状、重建结构并模拟生物物理过程。

Conclusion: Demeter为植物建模提供了一个表达力强的参数化框架，填补了现有模型在植物建模方面的空白，在农业和植物科学领域具有应用潜力。

Abstract: Learning 3D parametric shape models of objects has gained popularity in
vision and graphics and has showed broad utility in 3D reconstruction,
generation, understanding, and simulation. While powerful models exist for
humans and animals, equally expressive approaches for modeling plants are
lacking. In this work, we present Demeter, a data-driven parametric model that
encodes key factors of a plant morphology, including topology, shape,
articulation, and deformation into a compact learned representation. Unlike
previous parametric models, Demeter handles varying shape topology across
various species and models three sources of shape variation: articulation,
subcomponent shape variation, and non-rigid deformation. To advance crop plant
modeling, we collected a large-scale, ground-truthed dataset from a soybean
farm as a testbed. Experiments show that Demeter effectively synthesizes
shapes, reconstructs structures, and simulates biophysical processes. Code and
data is available at https://tianhang-cheng.github.io/Demeter/.

</details>


### [28] [REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting](https://arxiv.org/abs/2510.16410)
*Changyue Shi,Minghao Chen,Yiping Mao,Chuxiao Yang,Xinyuan Hu,Jiajun Ding,Zhou Yu*

Main category: cs.CV

TL;DR: REALM是一个创新的MLLM-agent框架，能够在3D高斯溅射表示上直接进行分割，通过全局到局部空间定位策略解决复杂人类指令与精确3D对象定位之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有3D分割方法难以解释模糊的、基于推理的指令，而擅长此类推理的2D视觉语言模型缺乏内在的3D空间理解能力。

Method: 在3D高斯溅射表示上直接进行分割，利用其渲染逼真新视图的能力；提出全局到局部空间定位策略：首先并行输入多个全局视图进行粗粒度定位，然后合成多个对象特写视图进行细粒度局部分割。

Result: 在LERF、3D-OVS和新引入的REALM3D基准测试中，REALM在解释显式和隐式指令方面表现出色，并支持对象移除、替换和风格转换等3D交互任务。

Conclusion: REALM框架在无需大量3D特定后训练的情况下，实现了基于推理的开放世界分割，展示了其实用性和多功能性。

Abstract: Bridging the gap between complex human instructions and precise 3D object
grounding remains a significant challenge in vision and robotics. Existing 3D
segmentation methods often struggle to interpret ambiguous, reasoning-based
instructions, while 2D vision-language models that excel at such reasoning lack
intrinsic 3D spatial understanding. In this paper, we introduce REALM, an
innovative MLLM-agent framework that enables open-world reasoning-based
segmentation without requiring extensive 3D-specific post-training. We perform
segmentation directly on 3D Gaussian Splatting representations, capitalizing on
their ability to render photorealistic novel views that are highly suitable for
MLLM comprehension. As directly feeding one or more rendered views to the MLLM
can lead to high sensitivity to viewpoint selection, we propose a novel
Global-to-Local Spatial Grounding strategy. Specifically, multiple global views
are first fed into the MLLM agent in parallel for coarse-level localization,
aggregating responses to robustly identify the target object. Then, several
close-up novel views of the object are synthesized to perform fine-grained
local segmentation, yielding accurate and consistent 3D masks. Extensive
experiments show that REALM achieves remarkable performance in interpreting
both explicit and implicit instructions across LERF, 3D-OVS, and our newly
introduced REALM3D benchmarks. Furthermore, our agent framework seamlessly
supports a range of 3D interaction tasks, including object removal,
replacement, and style transfer, demonstrating its practical utility and
versatility. Project page: https://ChangyueShi.github.io/REALM.

</details>


### [29] [SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning](https://arxiv.org/abs/2510.16416)
*Xiaojun Guo,Runyu Zhou,Yifei Wang,Qi Zhang,Chenheng Zhang,Stefanie Jegelka,Xiaohan Wang,Jiajun Chai,Guojun Yin,Wei Lin,Yisen Wang*

Main category: cs.CV

TL;DR: SSL4RL是一个利用自监督学习任务作为可验证奖励的强化学习框架，用于改进视觉语言模型在视觉证据利用方面的不足。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在视觉中心任务中往往过度依赖语言先验或使用文本捷径，缺乏有效的视觉证据利用。传统强化学习缺乏可扩展且可靠的奖励机制。

Method: 将自监督学习目标（如图像旋转预测、掩码补丁重建）重新构建为密集、自动的奖励信号，用于强化学习微调，无需人工偏好数据或不可靠的AI评估器。

Result: SSL4RL显著提升了视觉中心和视觉语言推理基准的性能，并在图学习中也取得了显著增益。

Conclusion: SSL4RL建立了一个使用可验证自监督目标对齐多模态模型的通用有效范式，为未来工作提供了新的设计原则。

Abstract: Vision-language models (VLMs) have shown remarkable abilities by integrating
large language models with visual inputs. However, they often fail to utilize
visual evidence adequately, either depending on linguistic priors in
vision-centric tasks or resorting to textual shortcuts during reasoning.
Although reinforcement learning (RL) can align models with desired behaviors,
its application to VLMs has been hindered by the lack of scalable and reliable
reward mechanisms. To overcome this challenge, we propose SSL4RL, a novel
framework that leverages self-supervised learning (SSL) tasks as a source of
verifiable rewards for RL-based fine-tuning. Our approach reformulates SSL
objectives-such as predicting image rotation or reconstructing masked
patches-into dense, automatic reward signals, eliminating the need for human
preference data or unreliable AI evaluators. Experiments show that SSL4RL
substantially improves performance on both vision-centric and vision-language
reasoning benchmarks. Furthermore, through systematic ablations, we identify
key factors-such as task difficulty, model scale, and semantic alignment with
the target domain-that influence the effectiveness of SSL4RL tasks, offering
new design principles for future work. We also demonstrate the framework's
generality by applying it to graph learning, where it yields significant gains.
SSL4RL establishes a versatile and effective paradigm for aligning multimodal
models using verifiable, self-supervised objectives.

</details>


### [30] [Machine Vision-Based Surgical Lighting System:Design and Implementation](https://arxiv.org/abs/2510.17287)
*Amir Gharghabi,Mahdi Hakiminezhad,Maryam Shafaei,Shaghayegh Gharghabi*

Main category: cs.CV

TL;DR: 提出基于YOLOv11算法的自动手术照明系统，通过检测蓝色标记自动调整LED光源位置，减少外科医生疲劳并提高照明一致性。


<details>
  <summary>Details</summary>
Motivation: 传统手术照明系统依赖手动调整，导致外科医生疲劳、颈部劳损以及因漂移和阴影造成的不一致照明问题。

Method: 使用YOLOv11目标检测算法识别手术目标区域上方的蓝色标记，通过两个配备倾斜-平移支架的伺服电机将高功率LED光源引导至识别位置。

Result: YOLO模型在验证集上达到96.7% mAP@50的准确率，验证集包含带有蓝色球形标记的模拟手术场景标注图像。

Conclusion: 这种基于机器视觉的自动化照明解决方案减少了外科医生的身体负担，提高了照明一致性，有助于改善手术效果。

Abstract: Effortless and ergonomically designed surgical lighting is critical for
precision and safety during procedures. However, traditional systems often rely
on manual adjustments, leading to surgeon fatigue, neck strain, and
inconsistent illumination due to drift and shadowing. To address these
challenges, we propose a novel surgical lighting system that leverages the
YOLOv11 object detection algorithm to identify a blue marker placed above the
target surgical site. A high-power LED light source is then directed to the
identified location using two servomotors equipped with tilt-pan brackets. The
YOLO model achieves 96.7% mAP@50 on the validation set consisting of annotated
images simulating surgical scenes with the blue spherical marker. By automating
the lighting process, this machine vision-based solution reduces physical
strain on surgeons, improves consistency in illumination, and supports improved
surgical outcomes.

</details>


### [31] [EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning](https://arxiv.org/abs/2510.16442)
*Haoran Sun,Chen Cai,Huiping Zhuang,Kong Aik Lee,Lap-Pui Chau,Yi Wang*

Main category: cs.CV

TL;DR: 本文提出可解释的深度伪造视频检测任务(EDVD)，设计了EDVD-LLaMA多模态大语言模型推理框架，通过时空细微信息标记化和细粒度多模态思维链机制，提供可追溯的推理过程和可信的解释。


<details>
  <summary>Details</summary>
Motivation: 传统深度伪造视频检测方法存在原理不透明、泛化能力不足的问题，需要能够识别伪造内容并提供可验证推理解释的检测器。

Method: 1. 时空细微信息标记化(ST-SIT)提取和融合全局局部跨帧深度伪造特征；2. 细粒度多模态思维链(Fg-MCoT)机制，引入面部特征数据作为硬约束；3. 构建可解释推理FF++基准数据集(ER-FF++set)。

Result: 实验表明EDVD-LLaMA在检测精度、可解释性、跨伪造方法和跨数据集场景处理方面表现出色，相比传统方法提供更可解释且优越的解决方案。

Conclusion: 该方法为深度伪造视频检测提供了可追溯的推理过程和可信的解释，具有优秀的检测性能和鲁棒性。

Abstract: The rapid development of deepfake video technology has not only facilitated
artistic creation but also made it easier to spread misinformation. Traditional
deepfake video detection (DVD) methods face issues such as a lack of
transparency in their principles and insufficient generalization capabilities
to cope with evolving forgery techniques. This highlights an urgent need for
detectors that can identify forged content and provide verifiable reasoning
explanations. This paper proposes the explainable deepfake video detection
(EDVD) task and designs the EDVD-LLaMA multimodal, a large language model
(MLLM) reasoning framework, which provides traceable reasoning processes
alongside accurate detection results and trustworthy explanations. Our approach
first incorporates a Spatio-Temporal Subtle Information Tokenization (ST-SIT)
to extract and fuse global and local cross-frame deepfake features, providing
rich spatio-temporal semantic information input for MLLM reasoning. Second, we
construct a Fine-grained Multimodal Chain-of-Thought (Fg-MCoT) mechanism, which
introduces facial feature data as hard constraints during the reasoning process
to achieve pixel-level spatio-temporal video localization, suppress
hallucinated outputs, and enhance the reliability of the chain of thought. In
addition, we build an Explainable Reasoning FF++ benchmark dataset
(ER-FF++set), leveraging structured data to annotate videos and ensure quality
control, thereby supporting dual supervision for reasoning and detection.
Extensive experiments demonstrate that EDVD-LLaMA achieves outstanding
performance and robustness in terms of detection accuracy, explainability, and
its ability to handle cross-forgery methods and cross-dataset scenarios.
Compared to previous DVD methods, it provides a more explainable and superior
solution. The source code and dataset will be publicly available.

</details>


### [32] [Enhancing Rotated Object Detection via Anisotropic Gaussian Bounding Box and Bhattacharyya Distance](https://arxiv.org/abs/2510.16445)
*Chien Thai,Mai Xuan Trang,Huong Ninh,Hoang Hiep Ly,Anh Son Le*

Main category: cs.CV

TL;DR: 本文提出了一种改进的损失函数，通过高斯边界框表示和Bhattacharyya距离来增强旋转物体检测的准确性和鲁棒性，解决了传统检测框架在旋转物体上的性能不足问题。


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉应用中，如航拍图像、遥感和自动驾驶，准确检测旋转物体是一个重要挑战。传统物体检测框架对轴对齐物体有效，但在处理旋转物体时由于无法有效捕捉方向变化而性能不佳。

Method: 提出使用高斯边界框表示和Bhattacharyya距离的改进损失函数，并倡导使用各向异性高斯表示来解决方形物体中各项同性方差的问题。该方法通过旋转不变损失函数有效捕捉旋转物体的几何特性。

Result: 将所提出的损失函数集成到最先进的基于深度学习的旋转物体检测器中，大量实验表明在平均精度指标上相比现有方法有显著提升。

Conclusion: 该方法在旋转物体检测方面具有建立新基准的潜力，对需要精确可靠物体定位的各种应用具有重要意义。

Abstract: Detecting rotated objects accurately and efficiently is a significant
challenge in computer vision, particularly in applications such as aerial
imagery, remote sensing, and autonomous driving. Although traditional object
detection frameworks are effective for axis-aligned objects, they often
underperform in scenarios involving rotated objects due to their limitations in
capturing orientation variations. This paper introduces an improved loss
function aimed at enhancing detection accuracy and robustness by leveraging the
Gaussian bounding box representation and Bhattacharyya distance. In addition,
we advocate for the use of an anisotropic Gaussian representation to address
the issues associated with isotropic variance in square-like objects. Our
proposed method addresses these challenges by incorporating a
rotation-invariant loss function that effectively captures the geometric
properties of rotated objects. We integrate this proposed loss function into
state-of-the-art deep learning-based rotated object detection detectors, and
extensive experiments demonstrated significant improvements in mean Average
Precision metrics compared to existing methods. The results highlight the
potential of our approach to establish new benchmark in rotated object
detection, with implications for a wide range of applications requiring precise
and reliable object localization irrespective of orientation.

</details>


### [33] [Instance-Aware Pseudo-Labeling and Class-Focused Contrastive Learning for Weakly Supervised Domain Adaptive Segmentation of Electron Microscopy](https://arxiv.org/abs/2510.16450)
*Shan Xiong,Jiabao Chen,Ye Wang,Jialin Peng*

Main category: cs.CV

TL;DR: 本文提出了一种弱监督域自适应方法，利用稀疏点标注实现电子显微镜图像中线粒体的高效分割，通过多任务学习和交叉教学机制显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 电子显微镜图像中线粒体分割需要大量标注，而无监督域自适应方法在实际应用中性能较低。为减少标注成本并提高性能，研究利用目标域上稀疏点标注的弱监督域自适应方法。

Method: 提出多任务学习框架，联合进行分割和中心检测，采用交叉教学机制和类聚焦跨域对比学习。引入分割自训练，通过实例感知伪标签选择策略语义选择可靠且多样化的伪标签。

Result: 在挑战性数据集上的验证表明，该方法优于现有的无监督域自适应和弱监督域自适应方法，显著缩小了与监督上界的性能差距。

Conclusion: 该方法在线粒体分割任务中实现了高效的弱监督域自适应，在减少标注成本的同时显著提升了分割性能。

Abstract: Annotation-efficient segmentation of the numerous mitochondria instances from
various electron microscopy (EM) images is highly valuable for biological and
neuroscience research. Although unsupervised domain adaptation (UDA) methods
can help mitigate domain shifts and reduce the high costs of annotating each
domain, they typically have relatively low performance in practical
applications. Thus, we investigate weakly supervised domain adaptation (WDA)
that utilizes additional sparse point labels on the target domain, which
require minimal annotation effort and minimal expert knowledge. To take full
use of the incomplete and imprecise point annotations, we introduce a multitask
learning framework that jointly conducts segmentation and center detection with
a novel cross-teaching mechanism and class-focused cross-domain contrastive
learning. While leveraging unlabeled image regions is essential, we introduce
segmentation self-training with a novel instance-aware pseudo-label (IPL)
selection strategy. Unlike existing methods that typically rely on pixel-wise
pseudo-label filtering, the IPL semantically selects reliable and diverse
pseudo-labels with the help of the detection task. Comprehensive validations
and comparisons on challenging datasets demonstrate that our method outperforms
existing UDA and WDA methods, significantly narrowing the performance gap with
the supervised upper bound. Furthermore, under the UDA setting, our method also
achieves substantial improvements over other UDA techniques.

</details>


### [34] [NavQ: Learning a Q-Model for Foresighted Vision-and-Language Navigation](https://arxiv.org/abs/2510.16457)
*Peiran Xu,Xicheng Gong,Yadong MU*

Main category: cs.CV

TL;DR: 提出一种面向目标视觉语言导航的前瞻性智能体，通过Q学习从大规模无标签轨迹数据中学习室内场景布局和物体关系知识，结合未来信息进行A*式搜索策略。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要基于历史信息做决策，忽视了行动的未来影响和长期结果，需要开发能够预见未来结果的前瞻性导航智能体。

Method: 使用Q学习训练Q模型生成Q特征描述候选行动的未来潜在信息，通过跨模态未来编码器将任务无关的Q特征与导航指令结合，产生反映未来前景的行动评分，结合历史评分进行A*式搜索。

Result: 在广泛使用的目标导向VLN数据集上进行的实验验证了所提方法的有效性。

Conclusion: 该方法通过整合未来信息和历史信息，实现了更有效的目标导向视觉语言导航。

Abstract: In this work we concentrate on the task of goal-oriented Vision-and-Language
Navigation (VLN). Existing methods often make decisions based on historical
information, overlooking the future implications and long-term outcomes of the
actions. In contrast, we aim to develop a foresighted agent. Specifically, we
draw upon Q-learning to train a Q-model using large-scale unlabeled trajectory
data, in order to learn the general knowledge regarding the layout and object
relations within indoor scenes. This model can generate a Q-feature, analogous
to the Q-value in traditional Q-network, for each candidate action, which
describes the potential future information that may be observed after taking
the specific action. Subsequently, a cross-modal future encoder integrates the
task-agnostic Q-feature with navigation instructions to produce a set of action
scores reflecting future prospects. These scores, when combined with the
original scores based on history, facilitate an A*-style searching strategy to
effectively explore the regions that are more likely to lead to the
destination. Extensive experiments conducted on widely used goal-oriented VLN
datasets validate the effectiveness of the proposed method.

</details>


### [35] [OOS-DSD: Improving Out-of-stock Detection in Retail Images using Auxiliary Tasks](https://arxiv.org/abs/2510.16508)
*Franko Šikić,Sven Lončarić*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的OOS-DSD方法，通过辅助学习改进缺货检测，在YOLOv8架构上增加卷积分支同时进行缺货检测、产品分割和场景深度估计，性能优于现有方法1.8% mAP。


<details>
  <summary>Details</summary>
Motivation: 缺货检测是零售验证中的重要过程，旨在推断货架上指定区域产品的不可用性。现有方法需要进一步提升检测性能。

Method: 扩展YOLOv8目标检测架构，增加卷积分支同时进行缺货检测、产品分割和深度估计。深度估计分支使用Depth Anything V2生成的伪标签进行训练，并提出了深度归一化程序来稳定训练过程。

Result: 实验结果表明，该方法在平均精度上比现有最优方法提高了1.8%。消融研究证实辅助学习使mAP提高3.7%，深度归一化程序使mAP提高4.2%。

Conclusion: OOS-DSD方法通过多任务辅助学习和深度归一化有效提升了缺货检测性能，证明了辅助学习在零售验证任务中的有效性。

Abstract: Out-of-stock (OOS) detection is a very important retail verification process
that aims to infer the unavailability of products in their designated areas on
the shelf. In this paper, we introduce OOS-DSD, a novel deep learning-based
method that advances OOS detection through auxiliary learning. In particular,
we extend a well-established YOLOv8 object detection architecture with
additional convolutional branches to simultaneously detect OOS, segment
products, and estimate scene depth. While OOS detection and product
segmentation branches are trained using ground truth data, the depth estimation
branch is trained using pseudo-labeled annotations produced by the
state-of-the-art (SOTA) depth estimation model Depth Anything V2. Furthermore,
since the aforementioned pseudo-labeled depth estimates display relative depth,
we propose an appropriate depth normalization procedure that stabilizes the
training process. The experimental results show that the proposed method
surpassed the performance of the SOTA OOS detection methods by 1.8% of the mean
average precision (mAP). In addition, ablation studies confirm the
effectiveness of auxiliary learning and the proposed depth normalization
procedure, with the former increasing mAP by 3.7% and the latter by 4.2%.

</details>


### [36] [Enhancing Compositional Reasoning in CLIP via Reconstruction and Alignment of Text Descriptions](https://arxiv.org/abs/2510.16540)
*Jihoon Kwon,Kyle Min,Jy-yong Sohn*

Main category: cs.CV

TL;DR: READ是一种微调方法，通过添加重构和对齐两个辅助目标来增强视觉语言模型的组合推理能力，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在组合推理方面表现不佳，主要原因是文本编码器倾向于关注单个单词而非它们之间的关系，这种局限性被对比训练强化，主要将单词与视觉对象对齐。

Method: READ方法在对比学习基础上添加两个辅助目标：(1) 标记级重构目标：使用冻结的预训练解码器基于原始标题嵌入重构替代标题；(2) 句子级对齐目标：在嵌入空间中显式对齐释义句子。

Result: READ-CLIP在五个主要组合推理基准测试中达到最先进性能，比最强的传统微调基线高出4.1%。将READ应用于现有CLIP变体也能提升这些基准测试的性能。

Conclusion: 重构和对齐目标提供互补优势：重构鼓励编码器捕捉标题内单词间的关系，而对齐确保不同措辞表达的释义具有一致表示。

Abstract: Despite recent advances, vision-language models trained with standard
contrastive objectives still struggle with compositional reasoning -- the
ability to understand structured relationships between visual and linguistic
elements. This shortcoming is largely due to the tendency of the text encoder
to focus on individual words rather than their relations, a limitation
reinforced by contrastive training that primarily aligns words with visual
objects. In this paper, we introduce REconstruction and Alignment of text
Descriptions (READ), a fine-tuning method designed to enhance compositional
reasoning by adding two auxiliary objectives to the contrastive learning: (1) a
token-level reconstruction objective, where a frozen pre-trained decoder
reconstructs alternative captions based on the embedding of the original
caption; and (2) a sentence-level alignment objective, which explicitly aligns
paraphrased sentences in the embedding space. We show that READ-CLIP, a model
derived by applying the READ method to the pre-trained CLIP model, achieves the
state-of-the-art performance across five major compositional reasoning
benchmarks, outperforming the strongest conventional fine-tuning baseline by up
to 4.1%. Furthermore, applying the READ to existing CLIP variants (including
NegCLIP and FSC-CLIP) also improves performance on these benchmarks.
Quantitative and qualitative analyses reveal that our proposed objectives --
reconstruction and alignment -- offer complementary benefits: the former
encourages the encoder to capture relationships between words within a caption,
while the latter ensures consistent representations for paraphrases expressed
with different wording.

</details>


### [37] [Watch Where You Move: Region-aware Dynamic Aggregation and Excitation for Gait Recognition](https://arxiv.org/abs/2510.16541)
*Binyuan Huang,Yongdong Luo,Xianda Guo,Xiawu Zheng,Zheng Zhu,Jiahui Pan,Chengju Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种区域感知动态聚合与激励框架（GaitRDAE），通过自动搜索运动区域、分配自适应时间尺度并应用相应注意力，解决了现有步态识别方法在动态变化运动区域建模方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有步态识别方法通常使用预定义区域进行时间建模，为不同类型区域分配固定或等效的时间尺度，难以建模随时间动态变化的运动区域并适应其特定模式。

Method: 提出了GaitRDAE框架，包含两个核心模块：区域感知动态聚合（RDA）模块动态搜索每个区域的最佳时间感受野；区域感知动态激励（RDE）模块强调包含更稳定行为模式运动区域的学习，同时抑制对更易受协变量影响的静态区域的注意力。

Result: 实验结果表明，GaitRDAE在多个基准数据集上达到了最先进的性能。

Conclusion: GaitRDAE通过动态搜索运动区域和自适应时间尺度分配，有效提升了步态识别的准确性，特别是在处理协变量影响和动态变化运动区域方面表现出色。

Abstract: Deep learning-based gait recognition has achieved great success in various
applications. The key to accurate gait recognition lies in considering the
unique and diverse behavior patterns in different motion regions, especially
when covariates affect visual appearance. However, existing methods typically
use predefined regions for temporal modeling, with fixed or equivalent temporal
scales assigned to different types of regions, which makes it difficult to
model motion regions that change dynamically over time and adapt to their
specific patterns. To tackle this problem, we introduce a Region-aware Dynamic
Aggregation and Excitation framework (GaitRDAE) that automatically searches for
motion regions, assigns adaptive temporal scales and applies corresponding
attention. Specifically, the framework includes two core modules: the
Region-aware Dynamic Aggregation (RDA) module, which dynamically searches the
optimal temporal receptive field for each region, and the Region-aware Dynamic
Excitation (RDE) module, which emphasizes the learning of motion regions
containing more stable behavior patterns while suppressing attention to static
regions that are more susceptible to covariates. Experimental results show that
GaitRDAE achieves state-of-the-art performance on several benchmark datasets.

</details>


### [38] [SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense](https://arxiv.org/abs/2510.16596)
*Yiyang Huang,Liang Shi,Yitian Zhang,Yi Xu,Yun Fu*

Main category: cs.CV

TL;DR: SHIELD是一个无需训练的训练框架，通过重新加权视觉标记、引入噪声衍生标记和应用对比解码的对抗攻击，有效缓解大型视觉语言模型中的物体幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在跨模态任务中表现出色，但物体幻觉（模型产生看似合理但不准确的物体描述）仍然是一个重大挑战。与之前关注LLM组件的研究不同，本文首次将LVLM幻觉追溯到视觉编码器，并识别出三个关键问题：统计偏差、固有偏差和脆弱性。

Method: 提出SHIELD框架，采用三种策略：重新加权视觉标记以减少统计偏差，引入噪声衍生标记以对抗固有偏差，应用对比解码的对抗攻击以解决脆弱性问题。

Result: 实验表明SHIELD在多种基准测试和LVLM家族中有效缓解了物体幻觉问题。此外，SHIELD在通用LVLM基准测试中表现出色，显示出其广泛适用性。

Conclusion: SHIELD是一个无需训练的有效框架，能够显著减少大型视觉语言模型中的物体幻觉，同时保持模型的通用性能，具有广泛的适用前景。

Abstract: Large Vision-Language Models (LVLMs) excel in diverse cross-modal tasks.
However, object hallucination, where models produce plausible but inaccurate
object descriptions, remains a significant challenge. In contrast to previous
work focusing on LLM components, this paper is the first to trace LVLM
hallucinations to visual encoders and identifies three key issues: statistical
bias, inherent bias, and vulnerability. To address these challenges, we propose
SHIELD, a training-free framework that mitigates hallucinations through three
strategies: re-weighting visual tokens to reduce statistical bias, introducing
noise-derived tokens to counter inherent bias, and applying adversarial attacks
with contrastive decoding to address vulnerability. Experiments demonstrate
that SHIELD effectively mitigates object hallucinations across diverse
benchmarks and LVLM families. Moreover, SHIELD achieves strong performance on
the general LVLM benchmark, highlighting its broad applicability. Code will be
released.

</details>


### [39] [VisionSelector: End-to-End Learnable Visual Token Compression for Efficient Multimodal LLMs](https://arxiv.org/abs/2510.16598)
*Jiaying Zhu,Yurui Zhu,Xin Lu,Wenrui Yan,Dong Li,Kunlin Liu,Xueyang Fu,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: VisionSelector是一个轻量级即插即用的视觉token压缩框架，通过可学习的决策过程解决MLLMs中视觉token过多导致的计算和内存瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在处理高分辨率图像或多图像输入时，由于生成大量视觉token而面临显著的计算和内存瓶颈。现有token压缩技术受限于启发式规则，可能丢弃关键信息并存在注意力偏差问题。

Method: 提出VisionSelector评分器模块，与MLLM主干解耦，包含可微分的Top-K机制和课程退火策略，实现端到端可学习的token选择过程，支持任意压缩率。

Result: 仅需12.85M可训练参数，在MME基准上保持100%准确率（30%保留预算），在10%保留预算下比先前方法提升12.14%，预填充速度翻倍。

Conclusion: VisionSelector提供了一种高效且自适应的token压缩解决方案，在各种压缩预算下均表现出优越性能，具有良好的泛化能力。

Abstract: Multimodal Large Language Models (MLLMs) encounter significant computational
and memory bottlenecks from the massive number of visual tokens generated by
high-resolution images or multi-image inputs. Previous token compression
techniques are often constrained by heuristic rules that risk discarding
critical information. They may suffer from biases, such as attention sinks,
that lead to sharp performance drops under aggressive compression ratios. To
address these limitations, we reformulate token compression as a lightweight
plug-and-play framework that reformulates token compression into an end-to-end
learnable decision process. To be specific, we propose VisionSelector, a scorer
module decoupled from the MLLM backbone that incorporates a differentiable
Top-K mechanism and a curriculum annealing strategy to bridge the
training-inference gap, enabling efficient and adaptive token selection various
arbitrary compression rates. Remarkably lightweight with only 12.85M trainable
parameters, VisionSelector demonstrates generalization across various
compression rates and adaptively identifying critical tokens. This leads to
superior performance across all compression budgets, evidenced by preserving
100% accuracy on MME with 30% retention budget, outperforming prior methods by
12.14% at 10% retention budget, and doubling prefill speed. Our code is
available at https://github.com/JulietChoo/VisionSelector .

</details>


### [40] [MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models](https://arxiv.org/abs/2510.16641)
*Young-Jun Lee,Byung-Kwan Lee,Jianshu Zhang,Yechan Hwang,Byungsoo Ko,Han-Gyu Kim,Dongyu Yao,Xuankun Rong,Eojin Joo,Seung-Ho Han,Bowon Ko,Ho-Jin Choi*

Main category: cs.CV

TL;DR: MultiVerse是一个新颖的多轮对话基准测试，包含647个对话，涵盖12个流行的VLM评估基准，用于评估视觉语言模型在复杂多轮对话中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的多轮数据集（如MMDU、ConvBench）仅部分覆盖用户遇到的各种对话场景，而真实应用需要更复杂的多轮对话能力。

Method: 从12个流行的VLM评估基准中提取647个对话，每个对话平均4轮；提出基于检查表的评估方法，使用GPT-4o作为自动评估器，测量37个关键方面的性能。

Result: 评估了18个VLM，即使最强的模型（如GPT-4o）在复杂多轮对话中也仅达到50%的成功率；提供完整对话上下文显著提升了较小或较弱模型的性能。

Conclusion: MultiVerse是评估VLM多轮交互能力的基准，揭示了当前模型在复杂对话中的局限性，并强调了上下文学习的重要性。

Abstract: Vision-and-Language Models (VLMs) have shown impressive capabilities on
single-turn benchmarks, yet real-world applications often demand more intricate
multi-turn dialogues. Existing multi-turn datasets (e.g, MMDU, ConvBench) only
partially capture the breadth and depth of conversational scenarios encountered
by users. In this work, we introduce MultiVerse, a novel multi-turn
conversation benchmark featuring 647 dialogues - each averaging four turns -
derived from a diverse set of 12 popular VLM evaluation benchmarks. With 484
tasks and 484 interaction goals, MultiVerse covers a wide range of topics, from
factual knowledge and perception to advanced reasoning tasks such as
mathematics and coding. To facilitate robust assessment, we propose a
checklist-based evaluation method that leverages GPT-4o as the automated
evaluator, measuring performance across 37 key aspects, including perceptual
accuracy, linguistic clarity, and factual correctness. We evaluate 18 VLMs on
MultiVerse, revealing that even the strongest models (e.g., GPT-4o) achieve
only a 50% success rate in complex multi-turn conversations, highlighting the
dataset's challenging nature. Notably, we find that providing full dialogue
context significantly enhances performance for smaller or weaker models,
emphasizing the importance of in-context learning. We believe MultiVerse is a
landscape of evaluating multi-turn interaction abilities for VLMs.

</details>


### [41] [Structured Interfaces for Automated Reasoning with 3D Scene Graphs](https://arxiv.org/abs/2510.16643)
*Aaron Ray,Jacob Arkin,Harel Biggie,Chuchu Fan,Luca Carlone,Nicholas Roy*

Main category: cs.CV

TL;DR: 本文提出了一种使用检索增强生成（RAG）方法，通过图数据库和Cypher查询语言接口，让大型语言模型能够有效处理大规模3D场景图，以解决自然语言与机器人世界表示之间的连接问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法将3D场景图序列化为文本放入LLM上下文窗口，但这种方法无法扩展到大型或丰富的3D场景图。需要一种更有效的方法来连接自然语言与机器人的世界表示。

Method: 使用检索增强生成方法，将3D场景图编码在图数据库中，为LLM提供Cypher查询语言作为工具接口，使其能够检索与任务相关的数据。

Result: 在指令跟随和场景问答任务上的评估表明，使用Cypher作为3D场景图接口的方法在本地和云端模型上都能显著扩展到大型、丰富的图结构，同时大幅减少场景图内容的token数量。

Conclusion: Cypher查询语言作为3D场景图的接口方法在扩展性和性能方面都优于基线方法，为基于语言的机器人任务提供了更有效的解决方案。

Abstract: In order to provide a robot with the ability to understand and react to a
user's natural language inputs, the natural language must be connected to the
robot's underlying representations of the world. Recently, large language
models (LLMs) and 3D scene graphs (3DSGs) have become a popular choice for
grounding natural language and representing the world. In this work, we address
the challenge of using LLMs with 3DSGs to ground natural language. Existing
methods encode the scene graph as serialized text within the LLM's context
window, but this encoding does not scale to large or rich 3DSGs. Instead, we
propose to use a form of Retrieval Augmented Generation to select a subset of
the 3DSG relevant to the task. We encode a 3DSG in a graph database and provide
a query language interface (Cypher) as a tool to the LLM with which it can
retrieve relevant data for language grounding. We evaluate our approach on
instruction following and scene question-answering tasks and compare against
baseline context window and code generation methods. Our results show that
using Cypher as an interface to 3D scene graphs scales significantly better to
large, rich graphs on both local and cloud-based models. This leads to large
performance improvements in grounded language tasks while also substantially
reducing the token count of the scene graph content. A video supplement is
available at https://www.youtube.com/watch?v=zY_YI9giZSA.

</details>


### [42] [HYDRA: HYbrid knowledge Distillation and spectral Reconstruction Algorithm for high channel hyperspectral camera applications](https://arxiv.org/abs/2510.16664)
*Christopher Thirgood,Oscar Mendez,Erin Ling,Jon Storey,Simon Hadfield*

Main category: cs.CV

TL;DR: 本文提出HYDRA方法，通过教师-学生模型架构和新的训练方法，解决了传统多尺度注意力方法在密集光谱重建中的局限性，实现了在未见场景下从三通道彩色图像重建高光谱图像的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统多尺度注意力方法只能处理稀疏光谱，而现代高光谱传感器包含数百个通道，需要开发能够处理密集光谱的高质量光谱重建方法。

Method: 使用教师模型封装潜在高光谱图像数据，学生模型学习从自然图像到教师编码域的映射，结合新颖的训练方法构建HYDRA架构。

Result: 在所有指标上达到SOTA性能，准确率提升18%，在不同通道深度下推理速度均优于当前SOTA模型。

Conclusion: HYDRA方法有效解决了先前光谱重建模型的关键限制，实现了高质量的光谱重建，为计算机视觉中的高光谱图像应用提供了有力支持。

Abstract: Hyperspectral images (HSI) promise to support a range of new applications in
computer vision. Recent research has explored the feasibility of generalizable
Spectral Reconstruction (SR), the problem of recovering a HSI from a natural
three-channel color image in unseen scenarios.
  However, previous Multi-Scale Attention (MSA) works have only demonstrated
sufficient generalizable results for very sparse spectra, while modern HSI
sensors contain hundreds of channels.
  This paper introduces a novel approach to spectral reconstruction via our
HYbrid knowledge Distillation and spectral Reconstruction Architecture (HYDRA).
  Using a Teacher model that encapsulates latent hyperspectral image data and a
Student model that learns mappings from natural images to the Teacher's encoded
domain, alongside a novel training method, we achieve high-quality spectral
reconstruction.
  This addresses key limitations of prior SR models, providing SOTA performance
across all metrics, including an 18\% boost in accuracy, and faster inference
times than current SOTA models at various channel depths.

</details>


### [43] [SDPA++: A General Framework for Self-Supervised Denoising with Patch Aggregation](https://arxiv.org/abs/2510.16702)
*Huy Minh Nhat Nguyen,Triet Hoang Minh Dao,Chau Vinh Hoang Truong,Cuong Tuan Nguyen*

Main category: cs.CV

TL;DR: 提出了一种名为SDPA++的自监督去噪框架，仅使用噪声OCT图像通过自融合和自监督去噪生成伪真实图像，然后训练集成去噪模型来增强图像清晰度。


<details>
  <summary>Details</summary>
Motivation: OCT成像在眼科疾病诊断中至关重要，但获取配对的干净和噪声OCT图像数据集具有挑战性，因为存在固有散斑噪声和临床成像环境的实际限制。

Method: SDPA++框架：首先通过自融合和自监督去噪从噪声OCT图像生成伪真实图像，然后使用基于块的策略训练集成去噪模型。

Result: 在IEEE SPS VIP Cup真实世界数据集上验证，使用CNR、MSR、TP和EP等指标评估性能改进，该数据集仅包含真实噪声OCT图像而无干净参考。

Conclusion: 该方法在仅有噪声图像的情况下有效提升OCT图像质量，具有改善临床实践图像质量和诊断结果的潜力。

Abstract: Optical Coherence Tomography (OCT) is a widely used non-invasive imaging
technique that provides detailed three-dimensional views of the retina, which
are essential for the early and accurate diagnosis of ocular diseases.
Consequently, OCT image analysis and processing have emerged as key research
areas in biomedical imaging. However, acquiring paired datasets of clean and
real-world noisy OCT images for supervised denoising models remains a
formidable challenge due to intrinsic speckle noise and practical constraints
in clinical imaging environments. To address these issues, we propose SDPA++: A
General Framework for Self-Supervised Denoising with Patch Aggregation. Our
novel approach leverages only noisy OCT images by first generating
pseudo-ground-truth images through self-fusion and self-supervised denoising.
These refined images then serve as targets to train an ensemble of denoising
models using a patch-based strategy that effectively enhances image clarity.
Performance improvements are validated via metrics such as Contrast-to-Noise
Ratio (CNR), Mean Square Ratio (MSR), Texture Preservation (TP), and Edge
Preservation (EP) on the real-world dataset from the IEEE SPS Video and Image
Processing Cup. Notably, the VIP Cup dataset contains only real-world noisy OCT
images without clean references, highlighting our method's potential for
improving image quality and diagnostic outcomes in clinical practice.

</details>


### [44] [Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization](https://arxiv.org/abs/2510.16704)
*Tianxin Wei,Yifan Chen,Xinrui He,Wenxuan Bao,Jingrui He*

Main category: cs.CV

TL;DR: 本文提出了一种新的领域连接对比学习（DCCL）方法来解决领域泛化问题，通过增强跨领域的概念连接性来提高模型在未见目标域上的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 训练和测试样本之间的分布偏移经常发生，阻碍模型的泛化性能。虽然对比学习能够学习类分离表示，但直接应用对比学习反而会损害领域泛化性能，原因是缺乏领域内类内连接性。

Method: 提出DCCL方法：在数据层面使用更激进的数据增强和跨领域正样本；在模型层面提出模型锚定技术，利用预训练表示中的类内连接性，并结合生成变换损失。

Result: 在五个标准领域泛化基准测试上的实验结果表明，DCCL即使在没有领域监督的情况下也优于最先进的基线方法。

Conclusion: DCCL通过增强跨领域的类内连接性，成功解决了对比学习在领域泛化中的性能下降问题，获得了更好的泛化表示。

Abstract: Distribution shifts between training and testing samples frequently occur in
practice and impede model generalization performance. This crucial challenge
thereby motivates studies on domain generalization (DG), which aim to predict
the label on unseen target domain data by solely using data from source
domains. It is intuitive to conceive the class-separated representations
learned in contrastive learning (CL) are able to improve DG, while the reality
is quite the opposite: users observe directly applying CL deteriorates the
performance. We analyze the phenomenon with the insights from CL theory and
discover lack of intra-class connectivity in the DG setting causes the
deficiency. We thus propose a new paradigm, domain-connecting contrastive
learning (DCCL), to enhance the conceptual connectivity across domains and
obtain generalizable representations for DG. On the data side, more aggressive
data augmentation and cross-domain positive samples are introduced to improve
intra-class connectivity. On the model side, to better embed the unseen test
domains, we propose model anchoring to exploit the intra-class connectivity in
pre-trained representations and complement the anchoring with generative
transformation loss. Extensive experiments on five standard DG benchmarks are
performed. The results verify that DCCL outperforms state-of-the-art baselines
even without domain supervision. The detailed model implementation and the code
are provided through https://github.com/weitianxin/DCCL

</details>


### [45] [HumanCM: One Step Human Motion Prediction](https://arxiv.org/abs/2510.16709)
*Liu Haojie,Gao Suixiang*

Main category: cs.CV

TL;DR: HumanCM是一个基于一致性模型的一步式人体运动预测框架，通过单步生成实现高效推理，相比扩散模型减少两个数量级的推理步骤，同时保持或超越现有方法的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型方法需要多步去噪过程，导致推理效率低下。HumanCM旨在通过一致性模型实现高效的单步运动生成，解决扩散模型推理速度慢的问题。

Method: 采用基于Transformer的时空架构，结合时间嵌入来建模长距离依赖关系并保持运动连贯性。学习噪声运动状态与干净运动状态之间的自一致映射。

Result: 在Human3.6M和HumanEva-I数据集上的实验表明，HumanCM在保持与最先进扩散模型相当或更优准确性的同时，将推理步骤减少了多达两个数量级。

Conclusion: HumanCM证明了通过一致性模型可以实现高效的单步人体运动预测，在保持高质量生成的同时显著提升推理效率，为实时运动预测应用提供了可行方案。

Abstract: We present HumanCM, a one-step human motion prediction framework built upon
consistency models. Instead of relying on multi-step denoising as in
diffusion-based methods, HumanCM performs efficient single-step generation by
learning a self-consistent mapping between noisy and clean motion states. The
framework adopts a Transformer-based spatiotemporal architecture with temporal
embeddings to model long-range dependencies and preserve motion coherence.
Experiments on Human3.6M and HumanEva-I demonstrate that HumanCM achieves
comparable or superior accuracy to state-of-the-art diffusion models while
reducing inference steps by up to two orders of magnitude.

</details>


### [46] [Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes](https://arxiv.org/abs/2510.16714)
*Xiongkun Linghu,Jiangyong Huang,Ziyu Zhu,Baoxiong Jia,Siyuan Huang*

Main category: cs.CV

TL;DR: 本文提出了SCENECOT框架，通过将复杂的3D场景推理任务分解为更简单的问题，并构建相应的视觉线索，实现了基于链式思维推理的3D场景理解。


<details>
  <summary>Details</summary>
Motivation: 现有3D大语言模型在实现基于场景对象的问答推理方面仍存在困难，主要原因是缺乏对人类场景-对象关联推理机制的深入探索。

Method: 提出了一种基于3D场景的链式思维推理方法(SCENECOT)，将复杂推理任务分解为更简单的问题，并利用多模态专家模块构建视觉线索。同时开发了SCENECOT-185K数据集，包含18.5万个高质量实例。

Result: 在各种复杂3D场景推理基准测试中的广泛实验表明，新框架实现了强大的性能，并具有较高的问答一致性。

Conclusion: 这是首次成功将链式思维推理应用于3D场景理解，实现了逐步的人类式推理，并显示出扩展到更广泛3D场景理解场景的潜力。

Abstract: Existing research on 3D Large Language Models (LLMs) still struggles to
achieve grounded question-answering, primarily due to the under-exploration of
the mech- anism of human-like scene-object grounded reasoning. This paper
bridges the gap by presenting a novel framework. We first introduce a grounded
Chain-of- Thought reasoning method in 3D scenes (SCENECOT), decoupling a
complex reasoning task into simpler and manageable problems, and building
corresponding visual clues based on multimodal expert modules. To enable such a
method, we develop SCENECOT-185K, the first large-scale grounded CoT reasoning
dataset, consisting of 185K high-quality instances. Extensive experiments
across various complex 3D scene reasoning benchmarks demonstrate that our new
framework achieves strong performance with high grounding-QA coherence. To the
best of our knowledge, this is the first successful application of CoT
reasoning to 3D scene understanding, enabling step-by-step human-like reasoning
and showing potential for extension to broader 3D scene understanding
scenarios.

</details>


### [47] [Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models](https://arxiv.org/abs/2510.16729)
*Jianbiao Mei,Yu Yang,Xuemeng Yang,Licheng Wen,Jiajun Lv,Botian Shi,Yong Liu*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: End-to-end autonomous driving systems increasingly rely on vision-centric
world models to understand and predict their environment. However, a common
ineffectiveness in these models is the full reconstruction of future scenes,
which expends significant capacity on redundantly modeling static backgrounds.
To address this, we propose IR-WM, an Implicit Residual World Model that
focuses on modeling the current state and evolution of the world. IR-WM first
establishes a robust bird's-eye-view representation of the current state from
the visual observation. It then leverages the BEV features from the previous
timestep as a strong temporal prior and predicts only the "residual", i.e., the
changes conditioned on the ego-vehicle's actions and scene context. To
alleviate error accumulation over time, we further apply an alignment module to
calibrate semantic and dynamic misalignments. Moreover, we investigate
different forecasting-planning coupling schemes and demonstrate that the
implicit future state generated by world models substantially improves planning
accuracy. On the nuScenes benchmark, IR-WM achieves top performance in both 4D
occupancy forecasting and trajectory planning.

</details>


### [48] [UKANFormer: Noise-Robust Semantic Segmentation for Coral Reef Mapping via a Kolmogorov-Arnold Network-Transformer Hybrid](https://arxiv.org/abs/2510.16730)
*Tianyang Dou,Ming Li,Jiangying Qin,Xuan Liao,Jiageng Zhong,Armin Gruen,Mengyi Deng*

Main category: cs.CV

TL;DR: UKANFormer是一种新型语义分割模型，用于在Allen Coral Atlas提供的噪声监督下实现高精度珊瑚礁映射，通过结合全局语义结构和局部边界细节，在噪声标签设置下超越了传统基线方法。


<details>
  <summary>Details</summary>
Motivation: 全球珊瑚礁产品如Allen Coral Atlas虽然提供了前所未有的覆盖范围，但其预测在空间精度和语义一致性方面存在限制，特别是在需要精细边界划分的区域。需要解决噪声监督下的高精度映射挑战。

Method: 基于UKAN架构，UKANFormer在解码器中加入了全局-局部变换器（GL-Trans）块，能够同时提取全局语义结构和局部边界细节。

Result: UKANFormer实现了珊瑚类IoU 67.00%和像素精度83.98%，在相同噪声标签设置下优于传统基线方法。模型产生的预测在视觉和结构上都比用于训练的噪声标签更准确。

Conclusion: 研究结果表明，架构设计可以缓解标签噪声，支持在非完美监督下进行可扩展映射，挑战了数据质量直接限制模型性能的观念，为生态监测提供了基础。

Abstract: Coral reefs are vital yet fragile ecosystems that require accurate
large-scale mapping for effective conservation. Although global products such
as the Allen Coral Atlas provide unprecedented coverage of global coral reef
distri-bution, their predictions are frequently limited in spatial precision
and semantic consistency, especially in regions requiring fine-grained boundary
delineation. To address these challenges, we propose UKANFormer, a novel
se-mantic segmentation model designed to achieve high-precision mapping under
noisy supervision derived from Allen Coral Atlas. Building upon the UKAN
architecture, UKANFormer incorporates a Global-Local Transformer (GL-Trans)
block in the decoder, enabling the extraction of both global semantic
structures and local boundary details. In experiments, UKANFormer achieved a
coral-class IoU of 67.00% and pixel accuracy of 83.98%, outperforming
conventional baselines under the same noisy labels setting. Remarkably, the
model produces predictions that are visually and structurally more accurate
than the noisy labels used for training. These results challenge the notion
that data quality directly limits model performance, showing that architectural
design can mitigate label noise and sup-port scalable mapping under imperfect
supervision. UKANFormer provides a foundation for ecological monitoring where
reliable labels are scarce.

</details>


### [49] [A Comprehensive Survey on World Models for Embodied AI](https://arxiv.org/abs/2510.16732)
*Xinqing Li,Xin He,Le Zhang,Yun Liu*

Main category: cs.CV

TL;DR: 该论文提出了一个关于具身AI中世界模型的统一框架，包括问题形式化、学习目标和三轴分类法，系统化整理了数据资源和评估指标，并对现有模型进行定量比较，指出了关键挑战。


<details>
  <summary>Details</summary>
Motivation: 具身AI需要能够感知、行动并预测行动如何重塑未来世界状态的智能体。世界模型作为内部模拟器，能够捕捉环境动态，支持感知、预测和决策制定。

Method: 提出了一个三轴分类法：(1) 功能性：决策耦合vs通用目的；(2) 时间建模：序列模拟与推理vs全局差异预测；(3) 空间表示：全局潜在向量、令牌特征序列、空间潜在网格和分解渲染表示。

Result: 系统化整理了机器人学、自动驾驶和通用视频设置中的数据资源和指标，覆盖像素预测质量、状态级理解和任务性能，并对最先进模型进行了定量比较。

Conclusion: 指出了关键开放挑战：统一数据集的稀缺性、需要评估物理一致性而非像素保真度的指标、模型性能与实时控制计算效率之间的权衡，以及实现长期时间一致性同时减轻误差累积的核心建模难度。

Abstract: Embodied AI requires agents that perceive, act, and anticipate how actions
reshape future world states. World models serve as internal simulators that
capture environment dynamics, enabling forward and counterfactual rollouts to
support perception, prediction, and decision making. This survey presents a
unified framework for world models in embodied AI. Specifically, we formalize
the problem setting and learning objectives, and propose a three-axis taxonomy
encompassing: (1) Functionality, Decision-Coupled vs. General-Purpose; (2)
Temporal Modeling, Sequential Simulation and Inference vs. Global Difference
Prediction; (3) Spatial Representation, Global Latent Vector, Token Feature
Sequence, Spatial Latent Grid, and Decomposed Rendering Representation. We
systematize data resources and metrics across robotics, autonomous driving, and
general video settings, covering pixel prediction quality, state-level
understanding, and task performance. Furthermore, we offer a quantitative
comparison of state-of-the-art models and distill key open challenges,
including the scarcity of unified datasets and the need for evaluation metrics
that assess physical consistency over pixel fidelity, the trade-off between
model performance and the computational efficiency required for real-time
control, and the core modeling difficulty of achieving long-horizon temporal
consistency while mitigating error accumulation. Finally, we maintain a curated
bibliography at https://github.com/Li-Zn-H/AwesomeWorldModels.

</details>


### [50] [Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling](https://arxiv.org/abs/2510.16751)
*Erik Riise,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: 研究表明，离散的自回归视觉模型比连续扩散模型更适合推理时搜索优化，光束搜索能显著提升文本到图像生成质量，让2B参数的自回归模型超越12B参数的扩散模型。


<details>
  <summary>Details</summary>
Motivation: 尽管推理时搜索在大型语言模型中取得了革命性进展，但在图像生成领域应用搜索策略却效果有限。研究者希望探索不同模型架构对推理时优化的影响。

Method: 采用离散的自回归视觉模型，利用光束搜索进行推理时优化，通过早期剪枝和计算重用提升效率，并进行系统性消融实验验证离散token空间的优势。

Result: 光束搜索显著提升了文本到图像生成质量，2B参数的自回归模型在多个基准测试中超越了12B参数的扩散模型。验证器分析揭示了速度与推理能力之间的权衡。

Conclusion: 模型架构（而不仅仅是规模）对于视觉生成中的推理时优化至关重要，离散的自回归模型比连续扩散模型更适合搜索策略的应用。

Abstract: While inference-time scaling through search has revolutionized Large Language
Models, translating these gains to image generation has proven difficult.
Recent attempts to apply search strategies to continuous diffusion models show
limited benefits, with simple random sampling often performing best. We
demonstrate that the discrete, sequential nature of visual autoregressive
models enables effective search for image generation. We show that beam search
substantially improves text-to-image generation, enabling a 2B parameter
autoregressive model to outperform a 12B parameter diffusion model across
benchmarks. Systematic ablations show that this advantage comes from the
discrete token space, which allows early pruning and computational reuse, and
our verifier analysis highlights trade-offs between speed and reasoning
capability. These findings suggest that model architecture, not just scale, is
critical for inference-time optimization in visual generation.

</details>


### [51] [Prominence-Aware Artifact Detection and Dataset for Image Super-Resolution](https://arxiv.org/abs/2510.16752)
*Ivan Molodetskikh,Kirill Malyshev,Mark Mirgaleev,Nikita Zagainov,Evgeney Bogatyrev,Dmitriy Vatolin*

Main category: cs.CV

TL;DR: 该论文提出了一个基于人类感知的SR伪影评估方法，构建了包含1302个伪影示例的数据集，并训练了一个轻量级回归器来生成空间显著度热图。


<details>
  <summary>Details</summary>
Motivation: 随着生成式图像超分辨率模型能力的增强，它们产生的伪影问题日益突出。作者认为应该根据伪影对人类观察者的显著程度来评估，而不是将其视为统一的二进制缺陷。

Method: 构建了一个包含1302个伪影示例的数据集，每个伪影都配有众包显著度评分。基于此数据集训练了一个轻量级回归器来生成空间显著度热图。

Result: 训练的回归器在检测显著伪影方面优于现有方法，能够生成空间显著度热图。

Conclusion: 该研究为SR伪影的显著度感知评估和缓解提供了数据集和工具，强调了根据人类感知评估伪影的重要性。

Abstract: Generative image super-resolution (SR) is rapidly advancing in visual quality
and detail restoration. As the capacity of SR models expands, however, so does
their tendency to produce artifacts: incorrect, visually disturbing details
that reduce perceived quality. Crucially, their perceptual impact varies: some
artifacts are barely noticeable while others strongly degrade the image. We
argue that artifacts should be characterized by their prominence to human
observers rather than treated as uniform binary defects. Motivated by this, we
present a novel dataset of 1302 artifact examples from 11 contemporary image-SR
methods, where each artifact is paired with a crowdsourced prominence score.
Building on this dataset, we train a lightweight regressor that produces
spatial prominence heatmaps and outperforms existing methods at detecting
prominent artifacts. We release the dataset and code to facilitate
prominence-aware evaluation and mitigation of SR artifacts.

</details>


### [52] [WaMaIR: Image Restoration via Multiscale Wavelet Convolutions and Mamba-based Channel Modeling with Texture Enhancement](https://arxiv.org/abs/2510.16765)
*Shengyu Zhu,Fan,Fuxuan Zhang*

Main category: cs.CV

TL;DR: 提出WaMaIR框架，通过全局多尺度小波变换卷积扩大感受野，结合Mamba通道感知模块捕获长距离依赖关系，并使用多尺度纹理增强损失函数，显著提升图像恢复中的纹理细节重建效果。


<details>
  <summary>Details</summary>
Motivation: 传统CNN方法在图像恢复中受限于小感受野和缺乏通道特征建模，难以充分恢复精细纹理细节。

Method: 采用全局多尺度小波变换卷积扩大感受野，引入Mamba通道感知模块捕获通道间长距离依赖，并设计多尺度纹理增强损失函数指导模型保留纹理结构。

Result: 大量实验证实WaMaIR在图像恢复任务中优于现有最先进方法，同时保持计算效率。

Conclusion: WaMaIR通过扩大感受野和增强通道特征建模，有效解决了图像恢复中的纹理细节重建问题，实现了更好的恢复效果和计算性能。

Abstract: Image restoration is a fundamental and challenging task in computer vision,
where CNN-based frameworks demonstrate significant computational efficiency.
However, previous CNN-based methods often face challenges in adequately
restoring fine texture details, which are limited by the small receptive field
of CNN structures and the lack of channel feature modeling. In this paper, we
propose WaMaIR, which is a novel framework with a large receptive field for
image perception and improves the reconstruction of texture details in restored
images. Specifically, we introduce the Global Multiscale Wavelet Transform
Convolutions (GMWTConvs) for expandding the receptive field to extract image
features, preserving and enriching texture features in model inputs. Meanwhile,
we propose the Mamba-Based Channel-Aware Module (MCAM), explicitly designed to
capture long-range dependencies within feature channels, which enhancing the
model sensitivity to color, edges, and texture information. Additionally, we
propose Multiscale Texture Enhancement Loss (MTELoss) for image restoration to
guide the model in preserving detailed texture structures effectively.
Extensive experiments confirm that WaMaIR outperforms state-of-the-art methods,
achieving better image restoration and efficient computational performance of
the model.

</details>


### [53] [Region in Context: Text-condition Image editing with Human-like semantic reasoning](https://arxiv.org/abs/2510.16772)
*Thuy Phuong Vu,Dinh-Cuong Hoang,Minhhuy Le,Phan Xuan Tan*

Main category: cs.CV

TL;DR: 提出Region in Context框架，通过多级语义对齐实现文本条件图像编辑，考虑区域在整体图像上下文中的角色，实现精确协调的编辑效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法将图像区域孤立处理，仅依赖局部线索而不考虑各部分对整体视觉和语义构成的贡献，导致编辑不一致、过渡不自然或图像连贯性丧失。

Method: 引入双级引导机制：区域在全图像上下文中表示并与详细区域级描述对齐，同时整个图像与大型视觉语言模型生成的全面场景级描述匹配，作为明确的语言参考指导局部修改和全局结构。

Result: 实验表明该方法能产生更连贯且与指令对齐的结果。

Conclusion: Region in Context框架通过多级语义对齐实现了更精确协调的文本条件图像编辑，解决了现有方法的局限性。

Abstract: Recent research has made significant progress in localizing and editing image
regions based on text. However, most approaches treat these regions in
isolation, relying solely on local cues without accounting for how each part
contributes to the overall visual and semantic composition. This often results
in inconsistent edits, unnatural transitions, or loss of coherence across the
image. In this work, we propose Region in Context, a novel framework for
text-conditioned image editing that performs multilevel semantic alignment
between vision and language, inspired by the human ability to reason about
edits in relation to the whole scene. Our method encourages each region to
understand its role within the global image context, enabling precise and
harmonized changes. At its core, the framework introduces a dual-level guidance
mechanism: regions are represented with full-image context and aligned with
detailed region-level descriptions, while the entire image is simultaneously
matched to a comprehensive scene-level description generated by a large
vision-language model. These descriptions serve as explicit verbal references
of the intended content, guiding both local modifications and global structure.
Experiments show that it produces more coherent and instruction-aligned
results. Code is available at:
https://github.com/thuyvuphuong/Region-in-Context.git

</details>


### [54] [GS2POSE: Marry Gaussian Splatting to 6D Object Pose Estimation](https://arxiv.org/abs/2510.16777)
*Junbo Li,Weimin Yuan,Yinuo Wang,Yue Zeng,Shihao Shu,Cai Meng,Xiangzhi Bai*

Main category: cs.CV

TL;DR: GS2POSE是一种新颖的6D物体姿态估计方法，通过结合Bundle Adjustment原理和3D高斯散射，构建了姿态可微渲染管道，在纹理缺失和光照变化条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统6D姿态估计方法依赖2D图像特征与3D模型特征的对应关系，但在纹理缺失物体和变化光照条件下表现不佳，需要新的解决方案。

Method: 基于Bundle Adjustment原理，利用李代数扩展3D高斯散射能力，构建姿态可微渲染管道，通过迭代优化姿态参数，同时更新3DGS模型中的颜色参数以适应光照变化。

Result: 在T-LESS、LineMod-Occlusion和LineMod数据集上分别实现了1.4%、2.8%和2.5%的精度提升。

Conclusion: GS2POSE通过结合BA原理和3DGS，有效解决了纹理缺失和光照变化下的6D姿态估计问题，在多个数据集上取得了显著改进。

Abstract: Accurate 6D pose estimation of 3D objects is a fundamental task in computer
vision, and current research typically predicts the 6D pose by establishing
correspondences between 2D image features and 3D model features. However, these
methods often face difficulties with textureless objects and varying
illumination conditions. To overcome these limitations, we propose GS2POSE, a
novel approach for 6D object pose estimation. GS2POSE formulates a pose
regression algorithm inspired by the principles of Bundle Adjustment (BA). By
leveraging Lie algebra, we extend the capabilities of 3DGS to develop a
pose-differentiable rendering pipeline, which iteratively optimizes the pose by
comparing the input image to the rendered image. Additionally, GS2POSE updates
color parameters within the 3DGS model, enhancing its adaptability to changes
in illumination. Compared to previous models, GS2POSE demonstrates accuracy
improvements of 1.4\%, 2.8\% and 2.5\% on the T-LESS, LineMod-Occlusion and
LineMod datasets, respectively.

</details>


### [55] [Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features](https://arxiv.org/abs/2510.16781)
*Shihao Ji,Zihui Song*

Main category: cs.CV

TL;DR: 提出了一种无需训练的视频理解框架，通过结合预训练视觉语言模型的语义先验和经典机器学习算法，将视频理解重新定义为高维语义特征空间中的自监督时空聚类问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解模型依赖大量标注数据和任务特定训练，成本高且扩展性有限，而大规模视觉语言模型在静态图像上的零样本推理能力尚未在视频领域充分发挥。

Method: 使用预训练VLM的冻结视觉编码器将视频流转换为语义特征轨迹，然后采用核时间分割(KTS)将连续特征流划分为离散的语义连贯事件片段，最后通过无监督密度聚类识别重复出现的宏观场景和主题。

Result: 通过从每个发现的聚类中选择代表性关键帧并利用VLM的文本生成能力，框架能自动生成视频内容的结构化多模态摘要。

Conclusion: 该方法为零样本、自动化的视频内容结构分析提供了一条有效、可解释且模型无关的途径。

Abstract: The remarkable zero-shot reasoning capabilities of large-scale Visual
Language Models (VLMs) on static images have yet to be fully translated to the
video domain. Conventional video understanding models often rely on extensive,
task-specific training on annotated datasets, a process that is both costly and
limited in scalability. This paper introduces a novel, training-free framework
for video understanding that circumvents end-to-end training by synergistically
combining the rich semantic priors of pre-trained VLMs with classic machine
learning algorithms for pattern discovery. Our core idea is to reframe video
understanding as a self-supervised spatio-temporal clustering problem within a
high-dimensional semantic feature space. The proposed pipeline first transforms
a video stream into a semantic feature trajectory using the frozen visual
encoder of a pre-trained VLM. Subsequently, we employ Kernel Temporal
Segmentation (KTS), a robust machine learning technique, to partition the
continuous feature stream into discrete, semantically coherent event segments.
These segments are then subjected to unsupervised density-based clustering to
identify recurring macroscopic scenes and themes throughout the video. By
selecting representative keyframes from each discovered cluster and leveraging
the VLM's generative capabilities for textual description, our framework
automatically produces a structured, multi-modal summary of the video content.
This approach provides an effective, interpretable, and model-agnostic pathway
for zero-shot, automated structural analysis of video content.

</details>


### [56] [Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs](https://arxiv.org/abs/2510.16785)
*Jiazhen Liu,Long Chen*

Main category: cs.CV

TL;DR: LENS是一种新颖的即插即用解决方案，通过为冻结的MLLM添加轻量级可训练头部，利用注意力图中的空间线索提取关键点，实现像素级分割，同时完全保留模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法需要微调模型以产生与掩码解码器兼容的输出，这会改变模型的输出空间并损害其内在泛化能力，违背了构建统一模型的目标。

Method: LENS在完全冻结的MLLM上附加轻量级可训练头部，通过精炼注意力图中的空间线索来提取关键点，并将其描述为与掩码解码器直接兼容的点级特征。

Result: LENS实现了与基于重训练方法相竞争甚至更优的分割性能，同时完全保留了MLLM的泛化能力，而微调方法会显著降低这种能力。

Conclusion: LENS的可附加设计为扩展MLLM建立了一个高效强大的范式，为实现真正多才多艺的统一模型铺平了道路。

Abstract: Integrating diverse visual capabilities into a unified model is a significant
trend in Multimodal Large Language Models (MLLMs). Among these, the inclusion
of segmentation poses a distinct set of challenges. To equip MLLMs with
pixel-level segmentation abilities, prevailing methods require finetuning the
model to produce specific outputs compatible with a mask decoder. This process
typically alters the model's output space and compromises its intrinsic
generalization, which undermines the goal of building a unified model. We
introduce LENS (Leveraging kEypoiNts for MLLMs' Segmentation), a novel
plug-and-play solution. LENS attaches a lightweight, trainable head to a
completely frozen MLLM. By refining the spatial cues embedded in attention
maps, LENS extracts keypoints and describes them into point-wise features
directly compatible with the mask decoder. Extensive experiments validate our
approach: LENS achieves segmentation performance competitive with or superior
to that of retraining-based methods. Crucially, it does so while fully
preserving the MLLM's generalization capabilities, which are significantly
degraded by finetuning approaches. As such, the attachable design of LENS
establishes an efficient and powerful paradigm for extending MLLMs, paving the
way for truly multi-talented, unified models.

</details>


### [57] [Unsupervised Monocular Road Segmentation for Autonomous Driving via Scene Geometry](https://arxiv.org/abs/2510.16790)
*Sara Hatami Rostami,Behrooz Nasihatkon*

Main category: cs.CV

TL;DR: 提出了一种完全无监督的道路分割方法，利用场景几何和时间一致性来区分道路与非道路区域，无需人工标注数据。


<details>
  <summary>Details</summary>
Motivation: 消除对昂贵人工标注数据集的依赖，开发可扩展的无监督道路分割方法用于自动驾驶。

Method: 首先基于几何先验生成弱标签（地平线以上为非道路，车辆前方四边形为道路），然后通过跨帧跟踪局部特征点并利用互信息最大化来强制执行时间一致性。

Result: 在Cityscapes数据集上实现了0.82的交并比(IoU)，表现出高精度和简单设计。

Conclusion: 结合几何约束和时间一致性为自动驾驶中的可扩展无监督道路分割展示了巨大潜力。

Abstract: This paper presents a fully unsupervised approach for binary road
segmentation (road vs. non-road), eliminating the reliance on costly manually
labeled datasets. The method leverages scene geometry and temporal cues to
distinguish road from non-road regions. Weak labels are first generated from
geometric priors, marking pixels above the horizon as non-road and a predefined
quadrilateral in front of the vehicle as road. In a refinement stage, temporal
consistency is enforced by tracking local feature points across frames and
penalizing inconsistent label assignments using mutual information
maximization. This enhances both precision and temporal stability. On the
Cityscapes dataset, the model achieves an Intersection-over-Union (IoU) of
0.82, demonstrating high accuracy with a simple design. These findings
demonstrate the potential of combining geometric constraints and temporal
consistency for scalable unsupervised road segmentation in autonomous driving.

</details>


### [58] [Personalized Image Filter: Mastering Your Photographic Style](https://arxiv.org/abs/2510.16791)
*Chengxuan Zhu,Shuchen Weng,Jiacong Fang,Peixuan Zhang,Si Li,Chao Xu,Boxin Shi*

Main category: cs.CV

TL;DR: 该论文提出了个性化图像滤镜（PIF），基于预训练文本到图像扩散模型，通过文本反演技术学习参考图像的摄影风格，实现有效的风格提取和迁移。


<details>
  <summary>Details</summary>
Motivation: 摄影风格作为特定摄影概念的组合，是著名摄影师魅力的来源。但学习和迁移摄影风格需要对照片从原始外观到最终编辑过程的深刻理解。现有方法要么无法从参考图像中学习有意义的摄影概念，要么无法保留内容图像的内容。

Method: 基于预训练文本到图像扩散模型，利用生成先验学习摄影概念的平均外观以及如何根据文本提示调整它们。使用文本反演技术通过优化摄影概念的提示来学习参考图像的摄影风格。

Result: PIF在提取和迁移各种摄影风格方面表现出色。

Conclusion: PIF能够有效解决摄影风格学习和迁移中的关键问题，在风格提取和迁移方面具有优异性能。

Abstract: Photographic style, as a composition of certain photographic concepts, is the
charm behind renowned photographers. But learning and transferring photographic
style need a profound understanding of how the photo is edited from the unknown
original appearance. Previous works either fail to learn meaningful
photographic concepts from reference images, or cannot preserve the content of
the content image. To tackle these issues, we proposed a Personalized Image
Filter (PIF). Based on a pretrained text-to-image diffusion model, the
generative prior enables PIF to learn the average appearance of photographic
concepts, as well as how to adjust them according to text prompts. PIF then
learns the photographic style of reference images with the textual inversion
technique, by optimizing the prompts for the photographic concepts. PIF shows
outstanding performance in extracting and transferring various kinds of
photographic style. Project page: https://pif.pages.dev/

</details>


### [59] [An RGB-D Image Dataset for Lychee Detection and Maturity Classification for Robotic Harvesting](https://arxiv.org/abs/2510.16800)
*Zhenpeng Zhang,Yi Wang,Shanglei Chai,Yingying Liu,Zekai Xie,Wenhao Huang,Pengyu Li,Zipei Luo,Dajiang Lu,Yibin Tian*

Main category: cs.CV

TL;DR: 研究者构建了一个包含11,414张荔枝图像的公开数据集，用于荔枝检测和成熟度分类，填补了自然生长环境下荔枝数据集的空白。


<details>
  <summary>Details</summary>
Motivation: 荔枝是高价值亚热带水果，基于视觉的采摘机器人可提高生产力并减少对劳动力的依赖，但目前缺乏在自然生长环境下一致且全面标注的公开荔枝数据集。

Method: 在不同天气条件和一天中不同时间采集多个荔枝品种的彩色图像，包含三个成熟度阶段，共11,414张图像（878张原始RGB图像、8,780张增强RGB图像和1,756张深度图像），由三人独立标注并由第四人验证。

Result: 数据集包含9,658对荔枝检测和成熟度分类标签，进行了详细的统计分析，并使用三种代表性深度学习模型进行了实验评估。

Conclusion: 该数据集为学术研究提供公开可用的高质量荔枝图像数据，支持荔枝检测和成熟度分类算法的开发。

Abstract: Lychee is a high-value subtropical fruit. The adoption of vision-based
harvesting robots can significantly improve productivity while reduce reliance
on labor. High-quality data are essential for developing such harvesting
robots. However, there are currently no consistently and comprehensively
annotated open-source lychee datasets featuring fruits in natural growing
environments. To address this, we constructed a dataset to facilitate lychee
detection and maturity classification. Color (RGB) images were acquired under
diverse weather conditions, and at different times of the day, across multiple
lychee varieties, such as Nuomici, Feizixiao, Heiye, and Huaizhi. The dataset
encompasses three different ripeness stages and contains 11,414 images,
consisting of 878 raw RGB images, 8,780 augmented RGB images, and 1,756 depth
images. The images are annotated with 9,658 pairs of lables for lychee
detection and maturity classification. To improve annotation consistency, three
individuals independently labeled the data, and their results were then
aggregated and verified by a fourth reviewer. Detailed statistical analyses
were done to examine the dataset. Finally, we performed experiments using three
representative deep learning models to evaluate the dataset. It is publicly
available for academic

</details>


### [60] [ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification](https://arxiv.org/abs/2510.16822)
*Yahia Battach,Abdulwahab Felemban,Faizan Farooq Khan,Yousef A. Radwan,Xiang Li,Fabio Marchese,Sara Beery,Burton H. Jones,Francesca Benzoni,Mohamed Elhoseiny*

Main category: cs.CV

TL;DR: ReefNet是一个大规模公开珊瑚礁图像数据集，包含约925,000个属级硬珊瑚注释，映射到世界海洋物种名录，旨在推动珊瑚礁自动监测和领域泛化研究。


<details>
  <summary>Details</summary>
Motivation: 由于气候变化等人为压力导致珊瑚礁快速衰退，急需可扩展的自动化监测方法。现有数据集在规模、地理覆盖范围和标签粒度方面存在限制，无法满足机器学习需求。

Method: 整合来自76个CoralNet来源和红海Al Wajh站点的图像数据，提供细粒度、分类学映射的标签。提出两种评估设置：源内基准测试和跨源基准测试，分别用于局部评估和领域泛化测试。

Result: 监督学习在源内表现良好，但跨域性能显著下降；零样本模型在所有情况下表现均较差，特别是对于稀有和视觉相似属。

Conclusion: ReefNet提供了一个具有挑战性的基准，旨在推动领域泛化和细粒度珊瑚分类的进展，将发布数据集、基准代码和预训练模型以促进全球珊瑚礁监测和保护。

Abstract: Coral reefs are rapidly declining due to anthropogenic pressures such as
climate change, underscoring the urgent need for scalable, automated
monitoring. We introduce ReefNet, a large public coral reef image dataset with
point-label annotations mapped to the World Register of Marine Species (WoRMS).
ReefNet aggregates imagery from 76 curated CoralNet sources and an additional
site from Al Wajh in the Red Sea, totaling approximately 925000 genus-level
hard coral annotations with expert-verified labels. Unlike prior datasets,
which are often limited by size, geography, or coarse labels and are not
ML-ready, ReefNet offers fine-grained, taxonomically mapped labels at a global
scale to WoRMS. We propose two evaluation settings: (i) a within-source
benchmark that partitions each source's images for localized evaluation, and
(ii) a cross-source benchmark that withholds entire sources to test domain
generalization. We analyze both supervised and zero-shot classification
performance on ReefNet and find that while supervised within-source performance
is promising, supervised performance drops sharply across domains, and
performance is low across the board for zero-shot models, especially for rare
and visually similar genera. This provides a challenging benchmark intended to
catalyze advances in domain generalization and fine-grained coral
classification. We will release our dataset, benchmarking code, and pretrained
models to advance robust, domain-adaptive, global coral reef monitoring and
conservation.

</details>


### [61] [Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction](https://arxiv.org/abs/2510.16832)
*Abdur Rahman,Mohammad Marufuzzaman,Jason Street,Haifeng Wang,Veera G. Gude,Randy Buchanan*

Main category: cs.CV

TL;DR: 提出了一种名为AdaptMoist的领域自适应方法，利用木材碎片图像的纹理特征来预测水分含量，解决了不同来源木材碎片数据分布变化的问题，显著提高了跨域预测准确性。


<details>
  <summary>Details</summary>
Motivation: 当前木材碎片水分含量预测方法存在局限性：直接方法（烘箱干燥）处理时间长且破坏样本，间接方法（近红外光谱、电容、图像）在不同来源木材碎片上准确性不足。数据分布变化会削弱数据驱动模型的性能，需要一种能够有效应对来源变异性的稳健方法。

Method: 1. 从木材碎片图像中提取五种不同的纹理特征进行综合分析；2. 提出AdaptMoist领域自适应方法，利用纹理特征将知识从一个木材碎片数据源转移到另一个数据源；3. 提出基于调整互信息的模型保存标准。

Result: 1. 结合所有五种纹理特征的特征集在预测水分含量时达到95%的准确率，始终优于单个纹理特征；2. AdaptMoist方法将跨域预测准确率提高了23%，平均准确率达到80%，而非自适应模型仅为57%。

Conclusion: AdaptMoist作为一种稳健的解决方案，在跨域木材碎片水分含量估计方面表现出色，使其成为依赖木材碎片的行业的潜在解决方案。纹理特征组合和领域自适应方法有效解决了来源变异性问题。

Abstract: Accurate and quick prediction of wood chip moisture content is critical for
optimizing biofuel production and ensuring energy efficiency. The current
widely used direct method (oven drying) is limited by its longer processing
time and sample destructiveness. On the other hand, existing indirect methods,
including near-infrared spectroscopy-based, electrical capacitance-based, and
image-based approaches, are quick but not accurate when wood chips come from
various sources. Variability in the source material can alter data
distributions, undermining the performance of data-driven models. Therefore,
there is a need for a robust approach that effectively mitigates the impact of
source variability. Previous studies show that manually extracted texture
features have the potential to predict wood chip moisture class. Building on
this, in this study, we conduct a comprehensive analysis of five distinct
texture feature types extracted from wood chip images to predict moisture
content. Our findings reveal that a combined feature set incorporating all five
texture features achieves an accuracy of 95% and consistently outperforms
individual texture features in predicting moisture content. To ensure robust
moisture prediction, we propose a domain adaptation method named AdaptMoist
that utilizes the texture features to transfer knowledge from one source of
wood chip data to another, addressing variability across different domains. We
also proposed a criterion for model saving based on adjusted mutual
information. The AdaptMoist method improves prediction accuracy across domains
by 23%, achieving an average accuracy of 80%, compared to 57% for non-adapted
models. These results highlight the effectiveness of AdaptMoist as a robust
solution for wood chip moisture content estimation across domains, making it a
potential solution for wood chip-reliant industries.

</details>


### [62] [From Mannequin to Human: A Pose-Aware and Identity-Preserving Video Generation Framework for Lifelike Clothing Display](https://arxiv.org/abs/2510.16833)
*Xiangyu Mu,Dongliang Zhou,Jie Hou,Haijun Zhang,Weili Guan*

Main category: cs.CV

TL;DR: 提出M2HVideo框架，将假人模特视频转换为身份可控、逼真的人类视频，解决了头部与身体运动不对齐以及时间建模导致的身份漂移问题。


<details>
  <summary>Details</summary>
Motivation: 假人模特展示服装成本低但缺乏真实感和表现细节，需要将假人视频转换为逼真的人类视频以提升在线时尚展示效果。

Method: 采用动态姿态感知头部编码器融合面部语义和身体姿态，引入像素空间的镜像损失，设计分布感知适配器对齐身份和服装特征的统计分布。

Result: 在UBC时尚数据集、自建ASOS数据集和新收集的MannequinVideos数据集上的实验表明，M2HVideo在服装一致性、身份保持和视频保真度方面优于现有方法。

Conclusion: M2HVideo框架有效解决了假人到人类视频生成中的关键挑战，实现了高质量的逼真人类视频合成。

Abstract: Mannequin-based clothing displays offer a cost-effective alternative to
real-model showcases for online fashion presentation, but lack realism and
expressive detail. To overcome this limitation, we introduce a new task called
mannequin-to-human (M2H) video generation, which aims to synthesize
identity-controllable, photorealistic human videos from footage of mannequins.
We propose M2HVideo, a pose-aware and identity-preserving video generation
framework that addresses two key challenges: the misalignment between head and
body motion, and identity drift caused by temporal modeling. In particular,
M2HVideo incorporates a dynamic pose-aware head encoder that fuses facial
semantics with body pose to produce consistent identity embeddings across
frames. To address the loss of fine facial details due to latent space
compression, we introduce a mirror loss applied in pixel space through a
denoising diffusion implicit model (DDIM)-based one-step denoising.
Additionally, we design a distribution-aware adapter that aligns statistical
distributions of identity and clothing features to enhance temporal coherence.
Extensive experiments on the UBC fashion dataset, our self-constructed ASOS
dataset, and the newly collected MannequinVideos dataset captured on-site
demonstrate that M2HVideo achieves superior performance in terms of clothing
consistency, identity preservation, and video fidelity in comparison to
state-of-the-art methods.

</details>


### [63] [2DGS-R: Revisiting the Normal Consistency Regularization in 2D Gaussian Splatting](https://arxiv.org/abs/2510.16837)
*Haofan Ren,Qingsong Yan,Ming Lu,Rongfeng Lu,Zunjie Zhu*

Main category: cs.CV

TL;DR: 本文提出2DGS-R方法，通过分层训练策略在保持几何精度的同时提升渲染质量，仅需1%额外存储和少量训练时间即可实现高质量渲染。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术难以准确表示表面，而2D高斯平面方法虽然几何保真度有所提升，但渲染质量仍受影响，目前无法在单次训练中同时优化几何和渲染质量。

Method: 采用分层训练方法：首先用法向一致性正则化训练原始2D高斯；然后选择渲染质量不足的2D高斯进行原地克隆操作；最后冻结不透明度微调模型。

Result: 相比原始2DGS，仅需1%额外存储和少量训练时间，即可获得高质量渲染结果，同时保持精细几何结构。

Conclusion: 该方法有效平衡了效率与性能，在视觉保真度和几何重建精度方面均有提升。

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have greatly influenced
neural fields, as it enables high-fidelity rendering with impressive visual
quality. However, 3DGS has difficulty accurately representing surfaces. In
contrast, 2DGS transforms the 3D volume into a collection of 2D planar Gaussian
disks. Despite advancements in geometric fidelity, rendering quality remains
compromised, highlighting the challenge of achieving both high-quality
rendering and precise geometric structures. This indicates that optimizing both
geometric and rendering quality in a single training stage is currently
unfeasible. To overcome this limitation, we present 2DGS-R, a new method that
uses a hierarchical training approach to improve rendering quality while
maintaining geometric accuracy. 2DGS-R first trains the original 2D Gaussians
with the normal consistency regularization. Then 2DGS-R selects the 2D
Gaussians with inadequate rendering quality and applies a novel in-place
cloning operation to enhance the 2D Gaussians. Finally, we fine-tune the 2DGS-R
model with opacity frozen. Experimental results show that compared to the
original 2DGS, our method requires only 1\% more storage and minimal additional
training time. Despite this negligible overhead, it achieves high-quality
rendering results while preserving fine geometric structures. These findings
indicate that our approach effectively balances efficiency with performance,
leading to improvements in both visual fidelity and geometric reconstruction
accuracy.

</details>


### [64] [ArmFormer: Lightweight Transformer Architecture for Real-Time Multi-Class Weapon Segmentation and Classification](https://arxiv.org/abs/2510.16854)
*Akhila Kambhatla,Taminul Islam,Khaled R Ahmed*

Main category: cs.CV

TL;DR: ArmFormer是一个轻量级基于transformer的语义分割框架，结合CBAM和MixVisionTransformer架构，用于多类武器像素级分割，在保持计算效率的同时实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统武器检测方法只能提供粗粒度的边界框定位，缺乏细粒度分割能力；现有语义分割模型要么牺牲精度换取计算效率，要么计算资源需求过高，不适合边缘部署场景。

Method: 将CBAM增强的编码器主干与注意力集成的hamburger解码器相结合，构建轻量级transformer语义分割框架，支持手枪、步枪、刀具、左轮手枪和人类五类分割。

Result: ArmFormer达到80.64% mIoU和89.13% mFscore的最先进性能，实时推理速度为82.26 FPS，仅需4.886G FLOPs和3.66M参数，比重量级模型计算量减少48倍。

Conclusion: ArmFormer是部署在便携式安全摄像头、监控无人机和嵌入式AI加速器上的最优解决方案，在分布式安全基础设施中具有重要应用价值。

Abstract: The escalating threat of weapon-related violence necessitates automated
detection systems capable of pixel-level precision for accurate threat
assessment in real-time security applications. Traditional weapon detection
approaches rely on object detection frameworks that provide only coarse
bounding box localizations, lacking the fine-grained segmentation required for
comprehensive threat analysis. Furthermore, existing semantic segmentation
models either sacrifice accuracy for computational efficiency or require
excessive computational resources incompatible with edge deployment scenarios.
This paper presents ArmFormer, a lightweight transformer-based semantic
segmentation framework that strategically integrates Convolutional Block
Attention Module (CBAM) with MixVisionTransformer architecture to achieve
superior accuracy while maintaining computational efficiency suitable for
resource-constrained edge devices. Our approach combines CBAM-enhanced encoder
backbone with attention-integrated hamburger decoder to enable multi-class
weapon segmentation across five categories: handgun, rifle, knife, revolver,
and human. Comprehensive experiments demonstrate that ArmFormer achieves
state-of-the-art performance with 80.64% mIoU and 89.13% mFscore while
maintaining real-time inference at 82.26 FPS. With only 4.886G FLOPs and 3.66M
parameters, ArmFormer outperforms heavyweight models requiring up to 48x more
computation, establishing it as the optimal solution for deployment on portable
security cameras, surveillance drones, and embedded AI accelerators in
distributed security infrastructure.

</details>


### [65] [Class-N-Diff: Classification-Induced Diffusion Model Can Make Fair Skin Cancer Diagnosis](https://arxiv.org/abs/2510.16887)
*Nusrat Munia,Abdullah Imran*

Main category: cs.CV

TL;DR: 提出了一种分类诱导的扩散模型Class-N-Diff，通过在扩散模型中集成分类器来同时生成和分类皮肤镜图像，提高了类别条件图像合成的控制能力。


<details>
  <summary>Details</summary>
Motivation: 传统类别条件生成模型在准确生成特定医学类别图像方面存在困难，限制了其在皮肤癌诊断等应用中的实用性。

Method: 在扩散模型中集成分类器，基于类别条件指导图像生成，实现同时生成和分类皮肤镜图像。

Result: 模型能够更好地控制类别条件图像合成，生成更真实和多样化的图像，同时分类器在下游诊断任务中表现出改进的性能。

Conclusion: Class-N-Diff通过独特的集成方式，成为增强基于扩散模型的合成皮肤镜图像生成质量和实用性的强大工具。

Abstract: Generative models, especially Diffusion Models, have demonstrated remarkable
capability in generating high-quality synthetic data, including medical images.
However, traditional class-conditioned generative models often struggle to
generate images that accurately represent specific medical categories, limiting
their usefulness for applications such as skin cancer diagnosis. To address
this problem, we propose a classification-induced diffusion model, namely,
Class-N-Diff, to simultaneously generate and classify dermoscopic images. Our
Class-N-Diff model integrates a classifier within a diffusion model to guide
image generation based on its class conditions. Thus, the model has better
control over class-conditioned image synthesis, resulting in more realistic and
diverse images. Additionally, the classifier demonstrates improved performance,
highlighting its effectiveness for downstream diagnostic tasks. This unique
integration in our Class-N-Diff makes it a robust tool for enhancing the
quality and utility of diffusion model-based synthetic dermoscopic image
generation. Our code is available at https://github.com/Munia03/Class-N-Diff.

</details>


### [66] [Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback](https://arxiv.org/abs/2510.16888)
*Zongjian Li,Zheyuan Liu,Qihui Zhang,Bin Lin,Shenghai Yuan,Zhiyuan Yan,Yang Ye,Wangbo Yu,Yuwei Niu,Li Yuan*

Main category: cs.CV

TL;DR: Edit-R1是一个基于策略优化的指令图像编辑后训练框架，通过DiffusionNFT方法实现高效训练，并利用MLLM作为无需训练的通用奖励模型，在多个基准测试中取得最先进成果。


<details>
  <summary>Details</summary>
Motivation: 基于监督微调的指令图像编辑模型容易过拟合到标注模式，限制了其在训练分布之外的泛化能力。

Method: 使用Diffusion Negative-aware Finetuning (DiffusionNFT)策略优化方法，结合多模态大语言模型作为训练免费的奖励模型，并设计了低方差组过滤机制来减少评分噪声。

Result: UniWorld-V2在ImgEdit和GEdit-Bench基准测试中分别获得4.49和7.83的分数，达到最先进水平。该框架具有模型无关性，可应用于多种基础模型。

Conclusion: Edit-R1框架通过策略优化和MLLM奖励模型有效提升了指令图像编辑的泛化能力和性能，具有广泛的适用性。

Abstract: Instruction-based image editing has achieved remarkable progress; however,
models solely trained via supervised fine-tuning often overfit to annotated
patterns, hindering their ability to explore and generalize beyond training
distributions. To this end, we introduce Edit-R1, a novel post-training
framework for instruction-based image editing based on policy optimization.
Specifically, we utilize Diffusion Negative-aware Finetuning (DiffusionNFT), a
likelihood-free policy optimization method consistent with the flow matching
forward process, thereby enabling the use of higher-order samplers and more
efficient training. Another key challenge here is the absence of a universal
reward model, resulting from the diverse nature of editing instructions and
tasks. To bridge this gap, we employ a Multimodal Large Language Model (MLLM)
as a unified, training-free reward model, leveraging its output logits to
provide fine-grained feedback. Furthermore, we carefully design a low-variance
group filtering mechanism to reduce MLLM scoring noise and stabilize
optimization. UniWorld-V2, trained with this framework, achieves
\textbf{state-of-the-art} results on the ImgEdit and GEdit-Bench benchmarks,
scoring 4.49 and 7.83, respectively. Crucially, our framework is
model-agnostic, delivering substantial performance gains when applied to
diverse base models like Qwen-Image-Edit and FLUX-Kontext, demonstrating its
wide applicability. Code and models are publicly available at
https://github.com/PKU-YuanGroup/UniWorld-V2.

</details>


### [67] [Contrail-to-Flight Attribution Using Ground Visible Cameras and Flight Surveillance Data](https://arxiv.org/abs/2510.16891)
*Ramon Dalmau,Gabriel Jarry,Philippe Very*

Main category: cs.CV

TL;DR: 本文提出了一种基于地面摄像机的凝结尾迹到航班归因框架，用于将观测到的凝结尾迹与生成它们的航班关联起来，以验证和校准凝结尾迹物理模型。


<details>
  <summary>Details</summary>
Motivation: 航空业的非CO2效应（特别是凝结尾迹）对气候影响显著，但卫星归因方法受限于空间和时间分辨率。地面摄像机能在凝结尾迹形成后立即以高分辨率捕捉，此时凝结尾迹仍保持细长线性且视觉上可区分。

Method: 利用地面可见摄像机凝结尾迹序列数据集，引入模块化框架，将基于地面摄像机观测的凝结尾迹与来自飞机监视和气象数据的理论凝结尾迹进行归因。框架支持多种几何表示和距离度量，包含时间平滑，并支持灵活的概率分配策略。

Result: 该工作建立了一个强大的基线，并为未来将凝结尾迹与其源航班关联的研究提供了模块化框架。

Conclusion: 基于地面摄像机的凝结尾迹归因方法为验证凝结尾迹物理模型提供了有效替代方案，克服了卫星方法的局限性，具有重要的研究价值和应用前景。

Abstract: Aviation's non-CO2 effects, particularly contrails, are a significant
contributor to its climate impact. Persistent contrails can evolve into
cirrus-like clouds that trap outgoing infrared radiation, with radiative
forcing potentially comparable to or exceeding that of aviation's CO2
emissions. While physical models simulate contrail formation, evolution and
dissipation, validating and calibrating these models requires linking observed
contrails to the flights that generated them, a process known as
contrail-to-flight attribution. Satellite-based attribution is challenging due
to limited spatial and temporal resolution, as contrails often drift and deform
before detection. In this paper, we evaluate an alternative approach using
ground-based cameras, which capture contrails shortly after formation at high
spatial and temporal resolution, when they remain thin, linear, and visually
distinct. Leveraging the ground visible camera contrail sequences (GVCCS)
dataset, we introduce a modular framework for attributing contrails observed
using ground-based cameras to theoretical contrails derived from aircraft
surveillance and meteorological data. The framework accommodates multiple
geometric representations and distance metrics, incorporates temporal
smoothing, and enables flexible probability-based assignment strategies. This
work establishes a strong baseline and provides a modular framework for future
research in linking contrails to their source flight.

</details>


### [68] [Beyond RGB: Leveraging Vision Transformers for Thermal Weapon Segmentation](https://arxiv.org/abs/2510.16913)
*Akhila Kambhatla,Ahmed R Khaled*

Main category: cs.CV

TL;DR: 本文评估了四种基于Transformer的架构（SegFormer、DeepLabV3+、SegNeXt和Swin Transformer）在热成像武器分割任务中的性能，在包含9,711张图像的自定义热成像数据集上取得了显著改进的分割效果。


<details>
  <summary>Details</summary>
Motivation: 热成像武器分割在低光照和视觉遮挡条件下对监控和安全应用至关重要。虽然CNN在热成像分割文献中占主导地位，但其捕捉长距离依赖关系和精细结构细节的能力有限。Vision Transformers在RGB分割任务中表现出色，但在热成像武器分割领域的潜力尚未充分探索。

Method: 使用MMSegmentation框架，采用标准增强策略来确保稳健的模型训练和公平的架构比较。评估了四种基于Transformer的架构：SegFormer、DeepLabV3+、SegNeXt和Swin Transformer，在包含9,711张图像的自定义热成像数据集上进行二元武器分割。

Result: SegFormer-b5实现了最高的mIoU（94.15%）和像素精度（97.04%），而SegFormer-b0提供了最快的推理速度（98.32 FPS）且具有竞争力的mIoU（90.84%）。SegNeXt-mscans在85.12 FPS和92.24% mIoU之间提供了平衡的性能，DeepLabV3+ R101-D8达到92.76% mIoU，速度为29.86 FPS。

Conclusion: Transformer架构在低光照和遮挡热成像环境中的武器检测方面表现出强大的泛化能力，提供了灵活的精度-速度权衡，适用于各种实时安全应用。

Abstract: Thermal weapon segmentation is crucial for surveillance and security
applications, enabling robust detection under lowlight and visually obscured
conditions where RGB-based systems fail. While convolutional neural networks
(CNNs) dominate thermal segmentation literature, their ability to capture
long-range dependencies and fine structural details is limited. Vision
Transformers (ViTs), with their global context modeling capabilities, have
achieved state-of-the-art results in RGB segmentation tasks, yet their
potential in thermal weapon segmentation remains underexplored. This work
adapts and evaluates four transformer-based architectures SegFormer,
DeepLabV3\+, SegNeXt, and Swin Transformer for binary weapon segmentation on a
custom thermal dataset comprising 9,711 images collected from real world
surveillance videos and automatically annotated using SAM2. We employ standard
augmentation strategies within the MMSegmentation framework to ensure robust
model training and fair architectural comparison. Experimental results
demonstrate significant improvements in segmentation performance: SegFormer-b5
achieves the highest mIoU (94.15\%) and Pixel Accuracy (97.04\%), while
SegFormer-b0 provides the fastest inference speed (98.32 FPS) with competitive
mIoU (90.84\%). SegNeXt-mscans offers balanced performance with 85.12 FPS and
92.24\% mIoU, and DeepLabV3\+ R101-D8 reaches 92.76\% mIoU at 29.86 FPS. The
transformer architectures demonstrate robust generalization capabilities for
weapon detection in low-light and occluded thermal environments, with flexible
accuracy-speed trade-offs suitable for diverse real-time security applications.

</details>


### [69] [Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input](https://arxiv.org/abs/2510.16926)
*Chenxu Li,Zhicai Wang,Yuan Sheng,Xingyu Zhu,Yanbin Hao,Xiang Wang*

Main category: cs.CV

TL;DR: 提出了Res-Bench基准测试，用于评估多模态大语言模型在不同输入分辨率下的性能稳定性，包含14,400个样本和12个分辨率级别，并引入了新的鲁棒性评估指标。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法主要关注语义性能，忽视了分辨率鲁棒性这一关键问题，即模型在不同输入分辨率下性能是否稳定。

Method: 设计了包含14,400个样本的Res-Bench基准测试，涵盖12个分辨率级别和6个核心能力维度，并提出了Spearman相关性和绝对/相对连续误差等鲁棒性指标。

Result: 对领先的MLLMs进行了大规模评估，包括模型中心和任务中心的鲁棒性分析、预处理策略研究以及微调稳定性增强探索。

Conclusion: Res-Bench填补了分辨率鲁棒性评估的空白，为多模态大语言模型的稳定性评估提供了全面框架。

Abstract: Multimodal Large Language Models (MLLMs) increasingly support dynamic image
resolutions. However, current evaluation paradigms primarily assess semantic
performance, overlooking the critical question of resolution robustness -
whether performance remains stable across varying input resolutions. To address
this gap, we introduce \textbf{Res-Bench}, a comprehensive benchmark comprising
14,400 samples across 12 resolution levels and six core capability dimensions.
We designed a novel evaluation framework that goes beyond traditional accuracy
metrics to capture performance stability. This framework introduces multiple
robustness metrics: Spearman's correlation for assessing resolution-performance
trends, and Absolute/Relative Continuous Error (ACE/RCE) for measuring
performance volatility. Using these metrics, we conducted a large-scale
evaluation of leading MLLMs. Our analysis encompasses: (1) model-centric and
task-centric robustness examination, (2) investigation of preprocessing
strategies including padding and super-resolution, and (3) exploration of
fine-tuning for stability enhancement.

</details>


### [70] [One-step Diffusion Models with Bregman Density Ratio Matching](https://arxiv.org/abs/2510.16983)
*Yuanzhi Zhu,Eleftherios Tsonis,Lucas Degeorge,Vicky Kalogeiton*

Main category: cs.CV

TL;DR: 提出了Di-Bregman框架，通过Bregman散度密度比匹配来加速扩散模型采样，实现高效的一步生成。


<details>
  <summary>Details</summary>
Motivation: 扩散和流模型生成质量高但计算成本昂贵，需要多步采样。现有蒸馏方法缺乏统一的理论基础。

Method: 将扩散蒸馏构建为基于Bregman散度的密度比匹配问题，提供凸分析视角统一多种现有目标。

Result: 在CIFAR-10和文本到图像生成任务中，Di-Bregman相比反向KL蒸馏获得更好的一步FID分数，同时保持与教师模型相近的视觉保真度。

Conclusion: Bregman密度比匹配是通向高效一步扩散生成的实际且理论基础扎实的途径。

Abstract: Diffusion and flow models achieve high generative quality but remain
computationally expensive due to slow multi-step sampling. Distillation methods
accelerate them by training fast student generators, yet most existing
objectives lack a unified theoretical foundation. In this work, we propose
Di-Bregman, a compact framework that formulates diffusion distillation as
Bregman divergence-based density-ratio matching. This convex-analytic view
connects several existing objectives through a common lens. Experiments on
CIFAR-10 and text-to-image generation demonstrate that Di-Bregman achieves
improved one-step FID over reverse-KL distillation and maintains high visual
fidelity compared to the teacher model. Our results highlight Bregman
density-ratio matching as a practical and theoretically-grounded route toward
efficient one-step diffusion generation.

</details>


### [71] [CARE: Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams](https://arxiv.org/abs/2510.16988)
*Junhao Zhao,Zishuai Liu,Ruili Fang,Jin Lu,Linghan Zhang,Fei Dou*

Main category: cs.CV

TL;DR: 提出CARE框架，通过序列-图像对比对齐方法解决ADL识别中序列和图像表示方法的局限性，实现状态最先进的性能


<details>
  <summary>Details</summary>
Motivation: 现有ADL识别方法存在表示层面的限制：序列方法保持时间顺序但对噪声敏感且缺乏空间感知，图像方法捕获全局模式但压缩时间动态并扭曲传感器布局，简单融合方法无法充分利用两种表示的互补优势

Method: 提出CARE端到端框架，集成时间感知的序列编码和空间感知的图像表示，使用序列-图像对比对齐(SICA)联合优化表示学习和分类，确保跨表示对齐和任务特定可区分性

Result: 在三个CASAS数据集上达到状态最先进性能：Milan 89.8%、Cairo 88.9%、Kyoto7 73.3%，并展示了对传感器故障和布局变化的鲁棒性

Conclusion: CARE框架通过对比对齐有效结合序列和图像表示的互补优势，为智能家居中可靠的ADL识别提供了潜力

Abstract: The recognition of Activities of Daily Living (ADLs) from event-triggered
ambient sensors is an essential task in Ambient Assisted Living, yet existing
methods remain constrained by representation-level limitations. Sequence-based
approaches preserve temporal order of sensor activations but are sensitive to
noise and lack spatial awareness, while image-based approaches capture global
patterns and implicit spatial correlations but compress fine-grained temporal
dynamics and distort sensor layouts. Naive fusion (e.g., feature concatenation)
fail to enforce alignment between sequence- and image-based representation
views, underutilizing their complementary strengths. We propose Contrastive
Alignment for ADL Recognition from Event-Triggered Sensor Streams (CARE), an
end-to-end framework that jointly optimizes representation learning via
Sequence-Image Contrastive Alignment (SICA) and classification via
cross-entropy, ensuring both cross-representation alignment and task-specific
discriminability. CARE integrates (i) time-aware, noise-resilient sequence
encoding with (ii) spatially-informed and frequency-sensitive image
representations, and employs (iii) a joint contrastive-classification objective
for end-to-end learning of aligned and discriminative embeddings. Evaluated on
three CASAS datasets, CARE achieves state-of-the-art performance (89.8% on
Milan, 88.9% on Cairo, and 73.3% on Kyoto7) and demonstrates robustness to
sensor malfunctions and layout variability, highlighting its potential for
reliable ADL recognition in smart homes.

</details>


### [72] [Training-free Online Video Step Grounding](https://arxiv.org/abs/2510.16989)
*Luca Zanella,Massimiliano Mancini,Yiming Wang,Alessio Tonioni,Elisa Ricci*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的在线视频步骤定位方法BaGLM，利用大型多模态模型的零样本能力，通过贝叶斯滤波整合历史帧信息，在三个数据集上超越了需要训练的最先进离线方法。


<details>
  <summary>Details</summary>
Motivation: 传统视频步骤定位方法需要带标注的训练集且需要离线处理整个视频，成本高且无法满足在线决策需求。本文旨在探索无需训练、在线处理的方法。

Method: 利用大型多模态模型（LMMs）的零样本能力预测有限帧的步骤，并开发BaGLM方法，通过贝叶斯滤波整合历史帧信息，包括使用大型语言模型提取的依赖矩阵和步骤进度估计。

Result: 实验表明，这种无需任务特定调优的在线策略优于离线和基于训练的方法。BaGLM在三个数据集上超越了最先进的基于训练的离线方法。

Conclusion: BaGLM展示了无需训练、在线处理的视频步骤定位方法的有效性，通过利用大型多模态模型的零样本能力和贝叶斯滤波整合历史信息，实现了优于传统方法的性能。

Abstract: Given a task and a set of steps composing it, Video Step Grounding (VSG) aims
to detect which steps are performed in a video. Standard approaches for this
task require a labeled training set (e.g., with step-level annotations or
narrations), which may be costly to collect. Moreover, they process the full
video offline, limiting their applications for scenarios requiring online
decisions. Thus, in this work, we explore how to perform VSG online and without
training. We achieve this by exploiting the zero-shot capabilities of recent
Large Multimodal Models (LMMs). In particular, we use LMMs to predict the step
associated with a restricted set of frames, without access to the whole video.
We show that this online strategy without task-specific tuning outperforms
offline and training-based models. Motivated by this finding, we develop
Bayesian Grounding with Large Multimodal Models (BaGLM), further injecting
knowledge of past frames into the LMM-based predictions. BaGLM exploits
Bayesian filtering principles, modeling step transitions via (i) a dependency
matrix extracted through large language models and (ii) an estimation of step
progress. Experiments on three datasets show superior performance of BaGLM over
state-of-the-art training-based offline methods.

</details>


### [73] [An empirical study of the effect of video encoders on Temporal Video Grounding](https://arxiv.org/abs/2510.17007)
*Ignacio M. De la Jara,Cristian Rodriguez-Opazo,Edison Marrese-Taylor,Felipe Bravo-Marquez*

Main category: cs.CV

TL;DR: 本文对时序视频定位任务中不同视频特征的影响进行了实证研究，通过在三个基准数据集上测试基于CNN、时序推理和transformer的视频编码器，发现仅改变视频编码器就能显著影响模型性能，并揭示了特征互补的潜力。


<details>
  <summary>Details</summary>
Motivation: 时序视频定位是计算机视觉中的基础任务，但现有研究主要集中于少数几种视频表示方法，可能导致长期架构过拟合。为解决这一问题，作者希望研究不同视频特征对经典架构的影响。

Method: 在Charades-STA、ActivityNet-Captions和YouCookII三个基准数据集上，提取基于CNN、时序推理和transformer的视频编码器特征，使用经典架构进行对比实验。

Result: 结果显示仅改变视频编码器就能显著影响模型性能，同时揭示了使用特定特征时的明显模式和错误，表明存在特征互补的潜力。

Conclusion: 不同视频特征对时序视频定位任务有显著影响，特征之间存在互补性，这为未来研究提供了重要的方向性指导。

Abstract: Temporal video grounding is a fundamental task in computer vision, aiming to
localize a natural language query in a long, untrimmed video. It has a key role
in the scientific community, in part due to the large amount of video generated
every day. Although we find extensive work in this task, we note that research
remains focused on a small selection of video representations, which may lead
to architectural overfitting in the long run. To address this issue, we propose
an empirical study to investigate the impact of different video features on a
classical architecture. We extract features for three well-known benchmarks,
Charades-STA, ActivityNet-Captions and YouCookII, using video encoders based on
CNNs, temporal reasoning and transformers. Our results show significant
differences in the performance of our model by simply changing the video
encoder, while also revealing clear patterns and errors derived from the use of
certain features, ultimately indicating potential feature complementarity.

</details>


### [74] [Do Satellite Tasks Need Special Pretraining?](https://arxiv.org/abs/2510.17014)
*Ani Vanyan,Alvard Barseghyan,Hakob Tamazyan,Tigran Galstyan,Vahan Huroyan,Naira Hovakimyan,Hrant Khachatrian*

Main category: cs.CV

TL;DR: 本文质疑专用遥感基础模型是否比通用视觉基础模型更有用，通过设计基准测试和训练iBOT模型，发现在ViT-B规模下专用模型并未带来一致改进。


<details>
  <summary>Details</summary>
Motivation: 研究动机是验证专用遥感基础模型是否真的比通用视觉基础模型更有优势，特别是在小规模场景下，考虑到遥感图像的独特特性和特定应用需求。

Method: 设计了一个简单基准测试来衡量遥感模型在低分辨率图像上的泛化能力，并在MillionAID数据集上训练了iBOT自监督视觉编码器，进行了遥感特定的修改。

Result: 结果显示，在ViT-B规模下，这些预训练模型都没有比通用基线模型带来一致的改进效果。

Conclusion: 结论表明，至少在较小规模下，专用遥感基础模型并不比通用视觉基础模型更有效，挑战了专用模型更有用的假设。

Abstract: Foundation models have advanced machine learning across various modalities,
including images. Recently multiple teams trained foundation models specialized
for remote sensing applications. This line of research is motivated by the
distinct characteristics of remote sensing imagery, specific applications and
types of robustness useful for satellite image analysis. In this work we
systematically challenge the idea that specific foundation models are more
useful than general-purpose vision foundation models, at least in the small
scale. First, we design a simple benchmark that measures generalization of
remote sensing models towards images with lower resolution for two downstream
tasks. Second, we train iBOT, a self-supervised vision encoder, on MillionAID,
an ImageNet-scale satellite imagery dataset, with several modifications
specific to remote sensing. We show that none of those pretrained models bring
consistent improvements upon general-purpose baselines at the ViT-B scale.

</details>


### [75] [Enrich and Detect: Video Temporal Grounding with Multimodal LLMs](https://arxiv.org/abs/2510.17023)
*Shraman Pramanick,Effrosyni Mavroudi,Yale Song,Rama Chellappa,Lorenzo Torresani,Triantafyllos Afouras*

Main category: cs.CV

TL;DR: ED-VTG是一种基于多模态大语言模型的细粒度视频时序定位方法，通过两阶段处理将文本查询转换为包含更多细节的丰富句子，然后使用轻量级解码器进行精确定位。


<details>
  <summary>Details</summary>
Motivation: 利用多模态大语言模型的能力来联合处理文本和视频，有效定位视频中的自然语言查询，解决直接定位时信息不足的问题。

Method: 采用两阶段方法：首先将语言查询转换为包含缺失细节的丰富句子，然后使用轻量级解码器基于上下文化的丰富查询表示来预测准确边界。使用多实例学习目标动态选择最佳查询版本以减少噪声和幻觉影响。

Result: 在视频时序定位和段落定位的各种基准测试中取得了最先进的结果，显著优于所有先前提出的基于LLM的时序定位方法，在零样本评估场景中保持明显优势。

Conclusion: ED-VTG方法在视频时序定位任务中表现出色，不仅超越了基于LLM的方法，还与专用模型相当或更优，特别是在零样本场景下具有明显优势。

Abstract: We introduce ED-VTG, a method for fine-grained video temporal grounding
utilizing multi-modal large language models. Our approach harnesses the
capabilities of multimodal LLMs to jointly process text and video, in order to
effectively localize natural language queries in videos through a two-stage
process. Rather than being directly grounded, language queries are initially
transformed into enriched sentences that incorporate missing details and cues
to aid in grounding. In the second stage, these enriched queries are grounded,
using a lightweight decoder, which specializes at predicting accurate
boundaries conditioned on contextualized representations of the enriched
queries. To mitigate noise and reduce the impact of hallucinations, our model
is trained with a multiple-instance-learning objective that dynamically selects
the optimal version of the query for each training sample. We demonstrate
state-of-the-art results across various benchmarks in temporal video grounding
and paragraph grounding settings. Experiments reveal that our method
significantly outperforms all previously proposed LLM-based temporal grounding
approaches and is either superior or comparable to specialized models, while
maintaining a clear advantage against them in zero-shot evaluation scenarios.

</details>


### [76] [Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding](https://arxiv.org/abs/2510.17034)
*Yutong Zhong*

Main category: cs.CV

TL;DR: 提出W2R2训练框架，通过解耦表示学习和针对性捷径抑制来解决多模态3D定位中的2D语义偏差问题，在不改变推理架构的情况下提升3D定位精度。


<details>
  <summary>Details</summary>
Motivation: 当前多模态3D定位模型存在严重的"2D语义偏差"，过度依赖2D图像特征进行粗略定位，而忽视3D几何输入，导致融合性能不佳。

Method: 采用解耦表示学习方法，将2D特征作为"What"识别的语义信标，3D特征作为"Where"定位的空间锚点。使用双目标损失函数，包括用于监督融合预测的对齐损失和通过边际机制惩罚2D主导伪输出的伪标签损失。

Result: 在ScanRefer和ScanQA数据集上的实验表明，W2R2在定位精度和鲁棒性方面取得显著提升，特别是在杂乱的室外场景中。

Conclusion: W2R2框架通过重新塑造模型内部表示空间，有效解决了2D语义偏差问题，实现了更精确的3D定位，且无需修改推理架构。

Abstract: Multimodal 3D grounding has garnered considerable interest in Vision-Language
Models (VLMs) \cite{yin2025spatial} for advancing spatial reasoning in complex
environments. However, these models suffer from a severe "2D semantic bias"
that arises from over-reliance on 2D image features for coarse localization,
largely disregarding 3D geometric inputs and resulting in suboptimal fusion
performance. In this paper, we propose a novel training framework called
What-Where Representation Re-Forming (W2R2) to tackle this issue via
disentangled representation learning and targeted shortcut suppression. Our
approach fundamentally reshapes the model's internal space by designating 2D
features as semantic beacons for "What" identification and 3D features as
spatial anchors for "Where" localization, enabling precise 3D grounding without
modifying inference architecture. Key components include a dual-objective loss
function with an Alignment Loss that supervises fused predictions using adapted
cross-entropy for multimodal synergy, and a Pseudo-Label Loss that penalizes
overly effective 2D-dominant pseudo-outputs via a margin-based mechanism.
Experiments conducted on ScanRefer and ScanQA demonstrate the effectiveness of
W2R2, with significant gains in localization accuracy and robustness,
particularly in cluttered outdoor scenes.

</details>


### [77] [Conditional Synthetic Live and Spoof Fingerprint Generation](https://arxiv.org/abs/2510.17035)
*Syed Konain Abbas,Sandip Purnapatra,M. G. Sarwar Murshed,Conor Miller-Lynch,Lambert Igene,Soumyabrata Dey,Stephanie Schuckers,Faraz Hussain*

Main category: cs.CV

TL;DR: 本文提出了一种使用条件StyleGAN2-ADA和StyleGAN3生成高分辨率合成活体指纹，并通过CycleGANs转换为逼真伪造指纹的方法，解决了生物特征数据收集中的隐私、成本和可访问性问题。


<details>
  <summary>Details</summary>
Motivation: 大型指纹数据集收集耗时、昂贵且需要严格的隐私保护措施，研究人员正在探索使用合成指纹数据来解决这些问题。

Method: 使用条件StyleGAN2-ADA和StyleGAN3架构生成特定手指身份的高分辨率合成活体指纹，然后使用CycleGANs将这些指纹转换为模拟各种呈现攻击材料（如EcoFlex、Play-Doh）的逼真伪造指纹。

Result: 创建了两个合成数据集（DB2和DB3），每个包含1,500个指纹图像，涵盖所有十个手指的多个印痕，并包括八种材料类型的相应伪造指纹。StyleGAN3模型实现了低至5的FID，生成的指纹在0.01% FAR下实现了99.47%的TAR。StyleGAN2-ADA模型在相同FAR下实现了98.67%的TAR。

Conclusion: 该方法生成的合成指纹数据集在保持高质量的同时，具有强大的隐私保护特性，匹配实验证实没有显著的身份泄露证据。

Abstract: Large fingerprint datasets, while important for training and evaluation, are
time-consuming and expensive to collect and require strict privacy measures.
Researchers are exploring the use of synthetic fingerprint data to address
these issues. This paper presents a novel approach for generating synthetic
fingerprint images (both spoof and live), addressing concerns related to
privacy, cost, and accessibility in biometric data collection. Our approach
utilizes conditional StyleGAN2-ADA and StyleGAN3 architectures to produce
high-resolution synthetic live fingerprints, conditioned on specific finger
identities (thumb through little finger). Additionally, we employ CycleGANs to
translate these into realistic spoof fingerprints, simulating a variety of
presentation attack materials (e.g., EcoFlex, Play-Doh). These synthetic spoof
fingerprints are crucial for developing robust spoof detection systems. Through
these generative models, we created two synthetic datasets (DB2 and DB3), each
containing 1,500 fingerprint images of all ten fingers with multiple
impressions per finger, and including corresponding spoofs in eight material
types. The results indicate robust performance: our StyleGAN3 model achieves a
Fr\'echet Inception Distance (FID) as low as 5, and the generated fingerprints
achieve a True Accept Rate of 99.47% at a 0.01% False Accept Rate. The
StyleGAN2-ADA model achieved a TAR of 98.67% at the same 0.01% FAR. We assess
fingerprint quality using standard metrics (NFIQ2, MINDTCT), and notably,
matching experiments confirm strong privacy preservation, with no significant
evidence of identity leakage, confirming the strong privacy-preserving
properties of our synthetic datasets.

</details>


### [78] [Click, Predict, Trust: Clinician-in-the-Loop AI Segmentation for Lung Cancer CT-Based Prognosis within the Knowledge-to-Action Framework](https://arxiv.org/abs/2510.17039)
*Mohammad R. Salmanpour,Sonya Falahati,Amir Hossein Pouria,Amin Mousavi,Somayeh Sadat Mehrnia,Morteza Alizadeh,Arman Gorji,Zeinab Farsangi,Alireza Safarian,Mehdi Maghsudi,Carlos Uribe,Arman Rahmim,Ren Yuan*

Main category: cs.CV

TL;DR: 本研究开发了一个临床医生在环的深度学习管道，用于肺癌CT图像分割和预后预测。使用多中心CT数据评估了5种深度学习模型，VNet在分割性能、放射组学稳定性和预测准确性方面表现最佳，半监督学习始终优于监督学习。放射科医生更青睐VNet生成的掩模，并倾向于将其作为初始分割进行精炼而非完全替代。


<details>
  <summary>Details</summary>
Motivation: 肺癌是癌症死亡的主要原因，CT成像在筛查、预后和治疗中至关重要。手动分割存在变异性且耗时，而深度学习虽然提供自动化但面临临床采纳障碍。本研究旨在开发一个临床医生在环的深度学习管道，以提高可重复性、预后准确性和临床信任度。

Method: 使用来自12个公共数据集的999名患者的多中心CT数据，评估了5种深度学习模型（3D Attention U-Net、ResUNet、VNet、ReconNet、SAM-Med3D），并在完整图像和点击点裁剪图像上与专家轮廓进行基准比较。使用497个PySERA提取的放射组学特征评估分割可重复性，预后建模比较了监督学习和半监督学习，涉及38种降维策略和24种分类器。6名医生在7个领域对分割掩模进行定性评估。

Result: VNet实现了最佳性能（Dice = 0.83，IoU = 0.71）、放射组学稳定性（平均相关性 = 0.76，ICC = 0.65）和半监督学习下的预测准确性（准确率 = 0.88，F1 = 0.83）。半监督学习在所有模型中始终优于监督学习。放射科医生更青睐VNet的瘤周表示和更平滑的边界，倾向于将AI生成的初始掩模用于精炼而非替换。

Conclusion: 将VNet与半监督学习相结合可产生准确、可重复且临床可信的基于CT的肺癌预后预测，突显了实现以医生为中心的AI转化的可行路径。

Abstract: Lung cancer remains the leading cause of cancer mortality, with CT imaging
central to screening, prognosis, and treatment. Manual segmentation is variable
and time-intensive, while deep learning (DL) offers automation but faces
barriers to clinical adoption. Guided by the Knowledge-to-Action framework,
this study develops a clinician-in-the-loop DL pipeline to enhance
reproducibility, prognostic accuracy, and clinical trust. Multi-center CT data
from 999 patients across 12 public datasets were analyzed using five DL models
(3D Attention U-Net, ResUNet, VNet, ReconNet, SAM-Med3D), benchmarked against
expert contours on whole and click-point cropped images. Segmentation
reproducibility was assessed using 497 PySERA-extracted radiomic features via
Spearman correlation, ICC, Wilcoxon tests, and MANOVA, while prognostic
modeling compared supervised (SL) and semi-supervised learning (SSL) across 38
dimensionality reduction strategies and 24 classifiers. Six physicians
qualitatively evaluated masks across seven domains, including clinical
meaningfulness, boundary quality, prognostic value, trust, and workflow
integration. VNet achieved the best performance (Dice = 0.83, IoU = 0.71),
radiomic stability (mean correlation = 0.76, ICC = 0.65), and predictive
accuracy under SSL (accuracy = 0.88, F1 = 0.83). SSL consistently outperformed
SL across models. Radiologists favored VNet for peritumoral representation and
smoother boundaries, preferring AI-generated initial masks for refinement
rather than replacement. These results demonstrate that integrating VNet with
SSL yields accurate, reproducible, and clinically trusted CT-based lung cancer
prognosis, highlighting a feasible path toward physician-centered AI
translation.

</details>


### [79] [Video Reasoning without Training](https://arxiv.org/abs/2510.17045)
*Deepak Sridhar,Kartikeya Bhardwaj,Jeya Pradha Jeyaraj,Nuno Vasconcelos,Ankita Nayak,Harris Teague*

Main category: cs.CV

TL;DR: 该论文提出了一种基于熵的视频推理方法V-Reason，通过优化LMM的value cache来改进推理过程中的微观探索和利用行为，无需RL训练即可显著提升性能并大幅减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的视频推理方法依赖昂贵的强化学习和冗长的思维链，导致训练和推理计算成本高，且推理过程的控制机制有限。

Method: 使用模型输出的熵作为信号，通过一个可训练的小型控制器对LMM的value cache进行基于熵目标的优化调整，改进推理过程中的微观探索和利用行为。

Result: 在多个视频推理数据集上显著优于基础指令调优模型，与RL训练模型的准确率差距缩小到0.6%以内，同时输出token减少58.6%。

Conclusion: 基于熵的推理过程控制方法能够有效提升视频推理性能，无需额外训练即可实现高效推理，具有重要的实用价值。

Abstract: Video reasoning using Large Multimodal Models (LMMs) relies on costly
reinforcement learning (RL) and verbose chain-of-thought, resulting in
substantial computational overhead during both training and inference.
Moreover, the mechanisms that control the thinking process in these reasoning
models are very limited. In this paper, using entropy of the model's output as
a signal, we discover that the high-quality models go through a series of
micro-explorations and micro-exploitations which keep the reasoning process
grounded (i.e., avoid excessive randomness while the model is exploring or
thinking through an answer). We further observe that once this "thinking"
process is over, more accurate models demonstrate a better convergence by
reducing the entropy significantly via a final exploitation phase (i.e., a more
certain convergence towards a solution trajectory). We then use these novel,
theoretically-grounded insights to tune the model's behavior directly at
inference, without using any RL or supervised fine-tuning. Specifically, during
inference, our proposed approach called V-Reason (Video-Reason) adapts the
value cache of the LMM via a few optimization steps on a small, trainable
controller using an entropy-based objective, i.e., no supervision from any
dataset or RL is necessary. This tuning improves the model's micro-exploration
and exploitation behavior during inference. Our experiments show that our
proposed method achieves significant improvements over the base
instruction-tuned models across several video reasoning datasets, narrowing the
gap with RL-trained models to within 0.6% average accuracy without any
training, while offering massive efficiency benefits: output tokens are reduced
by 58.6% compared to the RL model.

</details>


### [80] [How Universal Are SAM2 Features?](https://arxiv.org/abs/2510.17051)
*Masoud Khairi Atani,Alon Harell,Hyomin Choi,Runyu Yang,Fabien Racape,Ivan V. Bajic*

Main category: cs.CV

TL;DR: 该研究比较了通用视觉基础模型Hiera与专用分割模型SAM2的特征通用性，发现专用化虽然提升空间相关任务性能，但会损失语义信息，导致在概念距离较远的任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 理解通用视觉基础模型与专用模型之间的权衡对于高效特征编码设计至关重要，但目前这一权衡尚未被充分理解。

Method: 使用轻量级可训练neck来探测冻结特征的适应性，通过信息论成本量化专用化的代价，并对SAM2进行跨neck分析。

Result: SAM2在深度估计等空间相关任务上表现出色，但在姿态估计和图像描述等概念距离较远的任务上表现不如通用模型Hiera，显示出语义信息的损失。

Conclusion: 专用化在提升特定任务性能的同时会牺牲特征通用性，为设计面向多样化下游应用的高效特征编码和适应策略提供了量化基础。

Abstract: The trade-off between general-purpose foundation vision models and their
specialized counterparts is critical for efficient feature coding design and is
not yet fully understood. We investigate this trade-off by comparing the
feature versatility of the general-purpose Hiera encoder against the
segmentation-specialized Segment Anything Model 2 (SAM2). Using a lightweight,
trainable neck to probe the adaptability of their frozen features, we quantify
the information-theoretic cost of specialization. Our results reveal that while
SAM2's specialization is highly effective for spatially-related tasks like
depth estimation, it comes at a cost. The specialized SAM2 encoder
underperforms its generalist predecessor, Hiera, on conceptually distant tasks
such as pose estimation and image captioning, demonstrating a measurable loss
of broader semantic information. A novel cross-neck analysis on SAM2 reveals
that each level of adaptation creates a further representational bottleneck.
Our analysis illuminates these trade-offs in feature universality, providing a
quantitative foundation for designing efficient feature coding and adaptation
strategies for diverse downstream applications.

</details>


### [81] [ProDAT: Progressive Density-Aware Tail-Drop for Point Cloud Coding](https://arxiv.org/abs/2510.17068)
*Zhe Luo,Wenjing Jia,Stuart Perry*

Main category: cs.CV

TL;DR: 提出ProDAT方法，一种基于密度感知的渐进式点云编码机制，通过单一模型实现多比特率下的渐进解码，显著提升编码效率。


<details>
  <summary>Details</summary>
Motivation: 三维点云在自动驾驶、增强现实等应用中需要实时处理和低延迟，但大数据量和带宽限制阻碍了在资源受限环境中的高质量服务部署。现有学习型点云几何编码方法的固定潜在表示不支持渐进解码。

Method: 提出ProDAT方法，利用密度信息作为指导信号，根据重要性自适应解码潜在特征和坐标，通过单一模型实现多比特率下的渐进解码。

Result: 在基准数据集上的实验结果表明，ProDAT不仅支持渐进编码，而且在编码效率上优于最先进的学习型编码技术，在SemanticKITTI上PSNR-D2的BD-rate提升超过28.6%，在ShapeNet上提升超过18.15%。

Conclusion: ProDAT方法成功解决了点云渐进编码的问题，在保持高编码效率的同时实现了多比特率下的渐进解码能力。

Abstract: Three-dimensional (3D) point clouds are becoming increasingly vital in
applications such as autonomous driving, augmented reality, and immersive
communication, demanding real-time processing and low latency. However, their
large data volumes and bandwidth constraints hinder the deployment of
high-quality services in resource-limited environments. Progres- sive coding,
which allows for decoding at varying levels of detail, provides an alternative
by allowing initial partial decoding with subsequent refinement. Although
recent learning-based point cloud geometry coding methods have achieved notable
success, their fixed latent representation does not support progressive
decoding. To bridge this gap, we propose ProDAT, a novel density-aware
tail-drop mechanism for progressive point cloud coding. By leveraging density
information as a guidance signal, latent features and coordinates are decoded
adaptively based on their significance, therefore achieving progressive
decoding at multiple bitrates using one single model. Experimental results on
benchmark datasets show that the proposed ProDAT not only enables progressive
coding but also achieves superior coding efficiency compared to
state-of-the-art learning-based coding techniques, with over 28.6% BD-rate
improvement for PSNR- D2 on SemanticKITTI and over 18.15% for ShapeNet

</details>


### [82] [Towards a Generalizable Fusion Architecture for Multimodal Object Detection](https://arxiv.org/abs/2510.17078)
*Jad Berjawi,Yoann Dupas,Christophe C'erin*

Main category: cs.CV

TL;DR: 提出FMCAF架构，通过频域滤波和跨注意力融合增强RGB和红外图像的多模态目标检测性能，在LLVIP和VEDAI数据集上优于传统融合方法。


<details>
  <summary>Details</summary>
Motivation: 多模态目标检测在挑战性条件下通过利用多传感器模态的互补线索来提高鲁棒性，但现有方法往往针对特定数据集设计，缺乏通用性。

Method: FMCAF结合频域滤波块（Freq-Filter）抑制冗余光谱特征和基于跨注意力的融合模块（MCAF）改进模态间特征共享，无需数据集特定调优。

Result: 在LLVIP（低光行人检测）和VEDAI（航空车辆检测）数据集上，FMCAF优于传统拼接融合，VEDAI上mAP@50提升13.9%，LLVIP上提升1.1%。

Conclusion: FMCAF作为灵活的多模态融合基础架构，在未来的检测流程中具有潜力，支持跨不同多模态挑战的性能提升。

Abstract: Multimodal object detection improves robustness in chal- lenging conditions
by leveraging complementary cues from multiple sensor modalities. We introduce
Filtered Multi- Modal Cross Attention Fusion (FMCAF), a preprocess- ing
architecture designed to enhance the fusion of RGB and infrared (IR) inputs.
FMCAF combines a frequency- domain filtering block (Freq-Filter) to suppress
redun- dant spectral features with a cross-attention-based fusion module (MCAF)
to improve intermodal feature sharing. Unlike approaches tailored to specific
datasets, FMCAF aims for generalizability, improving performance across
different multimodal challenges without requiring dataset- specific tuning. On
LLVIP (low-light pedestrian detec- tion) and VEDAI (aerial vehicle detection),
FMCAF outper- forms traditional fusion (concatenation), achieving +13.9% mAP@50
on VEDAI and +1.1% on LLVIP. These results support the potential of FMCAF as a
flexible foundation for robust multimodal fusion in future detection pipelines.

</details>


### [83] [GSPlane: Concise and Accurate Planar Reconstruction via Structured Representation](https://arxiv.org/abs/2510.17095)
*Ruitong Gan,Junran Peng,Yang Liu,Chuanchen Luo,Qing Li,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: GSPlane通过引入平面先验来改进高斯泼溅的几何重建，特别针对平面区域提供更平滑精确的网格重建，并支持场景编辑应用。


<details>
  <summary>Details</summary>
Motivation: 当前高斯泼溅方法在重建平面区域时存在平滑度和精度不足的问题，而平面是3D场景特别是人造环境中的基本元素，需要结构化表示以支持下游编辑和物理模拟。

Method: 利用现成的分割和法向预测模型提取平面先验，建立结构化平面高斯坐标表示；引入动态高斯重分类器自适应重新分类高梯度平面高斯；使用优化的平面先验优化网格布局。

Result: 在保持渲染质量的同时，显著提高了各种基线下提取网格的几何精度，减少了顶点和面数，改善了拓扑结构。

Conclusion: GSPlane通过平面先验有效提升了高斯泼溅的几何重建质量，为场景编辑和操作提供了结构化表示。

Abstract: Planes are fundamental primitives of 3D sences, especially in man-made
environments such as indoor spaces and urban streets. Representing these planes
in a structured and parameterized format facilitates scene editing and physical
simulations in downstream applications. Recently, Gaussian Splatting (GS) has
demonstrated remarkable effectiveness in the Novel View Synthesis task, with
extensions showing great potential in accurate surface reconstruction. However,
even state-of-the-art GS representations often struggle to reconstruct planar
regions with sufficient smoothness and precision. To address this issue, we
propose GSPlane, which recovers accurate geometry and produces clean and
well-structured mesh connectivity for plane regions in the reconstructed scene.
By leveraging off-the-shelf segmentation and normal prediction models, GSPlane
extracts robust planar priors to establish structured representations for
planar Gaussian coordinates, which help guide the training process by enforcing
geometric consistency. To further enhance training robustness, a Dynamic
Gaussian Re-classifier is introduced to adaptively reclassify planar Gaussians
with persistently high gradients as non-planar, ensuring more reliable
optimization. Furthermore, we utilize the optimized planar priors to refine the
mesh layouts, significantly improving topological structure while reducing the
number of vertices and faces. We also explore applications of the structured
planar representation, which enable decoupling and flexible manipulation of
objects on supportive planes. Extensive experiments demonstrate that, with no
sacrifice in rendering quality, the introduction of planar priors significantly
improves the geometric accuracy of the extracted meshes across various
baselines.

</details>


### [84] [Towards Imperceptible Watermarking Via Environment Illumination for Consumer Cameras](https://arxiv.org/abs/2510.17114)
*Hodaka Kawachi,Tomoya Nakamura,Hiroaki Santo,SaiKiran Kumar Tedla,Trevor Dalton Canham,Yasushi Yagi,Michael S. Brown*

Main category: cs.CV

TL;DR: 提出一种使用LED环境照明为消费级相机生成视觉不可见水印的方法，通过优化LED光源的光谱特性，使其对人眼几乎不可见但对相机高度可检测。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在消费级相机视频中嵌入水印的技术，以支持隐私保护和内容验证，同时确保水印对人眼不可见。

Method: 采用光谱调制而非强度调制，联合考虑人眼视觉系统对可见光谱的敏感性、现代消费相机传感器的光谱灵敏度以及窄带LED产生宽带白光的特性。

Result: 实现了在标准低帧率（30-60 fps）下提取水印，能够在10秒视频片段中嵌入128位信息。

Conclusion: 该方法为隐私保护和内容验证提供了实用的水印嵌入解决方案，虽然信息传输速率有限但足以承载必要的元数据。

Abstract: This paper introduces a method for using LED-based environmental lighting to
produce visually imperceptible watermarks for consumer cameras. Our approach
optimizes an LED light source's spectral profile to be minimally visible to the
human eye while remaining highly detectable by typical consumer cameras. The
method jointly considers the human visual system's sensitivity to visible
spectra, modern consumer camera sensors' spectral sensitivity, and narrowband
LEDs' ability to generate broadband spectra perceived as "white light"
(specifically, D65 illumination). To ensure imperceptibility, we employ
spectral modulation rather than intensity modulation. Unlike conventional
visible light communication, our approach enables watermark extraction at
standard low frame rates (30-60 fps). While the information transfer rate is
modest-embedding 128 bits within a 10-second video clip-this capacity is
sufficient for essential metadata supporting privacy protection and content
verification.

</details>


### [85] [GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution Detection](https://arxiv.org/abs/2510.17131)
*Xin Gao,Jiyao Liu,Guanghao Li,Yueming Lyu,Jianxiong Gao,Weichen Yu,Ningsheng Xu,Liang Wang,Caifeng Shan,Ziwei Liu,Chenyang Si*

Main category: cs.CV

TL;DR: 提出GOOD框架，通过双重引导机制（图像级和特征级）指导扩散模型生成分布外样本，提升OOD检测性能


<details>
  <summary>Details</summary>
Motivation: 现有方法通过扰动文本条件嵌入生成OOD样本，存在语义不稳定和多样性不足的问题，限制了在真实OOD场景下的泛化能力

Method: 使用现成的ID分类器直接引导扩散采样轨迹：1）图像级引导基于对数分割梯度减少输入似然；2）特征级引导基于k-NN距离在分类器潜在空间中促进特征稀疏区域采样

Result: GOOD框架能够生成更可控和多样化的OOD样本，通过统一OOD评分自适应结合图像和特征差异，显著提升OOD检测性能

Conclusion: 使用GOOD生成的样本进行训练可以显著增强OOD检测能力，双重引导设计实现了更有效的分布外样本生成

Abstract: Recent advancements have explored text-to-image diffusion models for
synthesizing out-of-distribution (OOD) samples, substantially enhancing the
performance of OOD detection. However, existing approaches typically rely on
perturbing text-conditioned embeddings, resulting in semantic instability and
insufficient shift diversity, which limit generalization to realistic OOD. To
address these challenges, we propose GOOD, a novel and flexible framework that
directly guides diffusion sampling trajectories towards OOD regions using
off-the-shelf in-distribution (ID) classifiers. GOOD incorporates dual-level
guidance: (1) Image-level guidance based on the gradient of log partition to
reduce input likelihood, drives samples toward low-density regions in pixel
space. (2) Feature-level guidance, derived from k-NN distance in the
classifier's latent space, promotes sampling in feature-sparse regions. Hence,
this dual-guidance design enables more controllable and diverse OOD sample
generation. Additionally, we introduce a unified OOD score that adaptively
combines image and feature discrepancies, enhancing detection robustness. We
perform thorough quantitative and qualitative analyses to evaluate the
effectiveness of GOOD, demonstrating that training with samples generated by
GOOD can notably enhance OOD detection performance.

</details>


### [86] [KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation](https://arxiv.org/abs/2510.17137)
*WenBo Xu,Liu Liu,Li Zhang,Ran Zhang,Hao Wu,Dan Guo,Meng Wang*

Main category: cs.CV

TL;DR: KineDiff3D是一个统一的框架，通过运动学感知扩散模型从单视图输入重建和生成类别级铰接物体的形状，同时估计其姿态和关节参数。


<details>
  <summary>Details</summary>
Motivation: 铰接物体（如笔记本电脑和抽屉）由于其多部分几何结构和可变关节配置，在3D重建和姿态估计方面面临显著挑战，这些因素在不同状态下引入了结构多样性。

Method: 首先通过运动学感知VAE将完整几何（SDFs）、关节角度和部件分割编码到结构化潜空间；然后使用两个条件扩散模型：一个用于回归全局姿态和关节参数，另一个用于从部分观测生成运动学感知潜码；最后通过迭代优化模块双向细化重建精度和运动学参数。

Result: 在合成、半合成和真实世界数据集上的实验结果表明，该方法在准确重建铰接物体和估计其运动学特性方面具有有效性。

Conclusion: KineDiff3D框架能够有效处理铰接物体的3D重建和姿态估计问题，通过结合运动学感知编码和扩散模型实现了准确的重建结果。

Abstract: Articulated objects, such as laptops and drawers, exhibit significant
challenges for 3D reconstruction and pose estimation due to their multi-part
geometries and variable joint configurations, which introduce structural
diversity across different states. To address these challenges, we propose
KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object
Shape Reconstruction and Generation, a unified framework for reconstructing
diverse articulated instances and pose estimation from single view input.
Specifically, we first encode complete geometry (SDFs), joint angles, and part
segmentation into a structured latent space via a novel Kinematic-Aware VAE
(KA-VAE). In addition, we employ two conditional diffusion models: one for
regressing global pose (SE(3)) and joint parameters, and another for generating
the kinematic-aware latent code from partial observations. Finally, we produce
an iterative optimization module that bidirectionally refines reconstruction
accuracy and kinematic parameters via Chamfer-distance minimization while
preserving articulation constraints. Experimental results on synthetic,
semi-synthetic, and real-world datasets demonstrate the effectiveness of our
approach in accurately reconstructing articulated objects and estimating their
kinematic properties.

</details>


### [87] [GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image](https://arxiv.org/abs/2510.17157)
*Yinghui Wang,Xinyu Zhang,Peng Du*

Main category: cs.CV

TL;DR: GACO-CAD是一个两阶段后训练框架，通过深度和法线图作为几何先验提升单图像到CAD模型的几何精度，同时使用组长度奖励促进建模过程的简洁性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在从2D图像推断3D几何时空间推理能力有限的问题，降低工业概念设计的门槛。

Method: 两阶段方法：监督微调阶段使用深度和法线图作为多通道输入提供几何先验；强化学习阶段引入组长度奖励促进建模序列的简洁性，采用动态权重策略稳定训练。

Result: 在DeepCAD和Fusion360数据集上达到最先进性能，在代码有效性、几何精度和建模简洁性方面优于现有方法。

Conclusion: GACO-CAD框架有效提升了从单图像生成可编辑参数化CAD模型的几何准确性和建模效率。

Abstract: Generating editable, parametric CAD models from a single image holds great
potential to lower the barriers of industrial concept design. However, current
multi-modal large language models (MLLMs) still struggle with accurately
inferring 3D geometry from 2D images due to limited spatial reasoning
capabilities. We address this limitation by introducing GACO-CAD, a novel
two-stage post-training framework. It is designed to achieve a joint objective:
simultaneously improving the geometric accuracy of the generated CAD models and
encouraging the use of more concise modeling procedures. First, during
supervised fine-tuning, we leverage depth and surface normal maps as dense
geometric priors, combining them with the RGB image to form a multi-channel
input. In the context of single-view reconstruction, these priors provide
complementary spatial cues that help the MLLM more reliably recover 3D geometry
from 2D observations. Second, during reinforcement learning, we introduce a
group length reward that, while preserving high geometric fidelity, promotes
the generation of more compact and less redundant parametric modeling
sequences. A simple dynamic weighting strategy is adopted to stabilize
training. Experiments on the DeepCAD and Fusion360 datasets show that GACO-CAD
achieves state-of-the-art performance under the same MLLM backbone,
consistently outperforming existing methods in terms of code validity,
geometric accuracy, and modeling conciseness.

</details>


### [88] [Investigating Adversarial Robustness against Preprocessing used in Blackbox Face Recognition](https://arxiv.org/abs/2510.17169)
*Roland Croft,Brian Du,Darcy Joseph,Sharath Kumar*

Main category: cs.CV

TL;DR: 该论文研究了人脸识别系统中预处理对对抗攻击迁移性的影响，发现人脸检测模型的选择会显著降低攻击成功率，并提出了一种预处理不变的方法来提升攻击迁移性。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统容易受到对抗样本攻击，但现有研究往往忽略了预处理环节在攻击中的重要性。论文旨在探究不同预处理技术对黑盒攻击迁移性的影响。

Method: 研究了多种现成的最先进对抗攻击方法在不同预处理技术下的迁移性，分析了人脸检测模型和降采样插值方法的影响，并提出了一种使用输入变换的预处理不变方法来提升攻击迁移性。

Result: 人脸检测模型的选择可使攻击成功率降低高达78%，而降采样插值方法影响相对较小。即使在白盒设置中，人脸预处理要求也会降低攻击强度。提出的预处理不变方法可将攻击迁移性提升高达27%。

Conclusion: 预处理在人脸识别系统中至关重要，考虑预处理因素对于提高面部对抗样本的对抗泛化能力是必要的。

Abstract: Face Recognition (FR) models have been shown to be vulnerable to adversarial
examples that subtly alter benign facial images, exposing blind spots in these
systems, as well as protecting user privacy. End-to-end FR systems first obtain
preprocessed faces from diverse facial imagery prior to computing the
similarity of the deep feature embeddings. Whilst face preprocessing is a
critical component of FR systems, and hence adversarial attacks against them,
we observe that this preprocessing is often overlooked in blackbox settings.
Our study seeks to investigate the transferability of several out-of-the-box
state-of-the-art adversarial attacks against FR when applied against different
preprocessing techniques used in a blackbox setting. We observe that the choice
of face detection model can degrade the attack success rate by up to 78%,
whereas choice of interpolation method during downsampling has relatively
minimal impacts. Furthermore, we find that the requirement for facial
preprocessing even degrades attack strength in a whitebox setting, due to the
unintended interaction of produced noise vectors against face detection models.
Based on these findings, we propose a preprocessing-invariant method using
input transformations that improves the transferability of the studied attacks
by up to 27%. Our findings highlight the importance of preprocessing in FR
systems, and the need for its consideration towards improving the adversarial
generalisation of facial adversarial examples.

</details>


### [89] [Generation then Reconstruction: Accelerating Masked Autoregressive Models via Two-Stage Sampling](https://arxiv.org/abs/2510.17171)
*Feihong Yan,Peiru Wang,Yao Zhu,Kaiyu Pang,Qingyan Wei,Huiqi Li,Linfeng Zhang*

Main category: cs.CV

TL;DR: 提出GtR分层采样策略，通过结构生成和细节重建两阶段分解生成过程，实现MAR模型3.72倍加速同时保持生成质量，并引入FTS频率加权令牌选择优化计算分配。


<details>
  <summary>Details</summary>
Motivation: 解决MAR模型并行生成潜力受限于空间相关视觉令牌建模复杂性的问题，利用创建完整图像比基于基本框架补全图像更困难的观察，设计高效加速策略。

Method: GtR训练免费分层采样：结构生成阶段建立全局语义框架，细节重建阶段高效补全剩余令牌；FTS基于高频信息能量定位图像细节区域，为细节令牌分配更多计算预算。

Result: 在ImageNet类条件生成和文本到图像生成任务上实现3.72倍加速，保持可比质量（FID: 1.59, IS: 304.4 vs 原始1.59, 299.1），显著优于现有加速方法。

Conclusion: GtR通过层次化生成策略有效释放MAR模型加速潜力，FTS进一步优化计算分配，为高效视觉生成提供有前景的解决方案。

Abstract: Masked Autoregressive (MAR) models promise better efficiency in visual
generation than autoregressive (AR) models for the ability of parallel
generation, yet their acceleration potential remains constrained by the
modeling complexity of spatially correlated visual tokens in a single step. To
address this limitation, we introduce Generation then Reconstruction (GtR), a
training-free hierarchical sampling strategy that decomposes generation into
two stages: structure generation establishing global semantic scaffolding,
followed by detail reconstruction efficiently completing remaining tokens.
Assuming that it is more difficult to create an image from scratch than to
complement images based on a basic image framework, GtR is designed to achieve
acceleration by computing the reconstruction stage quickly while maintaining
the generation quality by computing the generation stage slowly. Moreover,
observing that tokens on the details of an image often carry more semantic
information than tokens in the salient regions, we further propose
Frequency-Weighted Token Selection (FTS) to offer more computation budget to
tokens on image details, which are localized based on the energy of high
frequency information. Extensive experiments on ImageNet class-conditional and
text-to-image generation demonstrate 3.72x speedup on MAR-H while maintaining
comparable quality (e.g., FID: 1.59, IS: 304.4 vs. original 1.59, 299.1),
substantially outperforming existing acceleration methods across various model
scales and generation tasks. Our codes will be released in
https://github.com/feihongyan1/GtR.

</details>


### [90] [Benchmarking Out-of-Distribution Detection for Plankton Recognition: A Systematic Evaluation of Advanced Methods in Marine Ecological Monitoring](https://arxiv.org/abs/2510.17179)
*Yingzi Han,Jiakai He,Chuanlong Xie,Jianping Li*

Main category: cs.CV

TL;DR: 本文针对浮游生物识别中分布偏移问题，基于DYB-PlanktonNet数据集构建了系统化的OoD基准测试，评估了22种OoD检测方法，发现ViM方法在远OoD场景中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 浮游生物识别模型在真实部署中面临分布偏移挑战，由于浮游生物形态复杂、物种多样性高且不断有新物种发现，导致推理时出现不可预测错误。目前该领域缺乏最新计算机视觉技术的系统整合和大规模评估基准。

Method: 基于DYB-PlanktonNet数据集精心设计了一系列模拟不同分布偏移场景的OoD基准测试，系统评估了22种OoD检测方法。

Result: 大量实验结果表明，ViM方法在构建的基准测试中显著优于其他方法，特别是在远OoD场景中关键指标有显著提升。

Conclusion: 这项全面评估不仅为自动浮游生物识别中的算法选择提供了可靠参考，也为浮游生物OoD检测的未来研究奠定了坚实基础。这是浮游生物识别领域首次大规模、系统性的OoD数据检测方法评估分析。

Abstract: Automated plankton recognition models face significant challenges during
real-world deployment due to distribution shifts (Out-of-Distribution, OoD)
between training and test data. This stems from plankton's complex
morphologies, vast species diversity, and the continuous discovery of novel
species, which leads to unpredictable errors during inference. Despite rapid
advancements in OoD detection methods in recent years, the field of plankton
recognition still lacks a systematic integration of the latest computer vision
developments and a unified benchmark for large-scale evaluation. To address
this, this paper meticulously designed a series of OoD benchmarks simulating
various distribution shift scenarios based on the DYB-PlanktonNet dataset
\cite{875n-f104-21}, and systematically evaluated twenty-two OoD detection
methods. Extensive experimental results demonstrate that the ViM
\cite{wang2022vim} method significantly outperforms other approaches in our
constructed benchmarks, particularly excelling in Far-OoD scenarios with
substantial improvements in key metrics. This comprehensive evaluation not only
provides a reliable reference for algorithm selection in automated plankton
recognition but also lays a solid foundation for future research in plankton
OoD detection. To our knowledge, this study marks the first large-scale,
systematic evaluation and analysis of Out-of-Distribution data detection
methods in plankton recognition. Code is available at
https://github.com/BlackJack0083/PlanktonOoD.

</details>


### [91] [Capturing Head Avatar with Hand Contacts from a Monocular Video](https://arxiv.org/abs/2510.17181)
*Haonan He,Yufeng Zheng,Jie Song*

Main category: cs.CV

TL;DR: 本文提出了一种联合学习详细头部化身和手脸交互引起的非刚性变形的新框架，解决了现有方法忽略手脸自然交互的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注面部区域，忽略了传达认知状态的手脸自然交互（如手托下巴、手指轻触脸颊等），这些交互对于真实感3D头部化身至关重要。

Method: 1) 在姿态跟踪中结合深度顺序损失和接触正则化来确保手脸正确空间关系；2) 从手脸交互数据集中学习手诱导面部变形的PCA基，将问题简化为估计紧凑的PCA参数；3) 引入基于物理模拟的接触损失来减少穿插伪影并增强物理合理性。

Result: 在iPhone拍摄的RGB(D)视频上评估，并构建了包含各种手交互类型的合成数据集。结果显示该方法比最先进的表面重建方法能捕捉更好的外观和更准确的面部变形几何。

Conclusion: 该方法能够有效捕捉手脸交互引起的面部变形，生成更真实、物理合理的3D头部化身，在保持外观质量的同时显著改善了变形几何的准确性。

Abstract: Photorealistic 3D head avatars are vital for telepresence, gaming, and VR.
However, most methods focus solely on facial regions, ignoring natural
hand-face interactions, such as a hand resting on the chin or fingers gently
touching the cheek, which convey cognitive states like pondering. In this work,
we present a novel framework that jointly learns detailed head avatars and the
non-rigid deformations induced by hand-face interactions.
  There are two principal challenges in this task. First, naively tracking hand
and face separately fails to capture their relative poses. To overcome this, we
propose to combine depth order loss with contact regularization during pose
tracking, ensuring correct spatial relationships between the face and hand.
Second, no publicly available priors exist for hand-induced deformations,
making them non-trivial to learn from monocular videos. To address this, we
learn a PCA basis specific to hand-induced facial deformations from a face-hand
interaction dataset. This reduces the problem to estimating a compact set of
PCA parameters rather than a full spatial deformation field. Furthermore,
inspired by physics-based simulation, we incorporate a contact loss that
provides additional supervision, significantly reducing interpenetration
artifacts and enhancing the physical plausibility of the results.
  We evaluate our approach on RGB(D) videos captured by an iPhone.
Additionally, to better evaluate the reconstructed geometry, we construct a
synthetic dataset of avatars with various types of hand interactions. We show
that our method can capture better appearance and more accurate deforming
geometry of the face than SOTA surface reconstruction methods.

</details>


### [92] [HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery](https://arxiv.org/abs/2510.17188)
*Vaibhav Rathore,Divyam Gupta,Biplab Banerjee*

Main category: cs.CV

TL;DR: HIDISC是一个双曲表示学习框架，用于解决领域泛化与广义类别发现问题，无需情景模拟训练，通过GPT引导扩散增强和切线空间插值实现高效泛化。


<details>
  <summary>Details</summary>
Motivation: 现有GCD方法假设训练和测试数据来自同一领域，限制了在开放世界场景中的适用性。DG-GCD要求模型泛化到包含新类别的未见领域，但现有方法计算成本高且存在误差累积。

Method: 使用GPT引导扩散进行领域增强，引入切线CutMix进行曲率感知插值，结合惩罚Busemann对齐、混合双曲对比正则化和自适应离群点排斥的统一损失函数，以及可学习的曲率参数。

Result: 在PACS、Office-Home和DomainNet数据集上取得了最先进的结果，持续优于现有的欧几里得和双曲(DG)-GCD基线方法。

Conclusion: HIDISC通过双曲表示学习有效解决了领域和类别级别的泛化问题，避免了高计算成本的情景模拟，实现了高效且性能优越的泛化能力。

Abstract: Generalized Category Discovery (GCD) aims to classify test-time samples into
either seen categories** -- available during training -- or novel ones, without
relying on label supervision. Most existing GCD methods assume simultaneous
access to labeled and unlabeled data during training and arising from the same
domain, limiting applicability in open-world scenarios involving distribution
shifts. Domain Generalization with GCD (DG-GCD) lifts this constraint by
requiring models to generalize to unseen domains containing novel categories,
without accessing targetdomain data during training. The only prior DG-GCD
method, DG2CD-Net, relies on episodic training with multiple synthetic domains
and task vector aggregation, incurring high computational cost and error
accumulation. We propose HIDISC, a hyperbolic representation learning framework
that achieves domain and category-level generalization without episodic
simulation. To expose the model to minimal but diverse domain variations, we
augment the source domain using GPT-guided diffusion, avoiding overfitting
while maintaining efficiency. To structure the representation space, we
introduce Tangent CutMix, a curvature-aware interpolation that synthesizes
pseudo-novel samples in tangent space, preserving manifold consistency. A
unified loss -- combining penalized Busemann alignment, hybrid hyperbolic
contrastive regularization, and adaptive outlier repulsion -- **facilitates
compact, semantically structured embeddings. A learnable curvature parameter
further adapts the geometry to dataset complexity. HIDISC achieves
state-of-the-art results on PACS , Office-Home , and DomainNet, consistently
outperforming the existing Euclidean and hyperbolic (DG)-GCD baselines.

</details>


### [93] [ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language Models](https://arxiv.org/abs/2510.17197)
*Pu Zhang,Yuwei Li,Xingyuan Xian,Guoming Tang*

Main category: cs.CV

TL;DR: 提出一种零样本的视觉令牌剪枝方法，通过平衡任务相关性和信息多样性，在保持性能的同时显著降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型处理能力增强，视觉令牌冗余导致推理成本过高，现有方法缺乏文本提示引导，无法优先考虑任务相关性。

Method: 采用分层方法：首先选择任务相关的核心视觉令牌，然后补充多样性令牌以保留更广泛上下文，实现任务相关性与信息多样性的平衡。

Result: 在多个模型和基准测试中，即使剪枝高达90%的令牌，性能仍能匹配或超越现有最优方法，同时显著降低GPU内存占用和推理延迟。

Conclusion: 提出的提示感知视觉令牌剪枝方法有效解决了视觉令牌冗余问题，在保持模型性能的同时大幅提升了推理效率。

Abstract: As the capabilities of Vision-Language Models (VLMs) advance, they can
process increasingly large inputs, which, unlike in LLMs, generates significant
visual token redundancy and leads to prohibitive inference costs. While many
methods aim to reduce these costs by pruning visual tokens, existing
approaches, whether based on attention or diversity, typically neglect the
guidance of the text prompt and thus fail to prioritize task relevance. In this
work, we propose a novel, zero-shot method that reframes the problem by
introducing a prompt-aware perspective, explicitly modeling visual token
pruning as a balance between task relevance and information diversity. Our
hierarchical approach first selects a core set of task-relevant visual tokens
and then supplements them with diversity tokens to preserve broader context.
Experiments across multiple models and benchmarks show that our method achieves
performance that matches or surpasses the state-of-the-art with only minimal
accuracy loss, even when pruning up to 90\% of the tokens. Furthermore, these
gains are accompanied by significant reductions in GPU memory footprint and
inference latency.

</details>


### [94] [From Pixels to People: Satellite-Based Mapping and Quantification of Riverbank Erosion and Lost Villages in Bangladesh](https://arxiv.org/abs/2510.17198)
*M Saifuzzaman Rafat,Mohd Ruhul Ameen,Akif Islam,Abu Saleh Musa Miah,Jungpil Shin*

Main category: cs.CV

TL;DR: 本文提出了一种基于Segment Anything Model (SAM)的方法，用于精确监测孟加拉国河流侵蚀造成的土地流失和定居点消失。通过构建首个包含消失定居点标注的数据集，并微调SAM模型，实现了对河流侵蚀的高精度检测。


<details>
  <summary>Details</summary>
Motivation: 孟加拉国河流每年吞噬村庄和农田，造成大规模社区消失和人口流离失所。传统人工监测这一缓慢灾难极为困难，需要开发自动化高精度监测工具。

Method: 首先使用简单的颜色通道分析进行粗略的土地和水体分割，然后微调SAM的掩码解码器以识别河岸侵蚀的细微特征。构建了包含2003-2025年Google Earth影像和消失定居点标注的数据集。

Result: 模型在河流侵蚀检测上表现出色，平均交并比达到86.30%，Dice分数达到92.60%，显著优于传统方法和现成的深度学习模型。

Conclusion: 本研究提供了三个关键贡献：首个孟加拉国河流侵蚀消失定居点标注数据集、专门针对此任务的微调AI模型，以及量化土地流失的方法。这些工具为政策制定者和灾害管理机构提供了监测侵蚀、预测轨迹和保护脆弱社区的有力手段。

Abstract: The great rivers of Bangladesh, arteries of commerce and sustenance, are also
agents of relentless destruction. Each year, they swallow whole villages and
vast tracts of farmland, erasing communities from the map and displacing
thousands of families. To track this slow-motion catastrophe has, until now,
been a Herculean task for human analysts. Here we show how a powerful
general-purpose vision model, the Segment Anything Model (SAM), can be adapted
to this task with remarkable precision. To do this, we assembled a new dataset
- a digital chronicle of loss compiled from historical Google Earth imagery of
Bangladesh's most vulnerable regions, including Mokterer Char Union, Kedarpur
Union, Balchipara village, and Chowhali Upazila, from 2003 to 2025. Crucially,
this dataset is the first to include manually annotated data on the settlements
that have vanished beneath the water. Our method first uses a simple
color-channel analysis to provide a rough segmentation of land and water, and
then fine-tunes SAM's mask decoder to recognize the subtle signatures of
riverbank erosion. The resulting model demonstrates a keen eye for this
destructive process, achieving a mean Intersection over Union of 86.30% and a
Dice score of 92.60% - a performance that significantly surpasses traditional
methods and off-the-shelf deep learning models. This work delivers three key
contributions: the first annotated dataset of disappeared settlements in
Bangladesh due to river erosion; a specialized AI model fine-tuned for this
critical task; and a method for quantifying land loss with compelling visual
evidence. Together, these tools provide a powerful new lens through which
policymakers and disaster management agencies can monitor erosion, anticipate
its trajectory, and ultimately protect the vulnerable communities in its path.

</details>


### [95] [Round Outcome Prediction in VALORANT Using Tactical Features from Video Analysis](https://arxiv.org/abs/2510.17199)
*Nirai Hayakawa,Kazumasa Shimari,Kazuma Yamasaki,Hirotatsu Hoshikawa,Rikuto Tsuchida,Kenichi Matsumoto*

Main category: cs.CV

TL;DR: 本文针对FPS游戏VALORANT，通过分析比赛录像中的小地图信息构建回合结果预测模型，利用TimeSformer视频识别模型结合战术特征，在回合中后期达到约81%的预测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有电竞比赛结果预测研究多基于比赛日志数据和统计信息，而VALORANT作为需要复杂策略的FPS游戏，需要更深入分析战术特征来提升预测准确性。

Method: 基于TimeSformer视频识别模型，从小地图信息中提取角色位置信息和游戏内事件等详细战术特征，构建增强数据集训练预测模型。

Result: 在增强战术事件标签的数据集上训练的模型达到约81%的预测准确率，特别是在回合中后期阶段，显著优于仅使用小地图信息本身训练的模型。

Conclusion: 从比赛录像中利用战术特征对于VALORANT回合结果预测非常有效，证明了战术分析在电竞预测中的重要性。

Abstract: Recently, research on predicting match outcomes in esports has been actively
conducted, but much of it is based on match log data and statistical
information. This research targets the FPS game VALORANT, which requires
complex strategies, and aims to build a round outcome prediction model by
analyzing minimap information in match footage. Specifically, based on the
video recognition model TimeSformer, we attempt to improve prediction accuracy
by incorporating detailed tactical features extracted from minimap information,
such as character position information and other in-game events. This paper
reports preliminary results showing that a model trained on a dataset augmented
with such tactical event labels achieved approximately 81% prediction accuracy,
especially from the middle phases of a round onward, significantly
outperforming a model trained on a dataset with the minimap information itself.
This suggests that leveraging tactical features from match footage is highly
effective for predicting round outcomes in VALORANT.

</details>


### [96] [EndoCIL: A Class-Incremental Learning Framework for Endoscopic Image Classification](https://arxiv.org/abs/2510.17200)
*Bingrong Liu,Jun Shi,Yushan Zheng*

Main category: cs.CV

TL;DR: EndoCIL是一个专门为内窥镜图像诊断设计的类增量学习框架，通过三个关键组件解决领域差异和类别不平衡问题，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 内窥镜图像分析中的类增量学习对于临床应用至关重要，但现有方法由于严重的领域差异和类别不平衡而无法有效缓解灾难性遗忘。

Method: EndoCIL包含三个核心组件：基于最大均值差异的重放策略选择多样化样本，先验正则化类别平衡损失解决类别不平衡，以及全连接梯度校准减轻新类偏向。

Result: 在四个公共内窥镜数据集上的广泛实验表明，EndoCIL在不同缓冲区大小和评估指标下普遍优于最先进的CIL方法。

Conclusion: 该框架有效平衡了终身内窥镜诊断中的稳定性和可塑性，显示出良好的临床可扩展性和部署潜力。

Abstract: Class-incremental learning (CIL) for endoscopic image analysis is crucial for
real-world clinical applications, where diagnostic models should continuously
adapt to evolving clinical data while retaining performance on previously
learned ones. However, existing replay-based CIL methods fail to effectively
mitigate catastrophic forgetting due to severe domain discrepancies and class
imbalance inherent in endoscopic imaging. To tackle these challenges, we
propose EndoCIL, a novel and unified CIL framework specifically tailored for
endoscopic image diagnosis. EndoCIL incorporates three key components: Maximum
Mean Discrepancy Based Replay (MDBR), employing a distribution-aligned greedy
strategy to select diverse and representative exemplars, Prior Regularized
Class Balanced Loss (PRCBL), designed to alleviate both inter-phase and
intra-phase class imbalance by integrating prior class distributions and
balance weights into the loss function, and Calibration of Fully-Connected
Gradients (CFG), which adjusts the classifier gradients to mitigate bias toward
new classes. Extensive experiments conducted on four public endoscopic datasets
demonstrate that EndoCIL generally outperforms state-of-the-art CIL methods
across varying buffer sizes and evaluation metrics. The proposed framework
effectively balances stability and plasticity in lifelong endoscopic diagnosis,
showing promising potential for clinical scalability and deployment.

</details>


### [97] [Optimizing DINOv2 with Registers for Face Anti-Spoofing](https://arxiv.org/abs/2510.17201)
*Mika Feng,Pierre Gallin-Martel,Koichi Ito,Takafumi Aoki*

Main category: cs.CV

TL;DR: 提出了一种基于DINOv2的活体检测方法，通过注册机制提取可泛化特征并抑制注意力机制中的扰动，有效区分真实人脸和欺骗攻击图像。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统容易受到恶意攻击者使用注册用户照片进行欺骗攻击的威胁，需要在人脸识别前检测此类欺骗攻击。

Method: 使用带有注册机制的DINOv2模型提取特征，抑制注意力机制中的扰动，专注于关键细微特征。

Result: 在ICCV2025第六届人脸反欺骗研讨会提供的统一物理-数字攻击检测数据集和SiW数据集上验证了方法的有效性。

Conclusion: 提出的DINOv2-based方法能够有效检测人脸欺骗攻击，通过专注于细微特征差异提高检测性能。

Abstract: Face recognition systems are designed to be robust against variations in head
pose, illumination, and image blur during capture. However, malicious actors
can exploit these systems by presenting a face photo of a registered user,
potentially bypassing the authentication process. Such spoofing attacks must be
detected prior to face recognition. In this paper, we propose a DINOv2-based
spoofing attack detection method to discern minute differences between live and
spoofed face images. Specifically, we employ DINOv2 with registers to extract
generalizable features and to suppress perturbations in the attention
mechanism, which enables focused attention on essential and minute features. We
demonstrate the effectiveness of the proposed method through experiments
conducted on the dataset provided by ``The 6th Face Anti-Spoofing Workshop:
Unified Physical-Digital Attacks Detection@ICCV2025'' and SiW dataset.

</details>


### [98] [$\mathcal{V}isi\mathcal{P}runer$: Decoding Discontinuous Cross-Modal Dynamics for Efficient Multimodal LLMs](https://arxiv.org/abs/2510.17205)
*Yingqi Fan,Anhao Zhao,Jinlan Fu,Junlong Tong,Hui Su,Yijie Pan,Wei Zhang,Xiaoyu Shen*

Main category: cs.CV

TL;DR: 本文通过系统分析揭示了多模态大语言模型的三阶段跨模态交互过程，并基于此提出了VisiPruner训练无关剪枝框架，可显著减少视觉相关注意力计算和FLOPs。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉语言任务中表现优异，但由于注意力计算的二次增长导致计算开销巨大。现有方法缺乏对MLLMs如何处理和融合多模态信息的基本理解。

Method: 通过系统分析发现三阶段跨模态交互过程：浅层识别任务意图、中层跨模态融合、深层语言精炼。基于此提出VisiPruner训练无关剪枝框架。

Result: VisiPruner在LLaVA-v1.5 7B上减少高达99%的视觉相关注意力计算和53.9%的FLOPs，显著优于现有方法，并在多种MLLMs上具有良好泛化性。

Conclusion: 研究不仅提供了有效的剪枝方法，还为训练高效MLLMs提供了可操作的指导原则，即模型架构应与其内在的层级处理动态保持一致。

Abstract: Multimodal Large Language Models (MLLMs) have achieved strong performance
across vision-language tasks, but suffer from significant computational
overhead due to the quadratic growth of attention computations with the number
of multimodal tokens. Though efforts have been made to prune tokens in MLLMs,
\textit{they lack a fundamental understanding of how MLLMs process and fuse
multimodal information.} Through systematic analysis, we uncover a
\textbf{three-stage} cross-modal interaction process: (1) Shallow layers
recognize task intent, with visual tokens acting as passive attention sinks;
(2) Cross-modal fusion occurs abruptly in middle layers, driven by a few
critical visual tokens; (3) Deep layers discard vision tokens, focusing solely
on linguistic refinement. Based on these findings, we propose
\emph{VisiPruner}, a training-free pruning framework that reduces up to 99\% of
vision-related attention computations and 53.9\% of FLOPs on LLaVA-v1.5 7B. It
significantly outperforms existing token pruning methods and generalizes across
diverse MLLMs. Beyond pruning, our insights further provide actionable
guidelines for training efficient MLLMs by aligning model architecture with its
intrinsic layer-wise processing dynamics. Our code is available at:
https://github.com/EIT-NLP/VisiPruner.

</details>


### [99] [Fair and Interpretable Deepfake Detection in Videos](https://arxiv.org/abs/2510.17264)
*Akihito Yoshii,Ryosuke Sonoda,Ramya Srinivasan*

Main category: cs.CV

TL;DR: 提出一个公平性感知的深度伪造检测框架，通过时序特征学习和人口统计感知数据增强来提高公平性和可解释性，在多个数据集上实现了公平性和准确性的最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法存在偏见、缺乏透明度且无法捕捉时序信息，导致跨不同人口群体的决策偏见和不可靠结果。

Method: 集成时序特征学习和人口统计感知数据增强，使用时序聚类进行深度伪造视频建模，概念提取提高检测可靠性，并引入人口统计感知数据增强方法平衡代表性不足群体。

Result: 在FaceForensics++、DFD、Celeb-DF和DFDC数据集上使用Xception、ResNet等最先进架构进行广泛实验，证明了该方法在公平性和准确性之间获得最佳权衡。

Conclusion: 所提出的公平性感知深度伪造检测框架有效解决了现有方法的偏见问题，提高了检测的公平性、可靠性和可解释性。

Abstract: Existing deepfake detection methods often exhibit bias, lack transparency,
and fail to capture temporal information, leading to biased decisions and
unreliable results across different demographic groups. In this paper, we
propose a fairness-aware deepfake detection framework that integrates temporal
feature learning and demographic-aware data augmentation to enhance fairness
and interpretability. Our method leverages sequence-based clustering for
temporal modeling of deepfake videos and concept extraction to improve
detection reliability while also facilitating interpretable decisions for
non-expert users. Additionally, we introduce a demography-aware data
augmentation method that balances underrepresented groups and applies
frequency-domain transformations to preserve deepfake artifacts, thereby
mitigating bias and improving generalization. Extensive experiments on
FaceForensics++, DFD, Celeb-DF, and DFDC datasets using state-of-the-art (SoTA)
architectures (Xception, ResNet) demonstrate the efficacy of the proposed
method in obtaining the best tradeoff between fairness and accuracy when
compared to SoTA.

</details>


### [100] [FineVision: Open Data Is All You Need](https://arxiv.org/abs/2510.17269)
*Luis Wiedmann,Orr Zohar,Amir Mahla,Xiaohan Wang,Rui Li,Thibaud Frere,Leandro von Werra,Aritra Roy Gosthipaty,Andrés Marafioti*

Main category: cs.CV

TL;DR: FineVision是一个精心收集、整理和统一的大规模视觉语言数据集，包含2400万个样本，通过半自动化人工参与流程整合了200多个数据源，并进行了严格的去重和去污染处理。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型的发展受到数据集碎片化、不一致和污染问题的阻碍，需要构建高质量、统一的大规模数据集来推动研究进展。

Method: 采用半自动化人工参与流程：自动化进行批量数据摄取和模式映射，人工审核员检查映射质量、验证注释准确性、格式多样性和安全性，发现问题时进行针对性修复和重新运行。

Result: 在FineVision上训练的模型在广泛评估套件中持续优于现有开放混合数据集训练的模型，证明了数据规模、数据卫生以及人机协同平衡的优势。

Conclusion: FineVision数据集及其整理工具将加速以数据为中心的视觉语言模型研究，强调了高质量数据整理对模型性能提升的重要性。

Abstract: The advancement of vision-language models (VLMs) is hampered by a fragmented
landscape of inconsistent and contaminated public datasets. We introduce
FineVision, a meticulously collected, curated, and unified corpus of 24 million
samples - the largest open resource of its kind. We unify more than 200 sources
into 185 subsets via a semi-automated, human-in-the-loop pipeline: automation
performs bulk ingestion and schema mapping, while reviewers audit mappings and
spot-check outputs to verify faithful consumption of annotations, appropriate
formatting and diversity, and safety; issues trigger targeted fixes and
re-runs. The workflow further applies rigorous de-duplication within and across
sources and decontamination against 66 public benchmarks. FineVision also
encompasses agentic/GUI tasks with a unified action space; reviewers validate
schemas and inspect a sample of trajectories to confirm executable fidelity.
Models trained on FineVision consistently outperform those trained on existing
open mixtures across a broad evaluation suite, underscoring the benefits of
scale, data hygiene, and balanced automation with human oversight. We release
the corpus and curation tools to accelerate data-centric VLM research.

</details>


### [101] [Enhanced Motion Forecasting with Plug-and-Play Multimodal Large Language Models](https://arxiv.org/abs/2510.17274)
*Katie Luo,Jingwei Ji,Tong He,Runsheng Xu,Yichen Xie,Dragomir Anguelov,Mingxing Tan*

Main category: cs.CV

TL;DR: PnF是一种即插即用的方法，通过多模态大语言模型增强现有运动预测模型，利用自然语言描述复杂场景，实现零样本推理，无需微调即可显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统依赖专用模型进行感知和运动预测，在标准条件下表现可靠，但难以经济高效地泛化到多样化的真实世界场景。

Method: 设计提示从MLLMs提取结构化场景理解，将这些信息蒸馏成可学习嵌入来增强现有行为预测模型，利用MLLMs的零样本推理能力。

Result: 在Waymo Open Motion Dataset和nuScenes Dataset上验证，两个最先进的运动预测模型都表现出持续的性能改进。

Conclusion: PnF方法通过自然语言描述复杂场景，实现了对现有运动预测模型的有效增强，在无需微调的情况下显著提升了预测性能。

Abstract: Current autonomous driving systems rely on specialized models for perceiving
and predicting motion, which demonstrate reliable performance in standard
conditions. However, generalizing cost-effectively to diverse real-world
scenarios remains a significant challenge. To address this, we propose
Plug-and-Forecast (PnF), a plug-and-play approach that augments existing motion
forecasting models with multimodal large language models (MLLMs). PnF builds on
the insight that natural language provides a more effective way to describe and
handle complex scenarios, enabling quick adaptation to targeted behaviors. We
design prompts to extract structured scene understanding from MLLMs and distill
this information into learnable embeddings to augment existing behavior
prediction models. Our method leverages the zero-shot reasoning capabilities of
MLLMs to achieve significant improvements in motion prediction performance,
while requiring no fine-tuning -- making it practical to adopt. We validate our
approach on two state-of-the-art motion forecasting models using the Waymo Open
Motion Dataset and the nuScenes Dataset, demonstrating consistent performance
improvements across both benchmarks.

</details>


### [102] [Exploring Structural Degradation in Dense Representations for Self-supervised Learning](https://arxiv.org/abs/2510.17299)
*Siran Dai,Qianqian Xu,Peisong Wen,Yang Liu,Qingming Huang*

Main category: cs.CV

TL;DR: 本文发现自监督学习中存在一个反直觉现象：长时间训练可能损害密集预测任务的性能，称为自监督密集退化(SDD)。作者提出了密集表示结构估计器(DSE)来无监督评估密集任务性能，并基于此开发了模型选择策略和正则化方法，有效缓解了退化问题。


<details>
  <summary>Details</summary>
Motivation: 观察到自监督学习在密集预测任务中存在性能退化现象，即训练时间越长性能反而下降，这挑战了传统认知。需要开发无监督方法来评估密集任务性能，因为在实际应用中通常缺乏标注数据。

Method: 提出了密集表示结构估计器(DSE)，包含类相关性度量和有效维度度量，用于无监督评估密集任务性能。基于DSE开发了模型选择策略和正则化方法。

Result: 在16种自监督方法和4个基准测试上的实验表明，模型选择策略平均提升mIoU 3.0%，计算成本可忽略。DSE正则化能持续缓解密集退化效应。

Conclusion: 自监督学习中确实存在密集退化现象，提出的DSE方法能有效评估密集任务性能并缓解退化问题，为自监督学习在密集预测任务中的应用提供了重要指导。

Abstract: In this work, we observe a counterintuitive phenomenon in self-supervised
learning (SSL): longer training may impair the performance of dense prediction
tasks (e.g., semantic segmentation). We refer to this phenomenon as
Self-supervised Dense Degradation (SDD) and demonstrate its consistent presence
across sixteen state-of-the-art SSL methods with various losses, architectures,
and datasets. When the model performs suboptimally on dense tasks at the end of
training, measuring the performance during training becomes essential. However,
evaluating dense performance effectively without annotations remains an open
challenge. To tackle this issue, we introduce a Dense representation Structure
Estimator (DSE), composed of a class-relevance measure and an effective
dimensionality measure. The proposed DSE is both theoretically grounded and
empirically validated to be closely correlated with the downstream performance.
Based on this metric, we introduce a straightforward yet effective model
selection strategy and a DSE-based regularization method. Experiments on
sixteen SSL methods across four benchmarks confirm that model selection
improves mIoU by $3.0\%$ on average with negligible computational cost.
Additionally, DSE regularization consistently mitigates the effects of dense
degradation. Code is available at
https://github.com/EldercatSAM/SSL-Degradation.

</details>


### [103] [LongInsightBench: A Comprehensive Benchmark for Evaluating Omni-Modal Models on Human-Centric Long-Video Understanding](https://arxiv.org/abs/2510.17305)
*ZhaoYang Han,Qihan Lin,Hao Liang,Bowen Chen,Zhou Liu,Wentao Zhang*

Main category: cs.CV

TL;DR: LongInsightBench是首个专注于长视频理解的基准测试，整合视觉、音频和文本多模态，包含约1000个信息密集的长视频和6个挑战性任务场景。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态模型在处理长视频时面临挑战，特别是在理解人类语言、观点、动作等上下文元素方面，需要专门的基准测试来评估模型性能。

Method: 从FineVideo数据集中精选约1000个长视频，设计6个任务场景（包括事件内和事件间任务），并开发三步半自动数据质量保证流程确保问题难度和有效性。

Result: 实验结果显示全模态模型在精确时间定位和长距离因果推理任务上仍面临挑战，扩展实验揭示了多模态融合中的信息丢失和处理偏差问题。

Conclusion: LongInsightBench为评估长视频理解能力提供了有效基准，揭示了当前全模态模型在复杂多模态任务中的局限性，特别是时间定位和因果推理方面。

Abstract: We introduce \textbf{LongInsightBench}, the first benchmark designed to
assess models' ability to understand long videos, with a focus on human
language, viewpoints, actions, and other contextual elements, while integrating
\textbf{visual, audio, and text} modalities. Our benchmark excels in three key
areas: \textbf{a) Long-Duration, Information-Dense Videos:} We carefully select
approximately 1,000 videos from open-source datasets FineVideo based on
duration limit and the information density of both visual and audio modalities,
focusing on content like lectures, interviews, and vlogs, which contain rich
language elements. \textbf{b) Diverse and Challenging Task Scenarios:} We have
designed six challenging task scenarios, including both Intra-Event and
Inter-Event Tasks. \textbf{c) Rigorous and Comprehensive Quality Assurance
Pipelines:} We have developed a three-step, semi-automated data quality
assurance pipeline to ensure the difficulty and validity of the synthesized
questions and answer options. Based on LongInsightBench, we designed a series
of experiments. Experimental results shows that Omni-modal models(OLMs) still
face challenge in tasks requiring precise temporal localization (T-Loc) and
long-range causal inference (CE-Caus). Extended experiments reveal the
information loss and processing bias in multi-modal fusion of OLMs. Our dataset
and code is available at
https://anonymous.4open.science/r/LongInsightBench-910F/.

</details>


### [104] [A Single Set of Adversarial Clothes Breaks Multiple Defense Methods in the Physical World](https://arxiv.org/abs/2510.17322)
*Wei Zhang,Zhanhao Hu,Xiao Li,Xiaopei Zhu,Xiaolin Hu*

Main category: cs.CV

TL;DR: 本文评估了现有对抗防御方法对对抗性服装的防御效果，发现所有防御方法在数字和物理世界中表现均不佳，并成功制作了能突破多种防御方法的单一对抗服装。


<details>
  <summary>Details</summary>
Motivation: 现有对抗补丁防御方法在面对大尺寸对抗攻击时可能失效，对抗性服装作为自然且覆盖面积大的攻击形式，为评估防御方法提供了良好测试案例。

Method: 通过制作对抗性服装，在数字和物理世界中测试多种防御方法的有效性，并设计单一服装来突破多个防御模型。

Result: 所有防御方法在对抗性服装攻击下表现不佳，单一对抗服装在物理世界中达到96.06%攻击成功率，对九个防御模型的攻击成功率均超过64.84%。

Conclusion: 现有对抗防御方法在面对大尺寸自然对抗攻击时存在共同脆弱性，需要开发更鲁棒的防御机制。

Abstract: In recent years, adversarial attacks against deep learning-based object
detectors in the physical world have attracted much attention. To defend
against these attacks, researchers have proposed various defense methods
against adversarial patches, a typical form of physically-realizable attack.
However, our experiments showed that simply enlarging the patch size could make
these defense methods fail. Motivated by this, we evaluated various defense
methods against adversarial clothes which have large coverage over the human
body. Adversarial clothes provide a good test case for adversarial defense
against patch-based attacks because they not only have large sizes but also
look more natural than a large patch on humans. Experiments show that all the
defense methods had poor performance against adversarial clothes in both the
digital world and the physical world. In addition, we crafted a single set of
clothes that broke multiple defense methods on Faster R-CNN. The set achieved
an Attack Success Rate (ASR) of 96.06% against the undefended detector and over
64.84% ASRs against nine defended models in the physical world, unveiling the
common vulnerability of existing adversarial defense methods against
adversarial clothes. Code is available at:
https://github.com/weiz0823/adv-clothes-break-multiple-defenses.

</details>


### [105] [CharDiff: A Diffusion Model with Character-Level Guidance for License Plate Image Restoration](https://arxiv.org/abs/2510.17330)
*Gyuhwan Park,Kihyun Na,Injung Kim*

Main category: cs.CV

TL;DR: 提出CharDiff框架，通过字符级引导的扩散模型有效恢复和识别严重退化的车牌图像，在恢复质量和识别准确率上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 车牌图像恢复不仅对车牌识别系统预处理很重要，还能提高证据价值、增强视觉界面清晰度，促进车牌图像的进一步利用。

Method: 使用基于扩散的框架，结合字符级先验知识，通过外部分割和OCR模块提取细粒度字符信息，并引入CHARM模块确保每个字符的引导仅限制在其自身区域。

Result: 在Roboflow-LP数据集上，相比最佳基线模型，实现了28%的相对CER降低，在恢复质量和识别准确率方面显著优于基线恢复模型。

Conclusion: 结构化字符引导条件化有效增强了基于扩散的车牌恢复和识别在实际部署场景中的鲁棒性。

Abstract: The significance of license plate image restoration goes beyond the
preprocessing stage of License Plate Recognition (LPR) systems, as it also
serves various purposes, including increasing evidential value, enhancing the
clarity of visual interface, and facilitating further utilization of license
plate images. We propose a novel diffusion-based framework with character-level
guidance, CharDiff, which effectively restores and recognizes severely degraded
license plate images captured under realistic conditions. CharDiff leverages
fine-grained character-level priors extracted through external segmentation and
Optical Character Recognition (OCR) modules tailored for low-quality license
plate images. For precise and focused guidance, CharDiff incorporates a novel
Character-guided Attention through Region-wise Masking (CHARM) module, which
ensures that each character's guidance is restricted to its own region, thereby
avoiding interference with other regions. In experiments, CharDiff
significantly outperformed the baseline restoration models in both restoration
quality and recognition accuracy, achieving a 28% relative reduction in CER on
the Roboflow-LP dataset, compared to the best-performing baseline model. These
results indicate that the structured character-guided conditioning effectively
enhances the robustness of diffusion-based license plate restoration and
recognition in practical deployment scenarios.

</details>


### [106] [iDETEX: Empowering MLLMs for Intelligent DETailed EXplainable IQA](https://arxiv.org/abs/2510.17332)
*Zhaoran Zhao,Xinli Yue,Jianhui Sun,Yuhao Xie,Tao Shao,Liangchao Yao,Fan Xia,Yuetang Deng*

Main category: cs.CV

TL;DR: 提出了iDETEX模型，这是一个统一的多模态大语言模型，能够同时执行质量定位、感知和描述三个关键任务，在ViDA-UGC基准测试中实现了最先进的性能，并在ICCV MIPI 2025挑战赛中排名第一。


<details>
  <summary>Details</summary>
Motivation: 解决图像质量评估从标量质量预测向更可解释、与人类对齐的评估范式发展的挑战，实现详细且可解释的图像质量评估。

Method: 设计了一套任务特定的离线增强模块和数据混合策略，辅以在线增强策略来充分利用多源监督，构建统一的多模态大语言模型iDETEX。

Result: 在ViDA-UGC基准测试中实现了所有子任务的最先进性能，在ICCV MIPI 2025详细图像质量评估挑战赛中排名第一。

Conclusion: iDETEX模型在提供准确且可解释的质量评估方面表现出有效性和鲁棒性，为详细图像质量评估提供了统一的解决方案。

Abstract: Image Quality Assessment (IQA) has progressed from scalar quality prediction
to more interpretable, human-aligned evaluation paradigms. In this work, we
address the emerging challenge of detailed and explainable IQA by proposing
iDETEX-a unified multimodal large language model (MLLM) capable of
simultaneously performing three key tasks: quality grounding, perception, and
description. To facilitate efficient and generalizable training across these
heterogeneous subtasks, we design a suite of task-specific offline augmentation
modules and a data mixing strategy. These are further complemented by online
enhancement strategies to fully exploit multi-sourced supervision. We validate
our approach on the large-scale ViDA-UGC benchmark, where iDETEX achieves
state-of-the-art performance across all subtasks. Our model ranks first in the
ICCV MIPI 2025 Detailed Image Quality Assessment Challenge, demonstrating its
effectiveness and robustness in delivering accurate and interpretable quality
assessments.

</details>


### [107] [Nearest-Class Mean and Logits Agreement for Wildlife Open-Set Recognition](https://arxiv.org/abs/2510.17338)
*Jiahao Huo,Mufhumudzi Muthivhi,Terence L. van Zyl,Fredrik Gustafsson*

Main category: cs.CV

TL;DR: 提出了一种后处理开放集识别方法，通过测量模型特征与预测logits之间的一致性来识别未知类，无需重新训练预训练模型。


<details>
  <summary>Details</summary>
Motivation: 当前野生动物分类模型在封闭世界设定下训练，当遇到未知类别时会过度自信。现有开放集识别方法大多需要重新训练模型，这限制了实际应用。

Method: 基于输入到最近类均值(NCM)的距离构建概率分布，然后将NCM分布与softmax概率进行比较，测量NCM与分类头之间的一致性。

Result: 在两个数据集上均排名前三，表现稳定。在非洲和瑞典动物数据集上分别达到93.41和95.35的AUROC。

Conclusion: 提出的后处理方法在开放集识别任务中表现优异且稳定，无需重新训练预训练模型，具有实际应用价值。

Abstract: Current state-of-the-art Wildlife classification models are trained under the
closed world setting. When exposed to unknown classes, they remain
overconfident in their predictions. Open-set Recognition (OSR) aims to classify
known classes while rejecting unknown samples. Several OSR methods have been
proposed to model the closed-set distribution by observing the feature, logit,
or softmax probability space. A significant drawback of many existing
approaches is the requirement to retrain the pre-trained classification model
with the OSR-specific strategy. This study contributes a post-processing OSR
method that measures the agreement between the models' features and predicted
logits. We propose a probability distribution based on an input's distance to
its Nearest Class Mean (NCM). The NCM-based distribution is then compared with
the softmax probabilities from the logit space to measure agreement between the
NCM and the classification head. Our proposed strategy ranks within the top
three on two evaluated datasets, showing consistent performance across the two
datasets. In contrast, current state-of-the-art methods excel on a single
dataset. We achieve an AUROC of 93.41 and 95.35 for African and Swedish
animals. The code can be found
https://github.com/Applied-Representation-Learning-Lab/OSR.

</details>


### [108] [Exploring The Missing Semantics In Event Modality](https://arxiv.org/abs/2510.17347)
*Jingqian Wu,Shengpeng Xu,Yunbo Jia,Edmund Y. Lam*

Main category: cs.CV

TL;DR: 提出Semantic-E2VID框架，通过跨模态特征对齐和语义感知特征融合，将视觉语义知识从图像模态迁移到事件模态，提升事件到视频重建的质量和语义信息恢复能力。


<details>
  <summary>Details</summary>
Motivation: 事件相机仅捕捉强度变化，忽略静态物体和背景，导致事件模态缺乏语义信息。现有E2V方法往往忽视语义信息在视频重建中的重要作用。

Method: 引入跨模态特征对齐模块将SAM模型的视觉语义迁移到事件编码器；设计语义感知特征融合块集成学习到的语义特征；提出语义感知E2V监督利用SAM生成的类别标签辅助重建。

Result: 在多个基准测试中显著提升帧质量，优于最先进的E2V方法。

Conclusion: Semantic-E2VID通过有效利用视觉语义知识，成功提升了事件到视频重建的性能，特别是在语义信息恢复方面。

Abstract: Event cameras offer distinct advantages such as low latency, high dynamic
range, and efficient motion capture. However, event-to-video reconstruction
(E2V), a fundamental event-based vision task, remains challenging, particularly
for reconstructing and recovering semantic information. This is primarily due
to the nature of the event camera, as it only captures intensity changes,
ignoring static objects and backgrounds, resulting in a lack of semantic
information in captured event modality. Further, semantic information plays a
crucial role in video and frame reconstruction, yet is often overlooked by
existing E2V approaches. To bridge this gap, we propose Semantic-E2VID, an E2V
framework that explores the missing visual semantic knowledge in event modality
and leverages it to enhance event-to-video reconstruction. Specifically,
Semantic-E2VID introduces a cross-modal feature alignment (CFA) module to
transfer the robust visual semantics from a frame-based vision foundation
model, the Segment Anything Model (SAM), to the event encoder, while aligning
the high-level features from distinct modalities. To better utilize the learned
semantic feature, we further propose a semantic-aware feature fusion (SFF)
block to integrate learned semantics in frame modality to form event
representations with rich semantics that can be decoded by the event decoder.
Further, to facilitate the reconstruction of semantic information, we propose a
novel Semantic Perceptual E2V Supervision that helps the model to reconstruct
semantic details by leveraging SAM-generated categorical labels. Extensive
experiments demonstrate that Semantic-E2VID significantly enhances frame
quality, outperforming state-of-the-art E2V methods across multiple benchmarks.
The sample code is included in the supplementary material.

</details>


### [109] [Glyph: Scaling Context Windows via Visual-Text Compression](https://arxiv.org/abs/2510.17800)
*Jiale Cheng,Yusen Liu,Xinyu Zhang,Yulin Fei,Wenyi Hong,Ruiliang Lyu,Weihan Wang,Zhe Su,Xiaotao Gu,Xiao Liu,Yushi Bai,Jie Tang,Hongning Wang,Minlie Huang*

Main category: cs.CV

TL;DR: Glyph框架通过将长文本渲染为图像，利用视觉语言模型处理，实现3-4倍的文本压缩，同时保持与主流LLM相当的准确率，显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统LLM在处理百万级token的长上下文时面临计算和内存成本过高的问题，限制了实际应用。

Method: 提出Glyph框架，将长文本渲染成图像，使用视觉语言模型处理；设计基于LLM的遗传搜索来优化视觉渲染配置，平衡准确性和压缩率。

Result: 在多个长上下文基准测试中实现3-4倍token压缩，准确率与Qwen3-8B相当；预填充和解码速度提升约4倍，SFT训练速度提升约2倍；128K上下文VLM可扩展到处理1M token任务。

Conclusion: 视觉上下文扩展方法为长文本处理提供了高效解决方案，在保持性能的同时显著降低计算成本，并有益于文档理解等多模态任务。

Abstract: Large language models (LLMs) increasingly rely on long-context modeling for
tasks such as document understanding, code analysis, and multi-step reasoning.
However, scaling context windows to the million-token level brings prohibitive
computational and memory costs, limiting the practicality of long-context LLMs.
In this work, we take a different perspective-visual context scaling-to tackle
this challenge. Instead of extending token-based sequences, we propose Glyph, a
framework that renders long texts into images and processes them with
vision-language models (VLMs). This approach substantially compresses textual
input while preserving semantic information, and we further design an
LLM-driven genetic search to identify optimal visual rendering configurations
for balancing accuracy and compression. Through extensive experiments, we
demonstrate that our method achieves 3-4x token compression while maintaining
accuracy comparable to leading LLMs such as Qwen3-8B on various long-context
benchmarks. This compression also leads to around 4x faster prefilling and
decoding, and approximately 2x faster SFT training. Furthermore, under extreme
compression, a 128K-context VLM could scale to handle 1M-token-level text
tasks. In addition, the rendered text data benefits real-world multimodal
tasks, such as document understanding. Our code and model are released at
https://github.com/thu-coai/Glyph.

</details>


### [110] [Recurrent Attention-based Token Selection for Efficient Streaming Video-LLMs](https://arxiv.org/abs/2510.17364)
*Vaggelis Dorovatas,Soroush Seifi,Gunshi Gupta,Rahaf Aljundi*

Main category: cs.CV

TL;DR: 提出一种无需训练的流式视频处理方法，通过LLM引导的视觉令牌选择、递归处理历史令牌和基于描述的问答，在保持性能的同时大幅减少计算量。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在处理流式长视频时面临效率挑战，无法实时响应查询，需要在线处理小时级视频内容。

Method: 1) 基于LLM注意力选择重要视觉令牌，可丢弃95%不重要的令牌；2) 递归处理历史选定令牌以保持时间连贯性；3) 基于描述的轻量级问答机制。

Result: 在流式视频基准测试中达到最先进性能，在效率和效果之间取得良好平衡。

Conclusion: 该方法为视频大语言模型在流式场景下的高效应用提供了可行的解决方案，显著提升了处理长视频的实时响应能力。

Abstract: Video Large Language Models (Video-LLMs) excel at understanding videos
in-context, provided they have full access to the video when answering queries.
However, these models face challenges in streaming scenarios where hour-long
videos must be processed online, and questions need timely responses. In this
work, we propose a training-free approach compatible with standard Video-LLMs,
leveraging three key concepts: 1) LLM-informed selection of visual tokens to
identify those that the LLM has attended to and contributed to its
understanding of each short clip. Our attention-based selection allows us to
discard up to ~95% of unimportant visual tokens with minimal performance loss;
2) Recurrent processing of past selected tokens to generate temporally coherent
understanding of each processed clip; 3) Caption-based question answering for
lightweight and accurate responses. Our method achieves state-of-the-art
performance on streaming video benchmarks, striking a balance between
efficiency and effectiveness.

</details>


### [111] [Beyond Real Faces: Synthetic Datasets Can Achieve Reliable Recognition Performance without Privacy Compromise](https://arxiv.org/abs/2510.17372)
*Paweł Borsukiewicz,Fadi Boutros,Iyiola E. Olatunji,Charles Beumier,Wendkûuni C. Ouedraogo,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.CV

TL;DR: 本研究通过系统评估25个合成人脸识别数据集（2018-2025），首次全面验证了合成数据替代真实数据集的可行性。最佳合成数据集VariFace和VIGFace分别达到95.67%和94.91%的识别准确率，超越了真实数据集CASIA-WebFace（94.70%）。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统的部署面临伦理困境：高精度需要大量未经同意收集的真实人脸数据，导致数据集撤回和GDPR等法规下的法律责任。合成人脸数据作为隐私保护替代方案缺乏实证证据。

Method: 系统文献回顾识别25个合成人脸识别数据集，结合严格实验验证。方法考察隐私保护合成数据的七个关键要求：身份泄露预防、类内变异性、身份可分离性、数据集规模、伦理数据来源、偏见缓解和基准可靠性。

Result: 实验涉及超过1000万个合成样本，最佳合成数据集VariFace（95.67%）和VIGFace（94.91%）超越真实数据集CASIA-WebFace（94.70%）。公开替代方案Vec2Face（93.52%）和CemiFace（93.22%）表现接近。合成数据确保适当的类内变异性同时保持身份可分离性。

Conclusion: 合成人脸数据在确保适当类内变异性和身份可分离性的同时，为偏见缓解提供前所未有的控制能力。这些结果确立了合成人脸数据作为人脸识别研究的科学可行且伦理必要的替代方案。

Abstract: The deployment of facial recognition systems has created an ethical dilemma:
achieving high accuracy requires massive datasets of real faces collected
without consent, leading to dataset retractions and potential legal liabilities
under regulations like GDPR. While synthetic facial data presents a promising
privacy-preserving alternative, the field lacks comprehensive empirical
evidence of its viability. This study addresses this critical gap through
extensive evaluation of synthetic facial recognition datasets. We present a
systematic literature review identifying 25 synthetic facial recognition
datasets (2018-2025), combined with rigorous experimental validation. Our
methodology examines seven key requirements for privacy-preserving synthetic
data: identity leakage prevention, intra-class variability, identity
separability, dataset scale, ethical data sourcing, bias mitigation, and
benchmark reliability. Through experiments involving over 10 million synthetic
samples, extended by a comparison of results reported on five standard
benchmarks, we provide the first comprehensive empirical assessment of
synthetic data's capability to replace real datasets. Best-performing synthetic
datasets (VariFace, VIGFace) achieve recognition accuracies of 95.67% and
94.91% respectively, surpassing established real datasets including
CASIA-WebFace (94.70%). While those images remain private, publicly available
alternatives Vec2Face (93.52%) and CemiFace (93.22%) come close behind. Our
findings reveal that they ensure proper intra-class variability while
maintaining identity separability. Demographic bias analysis shows that, even
though synthetic data inherits limited biases, it offers unprecedented control
for bias mitigation through generation parameters. These results establish
synthetic facial data as a scientifically viable and ethically imperative
alternative for facial recognition research.

</details>


### [112] [Facial Expression-based Parkinson's Disease Severity Diagnosis via Feature Fusion and Adaptive Class Balancing](https://arxiv.org/abs/2510.17373)
*Yintao Zhou,Wei Huang,Zhengyu Li,Jing Huang,Meng Pang*

Main category: cs.CV

TL;DR: 提出了一种基于多面部表情特征的帕金森病严重程度诊断方法，通过注意力机制融合多种表情特征，并采用自适应类别平衡策略解决类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于面部表情的PD诊断方法依赖单一表情类型易导致误诊，且忽略不同PD阶段的类别不平衡问题，大多数方法仅进行二元分类而非严重程度诊断。

Method: 通过注意力机制融合多种面部表情特征，采用自适应类别平衡策略根据类别分布和分类难度动态调整训练样本的贡献度。

Result: 实验结果表明该方法在PD严重程度诊断方面具有良好性能，注意力特征融合和自适应类别平衡策略有效。

Conclusion: 该方法为PD严重程度诊断提供了一种有效的解决方案，通过多表情特征融合和类别平衡策略提升了诊断准确性和鲁棒性。

Abstract: Parkinson's disease (PD) severity diagnosis is crucial for early detecting
potential patients and adopting tailored interventions. Diagnosing PD based on
facial expression is grounded in PD patients' "masked face" symptom and gains
growing interest recently for its convenience and affordability. However,
current facial expression-based approaches often rely on single type of
expression which can lead to misdiagnosis, and ignore the class imbalance
across different PD stages which degrades the prediction performance. Moreover,
most existing methods focus on binary classification (i.e., PD / non-PD) rather
than diagnosing the severity of PD. To address these issues, we propose a new
facial expression-based method for PD severity diagnosis which integrates
multiple facial expression features through attention-based feature fusion.
Moreover, we mitigate the class imbalance problem via an adaptive class
balancing strategy which dynamically adjusts the contribution of training
samples based on their class distribution and classification difficulty.
Experimental results demonstrate the promising performance of the proposed
method for PD severity diagnosis, as well as the efficacy of attention-based
feature fusion and adaptive class balancing.

</details>


### [113] [Closed-Loop Transfer for Weakly-supervised Affordance Grounding](https://arxiv.org/abs/2510.17384)
*Jiajin Tang,Zhengxuan Wei,Ge Zheng,Sibei Yang*

Main category: cs.CV

TL;DR: 本文提出LoopTrans框架，通过闭环知识转移机制，在自我中心视角和外部视角图像间双向传递交互知识，显著提升了弱监督可操作性定位的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅从外部视角图像单向向自我中心视角转移可操作性知识，限制了在复杂交互场景中的适用性。人类通过观察他人与物体交互就能学会新物体的使用方式，这种能力启发了双向知识转移的需求。

Method: 提出LoopTrans闭环框架，包含统一跨模态定位和去噪知识蒸馏机制，在自我中心视角和外部视角图像间建立双向知识转移，弥合领域差距。

Result: 实验表明LoopTrans在所有图像和视频基准测试指标上均取得一致提升，即使在人体完全遮挡物体交互区域的挑战性场景下也能有效处理。

Conclusion: 闭环知识转移框架能够有效增强可操作性知识的提取和转移，为复杂交互场景下的弱监督可操作性定位提供了新的解决方案。

Abstract: Humans can perform previously unexperienced interactions with novel objects
simply by observing others engage with them. Weakly-supervised affordance
grounding mimics this process by learning to locate object regions that enable
actions on egocentric images, using exocentric interaction images with
image-level annotations. However, extracting affordance knowledge solely from
exocentric images and transferring it one-way to egocentric images limits the
applicability of previous works in complex interaction scenarios. Instead, this
study introduces LoopTrans, a novel closed-loop framework that not only
transfers knowledge from exocentric to egocentric but also transfers back to
enhance exocentric knowledge extraction. Within LoopTrans, several innovative
mechanisms are introduced, including unified cross-modal localization and
denoising knowledge distillation, to bridge domain gaps between object-centered
egocentric and interaction-centered exocentric images while enhancing knowledge
transfer. Experiments show that LoopTrans achieves consistent improvements
across all metrics on image and video benchmarks, even handling challenging
scenarios where object interaction regions are fully occluded by the human
body.

</details>


### [114] [Monitoring Horses in Stalls: From Object to Event Detection](https://arxiv.org/abs/2510.17409)
*Dmitrii Galimzianov,Viacheslav Vyshegorodtsev,Ivan Nezhivykh*

Main category: cs.CV

TL;DR: 开发了一个基于视觉的自动化系统，用于监测马厩中马匹和人员的行为，使用YOLOv11和BoT-SORT进行目标检测与跟踪，通过物体轨迹和空间关系推断事件状态。


<details>
  <summary>Details</summary>
Motivation: 传统马匹行为监测方法劳动密集且耗时，需要自动化系统来早期发现健康与福利问题。

Method: 采用YOLOv11进行目标检测，BoT-SORT进行多目标跟踪，利用CLIP和GroundingDINO辅助构建自定义数据集，基于物体轨迹和空间关系推断事件状态。

Result: 系统能区分五种事件类型并考虑相机盲区，定性评估显示马匹相关事件检测可靠，但人员检测因数据稀缺存在局限。

Conclusion: 该工作为马场实时行为监测奠定了基础，对动物福利和厩舍管理具有重要意义。

Abstract: Monitoring the behavior of stalled horses is essential for early detection of
health and welfare issues but remains labor-intensive and time-consuming. In
this study, we present a prototype vision-based monitoring system that
automates the detection and tracking of horses and people inside stables using
object detection and multi-object tracking techniques. The system leverages
YOLOv11 and BoT-SORT for detection and tracking, while event states are
inferred based on object trajectories and spatial relations within the stall.
To support development, we constructed a custom dataset annotated with
assistance from foundation models CLIP and GroundingDINO. The system
distinguishes between five event types and accounts for the camera's blind
spots. Qualitative evaluation demonstrated reliable performance for
horse-related events, while highlighting limitations in detecting people due to
data scarcity. This work provides a foundation for real-time behavioral
monitoring in equine facilities, with implications for animal welfare and
stable management.

</details>


### [115] [DeepDetect: Learning All-in-One Dense Keypoints](https://arxiv.org/abs/2510.17422)
*Shaharyar Ahmed Khan Tareen,Filza Khan Tareen*

Main category: cs.CV

TL;DR: DeepDetect是一个智能、一体化、密集的关键点检测器，通过融合传统检测器的输出生成真实标签，训练轻量级ESPNet模型，在关键点密度、可重复性和正确匹配数量方面超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统关键点检测器（SIFT、SURF、ORB等）和学习方法（SuperPoint、R2D2等）存在对光度变化敏感、关键点密度和可重复性低、对挑战性场景适应性有限、缺乏语义理解等问题，无法优先关注视觉重要区域。

Method: 首先融合7个关键点检测器和2个边缘检测器的输出创建真实标签掩码，提取从角点、斑点到显著边缘和纹理的多样化视觉线索。然后使用这些掩码作为标签训练轻量高效的ESPNet模型。

Result: 在Oxford Affine Covariant Regions数据集上的评估显示，DeepDetect在关键点密度（0.5143）、可重复性（0.9582）和正确匹配数量（59,003）方面均达到最大值，超越其他检测器。

Conclusion: DeepDetect成功统一了传统检测器的优势，通过深度学习实现了语义关注和高密度关键点检测，能够适应多样化和视觉退化条件。

Abstract: Keypoint detection is the foundation of many computer vision tasks, including
image registration, structure-from motion, 3D reconstruction, visual odometry,
and SLAM. Traditional detectors (SIFT, SURF, ORB, BRISK, etc.) and learning
based methods (SuperPoint, R2D2, LF-Net, D2-Net, etc.) have shown strong
performance yet suffer from key limitations: sensitivity to photometric
changes, low keypoint density and repeatability, limited adaptability to
challenging scenes, and lack of semantic understanding, often failing to
prioritize visually important regions. We present DeepDetect, an intelligent,
all-in-one, dense keypoint detector that unifies the strengths of classical
detectors using deep learning. Firstly, we create ground-truth masks by fusing
outputs of 7 keypoint and 2 edge detectors, extracting diverse visual cues from
corners and blobs to prominent edges and textures in the images. Afterwards, a
lightweight and efficient model: ESPNet, is trained using these masks as
labels, enabling DeepDetect to focus semantically on images while producing
highly dense keypoints, that are adaptable to diverse and visually degraded
conditions. Evaluations on the Oxford Affine Covariant Regions dataset
demonstrate that DeepDetect surpasses other detectors in keypoint density,
repeatability, and the number of correct matches, achieving maximum values of
0.5143 (average keypoint density), 0.9582 (average repeatability), and 59,003
(correct matches).

</details>


### [116] [Leveraging AV1 motion vectors for Fast and Dense Feature Matching](https://arxiv.org/abs/2510.17434)
*Julien Zouein,Hossein Javidnia,François Pitié,Anil Kokaram*

Main category: cs.CV

TL;DR: 利用AV1运动向量生成密集亚像素对应关系和余弦一致性过滤的短轨迹，在短视频上性能与顺序SIFT相当但CPU使用更少，在117帧片段中实现0.46-0.62M点重建，重投影误差0.51-0.53像素


<details>
  <summary>Details</summary>
Motivation: 开发资源高效的压缩域对应关系前端，为完整流程提供可扩展的解决方案

Method: 重新利用AV1运动向量生成密集亚像素对应关系，通过余弦一致性过滤短轨迹

Result: 在短视频上运行性能与顺序SIFT相当但CPU使用更少，在117帧片段中成功注册所有图像并重建0.46-0.62M点，重投影误差0.51-0.53像素

Conclusion: 压缩域对应关系是实用且资源高效的前端，具有在完整流程中扩展的清晰路径

Abstract: We repurpose AV1 motion vectors to produce dense sub-pixel correspondences
and short tracks filtered by cosine consistency. On short videos, this
compressed-domain front end runs comparably to sequential SIFT while using far
less CPU, and yields denser matches with competitive pairwise geometry. As a
small SfM demo on a 117-frame clip, MV matches register all images and
reconstruct 0.46-0.62M points at 0.51-0.53,px reprojection error; BA time grows
with match density. These results show compressed-domain correspondences are a
practical, resource-efficient front end with clear paths to scaling in full
pipelines.

</details>


### [117] [Initialize to Generalize: A Stronger Initialization Pipeline for Sparse-View 3DGS](https://arxiv.org/abs/2510.17479)
*Feng Zhou,Wenkai Guo,Pu Cao,Zhicheng Zhang,Jianqin Yin*

Main category: cs.CV

TL;DR: 本文提出了一种改进稀疏视图3D高斯泼溅初始化的方法，通过频率感知SfM、3DGS自初始化和点云正则化来解决稀疏视图下的过拟合问题，在LLFF和Mip-NeRF360数据集上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 稀疏视图3D高斯泼溅容易对训练视图过拟合，导致新视角渲染出现模糊等伪影。先前工作主要通过增强初始化或添加训练时约束来解决，但本文通过控制实验发现初始化是决定性因素，因此专注于改进初始化策略。

Method: 1) 频率感知SfM：通过低频视图增强和宽松多视图对应关系改进低纹理区域覆盖；2) 3DGS自初始化：将光度监督提升为额外点，用学习的高斯中心补偿SfM稀疏区域；3) 点云正则化：通过简单几何/可见性先验强制多视图一致性和均匀空间覆盖。

Result: 在LLFF和Mip-NeRF360数据集上的实验表明，该方法在稀疏视图设置下取得了持续的性能提升，证明了其作为更强初始化策略的有效性。

Conclusion: 初始化是稀疏视图3D高斯泼溅的决定性因素，本文提出的综合初始化方法通过改进SfM覆盖、自初始化和点云正则化，显著提升了稀疏视图3D重建的性能。

Abstract: Sparse-view 3D Gaussian Splatting (3DGS) often overfits to the training
views, leading to artifacts like blurring in novel view rendering. Prior work
addresses it either by enhancing the initialization (\emph{i.e.}, the point
cloud from Structure-from-Motion (SfM)) or by adding training-time constraints
(regularization) to the 3DGS optimization. Yet our controlled ablations reveal
that initialization is the decisive factor: it determines the attainable
performance band in sparse-view 3DGS, while training-time constraints yield
only modest within-band improvements at extra cost. Given initialization's
primacy, we focus our design there. Although SfM performs poorly under sparse
views due to its reliance on feature matching, it still provides reliable seed
points. Thus, building on SfM, our effort aims to supplement the regions it
fails to cover as comprehensively as possible. Specifically, we design: (i)
frequency-aware SfM that improves low-texture coverage via low-frequency view
augmentation and relaxed multi-view correspondences; (ii) 3DGS
self-initialization that lifts photometric supervision into additional points,
compensating SfM-sparse regions with learned Gaussian centers; and (iii)
point-cloud regularization that enforces multi-view consistency and uniform
spatial coverage through simple geometric/visibility priors, yielding a clean
and reliable point cloud. Our experiments on LLFF and Mip-NeRF360 demonstrate
consistent gains in sparse-view settings, establishing our approach as a
stronger initialization strategy. Code is available at
https://github.com/zss171999645/ItG-GS.

</details>


### [118] [SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries](https://arxiv.org/abs/2510.17482)
*Chenxu Dang,Haiyan Liu,Guangjun Bao,Pei An,Xinyue Tang,Jie Ma,Bingchuan Sun,Yan Wang*

Main category: cs.CV

TL;DR: SparseWorld是一个新颖的4D占用世界模型，通过稀疏动态查询实现灵活、自适应和高效的场景感知与预测。


<details>
  <summary>Details</summary>
Motivation: 现有占用世界模型依赖静态固定嵌入或网格，限制了感知灵活性，且基于网格的"原位分类"与真实场景的动态连续性存在潜在不匹配。

Method: 提出范围自适应感知模块，通过可学习查询结合车辆状态调制和时空关联实现扩展范围感知；设计状态条件预测模块，用回归引导公式替代基于分类的预测；采用时间感知自调度训练策略。

Result: 在感知、预测和规划任务上达到最先进性能，验证了模型在灵活性、适应性和效率方面的优势。

Conclusion: SparseWorld通过稀疏动态查询成功解决了现有占用世界模型的局限性，为4D环境建模提供了更灵活高效的解决方案。

Abstract: Semantic occupancy has emerged as a powerful representation in world models
for its ability to capture rich spatial semantics. However, most existing
occupancy world models rely on static and fixed embeddings or grids, which
inherently limit the flexibility of perception. Moreover, their ``in-place
classification" over grids exhibits a potential misalignment with the dynamic
and continuous nature of real scenarios.In this paper, we propose SparseWorld,
a novel 4D occupancy world model that is flexible, adaptive, and efficient,
powered by sparse and dynamic queries. We propose a Range-Adaptive Perception
module, in which learnable queries are modulated by the ego vehicle states and
enriched with temporal-spatial associations to enable extended-range
perception. To effectively capture the dynamics of the scene, we design a
State-Conditioned Forecasting module, which replaces classification-based
forecasting with regression-guided formulation, precisely aligning the dynamic
queries with the continuity of the 4D environment. In addition, We specifically
devise a Temporal-Aware Self-Scheduling training strategy to enable smooth and
efficient training. Extensive experiments demonstrate that SparseWorld achieves
state-of-the-art performance across perception, forecasting, and planning
tasks. Comprehensive visualizations and ablation studies further validate the
advantages of SparseWorld in terms of flexibility, adaptability, and
efficiency. The code is available at https://github.com/MSunDYY/SparseWorld.

</details>


### [119] [Split-Fuse-Transport: Annotation-Free Saliency via Dual Clustering and Optimal Transport Alignment](https://arxiv.org/abs/2510.17484)
*Muhammad Umer Ramzan,Ali Zia,Abdelwahed Khamis,Noman Ali,Usman Ali,Wei Xiang*

Main category: cs.CV

TL;DR: POTNet通过熵引导的双聚类头和最优传输技术，在无监督显著目标检测中生成高质量伪掩码，AutoSOD管道无需像素级标签即可达到接近监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 显著目标检测作为计算机视觉基础任务，作者认为在获得可靠伪掩码的情况下，无需像素级标签也能达到接近监督方法的精度。现有原型方法存在边界和内部像素几何特性差异以及最优传输利用不足的问题。

Method: 提出POTNet，改进原型最优传输方法：使用熵引导的双聚类头（高熵像素用谱聚类，低熵像素用k-means），通过最优传输对齐两个原型集，在单次前向传播中生成更清晰的伪掩码。基于此构建AutoSOD端到端无监督管道。

Result: 在五个基准测试上，AutoSOD在F-measure指标上比无监督方法提升26%，比弱监督方法提升36%，进一步缩小了与全监督模型的差距。

Conclusion: POTNet的双聚类设计和最优传输对齐能够生成高质量的伪掩码，AutoSOD证明了无监督显著目标检测可以达到接近监督方法的性能，同时提高了训练效率。

Abstract: Salient object detection (SOD) aims to segment visually prominent regions in
images and serves as a foundational task for various computer vision
applications. We posit that SOD can now reach near-supervised accuracy without
a single pixel-level label, but only when reliable pseudo-masks are available.
We revisit the prototype-based line of work and make two key observations.
First, boundary pixels and interior pixels obey markedly different geometry;
second, the global consistency enforced by optimal transport (OT) is
underutilized if prototype quality is weak. To address this, we introduce
POTNet, an adaptation of Prototypical Optimal Transport that replaces POT's
single k-means step with an entropy-guided dual-clustering head: high-entropy
pixels are organized by spectral clustering, low-entropy pixels by k-means, and
the two prototype sets are subsequently aligned by OT. This
split-fuse-transport design yields sharper, part-aware pseudo-masks in a single
forward pass, without handcrafted priors. Those masks supervise a standard
MaskFormer-style encoder-decoder, giving rise to AutoSOD, an end-to-end
unsupervised SOD pipeline that eliminates SelfMask's offline voting yet
improves both accuracy and training efficiency. Extensive experiments on five
benchmarks show that AutoSOD outperforms unsupervised methods by up to 26% and
weakly supervised methods by up to 36% in F-measure, further narrowing the gap
to fully supervised models.

</details>


### [120] [Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization](https://arxiv.org/abs/2510.17501)
*Yuanli Wu,Long Zhang,Yue Du,Bin Li*

Main category: cs.CV

TL;DR: 提出了一种基于评分准则和伪标签的零样本视频摘要框架，通过将少量真实标注转化为高质量伪标签，构建数据集自适应的评分准则来指导可解释的场景评估，在无需参数调优的情况下实现局部显著性和全局连贯性的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有监督方法标注成本高且跨数据集泛化能力有限，无监督方法难以捕捉高层次语义和细粒度叙事线索，零样本方法对人工提示模板敏感且依赖数据集特定的分数归一化。

Method: 使用评分准则引导的伪标签提示框架，将少量真实标注转化为高置信度伪标签，构建结构化评分准则；推理时首尾片段仅基于描述评分，中间片段结合相邻场景的上下文摘要来评估叙事进展和冗余。

Result: 在SumMe和TVSum数据集上分别达到57.58和63.05的F1分数，超越了无监督和先前零样本基线方法，接近监督方法的性能。

Conclusion: 评分准则引导的伪标签方法有效稳定了基于LLM的评分，为视频摘要建立了一个通用、可解释的零样本范式。

Abstract: With the rapid proliferation of video content across social media,
surveillance, and education platforms, efficiently summarizing long videos into
concise yet semantically faithful surrogates has become increasingly vital.
Existing supervised methods achieve strong in-domain accuracy by learning from
dense annotations but suffer from high labeling costs and limited cross-dataset
generalization, while unsupervised approaches, though label-free, often fail to
capture high-level human semantics and fine-grained narrative cues. More
recently, zero-shot prompting pipelines have leveraged large language models
(LLMs) for training-free video summarization, yet remain highly sensitive to
handcrafted prompt templates and dataset-specific score normalization. To
overcome these limitations, we introduce a rubric-guided, pseudo-labeled
prompting framework that transforms a small subset of ground-truth annotations
into high-confidence pseudo labels, which are aggregated into structured,
dataset-adaptive scoring rubrics guiding interpretable scene evaluation. During
inference, first and last segments are scored based solely on their
descriptions, whereas intermediate ones incorporate brief contextual summaries
of adjacent scenes to assess narrative progression and redundancy. This
contextual prompting enables the LLM to balance local salience and global
coherence without parameter tuning. On SumMe and TVSum, our method achieves F1
scores of \textbf{57.58} and \textbf{63.05}, surpassing unsupervised and prior
zero-shot baselines while approaching supervised performance. The results
demonstrate that rubric-guided pseudo labeling effectively stabilizes LLM-based
scoring and establishes a general, interpretable zero-shot paradigm for video
summarization.

</details>


### [121] [MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models](https://arxiv.org/abs/2510.17519)
*Yongshun Zhang,Zhongyi Fan,Yonghang Zhang,Zhangzikang Li,Weifeng Chen,Zhongwei Feng,Chaoyue Wang,Peng Hou,Anxiang Zeng*

Main category: cs.CV

TL;DR: 本文提出了一个针对大规模视频生成模型的训练框架，通过优化数据处理、模型架构、训练策略和基础设施四个支柱，显著提升了训练效率和性能。最终模型MUG-V 10B在整体性能上达到最新水平，在电商视频生成任务上超越开源基线。


<details>
  <summary>Details</summary>
Motivation: 训练大规模视频生成模型面临跨模态文本-视频对齐、长序列处理和复杂时空依赖等挑战，需要解决资源密集和效率低下的问题。

Method: 优化四个支柱：数据处理、模型架构、训练策略和基础设施，包括数据预处理、视频压缩、参数缩放、课程式预训练和对齐导向的后训练。

Result: MUG-V 10B模型在整体性能上匹配最新视频生成器，在电商视频生成任务上通过人工评估超越领先开源基线。

Conclusion: 成功开发了高效的大规模视频生成训练框架，并开源了完整技术栈，包括模型权重、基于Megatron-Core的大规模训练代码和推理流水线。

Abstract: In recent years, large-scale generative models for visual content
(\textit{e.g.,} images, videos, and 3D objects/scenes) have made remarkable
progress. However, training large-scale video generation models remains
particularly challenging and resource-intensive due to cross-modal text-video
alignment, the long sequences involved, and the complex spatiotemporal
dependencies. To address these challenges, we present a training framework that
optimizes four pillars: (i) data processing, (ii) model architecture, (iii)
training strategy, and (iv) infrastructure for large-scale video generation
models. These optimizations delivered significant efficiency gains and
performance improvements across all stages of data preprocessing, video
compression, parameter scaling, curriculum-based pretraining, and
alignment-focused post-training. Our resulting model, MUG-V 10B, matches recent
state-of-the-art video generators overall and, on e-commerce-oriented video
generation tasks, surpasses leading open-source baselines in human evaluations.
More importantly, we open-source the complete stack, including model weights,
Megatron-Core-based large-scale training code, and inference pipelines for
video generation and enhancement. To our knowledge, this is the first public
release of large-scale video generation training code that exploits
Megatron-Core to achieve high training efficiency and near-linear multi-node
scaling, details are available in
\href{https://github.com/Shopee-MUG/MUG-V}{our webpage}.

</details>


### [122] [MambaX-Net: Dual-Input Mamba-Enhanced Cross-Attention Network for Longitudinal MRI Segmentation](https://arxiv.org/abs/2510.17529)
*Yovin Yahathugoda,Davide Prezzi,Piyalitt Ittichaiwong,Vicky Goh,Sebastien Ourselin,Michela Antonelli*

Main category: cs.CV

TL;DR: MambaX-Net是一种新颖的半监督双扫描3D分割架构，用于前列腺癌主动监测中的纵向MRI分割，通过利用先前时间点的MRI和分割掩码来改进当前时间点的分割精度。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习分割模型在纵向主动监测分析中的局限性，这些模型通常基于单时间点和专家标注数据训练，无法有效处理多时间点和专家标注稀缺的情况。

Method: 提出MambaX-Net架构，包含Mamba增强的交叉注意力模块和形状提取器模块，采用半监督自训练策略利用预训练nnU-Net生成的伪标签进行学习。

Result: 在纵向主动监测数据集上的评估显示，MambaX-Net显著优于最先进的U-Net和Transformer模型，即使在有限和噪声数据下也能实现优越的前列腺区域分割。

Conclusion: MambaX-Net为前列腺癌主动监测提供了一种有效的纵向分割解决方案，能够克服专家标注稀缺的挑战，实现准确的前列腺区域分割。

Abstract: Active Surveillance (AS) is a treatment option for managing low and
intermediate-risk prostate cancer (PCa), aiming to avoid overtreatment while
monitoring disease progression through serial MRI and clinical follow-up.
Accurate prostate segmentation is an important preliminary step for automating
this process, enabling automated detection and diagnosis of PCa. However,
existing deep-learning segmentation models are often trained on
single-time-point and expertly annotated datasets, making them unsuitable for
longitudinal AS analysis, where multiple time points and a scarcity of expert
labels hinder their effective fine-tuning. To address these challenges, we
propose MambaX-Net, a novel semi-supervised, dual-scan 3D segmentation
architecture that computes the segmentation for time point t by leveraging the
MRI and the corresponding segmentation mask from the previous time point. We
introduce two new components: (i) a Mamba-enhanced Cross-Attention Module,
which integrates the Mamba block into cross attention to efficiently capture
temporal evolution and long-range spatial dependencies, and (ii) a Shape
Extractor Module that encodes the previous segmentation mask into a latent
anatomical representation for refined zone delination. Moreover, we introduce a
semi-supervised self-training strategy that leverages pseudo-labels generated
from a pre-trained nnU-Net, enabling effective learning without expert
annotations. MambaX-Net was evaluated on a longitudinal AS dataset, and results
showed that it significantly outperforms state-of-the-art U-Net and
Transformer-based models, achieving superior prostate zone segmentation even
when trained on limited and noisy data.

</details>


### [123] [WP-CrackNet: A Collaborative Adversarial Learning Framework for End-to-End Weakly-Supervised Road Crack Detection](https://arxiv.org/abs/2510.17566)
*Nachuan Ma,Zhengfei Song,Qiang Hu,Xiaoyu Tang,Chengxi Zhang,Rui Fan,Lihua Xie*

Main category: cs.CV

TL;DR: WP-CrackNet是一种弱监督的道路裂缝检测方法，仅使用图像级标签进行像素级检测。该方法通过分类器、重构器和检测器的对抗学习，结合路径感知注意力模块和中心增强CAM一致性模块，在减少标注成本的同时实现与监督方法相当的检测性能。


<details>
  <summary>Details</summary>
Motivation: 为了减少对昂贵像素级标注的依赖，推动智能城市基础设施维护的可扩展性，作者提出了一种仅需图像级标签的弱监督道路裂缝检测方法。

Method: WP-CrackNet包含三个组件：生成类激活图的分类器、测量特征可推断性的重构器、以及产生像素级检测结果的检测器。通过对抗学习使裂缝CAM覆盖完整裂缝区域，检测器从后处理的CAM伪标签中学习。还设计了路径感知注意力模块和中心增强CAM一致性模块来提升性能。

Result: 在三个自建图像级数据集上的广泛实验表明，WP-CrackNet实现了与监督方法相当的结果，并优于现有的弱监督方法，显著推进了可扩展道路检测。

Conclusion: WP-CrackNet通过弱监督学习有效降低了道路裂缝检测的标注成本，同时保持了高检测精度，为智能基础设施维护提供了可扩展的解决方案。

Abstract: Road crack detection is essential for intelligent infrastructure maintenance
in smart cities. To reduce reliance on costly pixel-level annotations, we
propose WP-CrackNet, an end-to-end weakly-supervised method that trains with
only image-level labels for pixel-wise crack detection. WP-CrackNet integrates
three components: a classifier generating class activation maps (CAMs), a
reconstructor measuring feature inferability, and a detector producing
pixel-wise road crack detection results. During training, the classifier and
reconstructor alternate in adversarial learning to encourage crack CAMs to
cover complete crack regions, while the detector learns from pseudo labels
derived from post-processed crack CAMs. This mutual feedback among the three
components improves learning stability and detection accuracy. To further boost
detection performance, we design a path-aware attention module (PAAM) that
fuses high-level semantics from the classifier with low-level structural cues
from the reconstructor by modeling spatial and channel-wise dependencies.
Additionally, a center-enhanced CAM consistency module (CECCM) is proposed to
refine crack CAMs using center Gaussian weighting and consistency constraints,
enabling better pseudo-label generation. We create three image-level datasets
and extensive experiments show that WP-CrackNet achieves comparable results to
supervised methods and outperforms existing weakly-supervised methods,
significantly advancing scalable road inspection. The source code package and
datasets are available at https://mias.group/WP-CrackNet/.

</details>


### [124] [PAGE-4D: Disentangled Pose and Geometry Estimation for 4D Perception](https://arxiv.org/abs/2510.17568)
*Kaichen Zhou,Yuhan Wang,Grace Chen,Xinhai Chang,Gaspard Beaudouin,Fangneng Zhan,Paul Pu Liang,Mengyu Wang*

Main category: cs.CV

TL;DR: PAGE-4D是一个前馈模型，扩展了VGGT以处理动态场景，能够在无需后处理的情况下进行相机姿态估计、深度预测和点云重建。


<details>
  <summary>Details</summary>
Motivation: 现有的3D前馈模型（如VGGT）在静态数据集上训练，但在涉及复杂动态元素（如移动人物或可变形物体）的真实场景中表现不佳。

Method: 提出动态感知聚合器，通过预测动态感知掩码来分离静态和动态信息——在姿态估计时抑制运动线索，在几何重建时增强它们。

Result: 大量实验表明，PAGE-4D在动态场景中始终优于原始VGGT，在相机姿态估计、单目和视频深度估计以及密集点图重建方面取得了优异结果。

Conclusion: PAGE-4D成功解决了多任务4D重建中的任务冲突问题，通过动态感知机制在动态场景中实现了更好的性能。

Abstract: Recent 3D feed-forward models, such as the Visual Geometry Grounded
Transformer (VGGT), have shown strong capability in inferring 3D attributes of
static scenes. However, since they are typically trained on static datasets,
these models often struggle in real-world scenarios involving complex dynamic
elements, such as moving humans or deformable objects like umbrellas. To
address this limitation, we introduce PAGE-4D, a feedforward model that extends
VGGT to dynamic scenes, enabling camera pose estimation, depth prediction, and
point cloud reconstruction -- all without post-processing. A central challenge
in multi-task 4D reconstruction is the inherent conflict between tasks:
accurate camera pose estimation requires suppressing dynamic regions, while
geometry reconstruction requires modeling them. To resolve this tension, we
propose a dynamics-aware aggregator that disentangles static and dynamic
information by predicting a dynamics-aware mask -- suppressing motion cues for
pose estimation while amplifying them for geometry reconstruction. Extensive
experiments show that PAGE-4D consistently outperforms the original VGGT in
dynamic scenarios, achieving superior results in camera pose estimation,
monocular and video depth estimation, and dense point map reconstruction.

</details>


### [125] [Integrating BIM and UAV-based photogrammetry for Automated 3D Structure Model Segmentation](https://arxiv.org/abs/2510.17609)
*Siqi Chen,Shanyue Guan*

Main category: cs.CV

TL;DR: 提出基于机器学习的自动化3D点云分割框架，结合无人机扫描的真实点云和BIM生成的合成数据，用于基础设施结构健康监测中的组件分割。


<details>
  <summary>Details</summary>
Motivation: 解决传统依赖耗时且易出错的人工标注方法来分割3D模型中特定结构组件的问题，提高基础设施监测的精度和效率。

Method: 利用无人机扫描的真实点云和BIM生成的合成数据的互补优势，开发机器学习框架进行自动化3D点云分割。

Result: 在铁路轨道数据集验证中，能够高精度识别和分割主要组件（如铁轨和枕木），使用小规模数据集结合BIM数据显著减少训练时间并保持合理分割精度。

Conclusion: 该自动化方法提高了3D基础设施模型分割的精度和效率，推动了无人机和BIM技术在结构健康监测和基础设施管理中的集成应用。

Abstract: The advancement of UAV technology has enabled efficient, non-contact
structural health monitoring. Combined with photogrammetry, UAVs can capture
high-resolution scans and reconstruct detailed 3D models of infrastructure.
However, a key challenge remains in segmenting specific structural components
from these models-a process traditionally reliant on time-consuming and
error-prone manual labeling. To address this issue, we propose a machine
learning-based framework for automated segmentation of 3D point clouds. Our
approach uses the complementary strengths of real-world UAV-scanned point
clouds and synthetic data generated from Building Information Modeling (BIM) to
overcome the limitations associated with manual labeling. Validation on a
railroad track dataset demonstrated high accuracy in identifying and segmenting
major components such as rails and crossties. Moreover, by using smaller-scale
datasets supplemented with BIM data, the framework significantly reduced
training time while maintaining reasonable segmentation accuracy. This
automated approach improves the precision and efficiency of 3D infrastructure
model segmentation and advances the integration of UAV and BIM technologies in
structural health monitoring and infrastructure management.

</details>


### [126] [One Dinomaly2 Detect Them All: A Unified Framework for Full-Spectrum Unsupervised Anomaly Detection](https://arxiv.org/abs/2510.17611)
*Jia Guo,Shuai Lu,Lei Fan,Zelin Li,Donglin Di,Yang Song,Weihang Zhang,Wenbing Zhu,Hong Yan,Fang Chen,Huiqi Li,Hongen Liao*

Main category: cs.CV

TL;DR: Dinomaly2是一个统一的图像无监督异常检测框架，通过五个简单元素的组合在多类模型上实现卓越性能，并扩展到多种数据模态和任务设置。


<details>
  <summary>Details</summary>
Motivation: 现有多类异常检测模型性能显著落后于单类模型，且领域分裂为针对特定场景的专门方法，需要统一的解决方案。

Method: 采用"少即是多"理念，在标准重建框架中协调五个简单元素，实现方法极简主义，无需修改即可自然扩展到不同任务。

Result: 在12个异常检测基准测试中表现优异，多类模型在MVTec-AD和VisA上分别达到99.9%和99.3%的图像级AUROC；仅用每类8个正常样本即可超越之前的全样本模型。

Conclusion: Dinomaly2通过极简设计、计算可扩展性和通用适用性，成为现实世界异常检测应用的统一解决方案。

Abstract: Unsupervised anomaly detection (UAD) has evolved from building specialized
single-class models to unified multi-class models, yet existing multi-class
models significantly underperform the most advanced one-for-one counterparts.
Moreover, the field has fragmented into specialized methods tailored to
specific scenarios (multi-class, 3D, few-shot, etc.), creating deployment
barriers and highlighting the need for a unified solution. In this paper, we
present Dinomaly2, the first unified framework for full-spectrum image UAD,
which bridges the performance gap in multi-class models while seamlessly
extending across diverse data modalities and task settings. Guided by the "less
is more" philosophy, we demonstrate that the orchestration of five simple
element achieves superior performance in a standard reconstruction-based
framework. This methodological minimalism enables natural extension across
diverse tasks without modification, establishing that simplicity is the
foundation of true universality. Extensive experiments on 12 UAD benchmarks
demonstrate Dinomaly2's full-spectrum superiority across multiple modalities
(2D, multi-view, RGB-3D, RGB-IR), task settings (single-class, multi-class,
inference-unified multi-class, few-shot) and application domains (industrial,
biological, outdoor). For example, our multi-class model achieves unprecedented
99.9% and 99.3% image-level (I-) AUROC on MVTec-AD and VisA respectively. For
multi-view and multi-modal inspection, Dinomaly2 demonstrates state-of-the-art
performance with minimum adaptations. Moreover, using only 8 normal examples
per class, our method surpasses previous full-shot models, achieving 98.7% and
97.4% I-AUROC on MVTec-AD and VisA. The combination of minimalistic design,
computational scalability, and universal applicability positions Dinomaly2 as a
unified solution for the full spectrum of real-world anomaly detection
applications.

</details>


### [127] [4DSegStreamer: Streaming 4D Panoptic Segmentation via Dual Threads](https://arxiv.org/abs/2510.17664)
*Ling Liu,Jun Tian,Li Yi*

Main category: cs.CV

TL;DR: 4DSegStreamer是一个用于4D全景分割的流式处理框架，采用双线程系统处理动态环境中的实时感知，可集成到现有3D/4D分割方法中，在室内外数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决高度动态环境（如人群疏散、自动驾驶）中需要实时、细粒度感知的问题，在有限时间预算内实现4D全景分割。

Method: 采用双线程系统：预测线程利用历史运动和几何信息提取特征并预测未来动态；推理线程通过对齐最新内存并补偿自运动和动态物体移动来确保对输入帧的及时预测。

Result: 在室内HOI4D数据集和室外SemanticKITTI、nuScenes数据集上的综合实验证明了方法的有效性，特别是在复杂场景中准确预测动态物体方面表现突出。

Conclusion: 4DSegStreamer是一个通用且鲁棒的流式处理框架，能够有效处理高FPS条件下的4D全景分割任务，为动态环境中的实时感知提供了可行解决方案。

Abstract: 4D panoptic segmentation in a streaming setting is critical for highly
dynamic environments, such as evacuating dense crowds and autonomous driving in
complex scenarios, where real-time, fine-grained perception within a
constrained time budget is essential. In this paper, we introduce
4DSegStreamer, a novel framework that employs a Dual-Thread System to
efficiently process streaming frames. The framework is general and can be
seamlessly integrated into existing 3D and 4D segmentation methods to enable
real-time capability. It also demonstrates superior robustness compared to
existing streaming perception approaches, particularly under high FPS
conditions. The system consists of a predictive thread and an inference thread.
The predictive thread leverages historical motion and geometric information to
extract features and forecast future dynamics. The inference thread ensures
timely prediction for incoming frames by aligning with the latest memory and
compensating for ego-motion and dynamic object movements. We evaluate
4DSegStreamer on the indoor HOI4D dataset and the outdoor SemanticKITTI and
nuScenes datasets. Comprehensive experiments demonstrate the effectiveness of
our approach, particularly in accurately predicting dynamic objects in complex
scenes.

</details>


### [128] [PICABench: How Far Are We from Physically Realistic Image Editing?](https://arxiv.org/abs/2510.17681)
*Yuandong Pu,Le Zhuo,Songhao Han,Jinbo Xing,Kaiwen Zhu,Shuo Cao,Bin Fu,Si Liu,Hongsheng Li,Yu Qiao,Wenlong Zhang,Xi Chen,Yihao Liu*

Main category: cs.CV

TL;DR: 该论文介绍了PICABench基准测试，用于系统评估图像编辑的物理真实性，涵盖光学、力学和状态转换等八个维度，并提出了PICAEval评估协议和PICA-100K训练数据集。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑模型主要关注指令完成度，但忽视了物理效果的真实性，如移除物体时也应移除其阴影、反射和与周围物体的交互。

Method: 提出PICABench基准测试系统评估物理真实性，使用PICAEval评估协议（基于VLM作为评判者），并构建PICA-100K训练数据集从视频中学习物理知识。

Result: 评估主流模型后发现物理真实性仍然是一个具有挑战性的问题，存在很大的改进空间。

Conclusion: 该基准测试和解决方案为未来从简单内容编辑向物理一致性真实感的发展奠定了基础。

Abstract: Image editing has achieved remarkable progress recently. Modern editing
models could already follow complex instructions to manipulate the original
content. However, beyond completing the editing instructions, the accompanying
physical effects are the key to the generation realism. For example, removing
an object should also remove its shadow, reflections, and interactions with
nearby objects. Unfortunately, existing models and benchmarks mainly focus on
instruction completion but overlook these physical effects. So, at this moment,
how far are we from physically realistic image editing? To answer this, we
introduce PICABench, which systematically evaluates physical realism across
eight sub-dimension (spanning optics, mechanics, and state transitions) for
most of the common editing operations (add, remove, attribute change, etc). We
further propose the PICAEval, a reliable evaluation protocol that uses
VLM-as-a-judge with per-case, region-level human annotations and questions.
Beyond benchmarking, we also explore effective solutions by learning physics
from videos and construct a training dataset PICA-100K. After evaluating most
of the mainstream models, we observe that physical realism remains a
challenging problem with large rooms to explore. We hope that our benchmark and
proposed solutions can serve as a foundation for future work moving from naive
content editing toward physically consistent realism.

</details>


### [129] [Intelligent Communication Mixture-of-Experts Boosted-Medical Image Segmentation Foundation Model](https://arxiv.org/abs/2510.17684)
*Xinwei Zhang,Hu Chen,Zhe Yuan,Sukun Tian,Peng Feng*

Main category: cs.CV

TL;DR: IC-MoE是一个用于医学图像分割的智能通信混合专家模型，通过构建三种专家类型和像素概率自适应投票策略，增强高层特征表示能力，同时保持预训练权重的结构完整性。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割基础模型在自适应微调时存在两个关键问题：高层特征表示不足，以及微调过程破坏预训练权重的结构完整性。

Method: 1) 构建基础专家、语义专家和自适应专家，采用像素概率自适应投票策略进行专家选择和融合；2) 提出语义引导的对比学习方法解决对比学习中弱监督问题。

Result: 在三个公共医学图像分割数据集上的广泛实验表明，IC-MoE优于其他最先进模型，有效补充了基础医学图像分割模型的高层特征和预训练结构完整性。

Conclusion: IC-MoE在保持预训练权重结构完整性的同时，显著增强了高层特征表示能力，并在多样医学图像分割场景中展现出优异的泛化能力。

Abstract: Foundation models for medical image segmentation have achieved remarkable
performance. Adaptive fine-tuning of natural image segmentation foundation
models is crucial for medical image segmentation tasks. However, some
limitations exist in existing fine-tuning methods: 1) insufficient
representation of high-level features and 2) the fine-tuning process disrupts
the structural integrity of pretrained weights. Inspired by these critical
problems, we propose an intelligent communication mixture-of-experts
boosted-medical image segmentation foundation model, named IC-MoE, with twofold
ideas: 1) We construct basic experts, semantic experts, and adaptive experts.
Moreover, we implement a pixel probability adaptive voting strategy, which
enables expert selection and fusion through label consistency and load
balancing. This approach preliminarily enhances the representation capability
of high-level features while preserving the structural integrity of pretrained
weights. 2) We propose a semantic-guided contrastive learning method to address
the issue of weak supervision in contrastive learning. This method further
enhances the representation capability of high-level features while preserving
the structural integrity of pretrained weights. Extensive experiments across
three public medical image segmentation datasets demonstrate that the IC-MoE
outperforms other SOTA models. Consequently, the proposed IC-MoE effectively
supplements foundational medical image segmentation models with high-level
features and pretrained structural integrity. We also validate the superior
generalizability of the IC-MoE across diverse medical image segmentation
scenarios.

</details>


### [130] [Multilingual Text-to-Image Person Retrieval via Bidirectional Relation Reasoning and Aligning](https://arxiv.org/abs/2510.17685)
*Min Cao,Xinyu Zhou,Ding Jiang,Bo Du,Mang Ye,Min Zhang*

Main category: cs.CV

TL;DR: 本文提出了一个多语言文本到图像人物检索任务，开发了多语言TIPR基准，并提出了Bi-IRRA框架，通过双向隐式关系推理和多维全局对齐来解决模态异质性问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像人物检索方法面临模态异质性问题，全局方法忽略细粒度差异，局部方法需要先验信息，且当前方法主要针对英语，限制了在多语言环境中的应用。

Method: 提出Bi-IRRA框架，包含双向隐式关系推理模块（通过掩码图像和文本的双向预测增强跨语言和跨模态的局部关系建模）和多维全局对齐模块（桥接模态异质性）。

Result: 该方法在所有多语言TIPR数据集上取得了新的最先进结果。

Conclusion: Bi-IRRA框架有效解决了多语言文本到图像人物检索中的模态异质性问题，为多语言环境下的跨模态检索提供了有效解决方案。

Abstract: Text-to-image person retrieval (TIPR) aims to identify the target person
using textual descriptions, facing challenge in modality heterogeneity. Prior
works have attempted to address it by developing cross-modal global or local
alignment strategies. However, global methods typically overlook fine-grained
cross-modal differences, whereas local methods require prior information to
explore explicit part alignments. Additionally, current methods are
English-centric, restricting their application in multilingual contexts. To
alleviate these issues, we pioneer a multilingual TIPR task by developing a
multilingual TIPR benchmark, for which we leverage large language models for
initial translations and refine them by integrating domain-specific knowledge.
Correspondingly, we propose Bi-IRRA: a Bidirectional Implicit Relation
Reasoning and Aligning framework to learn alignment across languages and
modalities. Within Bi-IRRA, a bidirectional implicit relation reasoning module
enables bidirectional prediction of masked image and text, implicitly enhancing
the modeling of local relations across languages and modalities, a
multi-dimensional global alignment module is integrated to bridge the modality
heterogeneity. The proposed method achieves new state-of-the-art results on all
multilingual TIPR datasets. Data and code are presented in
https://github.com/Flame-Chasers/Bi-IRRA.

</details>


### [131] [Towards 3D Objectness Learning in an Open World](https://arxiv.org/abs/2510.17686)
*Taichi Liu,Zhenyu Wang,Ruofeng Liu,Guang Wang,Desheng Zhang*

Main category: cs.CV

TL;DR: OP3Det是一个无需文本提示的开放世界3D检测器，通过结合2D语义先验和3D几何先验，利用跨模态专家混合实现通用3D物体性学习，在开放世界场景中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统闭集3D检测器难以泛化到开放世界场景，而直接应用3D开放词汇模型存在词汇扩展和语义重叠问题，需要研究学习通用3D物体性的方法。

Method: 提出OP3Det，利用2D基础模型的强泛化能力和零样本能力，结合2D语义先验和3D几何先验生成类别无关的候选区域，通过点云和RGB图像的跨模态专家混合动态路由单模态和多模态特征。

Result: OP3Det在AR指标上比现有开放世界3D检测器提升高达16.0%，比闭集3D检测器提升13.5%，表现出卓越性能。

Conclusion: OP3Det通过有效结合2D和3D先验知识，实现了无需文本提示的开放世界3D物体检测，在通用3D物体性学习方面取得显著进展。

Abstract: Recent advancements in 3D object detection and novel category detection have
made significant progress, yet research on learning generalized 3D objectness
remains insufficient. In this paper, we delve into learning open-world 3D
objectness, which focuses on detecting all objects in a 3D scene, including
novel objects unseen during training. Traditional closed-set 3D detectors
struggle to generalize to open-world scenarios, while directly incorporating 3D
open-vocabulary models for open-world ability struggles with vocabulary
expansion and semantic overlap. To achieve generalized 3D object discovery, We
propose OP3Det, a class-agnostic Open-World Prompt-free 3D Detector to detect
any objects within 3D scenes without relying on hand-crafted text prompts. We
introduce the strong generalization and zero-shot capabilities of 2D foundation
models, utilizing both 2D semantic priors and 3D geometric priors for
class-agnostic proposals to broaden 3D object discovery. Then, by integrating
complementary information from point cloud and RGB image in the cross-modal
mixture of experts, OP3Det dynamically routes uni-modal and multi-modal
features to learn generalized 3D objectness. Extensive experiments demonstrate
the extraordinary performance of OP3Det, which significantly surpasses existing
open-world 3D detectors by up to 16.0% in AR and achieves a 13.5% improvement
compared to closed-world 3D detectors.

</details>


### [132] [GAS: Improving Discretization of Diffusion ODEs via Generalized Adversarial Solver](https://arxiv.org/abs/2510.17699)
*Aleksandr Oganov,Ilya Bykov,Eva Neudachina,Mishan Aliev,Alexander Tolmachev,Alexander Sidorov,Aleksandr Zuev,Andrey Okhotin,Denis Rakitin,Aibek Alanov*

Main category: cs.CV

TL;DR: 本文提出了一种广义对抗求解器（GAS），通过简单的ODE采样器参数化和对抗训练，在减少扩散模型采样计算成本的同时保持细节保真度。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然生成质量优秀，但采样过程计算成本高昂。现有方法依赖复杂训练技巧且未能明确关注细节保真度。

Method: 提出广义求解器参数化ODE采样器，无需额外训练技巧；结合原始蒸馏损失与对抗训练以减少伪影并增强细节保真度。

Result: 在相似资源约束下，该方法相比现有求解器训练方法表现出更优越的性能。

Conclusion: 广义对抗求解器提供了一种简单有效的解决方案，在减少扩散模型采样计算成本的同时保持了高质量的细节生成。

Abstract: While diffusion models achieve state-of-the-art generation quality, they
still suffer from computationally expensive sampling. Recent works address this
issue with gradient-based optimization methods that distill a few-step ODE
diffusion solver from the full sampling process, reducing the number of
function evaluations from dozens to just a few. However, these approaches often
rely on intricate training techniques and do not explicitly focus on preserving
fine-grained details. In this paper, we introduce the Generalized Solver: a
simple parameterization of the ODE sampler that does not require additional
training tricks and improves quality over existing approaches. We further
combine the original distillation loss with adversarial training, which
mitigates artifacts and enhances detail fidelity. We call the resulting method
the Generalized Adversarial Solver and demonstrate its superior performance
compared to existing solver training methods under similar resource
constraints. Code is available at https://github.com/3145tttt/GAS.

</details>


### [133] [Improving Cross-Patient Generalization in Parkinson's Disease Detection through Chunk-Based Analysis of Hand-Drawn Patterns](https://arxiv.org/abs/2510.17703)
*Mhd Adnan Albani,Riad Sonbol*

Main category: cs.CV

TL;DR: 提出一种两阶段方法用于帕金森病检测：第一阶段按绘图类型分类，第二阶段通过分块策略提取特征并检测帕金森病，使用集成方法合并各块决策，在未见患者数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有帕金森病检测方法的两大局限：数据集不足和处理未见患者数据时的鲁棒性问题。

Method: 采用两阶段方法：绘图类型分类和特征提取检测，使用2x2分块策略分别处理图像块，通过集成方法合并决策。

Result: 在NewHandPD数据集上，对已见患者准确率达97.08%，对未见患者达94.91%，性能差距仅2.17个百分点，优于现有方法。

Conclusion: 所提出的分块策略和集成方法有效提高了帕金森病检测的鲁棒性，特别是在处理未见患者数据时表现优异。

Abstract: Parkinson's disease (PD) is a neurodegenerative disease affecting about 1% of
people over the age of 60, causing motor impairments that impede hand
coordination activities such as writing and drawing. Many approaches have tried
to support early detection of Parkinson's disease based on hand-drawn images;
however, we identified two major limitations in the related works: (1) the lack
of sufficient datasets, (2) the robustness when dealing with unseen patient
data. In this paper, we propose a new approach to detect Parkinson's disease
that consists of two stages: The first stage classifies based on their drawing
type(circle, meander, spiral), and the second stage extracts the required
features from the images and detects Parkinson's disease. We overcame the
previous two limitations by applying a chunking strategy where we divide each
image into 2x2 chunks. Each chunk is processed separately when extracting
features and recognizing Parkinson's disease indicators. To make the final
classification, an ensemble method is used to merge the decisions made from
each chunk. Our evaluation shows that our proposed approach outperforms the top
performing state-of-the-art approaches, in particular on unseen patients. On
the NewHandPD dataset our approach, it achieved 97.08% accuracy for seen
patients and 94.91% for unseen patients, our proposed approach maintained a gap
of only 2.17 percentage points, compared to the 4.76-point drop observed in
prior work.

</details>


### [134] [Raindrop GS: A Benchmark for 3D Gaussian Splatting under Raindrop Conditions](https://arxiv.org/abs/2510.17719)
*Zhiqiang Teng,Beibei Lin,Tingting Chen,Zifeng Yuan,Xuanyi Li,Xuanyu Zhang,Shunli Zhang*

Main category: cs.CV

TL;DR: RaindropGS是一个用于评估3D高斯溅射在雨滴条件下性能的基准测试，针对真实世界中雨滴遮挡和光学扭曲问题，包含数据准备、处理和雨滴感知3DGS评估三个部分。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常使用合成雨滴图像和已知相机位姿，但真实场景中雨滴会干扰相机位姿估计和点云初始化，且合成与真实雨滴存在显著领域差距。

Method: 收集真实世界雨滴重建数据集，包含雨滴聚焦、背景聚焦和无雨地面实况三组对齐图像集，通过完整流程评估不同焦点条件下的重建质量。

Result: 揭示了现有3DGS方法在无约束雨滴图像上的性能限制，以及不同流程组件的影响：相机焦点位置对重建性能的影响，不准确的位姿和点云初始化对重建的干扰。

Conclusion: 为开发在雨滴条件下更鲁棒的3DGS方法提供了明确方向。

Abstract: 3D Gaussian Splatting (3DGS) under raindrop conditions suffers from severe
occlusions and optical distortions caused by raindrop contamination on the
camera lens, substantially degrading reconstruction quality. Existing
benchmarks typically evaluate 3DGS using synthetic raindrop images with known
camera poses (constrained images), assuming ideal conditions. However, in
real-world scenarios, raindrops often interfere with accurate camera pose
estimation and point cloud initialization. Moreover, a significant domain gap
between synthetic and real raindrops further impairs generalization. To tackle
these issues, we introduce RaindropGS, a comprehensive benchmark designed to
evaluate the full 3DGS pipeline-from unconstrained, raindrop-corrupted images
to clear 3DGS reconstructions. Specifically, the whole benchmark pipeline
consists of three parts: data preparation, data processing, and raindrop-aware
3DGS evaluation, including types of raindrop interference, camera pose
estimation and point cloud initialization, single image rain removal
comparison, and 3D Gaussian training comparison. First, we collect a real-world
raindrop reconstruction dataset, in which each scene contains three aligned
image sets: raindrop-focused, background-focused, and rain-free ground truth,
enabling a comprehensive evaluation of reconstruction quality under different
focus conditions. Through comprehensive experiments and analyses, we reveal
critical insights into the performance limitations of existing 3DGS methods on
unconstrained raindrop images and the varying impact of different pipeline
components: the impact of camera focus position on 3DGS reconstruction
performance, and the interference caused by inaccurate pose and point cloud
initialization on reconstruction. These insights establish clear directions for
developing more robust 3DGS methods under raindrop conditions.

</details>


### [135] [MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues](https://arxiv.org/abs/2510.17722)
*Yaning Pan,Zekun Wang,Qianqian Xie,Yongqian Wen,Yuanxing Zhang,Guohui Zhang,Haoxuan Hu,Zhiyu Pan,Yibing Huang,Zhidong Gan,Yonghong Lin,An Ping,Tianhao Peng,Jiaheng Liu*

Main category: cs.CV

TL;DR: MT-Video-Bench是一个用于评估多模态大语言模型在多轮视频对话中能力的基准测试，包含987个精心策划的多轮对话，涵盖六个核心能力维度。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准仅限于单轮问答，无法反映真实场景中多轮对话的复杂性，因此需要开发专门针对多轮视频对话的评估基准。

Method: 引入MT-Video-Bench基准，主要评估感知性和交互性相关的六个核心能力，涵盖多样化领域的多轮对话。

Result: 通过对各种开源和闭源MLLMs的广泛评估，揭示了这些模型在处理多轮视频对话时存在显著的性能差异和局限性。

Conclusion: MT-Video-Bench基准将公开可用，以促进未来在多轮视频对话理解方面的研究。

Abstract: The recent development of Multimodal Large Language Models (MLLMs) has
significantly advanced AI's ability to understand visual modalities. However,
existing evaluation benchmarks remain limited to single-turn question
answering, overlooking the complexity of multi-turn dialogues in real-world
scenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video
understanding benchmark for evaluating MLLMs in multi-turn dialogues.
Specifically, our MT-Video-Bench mainly assesses six core competencies that
focus on perceptivity and interactivity, encompassing 987 meticulously curated
multi-turn dialogues from diverse domains. These capabilities are rigorously
aligned with real-world applications, such as interactive sports analysis and
multi-turn video-based intelligent tutoring. With MT-Video-Bench, we
extensively evaluate various state-of-the-art open-source and closed-source
MLLMs, revealing their significant performance discrepancies and limitations in
handling multi-turn video dialogues. The benchmark will be publicly available
to foster future research.

</details>


### [136] [Signature Forgery Detection: Improving Cross-Dataset Generalization](https://arxiv.org/abs/2510.17724)
*Matheus Ramos Parracho*

Main category: cs.CV

TL;DR: 该研究探索了签名伪造检测的特征学习策略，重点关注提高跨数据集泛化能力。使用三个公共基准数据集，开发了基于原始签名图像和壳预处理两种实验流程，发现原始图像模型表现更好，但壳预处理模型显示出未来改进潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在离线签名验证方面取得了显著进展，但大多数方法在跨数据集泛化方面仍存在困难，因为笔迹风格和采集协议的差异会降低性能。

Method: 使用CEDAR、ICDAR和GPDS Synthetic三个公共基准数据集，开发了两种实验流程：基于原始签名图像的方法和采用壳预处理的方法。

Result: 原始图像模型在跨基准测试中获得了更高的性能，而基于壳预处理的方法显示出未来改进的潜力。

Conclusion: 研究结果表明原始图像方法在当前表现更好，但壳预处理方法为构建稳健的跨域签名验证系统提供了有前景的方向。

Abstract: Automated signature verification is a critical biometric technique used in
banking, identity authentication, and legal documentation. Despite the notable
progress achieved by deep learning methods, most approaches in offline
signature verification still struggle to generalize across datasets, as
variations in handwriting styles and acquisition protocols often degrade
performance. This study investigates feature learning strategies for signature
forgery detection, focusing on improving cross-dataset generalization -- that
is, model robustness when trained on one dataset and tested on another. Using
three public benchmarks -- CEDAR, ICDAR, and GPDS Synthetic -- two experimental
pipelines were developed: one based on raw signature images and another
employing a preprocessing method referred to as shell preprocessing. Several
behavioral patterns were identified and analyzed; however, no definitive
superiority between the two approaches was established. The results show that
the raw-image model achieved higher performance across benchmarks, while the
shell-based model demonstrated promising potential for future refinement toward
robust, cross-domain signature verification.

</details>


### [137] [Can Image-To-Video Models Simulate Pedestrian Dynamics?](https://arxiv.org/abs/2510.17731)
*Aaron Appelle,Jerome P. Lynch*

Main category: cs.CV

TL;DR: 该研究探索了基于扩散变换器的图像到视频模型是否能够生成拥挤公共场景中真实的行人运动模式，通过使用行人轨迹基准中的关键帧作为条件输入，并用量化指标评估其轨迹预测性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是验证当前高性能的图像到视频模型是否具备生成真实行人运动模式的能力，特别是在拥挤公共场景中。这些模型通过大规模视频数据集训练已展现出显著的内在世界建模能力。

Method: 方法框架是将图像到视频模型条件化于从行人轨迹基准中提取的关键帧，然后使用行人动力学的量化指标来评估这些模型的轨迹预测性能。

Result: 论文未提供具体的实验结果数据，但描述了研究框架和评估方法。

Conclusion: 该研究提出了一个评估框架，用于测试扩散变换器模型在生成真实行人运动模式方面的能力，为理解这些模型的世界建模能力提供了新的视角。

Abstract: Recent high-performing image-to-video (I2V) models based on variants of the
diffusion transformer (DiT) have displayed remarkable inherent world-modeling
capabilities by virtue of training on large scale video datasets. We
investigate whether these models can generate realistic pedestrian movement
patterns in crowded public scenes. Our framework conditions I2V models on
keyframes extracted from pedestrian trajectory benchmarks, then evaluates their
trajectory prediction performance using quantitative measures of pedestrian
dynamics.

</details>


### [138] [Joint Multi-Condition Representation Modelling via Matrix Factorisation for Visual Place Recognition](https://arxiv.org/abs/2510.17739)
*Timur Ismagilov,Shakaiba Majeed,Michael Milford,Tan Viet Tuyen Nguyen,Sarvapali D. Ramchurn,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 提出一种无需训练的描述符无关方法，通过矩阵分解将多个参考描述符联合建模为基表示，实现基于投影的残差匹配，在多外观和多视角视觉地点识别中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决多参考视觉地点识别中，现有方法在增加数据多样性和模型复杂度时带来的高计算成本问题，以及描述符级融合方法在多传感器设置或启发式方法下对外观和视角变化的有限改进。

Method: 采用训练自由的描述符无关方法，通过矩阵分解将多个参考描述符联合建模为基表示，实现基于投影的残差匹配。

Result: 在多外观数据上，该方法比单参考方法Recall@1提升约18%，在非结构化数据上获得约5%的增益，在外观和视角变化下均优于多参考基线方法。

Conclusion: 该方法在保持轻量级的同时展现出强大的泛化能力，在多参考视觉地点识别任务中实现了显著性能提升。

Abstract: We address multi-reference visual place recognition (VPR), where reference
sets captured under varying conditions are used to improve localisation
performance. While deep learning with large-scale training improves robustness,
increasing data diversity and model complexity incur extensive computational
cost during training and deployment. Descriptor-level fusion via voting or
aggregation avoids training, but often targets multi-sensor setups or relies on
heuristics with limited gains under appearance and viewpoint change. We propose
a training-free, descriptor-agnostic approach that jointly models places using
multiple reference descriptors via matrix decomposition into basis
representations, enabling projection-based residual matching. We also introduce
SotonMV, a structured benchmark for multi-viewpoint VPR. On multi-appearance
data, our method improves Recall@1 by up to ~18% over single-reference and
outperforms multi-reference baselines across appearance and viewpoint changes,
with gains of ~5% on unstructured data, demonstrating strong generalisation
while remaining lightweight.

</details>


### [139] [Towards Explainable Skin Cancer Classification: A Dual-Network Attention Model with Lesion Segmentation and Clinical Metadata Fusion](https://arxiv.org/abs/2510.17773)
*Md. Enamul Atiq,Shaikh Anowarul Fattah*

Main category: cs.CV

TL;DR: 提出一种基于双编码器注意力框架的皮肤病变分类方法，结合分割病变和临床元数据，提高分类准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌早期检测对患者预后至关重要，但现有深度学习模型存在"黑箱"问题，限制了临床信任。需要开发既能提高准确性又能增强可解释性的方法。

Method: 使用带有双注意力门和空洞空间金字塔池化的Deep-UNet进行病变分割，然后采用双DenseNet201编码器分别处理原始图像和分割病变，通过多头交叉注意力融合特征，并集成基于transformer的患者元数据模块。

Result: 在HAM10000数据集和ISIC 2018、2019挑战中，该方法实现了最先进的分割性能，显著提高了分类准确率和平均AUC。Grad-CAM热图验证了模型基于病变区域进行预测的可靠性。

Conclusion: 将精确的病变分割和临床数据与基于注意力的融合相结合，可以构建更准确和可解释的皮肤癌分类模型。

Abstract: Skin cancer is a life-threatening disease where early detection significantly
improves patient outcomes. Automated diagnosis from dermoscopic images is
challenging due to high intra-class variability and subtle inter-class
differences. Many deep learning models operate as "black boxes," limiting
clinical trust. In this work, we propose a dual-encoder attention-based
framework that leverages both segmented lesions and clinical metadata to
enhance skin lesion classification in terms of both accuracy and
interpretability. A novel Deep-UNet architecture with Dual Attention Gates
(DAG) and Atrous Spatial Pyramid Pooling (ASPP) is first employed to segment
lesions. The classification stage uses two DenseNet201 encoders-one on the
original image and another on the segmented lesion whose features are fused via
multi-head cross-attention. This dual-input design guides the model to focus on
salient pathological regions. In addition, a transformer-based module
incorporates patient metadata (age, sex, lesion site) into the prediction. We
evaluate our approach on the HAM10000 dataset and the ISIC 2018 and 2019
challenges. The proposed method achieves state-of-the-art segmentation
performance and significantly improves classification accuracy and average AUC
compared to baseline models. To validate our model's reliability, we use
Gradient-weighted Class Activation Mapping (Grad-CAM) to generate heatmaps.
These visualizations confirm that our model's predictions are based on the
lesion area, unlike models that rely on spurious background features. These
results demonstrate that integrating precise lesion segmentation and clinical
data with attention-based fusion leads to a more accurate and interpretable
skin cancer classification model.

</details>


### [140] [SparseVILA: Decoupling Visual Sparsity for Efficient VLM Inference](https://arxiv.org/abs/2510.17777)
*Samir Khaki,Junxian Guo,Jiaming Tang,Shang Yang,Yukang Chen,Konstantinos N. Plataniotis,Yao Lu,Song Han,Zhijian Liu*

Main category: cs.CV

TL;DR: SparseVILA是一种新的高效视觉语言模型推理范式，通过在预填充阶段剪枝冗余视觉token，在解码阶段仅检索查询相关token，实现视觉稀疏性解耦，显著提升推理速度同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型的可扩展性受到视觉token数量增长导致的推理延迟限制，需要开发更高效的推理方法。

Method: 提出SparseVILA框架，在预填充阶段进行查询无关的剪枝，在解码阶段进行查询感知的token检索，基于AWQ优化的推理流水线实现。

Result: 在长上下文视频任务中实现预填充速度提升4.0倍，解码速度提升2.5倍，端到端加速2.6倍，同时在文档理解和推理任务上提高准确性。

Conclusion: 通过解耦查询无关剪枝和查询感知检索，SparseVILA为高效多模态推理提供了新的方向，无需训练即可加速大型视觉语言模型且不牺牲能力。

Abstract: Vision Language Models (VLMs) have rapidly advanced in integrating visual and
textual reasoning, powering applications across high-resolution image
understanding, long-video analysis, and multi-turn conversation. However, their
scalability remains limited by the growing number of visual tokens that
dominate inference latency. We present SparseVILA, a new paradigm for efficient
VLM inference that decouples visual sparsity across the prefilling and decoding
stages. SparseVILA distributes sparsity across stages by pruning redundant
visual tokens during prefill and retrieving only query-relevant tokens during
decoding. This decoupled design matches leading prefill pruning methods while
preserving multi-turn fidelity by retaining most of the visual cache so that
query-aware tokens can be retrieved at each conversation round. Built on an
AWQ-optimized inference pipeline, SparseVILA achieves up to 4.0 times faster
prefilling, 2.5 times faster decoding, and an overall 2.6 times end-to-end
speedup on long-context video tasks -- while improving accuracy on
document-understanding and reasoning tasks. By decoupling query-agnostic
pruning and query-aware retrieval, SparseVILA establishes a new direction for
efficient multimodal inference, offering a training-free, architecture-agnostic
framework for accelerating large VLMs without sacrificing capability.

</details>


### [141] [ConsistEdit: Highly Consistent and Precise Training-free Visual Editing](https://arxiv.org/abs/2510.17803)
*Zixin Yin,Ling-Hao Chen,Lionel Ni,Xili Dai*

Main category: cs.CV

TL;DR: 提出了ConsistEdit方法，针对MM-DiT架构的注意力控制技术，解决了现有训练自由编辑方法在编辑强度与一致性保持之间的平衡问题，支持多轮和视频编辑。


<details>
  <summary>Details</summary>
Motivation: 现有训练自由注意力控制方法在同时实现强编辑能力和保持源一致性方面存在困难，特别是在多轮和视频编辑中视觉错误会累积。大多数方法强制全局一致性，限制了细粒度编辑能力。

Method: 基于对MM-DiT架构的深入分析，提出ConsistEdit方法，包含仅视觉注意力控制、掩码引导预注意力融合、以及查询、键和值令牌的差异化操作。

Result: 在广泛的图像和视频编辑任务中实现最先进性能，包括结构一致和不一致场景。首个无需手工操作即可在所有推理步骤和注意力层执行编辑的方法。

Conclusion: ConsistEdit显著提高了可靠性和一致性，支持稳健的多轮和多区域编辑，并支持结构一致性的渐进调整，实现更精细的控制。

Abstract: Recent advances in training-free attention control methods have enabled
flexible and efficient text-guided editing capabilities for existing generation
models. However, current approaches struggle to simultaneously deliver strong
editing strength while preserving consistency with the source. This limitation
becomes particularly critical in multi-round and video editing, where visual
errors can accumulate over time. Moreover, most existing methods enforce global
consistency, which limits their ability to modify individual attributes such as
texture while preserving others, thereby hindering fine-grained editing.
Recently, the architectural shift from U-Net to MM-DiT has brought significant
improvements in generative performance and introduced a novel mechanism for
integrating text and vision modalities. These advancements pave the way for
overcoming challenges that previous methods failed to resolve. Through an
in-depth analysis of MM-DiT, we identify three key insights into its attention
mechanisms. Building on these, we propose ConsistEdit, a novel attention
control method specifically tailored for MM-DiT. ConsistEdit incorporates
vision-only attention control, mask-guided pre-attention fusion, and
differentiated manipulation of the query, key, and value tokens to produce
consistent, prompt-aligned edits. Extensive experiments demonstrate that
ConsistEdit achieves state-of-the-art performance across a wide range of image
and video editing tasks, including both structure-consistent and
structure-inconsistent scenarios. Unlike prior methods, it is the first
approach to perform editing across all inference steps and attention layers
without handcraft, significantly enhancing reliability and consistency, which
enables robust multi-round and multi-region editing. Furthermore, it supports
progressive adjustment of structural consistency, enabling finer control.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [142] [Quantum NLP models on Natural Language Inference](https://arxiv.org/abs/2510.15972)
*Ling Sun,Peter Sullivan,Michael Martin,Yun Zhou*

Main category: cs.CL

TL;DR: 本文研究量子自然语言处理在自然语言推理任务中的应用，比较量子、混合和经典模型在少样本设置下的表现，引入信息增益参数比新指标评估学习效率。


<details>
  <summary>Details</summary>
Motivation: 探索量子自然语言处理在语义建模中的潜力，特别是在少样本学习场景下，通过将组合结构嵌入量子电路来提升模型效率。

Method: 使用lambeq库和DisCoCat框架构建参数化量子电路，训练语义相关性和推理分类任务，并提出基于聚类的架构促进参数共享。

Result: 量子模型在参数数量大幅减少的情况下达到与经典基线相当的性能，在推理任务上优于随机初始化的transformer模型，且学习效率比经典模型高出最多五个数量级。

Conclusion: 量子自然语言处理在低资源、结构敏感的场景中展现出巨大潜力，其高参数效率使其成为有前景的研究方向。

Abstract: Quantum natural language processing (QNLP) offers a novel approach to
semantic modeling by embedding compositional structure directly into quantum
circuits. This paper investigates the application of QNLP models to the task of
Natural Language Inference (NLI), comparing quantum, hybrid, and classical
transformer-based models under a constrained few-shot setting. Using the lambeq
library and the DisCoCat framework, we construct parameterized quantum circuits
for sentence pairs and train them for both semantic relatedness and inference
classification. To assess efficiency, we introduce a novel
information-theoretic metric, Information Gain per Parameter (IGPP), which
quantifies learning dynamics independent of model size. Our results demonstrate
that quantum models achieve performance comparable to classical baselines while
operating with dramatically fewer parameters. The Quantum-based models
outperform randomly initialized transformers in inference and achieve lower
test error on relatedness tasks. Moreover, quantum models exhibit significantly
higher per-parameter learning efficiency (up to five orders of magnitude more
than classical counterparts), highlighting the promise of QNLP in low-resource,
structure-sensitive settings. To address circuit-level isolation and promote
parameter sharing, we also propose a novel cluster-based architecture that
improves generalization by tying gate parameters to learned word clusters
rather than individual tokens.

</details>


### [143] [Fusion-Augmented Large Language Models: Boosting Diagnostic Trustworthiness via Model Consensus](https://arxiv.org/abs/2510.16057)
*Md Kamrul Siam,Md Jobair Hossain Faruk,Jerry Q. Cheng,Huanying Gu*

Main category: cs.CL

TL;DR: 该研究提出了一种基于ChatGPT和Claude的多模型融合框架，通过图像和合成临床笔记的多模态输入以及基于相似性共识的方法，显著提高了胸部X光片诊断的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 提高AI辅助放射学诊断的可信度和临床实用性，通过多模型融合和多模态输入减少诊断错误。

Method: 使用ChatGPT和Claude两种大型语言模型，在CheXpert数据集上进行评估。首先使用纯图像提示评估单模型性能，然后通过95%输出相似性阈值进行共识融合。进一步引入合成临床笔记作为多模态输入，评估图像+文本组合的性能。

Result: 在单模型图像模式下，ChatGPT准确率62.8%，Claude准确率76.9%；共识融合后提升至77.6%。在多模态输入下，ChatGPT提升至84%，Claude为76%，共识准确率达到91.3%。共识融合在所有实验条件下均优于单个模型。

Conclusion: 整合互补模态和使用输出级共识可以有效提高AI辅助放射学诊断的可靠性和临床实用性，为减少诊断错误提供了实用路径且计算开销最小。

Abstract: This study presents a novel multi-model fusion framework leveraging two
state-of-the-art large language models (LLMs), ChatGPT and Claude, to enhance
the reliability of chest X-ray interpretation on the CheXpert dataset. From the
full CheXpert corpus of 224,316 chest radiographs, we randomly selected 234
radiologist-annotated studies to evaluate unimodal performance using image-only
prompts. In this setting, ChatGPT and Claude achieved diagnostic accuracies of
62.8% and 76.9%, respectively. A similarity-based consensus approach, using a
95% output similarity threshold, improved accuracy to 77.6%. To assess the
impact of multimodal inputs, we then generated synthetic clinical notes
following the MIMIC-CXR template and evaluated a separate subset of 50 randomly
selected cases paired with both images and synthetic text. On this multimodal
cohort, performance improved to 84% for ChatGPT and 76% for Claude, while
consensus accuracy reached 91.3%. Across both experimental conditions,
agreement-based fusion consistently outperformed individual models. These
findings highlight the utility of integrating complementary modalities and
using output-level consensus to improve the trustworthiness and clinical
utility of AI-assisted radiological diagnosis, offering a practical path to
reduce diagnostic errors with minimal computational overhead.

</details>


### [144] [Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs](https://arxiv.org/abs/2510.16062)
*Guiyao Tie,Zenghui Yuan,Zeli Zhao,Chaoran Hu,Tianhe Gu,Ruihang Zhang,Sizhe Zhang,Junran Wu,Xiaoyue Tu,Ming Jin,Qingsong Wen,Lixing Chen,Pan Zhou,Lichao Sun*

Main category: cs.CL

TL;DR: CorrectBench是一个评估大语言模型自校正方法的基准，涵盖常识推理、数学推理和代码生成任务。研究发现自校正能提升准确性但降低效率，简单的思维链方法表现竞争性。


<details>
  <summary>Details</summary>
Motivation: 尽管已有多种自校正方法被提出，但缺乏对这些方法的全面评估，且LLM是否能真正自我校正仍存疑问。

Method: 开发CorrectBench基准，评估内在、外部和微调三种自校正策略在三个推理任务上的效果。

Result: 自校正方法能提高准确性，混合策略可进一步改善但降低效率；推理LLM在额外自校正下优化有限且时间成本高；简单思维链基线表现竞争性。

Conclusion: 自校正有潜力提升LLM推理性能，但需平衡推理能力与操作效率，建议进一步研究优化这一平衡。

Abstract: Self-correction of large language models (LLMs) emerges as a critical
component for enhancing their reasoning performance. Although various
self-correction methods have been proposed, a comprehensive evaluation of these
methods remains largely unexplored, and the question of whether LLMs can truly
correct themselves is a matter of significant interest and concern. In this
study, we introduce CorrectBench, a benchmark developed to evaluate the
effectiveness of self-correction strategies, including intrinsic, external, and
fine-tuned approaches, across three tasks: commonsense reasoning, mathematical
reasoning, and code generation. Our findings reveal that: 1) Self-correction
methods can improve accuracy, especially for complex reasoning tasks; 2) Mixing
different self-correction strategies yields further improvements, though it
reduces efficiency; 3) Reasoning LLMs (e.g., DeepSeek-R1) have limited
optimization under additional self-correction methods and have high time costs.
Interestingly, a comparatively simple chain-of-thought (CoT) baseline
demonstrates competitive accuracy and efficiency. These results underscore the
potential of self-correction to enhance LLM's reasoning performance while
highlighting the ongoing challenge of improving their efficiency. Consequently,
we advocate for further research focused on optimizing the balance between
reasoning capabilities and operational efficiency. Project Page:
https://correctbench.github.io/

</details>


### [145] [EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle](https://arxiv.org/abs/2510.16079)
*Rong Wu,Xiaoman Wang,Jianbiao Mei,Pinlong Cai,Daocheng Fu,Cheng Yang,Licheng Wen,Xuemeng Yang,Yufan Shen,Yuxin Wang,Botian Shi*

Main category: cs.CL

TL;DR: EvolveR是一个让LLM智能体通过闭环经验生命周期实现自我改进的框架，包含离线自我蒸馏和在线交互两个阶段，在复杂多跳问答基准上优于现有智能体基线。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在工具使用方面表现出色，但缺乏从自身经验中系统性学习的能力，无法迭代优化问题解决策略。

Method: 采用闭环经验生命周期：1）离线自我蒸馏，将交互轨迹合成为结构化、可重用的抽象策略原则库；2）在线交互，智能体与任务交互并检索蒸馏原则指导决策，积累多样化行为轨迹；使用策略强化机制迭代更新智能体。

Result: 在复杂多跳问答基准上，EvolveR实现了优于现有强智能体基线的性能表现。

Conclusion: 该工作为智能体不仅从外部数据学习，还能从自身行为后果中学习提供了全面蓝图，为更自主和持续改进的系统铺平了道路。

Abstract: Current Large Language Model (LLM) agents show strong performance in tool
use, but lack the crucial capability to systematically learn from their own
experiences. While existing frameworks mainly focus on mitigating external
knowledge gaps, they fail to address a more fundamental limitation: the
inability to iteratively refine problem-solving strategies. In this work, we
introduce EvolveR, a framework designed to enable agent to self-improve through
a complete, closed-loop experience lifecycle. This lifecycle comprises two key
stages: (1) Offline Self-Distillation, where the agent's interaction
trajectories are synthesized into a structured repository of abstract, reusable
strategic principles; (2) Online Interaction, where the agent interacts with
tasks and actively retrieves distilled principles to guide its decision-making,
accumulating a diverse set of behavioral trajectories. This loop employs a
policy reinforcement mechanism to iteratively update the agent based on its
performance. We demonstrate the effectiveness of EvolveR on complex multi-hop
question-answering benchmarks, where it achieves superior performance over
strong agentic baselines. Our work presents a comprehensive blueprint for
agents that learn not only from external data but also from the consequences of
their own actions, paving the way for more autonomous and continuously
improving systems. Code is available at https://github.com/Edaizi/EvolveR.

</details>


### [146] [Evaluating Prompting Strategies and Large Language Models in Systematic Literature Review Screening: Relevance and Task-Stage Classification](https://arxiv.org/abs/2510.16091)
*Binglan Han,Anuradha Mathrani,Teo Susnjak*

Main category: cs.CL

TL;DR: 本研究量化了提示策略与大型语言模型在系统文献综述筛选阶段的交互作用，评估了6个LLM在5种提示类型下的表现，发现CoT-few-shot提供最可靠的精确度-召回率平衡，并推荐了分阶段工作流程。


<details>
  <summary>Details</summary>
Motivation: 系统分析提示策略与大型语言模型在自动化文献筛选中的交互作用，为任务适应性LLM部署提供比较基准和实用指导。

Method: 评估6个LLM在5种提示类型下进行相关性分类和6个Level-2任务，使用准确率、精确度、召回率和F1分数作为评估指标。

Result: CoT-few-shot提供最可靠的精确度-召回率平衡；零样本在高灵敏度筛选时最大化召回率；自反思因过度包容性和模型间不稳定性表现不佳。GPT-4o和DeepSeek整体表现稳健，GPT-4o-mini在显著更低成本下表现有竞争力。

Conclusion: 推荐分阶段工作流程：首先使用低成本模型和结构化提示进行初步筛选，仅将边界案例升级到更高容量模型。LLM在自动化文献筛选方面具有不均衡但有前景的潜力。

Abstract: This study quantifies how prompting strategies interact with large language
models (LLMs) to automate the screening stage of systematic literature reviews
(SLRs). We evaluate six LLMs (GPT-4o, GPT-4o-mini, DeepSeek-Chat-V3,
Gemini-2.5-Flash, Claude-3.5-Haiku, Llama-4-Maverick) under five prompt types
(zero-shot, few-shot, chain-of-thought (CoT), CoT-few-shot, self-reflection)
across relevance classification and six Level-2 tasks, using accuracy,
precision, recall, and F1. Results show pronounced model-prompt interaction
effects: CoT-few-shot yields the most reliable precision-recall balance;
zero-shot maximizes recall for high-sensitivity passes; and self-reflection
underperforms due to over-inclusivity and instability across models. GPT-4o and
DeepSeek provide robust overall performance, while GPT-4o-mini performs
competitively at a substantially lower dollar cost. A cost-performance analysis
for relevance classification (per 1,000 abstracts) reveals large absolute
differences among model-prompt pairings; GPT-4o-mini remains low-cost across
prompts, and structured prompts (CoT/CoT-few-shot) on GPT-4o-mini offer
attractive F1 at a small incremental cost. We recommend a staged workflow that
(1) deploys low-cost models with structured prompts for first-pass screening
and (2) escalates only borderline cases to higher-capacity models. These
findings highlight LLMs' uneven but promising potential to automate literature
screening. By systematically analyzing prompt-model interactions, we provide a
comparative benchmark and practical guidance for task-adaptive LLM deployment.

</details>


### [147] [Facts in Stats: Impacts of Pretraining Diversity on Language Model Generalization](https://arxiv.org/abs/2510.16096)
*Tina Behnia,Puneesh Deora,Christos Thrampoulidis*

Main category: cs.CL

TL;DR: 该论文提出了一个合成测试平台，用于系统分析语言模型中统计规律与事实关联之间的交互作用，发现上下文多样性和结构对事实泛化能力有重要影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对语言模型中统计规律与事实关联交互作用的系统分析，特别是它们如何影响泛化能力。

Method: 设计了一个灵活的合成测试平台，将通用标记的统计流与抽象事实的源-目标标记对流相结合，通过控制流组成和多样性水平来独立操纵上下文结构。

Result: 研究发现更高的上下文多样性会延迟分布内事实准确性，但对分布外事实泛化的影响取决于上下文结构；在某些情况下多样性对非平凡事实回忆至关重要；优化瓶颈主要出现在嵌入和解嵌入层。

Conclusion: 上下文设计和多样性水平的相互作用影响不同泛化方面，合成框架为未来研究提供了受控测试平台，能够分离在大规模研究中可能混淆的效应。

Abstract: Language models are pretrained on sequences that blend statistical
regularities (making text fluent) with factual associations between specific
tokens (knowledge of facts). While recent work suggests that the variability of
their interaction, such as paraphrases of factual associations, critically
determines generalization ability, we lack a systematic analysis of these
impacts. This paper introduces a flexible synthetic testbed that combines a
statistical stream of generic tokens with an abstract factual stream of
source-target token pairs, enabling fine-grained control over their
interaction. The design enables the independent control of diversity nature by
manipulating stream composition (contextual structure) and the diversity level
by varying which statistical streams each fact appears in. Through controlled
experiments, we find that while higher contextual diversity delays
in-distribution (ID) factual accuracy, its impact on out-of-distribution (OOD)
factual generalization depends critically on contextual structure. In some
cases, OOD performance follows the same trend as ID, but in others, diversity
becomes essential for non-trivial factual recall. Even when low diversity
prohibits factual recall, optimal diversity levels depend on training duration.
Beyond factual recall failures, we identify structures where statistical
generalization fails independently, and others where both capabilities degrade.
This shows how the interplay between contextual design and diversity level
impacts different generalization aspects. Further, through a series of
controlled interventions on the model components, we trace the OOD failures to
distinct optimization bottlenecks, highlighting the importance of the embedding
and unembedding layers. Our synthetic framework allows us to isolate effects
that would be confounded in large-scale studies, offering a controlled testbed
for future investigations.

</details>


### [148] [In Generative AI We (Dis)Trust? Computational Analysis of Trust and Distrust in Reddit Discussions](https://arxiv.org/abs/2510.16173)
*Aria Pessianzadeh,Naima Sultana,Hildegarde Van den Bulck,David Gefen,Shahin Jabari,Rezvaneh Rezapour*

Main category: cs.CL

TL;DR: 本文提出了首个关于生成式AI信任与不信任的计算研究，使用2022-2025年Reddit多子版块数据集，结合众包标注和分类模型进行大规模分析。研究发现信任与不信任基本平衡，受主要模型发布影响，技术性能和可用性是主要维度，个人经验是态度形成的最常见原因。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI系统融入日常生活，理解公众对其的信任对负责任采用和治理至关重要。现有AI信任研究多来自心理学和人机交互领域，缺乏计算性、大规模和纵向的方法来衡量对生成式AI和大型语言模型的信任与不信任。

Method: 使用2022-2025年多子版块Reddit数据集（39个子版块，197,618个帖子），结合众包标注代表性样本和分类模型来扩展分析规模。

Result: 研究发现信任与不信任随时间基本平衡，围绕主要模型发布出现变化。技术性能和可用性是最主要的维度，个人经验是态度形成的最常见原因。不同信任者群体（如专家、伦理学家、普通用户）展现出不同的模式。

Conclusion: 研究结果为大规模信任分析提供了方法论框架，并为理解公众对生成式AI不断演变的认知提供了见解。

Abstract: The rise of generative AI (GenAI) has impacted many aspects of human life. As
these systems become embedded in everyday practices, understanding public trust
in them also becomes essential for responsible adoption and governance. Prior
work on trust in AI has largely drawn from psychology and human-computer
interaction, but there is a lack of computational, large-scale, and
longitudinal approaches to measuring trust and distrust in GenAI and large
language models (LLMs). This paper presents the first computational study of
Trust and Distrust in GenAI, using a multi-year Reddit dataset (2022--2025)
spanning 39 subreddits and 197,618 posts. Crowd-sourced annotations of a
representative sample were combined with classification models to scale
analysis. We find that Trust and Distrust are nearly balanced over time, with
shifts around major model releases. Technical performance and usability
dominate as dimensions, while personal experience is the most frequent reason
shaping attitudes. Distinct patterns also emerge across trustors (e.g.,
experts, ethicists, general users). Our results provide a methodological
framework for large-scale Trust analysis and insights into evolving public
perceptions of GenAI.

</details>


### [149] [EgMM-Corpus: A Multimodal Vision-Language Dataset for Egyptian Culture](https://arxiv.org/abs/2510.16198)
*Mohamed Gamil,Abdelrahman Elsayed,Abdelrahman Lila,Ahmed Gad,Hesham Abdelgawad,Mohamed Aref,Ahmed Fares*

Main category: cs.CL

TL;DR: 本文介绍了EgMM-Corpus，一个专门针对埃及文化的多模态数据集，包含3000多张图像，涵盖313个概念，用于评估和训练在埃及文化背景下的视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前AI领域的多模态文化多样性数据集仍然有限，特别是针对中东和非洲地区。为了填补这一空白，作者创建了专门针对埃及文化的多模态数据集。

Method: 设计并运行新的数据收集流程，收集了涵盖地标、食物和民间传说等313个概念的3000多张图像，每个条目都经过人工验证文化真实性和多模态一致性。

Result: 在EgMM-Corpus上评估CLIP的零样本性能，Top-1准确率为21.2%，Top-5准确率为36.4%。这些结果显示了大规模视觉语言模型中存在的文化偏见。

Conclusion: EgMM-Corpus作为开发文化感知模型的基准具有重要意义，突显了解决AI模型中文化偏见问题的必要性。

Abstract: Despite recent advances in AI, multimodal culturally diverse datasets are
still limited, particularly for regions in the Middle East and Africa. In this
paper, we introduce EgMM-Corpus, a multimodal dataset dedicated to Egyptian
culture. By designing and running a new data collection pipeline, we collected
over 3,000 images, covering 313 concepts across landmarks, food, and folklore.
Each entry in the dataset is manually validated for cultural authenticity and
multimodal coherence. EgMM-Corpus aims to provide a reliable resource for
evaluating and training vision-language models in an Egyptian cultural context.
We further evaluate the zero-shot performance of Contrastive Language-Image
Pre-training CLIP on EgMM-Corpus, on which it achieves 21.2% Top-1 accuracy and
36.4% Top-5 accuracy in classification. These results underscore the existing
cultural bias in large-scale vision-language models and demonstrate the
importance of EgMM-Corpus as a benchmark for developing culturally aware
models.

</details>


### [150] [What Can String Probability Tell Us About Grammaticality?](https://arxiv.org/abs/2510.16227)
*Jennifer Hu,Ethan Gotlieb Wilcox,Siyuan Song,Kyle Mahowald,Roger P. Levy*

Main category: cs.CL

TL;DR: 该论文探讨语言模型是否学习了语法知识，通过理论分析和实验验证，建立了概率与语法性之间的关系，并提出了三个可验证的预测。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否真正掌握了语法知识，因为概率和语法性在语言学中是不同概念，需要明确字符串概率能否揭示模型的语法知识。

Method: 基于语料库数据生成过程的简单假设，进行理论分析，并使用28万对英语和中文句子对进行实证验证，包括最小对分析、模型与人类判断相关性比较等。

Result: 验证了三个预测：(1) 最小对字符串概率相关性；(2) 模型与人类在最小对中差异的相关性；(3) 语法与不语法字符串在概率空间中的分离度较差。

Conclusion: 为使用概率研究语言模型的结构知识提供了理论基础，并为未来语言模型语法评估指明了方向。

Abstract: What have language models (LMs) learned about grammar? This question remains
hotly debated, with major ramifications for linguistic theory. However, since
probability and grammaticality are distinct notions in linguistics, it is not
obvious what string probabilities can reveal about an LM's underlying
grammatical knowledge. We present a theoretical analysis of the relationship
between grammar, meaning, and string probability, based on simple assumptions
about the generative process of corpus data. Our framework makes three
predictions, which we validate empirically using 280K sentence pairs in English
and Chinese: (1) correlation between the probability of strings within minimal
pairs, i.e., string pairs with minimal semantic differences; (2) correlation
between models' and humans' deltas within minimal pairs; and (3) poor
separation in probability space between unpaired grammatical and ungrammatical
strings. Our analyses give theoretical grounding for using probability to learn
about LMs' structural knowledge, and suggest directions for future work in LM
grammatical evaluation.

</details>


### [151] [Towards Low-Resource Alignment to Diverse Perspectives with Sparse Feedback](https://arxiv.org/abs/2510.16257)
*Chu Fei Luo,Samuel Dahan,Xiaodan Zhu*

Main category: cs.CL

TL;DR: 该研究提出两种方法（多元化解码和模型引导）来增强语言模型在低资源设置下的多元化对齐能力，仅用50个标注样本就能在多个高风险任务中提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型对社会影响增大，需要确保它们能够对齐多样化的视角并反映人类价值观的细微差别。当前流行的训练范式假设每个查询只有一个最优答案，导致响应泛化且对齐效果差。

Method: 提出两种方法：1）多元化解码，2）模型引导。在低资源设置下仅使用50个标注样本进行实验。

Result: 模型引导方法在零样本和少样本基线上表现一致提升，在仇恨言论检测和错误信息检测等高风险任务中降低了假阳性率，在GlobalOpinionQA中改善了与人类价值观的分布对齐。

Conclusion: 该工作强调了多样性的重要性，展示了语言模型如何适应考虑细微视角，为提升模型多元化对齐提供了有效方法。

Abstract: As language models have a greater impact on society, it is important to
ensure they are aligned to a diverse range of perspectives and are able to
reflect nuance in human values. However, the most popular training paradigms
for modern language models often assume there is one optimal answer for every
query, leading to generic responses and poor alignment. In this work, we aim to
enhance pluralistic alignment of language models in a low-resource setting with
two methods: pluralistic decoding and model steering. We empirically
demonstrate that model steering offers consistent improvement over zero-shot
and few-shot baselines with only 50 annotated samples. Our proposed methods
decrease false positives in several high-stakes tasks such as hate speech
detection and misinformation detection, and improves the distributional
alignment to human values in GlobalOpinionQA. We hope our work highlights the
importance of diversity and how language models can be adapted to consider
nuanced perspectives.

</details>


### [152] [Thinking About Thinking: Evaluating Reasoning in Post-Trained Language Models](https://arxiv.org/abs/2510.16340)
*Pratham Singla,Shivank Garg,Ayush Singh,Ishan Garg,Ketan Suhaas Saichandran*

Main category: cs.CL

TL;DR: 该研究评估了后训练大语言模型对其学习策略的认知能力，包括策略意识、泛化能力和推理对齐性，发现RL训练模型比SFT模型具有更强的策略意识和泛化能力，但推理对齐性较弱。


<details>
  <summary>Details</summary>
Motivation: 探索后训练大语言模型是否真正理解它们通过生成规划标记所学习的内容和推理过程，定义并评估模型对其学习策略的认知能力。

Method: 定义了三个核心能力：学习策略意识、策略跨领域泛化、内部推理轨迹与最终输出的对齐性。在多个需要学习不同策略的任务上进行实证评估，对比了SFT、DPO和GRPO三种后训练方法的模型表现。

Result: RL训练模型比SFT模型表现出更强的学习策略意识和在结构相似新任务上的泛化能力，但推理轨迹与最终输出的对齐性较弱，GRPO训练模型的对齐性问题最为明显。

Conclusion: 后训练技术确实增强了LLMs处理复杂逻辑任务的能力，但模型对其学习内容的认知存在差异，RL方法在策略意识和泛化方面表现更好，但在推理透明度方面存在挑战。

Abstract: Recent advances in post-training techniques have endowed Large Language
Models (LLMs) with enhanced capabilities for tackling complex, logic-intensive
tasks through the generation of supplementary planning tokens. This development
raises a fundamental question: Are these models aware of what they "learn" and
"think"? To address this, we define three core competencies: (1) awareness of
learned latent policies, (2) generalization of these policies across domains,
and (3) alignment between internal reasoning traces and final outputs. We
empirically evaluate these abilities on several tasks, each designed to require
learning a distinct policy. Furthermore, we contrast the profiles of models
post-trained via Supervised Fine-Tuning (SFT), Direct Policy Optimization
(DPO), and Group Relative Policy Optimization (GRPO). Our findings indicate
that RL-trained models not only demonstrate greater awareness of their learned
behaviors and stronger generalizability to novel, structurally similar tasks
than SFT models but also often exhibit weak alignment between their reasoning
traces and final outputs, an effect most pronounced in GRPO-trained models.

</details>


### [153] [Utilising Large Language Models for Generating Effective Counter Arguments to Anti-Vaccine Tweets](https://arxiv.org/abs/2510.16359)
*Utsav Dhanuka,Soham Poddar,Saptarshi Ghosh*

Main category: cs.CL

TL;DR: 本文研究了利用大型语言模型生成针对疫苗错误信息的实时反驳论点，通过多种提示策略和微调方法优化反驳生成，并训练分类器对反疫苗推文进行多标签分类以实现更情境感知的反驳。


<details>
  <summary>Details</summary>
Motivation: 在社交媒体影响公共卫生的时代，打击疫苗怀疑论和错误信息成为关键社会目标。虽然错误信息检测已取得进展，但生成针对这些声明的实时定制反驳论点仍是一个未被充分探索的领域。

Method: 基于先前错误信息辟谣研究，实验了各种提示策略和微调方法以优化反驳论点生成。训练分类器将反疫苗推文分类为多标签类别（如疫苗效力担忧、副作用、政治影响等），实现更情境感知的反驳。

Result: 通过人工判断、基于LLM的评估和自动指标的评估显示，这些方法之间存在强一致性。结果表明，整合标签描述和结构化微调能增强反驳论点的有效性。

Conclusion: 该方法为大规模缓解疫苗错误信息提供了一个有前景的途径，展示了LLM在生成有效反驳论点方面的能力。

Abstract: In an era where public health is increasingly influenced by information
shared on social media, combatting vaccine skepticism and misinformation has
become a critical societal goal. Misleading narratives around vaccination have
spread widely, creating barriers to achieving high immunisation rates and
undermining trust in health recommendations. While efforts to detect
misinformation have made significant progress, the generation of real time
counter-arguments tailored to debunk such claims remains an insufficiently
explored area. In this work, we explore the capabilities of LLMs to generate
sound counter-argument rebuttals to vaccine misinformation. Building on prior
research in misinformation debunking, we experiment with various prompting
strategies and fine-tuning approaches to optimise counter-argument generation.
Additionally, we train classifiers to categorise anti-vaccine tweets into
multi-labeled categories such as concerns about vaccine efficacy, side effects,
and political influences allowing for more context aware rebuttals. Our
evaluation, conducted through human judgment, LLM based assessments, and
automatic metrics, reveals strong alignment across these methods. Our findings
demonstrate that integrating label descriptions and structured fine-tuning
enhances counter-argument effectiveness, offering a promising approach for
mitigating vaccine misinformation at scale.

</details>


### [154] [End-to-End Argument Mining through Autoregressive Argumentative Structure Prediction](https://arxiv.org/abs/2510.16363)
*Nilmadhab Das,Vishal Vaibhav,Yash Sunil Choudhary,V. Vijaya Saradhi,Ashish Anand*

Main category: cs.CL

TL;DR: 该研究提出了自回归论证结构预测(AASP)框架，用于联合建模论证挖掘中的论证组件和论证关系，通过预定义动作集逐步构建论证结构，在三个标准基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过生成式范式扁平化处理论证结构，难以有效建模论证组件与论证关系之间的复杂依赖关系，需要一种能够联合处理这些任务并捕捉论证推理流程的方法。

Method: 采用自回归论证结构预测(AASP)框架，将论证结构建模为受约束的预定义动作集，利用条件预训练语言模型以自回归方式逐步构建论证结构，从而有效捕捉论证推理流程。

Result: 在三个标准论证挖掘基准测试中，AASP在两个基准上实现了所有任务的最先进结果，在另一个基准上也取得了强劲表现。

Conclusion: AASP框架通过自回归结构预测有效建模了论证组件和论证关系之间的依赖，为论证挖掘任务提供了一种高效的端到端解决方案。

Abstract: Argument Mining (AM) helps in automating the extraction of complex
argumentative structures such as Argument Components (ACs) like Premise, Claim
etc. and Argumentative Relations (ARs) like Support, Attack etc. in an
argumentative text. Due to the inherent complexity of reasoning involved with
this task, modelling dependencies between ACs and ARs is challenging. Most of
the recent approaches formulate this task through a generative paradigm by
flattening the argumentative structures. In contrast to that, this study
jointly formulates the key tasks of AM in an end-to-end fashion using
Autoregressive Argumentative Structure Prediction (AASP) framework. The
proposed AASP framework is based on the autoregressive structure prediction
framework that has given good performance for several NLP tasks. AASP framework
models the argumentative structures as constrained pre-defined sets of actions
with the help of a conditional pre-trained language model. These actions build
the argumentative structures step-by-step in an autoregressive manner to
capture the flow of argumentative reasoning in an efficient way. Extensive
experiments conducted on three standard AM benchmarks demonstrate that AASP
achieves state-of-theart (SoTA) results across all AM tasks in two benchmarks
and delivers strong results in one benchmark.

</details>


### [155] [Navigating through the hidden embedding space: steering LLMs to improve mental health assessment](https://arxiv.org/abs/2510.16373)
*Federico Ravenda,Seyed Ali Bahrainian,Andrea Raballo,Antonietta Mira*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级方法，通过线性变换特定层的激活向量来提升语言模型在心理健康评估任务中的表现，无需依赖计算密集型技术。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型快速发展，但小规模模型在特定领域应用中仍表现不佳，特别是在心理健康等敏感高影响领域需要更有效的适应方法。

Method: 采用轻量级方法，对特定层的激活应用线性变换，利用转向向量引导模型输出，无需计算密集型技术。

Result: 该方法在两个任务中均取得改进：识别Reddit帖子是否有助于检测抑郁症状的相关性预测任务，以及基于用户Reddit帖子历史完成标准化抑郁筛查问卷的任务。

Conclusion: 转向机制作为计算效率高的工具，在语言模型心理健康领域适应方面具有未开发的潜力。

Abstract: The rapid evolution of Large Language Models (LLMs) is transforming AI,
opening new opportunities in sensitive and high-impact areas such as Mental
Health (MH). Yet, despite these advancements, recent evidence reveals that
smaller-scale models still struggle to deliver optimal performance in
domain-specific applications. In this study, we present a cost-efficient yet
powerful approach to improve MH assessment capabilities of an LLM, without
relying on any computationally intensive techniques. Our lightweight method
consists of a linear transformation applied to a specific layer's activations,
leveraging steering vectors to guide the model's output. Remarkably, this
intervention enables the model to achieve improved results across two distinct
tasks: (1) identifying whether a Reddit post is useful for detecting the
presence or absence of depressive symptoms (relevance prediction task), and (2)
completing a standardized psychological screening questionnaire for depression
based on users' Reddit post history (questionnaire completion task). Results
highlight the untapped potential of steering mechanisms as computationally
efficient tools for LLMs' MH domain adaptation.

</details>


### [156] [Unleashing Diverse Thinking Modes in LLMs through Multi-Agent Collaboration](https://arxiv.org/abs/2510.16645)
*Zhixuan He,Yue Feng*

Main category: cs.CL

TL;DR: DiMo是一个多智能体协作框架，通过模拟四个专门化LLM智能体之间的结构化辩论来增强性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然性能强大但缺乏可解释的推理过程，需要一种能够提供明确可审计推理链的方法。

Method: 采用四个专门化智能体代表不同推理范式，通过迭代辩论相互挑战和优化初始响应，形成协作探索。

Result: 在六个基准测试和统一开源设置下，DiMo相比单模型和辩论基线提高了准确性，在数学问题上提升最大。

Conclusion: DiMo是一个语义感知的Web原生多智能体框架，能够生成语义类型化、URL注释的证据链，支持下游系统检查和重用。

Abstract: Large Language Models (LLMs) demonstrate strong performance but often lack
interpretable reasoning. This paper introduces the Multi-Agent Collaboration
Framework for Diverse Thinking Modes (DiMo), which enhances both performance
and interpretability by simulating a structured debate among four specialized
LLM agents. Each agent embodies a distinct reasoning paradigm, allowing the
framework to collaboratively explore diverse cognitive approaches. Through
iterative debate, agents challenge and refine initial responses, yielding more
robust conclusions and an explicit, auditable reasoning chain. Across six
benchmarks and under a unified open-source setup, DiMo improves accuracy over
widely used single-model and debate baselines, with the largest gains on math.
We position DiMo as a semantics-aware, Web-native multi-agent framework: it
models human-machine intelligence with LLM agents that produce semantically
typed, URL-annotated evidence chains for explanations and user-friendly
interactions. Although our experiments use standard reasoning benchmarks, the
framework is designed to be instantiated over Web corpora and knowledge graphs,
combining retrieval-augmented reasoning with structured justifications that
downstream systems can inspect and reuse.

</details>


### [157] [MoReBench: Evaluating Procedural and Pluralistic Moral Reasoning in Language Models, More than Outcomes](https://arxiv.org/abs/2510.16380)
*Yu Ying Chiu,Michael S. Lee,Rachel Calcott,Brandon Handoko,Paul de Font-Reaulx,Paula Rodriguez,Chen Bo Calvin Zhang,Ziwen Han,Udari Madhushani Sehwag,Yash Maurya,Christina Q Knight,Harry R. Lloyd,Florence Bacus,Mantas Mazeika,Bing Liu,Yejin Choi,Mitchell L Gordon,Sydney Levine*

Main category: cs.CL

TL;DR: MoReBench是一个包含1000个道德场景和23000多个评估标准的基准测试，用于评估AI模型在道德推理过程中的表现，重点关注推理过程而非最终答案。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统越来越多地参与决策，需要理解它们如何做出决策而不仅仅是决策结果。道德困境是评估AI过程推理的理想测试平台，因为允许多种合理的结论。

Method: 创建MoReBench数据集，包含道德场景和专家制定的评估标准，涵盖识别道德考量、权衡利弊、提供可行建议等方面。同时创建MoReBench-Theory测试AI在五种规范伦理框架下的推理能力。

Result: 研究表明，现有的数学、代码和科学推理基准无法预测模型在道德推理方面的能力。模型显示出对特定道德框架的偏好，这可能是流行训练范式的副作用。

Conclusion: 这些基准测试推动了以过程为重点的推理评估，朝着更安全、更透明的AI发展。

Abstract: As AI systems progress, we rely more on them to make decisions with us and
for us. To ensure that such decisions are aligned with human values, it is
imperative for us to understand not only what decisions they make but also how
they come to those decisions. Reasoning language models, which provide both
final responses and (partially transparent) intermediate thinking traces,
present a timely opportunity to study AI procedural reasoning. Unlike math and
code problems which often have objectively correct answers, moral dilemmas are
an excellent testbed for process-focused evaluation because they allow for
multiple defensible conclusions. To do so, we present MoReBench: 1,000 moral
scenarios, each paired with a set of rubric criteria that experts consider
essential to include (or avoid) when reasoning about the scenarios. MoReBench
contains over 23 thousand criteria including identifying moral considerations,
weighing trade-offs, and giving actionable recommendations to cover cases on AI
advising humans moral decisions as well as making moral decisions autonomously.
Separately, we curate MoReBench-Theory: 150 examples to test whether AI can
reason under five major frameworks in normative ethics. Our results show that
scaling laws and existing benchmarks on math, code, and scientific reasoning
tasks fail to predict models' abilities to perform moral reasoning. Models also
show partiality towards specific moral frameworks (e.g., Benthamite Act
Utilitarianism and Kantian Deontology), which might be side effects of popular
training paradigms. Together, these benchmarks advance process-focused
reasoning evaluation towards safer and more transparent AI.

</details>


### [158] [Verification-Aware Planning for Multi-Agent Systems](https://arxiv.org/abs/2510.17109)
*Tianyang Xu,Dan Zhang,Kushan Mitra,Estevam Hruschka*

Main category: cs.CL

TL;DR: VeriMAP是一个用于多智能体协作的验证感知规划框架，通过分解任务、建模子任务依赖关系，并将规划器定义的通过标准编码为Python和自然语言的子任务验证函数，解决了多智能体协作中的规划、协调和验证挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型智能体在处理复杂任务时需要多智能体协作，但协作过程中存在规划、协调和验证的挑战，执行失败往往源于任务解释、输出格式或智能体间交接的细微偏差。

Method: VeriMAP框架包括任务分解、子任务依赖建模，以及将规划器定义的通过标准编码为Python和自然语言的子任务验证函数。

Result: 在多个数据集上的评估表明，VeriMAP优于单智能体和多智能体基线，同时提高了系统的鲁棒性和可解释性。

Conclusion: 验证感知规划能够在多智能体系统中实现可靠的协调和迭代优化，无需依赖外部标签或注释。

Abstract: Large language model (LLM) agents are increasingly deployed to tackle complex
tasks, often necessitating collaboration among multiple specialized agents.
However, multi-agent collaboration introduces new challenges in planning,
coordination, and verification. Execution failures frequently arise not from
flawed reasoning alone, but from subtle misalignments in task interpretation,
output format, or inter-agent handoffs. To address these challenges, we present
VeriMAP, a framework for multi-agent collaboration with verification-aware
planning. The VeriMAP planner decomposes tasks, models subtask dependencies,
and encodes planner-defined passing criteria as subtask verification functions
(VFs) in Python and natural language. We evaluate VeriMAP on diverse datasets,
demonstrating that it outperforms both single- and multi-agent baselines while
enhancing system robustness and interpretability. Our analysis highlights how
verification-aware planning enables reliable coordination and iterative
refinement in multi-agent systems, without relying on external labels or
annotations.

</details>


### [159] [Probing the Hidden Talent of ASR Foundation Models for L2 English Oral Assessment](https://arxiv.org/abs/2510.16387)
*Fu-An Chao,Bi-Cheng Yan,Berlin Chen*

Main category: cs.CL

TL;DR: 本文探索了Whisper模型在二语口语评估中的潜力，通过提取隐藏表示中的声学和语言特征，仅需轻量级分类器即可在GEPT图片描述数据集上超越现有先进基线。


<details>
  <summary>Details</summary>
Motivation: 挖掘Whisper这一成熟ASR基础模型在二语口语评估中的未开发潜力，超越仅分析转录文本的传统方法。

Method: 从Whisper的隐藏表示中提取声学和语言特征，仅训练轻量级分类器，并融入图像和文本提示作为辅助相关线索。

Result: 在GEPT图片描述数据集上表现优异，超越包括多模态方法在内的现有先进基线，且无需任务特定微调即可编码熟练度模式和语义信息。

Conclusion: Whisper模型具有作为口语评估和其他口语理解任务强大基础的潜力，能够内在地编码熟练度模式和语义信息。

Abstract: In this paper, we explore the untapped potential of Whisper, a
well-established automatic speech recognition (ASR) foundation model, in the
context of L2 spoken language assessment (SLA). Unlike prior studies that
extrinsically analyze transcriptions produced by Whisper, our approach goes a
step further to probe its latent capabilities by extracting acoustic and
linguistic features from hidden representations. With only a lightweight
classifier being trained on top of Whisper's intermediate and final outputs,
our method achieves strong performance on the GEPT picture-description dataset,
outperforming existing cutting-edge baselines, including a multimodal approach.
Furthermore, by incorporating image and text-prompt information as auxiliary
relevance cues, we demonstrate additional performance gains. Finally, we
conduct an in-depth analysis of Whisper's embeddings, which reveals that, even
without task-specific fine-tuning, the model intrinsically encodes both ordinal
proficiency patterns and semantic aspects of speech, highlighting its potential
as a powerful foundation for SLA and other spoken language understanding tasks.

</details>


### [160] [FrugalPrompt: Reducing Contextual Overhead in Large Language Models via Token Attribution](https://arxiv.org/abs/2510.16439)
*Syed Rifat Raiyan,Md Farhan Ishmam,Abdullah Al Imran,Mohammad Ali Moni*

Main category: cs.CL

TL;DR: FrugalPrompt是一种新颖的LLM提示压缩框架，通过保留最具语义重要性的token来减少输入长度，在多个NLP任务中实现20%压缩率时仅带来边际性能损失，但在数学推理任务上性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的冗长输入会增加成本、碳足迹和推理延迟，而典型提示中存在大量冗余的低效用token，只有少数token承载主要语义权重。

Method: 利用GlobEnc和DecompX两种token归因方法为输入序列中的每个token分配显著性分数，按原始顺序保留前k%的token，获得稀疏的压缩提示。

Result: 在情感分析、常识问答和摘要任务中，20%的提示压缩仅带来边际性能损失；但在数学推理任务上性能急剧恶化；使用底部k%和随机k%token的分析揭示了不对称性能模式。

Conclusion: 该工作有助于更细致地理解LLM在性能-效率权衡中的行为，界定了容忍上下文稀疏性的任务与需要完整上下文的任务之间的边界。

Abstract: Large language models (LLMs) owe much of their stellar performance to
expansive input contexts, yet such verbosity inflates monetary costs, carbon
footprint, and inference-time latency. Much of this overhead manifests from the
redundant low-utility tokens present in typical prompts, as only a fraction of
tokens typically carries the majority of the semantic weight. We address this
inefficiency by introducing FrugalPrompt, a novel prompt compression framework
for LLMs, which retains only the most semantically significant tokens.
Leveraging two state-of-the-art token attribution methods, GlobEnc and DecompX,
we assign salience scores to every token in an input sequence, rank them to
preserve the top-k% tokens in their original order, and obtain a sparse
frugalized prompt. We evaluate the approach across four NLP tasks: Sentiment
Analysis, Commonsense QA, Summarization, and Mathematical Reasoning, using a
suite of frontier LLMs. For the first three tasks, a 20% prompt reduction
incurs only a marginal loss in task performance, demonstrating that
contemporary LLMs can reconstruct elided context from high-salience cues. In
contrast, performance on mathematical reasoning deteriorates sharply,
reflecting a stronger dependence on complete token continuity. Further analysis
with bottom-k% and random-k% tokens reveals asymmetric performance patterns
that may suggest potential task contamination effects, wherein models may
resort to shallow memorized patterns from pretraining exposure for conventional
NLP tasks. We posit that our work contributes to a more nuanced understanding
of LLM behavior in performance-efficiency trade-offs, and delineate the
boundary between tasks tolerant to contextual sparsity and those requiring
exhaustive context. Our source code and models are available at:
https://github.com/Starscream-11813/Frugal-ICL

</details>


### [161] [BenCao: An Instruction-Tuned Large Language Model for Traditional Chinese Medicine](https://arxiv.org/abs/2510.17415)
*Jiacheng Xie,Yang Yu,Yibo Chen,Hanyao Zhang,Lening Zhao,Jiaxuan He,Lei Jiang,Xiaoting Tang,Guanghui An,Dong Xu*

Main category: cs.CL

TL;DR: 本文开发了BenCao，一个基于ChatGPT的中医多模态助手，通过自然语言指令调优而非参数重训练，整合了结构化知识库、诊断数据和专家反馈，在中医问答和多模态分类任务中表现优于通用领域和中医领域模型。


<details>
  <summary>Details</summary>
Motivation: 传统中医依赖整体推理、隐含逻辑和多模态诊断线索，现有中医领域大语言模型在文本理解方面取得进展，但缺乏多模态整合、可解释性和临床适用性。

Method: 开发BenCao系统，整合超过1000部经典和现代文本的知识库，采用基于场景的指令框架，包含思维链模拟机制用于可解释推理，并涉及持证中医师的反馈精炼过程，连接外部API进行舌像分类和多模态数据库检索。

Result: 在单选择题基准测试和多模态分类任务评估中，BenCao在诊断、草药识别和体质分类方面实现了优于通用领域和中医领域模型的准确率，截至2025年10月已在OpenAI GPTs商店部署，被全球近1000名用户访问。

Conclusion: 本研究证明了通过基于自然语言的指令调优和多模态整合开发中医领域大语言模型的可行性，为将生成式AI与传统医学推理对齐提供了实用框架，并为实际部署提供了可扩展路径。

Abstract: Traditional Chinese Medicine (TCM), with a history spanning over two
millennia, plays a role in global healthcare. However, applying large language
models (LLMs) to TCM remains challenging due to its reliance on holistic
reasoning, implicit logic, and multimodal diagnostic cues. Existing TCM-domain
LLMs have made progress in text-based understanding but lack multimodal
integration, interpretability, and clinical applicability. To address these
limitations, we developed BenCao, a ChatGPT-based multimodal assistant for TCM,
integrating structured knowledge bases, diagnostic data, and expert feedback
refinement. BenCao was trained through natural language instruction tuning
rather than parameter retraining, aligning with expert-level reasoning and
ethical norms specific to TCM. The system incorporates a comprehensive
knowledge base of over 1,000 classical and modern texts, a scenario-based
instruction framework for diverse interactions, a chain-of-thought simulation
mechanism for interpretable reasoning, and a feedback refinement process
involving licensed TCM practitioners. BenCao connects to external APIs for
tongue-image classification and multimodal database retrieval, enabling dynamic
access to diagnostic resources. In evaluations across single-choice question
benchmarks and multimodal classification tasks, BenCao achieved superior
accuracy to general-domain and TCM-domain models, particularly in diagnostics,
herb recognition, and constitution classification. The model was deployed as an
interactive application on the OpenAI GPTs Store, accessed by nearly 1,000
users globally as of October 2025. This study demonstrates the feasibility of
developing a TCM-domain LLM through natural language-based instruction tuning
and multimodal integration, offering a practical framework for aligning
generative AI with traditional medical reasoning and a scalable pathway for
real-world deployment.

</details>


### [162] [TrajSelector: Harnessing Latent Representations for Efficient and Effective Best-of-N in Large Reasoning Model](https://arxiv.org/abs/2510.16449)
*Bin Yu,Xinming Wang,Shijie Lian,Haotian Li,Changti Wu,Ruina Hu,Bailing Wang,Yuliang Wei,Kai Chen*

Main category: cs.CL

TL;DR: TrajSelector是一个高效的Best-of-N框架，利用LLM隐藏状态进行过程级评分，通过轻量级验证器评估推理轨迹质量，在保持较低推理成本的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有外部测试时扩展方法面临计算开销高和LLM内在潜在表示利用不足的问题，需要更高效的Best-of-N选择框架。

Method: 使用轻量级验证器（仅0.6B参数）评估步骤级轨迹质量，聚合得分识别最优推理轨迹，采用端到端训练方法无需大量步骤级标注。

Result: 在五个基准测试中，TrajSelector在Best-of-32设置下比多数投票准确率高4.61%，比现有过程奖励模型高4.31%到12.21%，同时保持较低推理成本。

Conclusion: TrajSelector通过有效利用LLM隐藏状态，提供了一个计算效率高且性能优越的Best-of-N推理轨迹选择框架。

Abstract: Large language models (LLMs) have shown remarkable progress in complex
reasoning tasks, largely enabled by test-time scaling (TTS) paradigms that
allocate additional compute during inference. Among these, external TTS
(particularly the Best-of-N selection paradigm) yields scalable performance
improvements by selecting from multiple independently generated reasoning
trajectories. However, this approach faces key limitations: (i) the high
computational overhead of deploying process reward models, (ii) the
underutilization of the LLM's intrinsic latent representations. We introduce
TrajSelector, an efficient and effective Best-of-N framework that exploit the
hidden states in the sampler LLM for process-level scoring. A lightweight
verifier (with only 0.6B parameters) evaluates the quality of step-wise
trajectory, and then aggregates these scores to identify the optimal reasoning
trajectory. Our framework employs a fully data-driven, end-to-end training
recipe that eliminates reliance on massive step-level annotations. Experiential
results across five benchmarks demonstrate that TrajSelector delivers
consistent performance gains. In Best-of-32 settings, it surpasses majority
voting by 4.61% accuracy and outperforms existing process reward models by
4.31% to 12.21%, all while maintaining lower inference costs.

</details>


### [163] [RAVEN: Robust Advertisement Video Violation Temporal Grounding via Reinforcement Reasoning](https://arxiv.org/abs/2510.16455)
*Deyi Ji,Yuekui Yang,Haiyang Wu,Shaoping Ma,Tianrun Chen,Lanyun Zhu*

Main category: cs.CL

TL;DR: RAVEN是一个用于广告视频违规检测的新框架，结合课程强化学习和多模态大语言模型，通过渐进式训练策略和GRPO优化方法，在工业数据集和公共基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有广告视频违规检测方法在精确时间定位、噪声标注和泛化能力方面存在不足，需要开发更有效的解决方案。

Method: 集成课程强化学习与多模态大语言模型，采用渐进式训练策略结合精确和粗略标注数据，使用GRPO开发推理能力，并设计多层次复杂奖励机制。

Result: 在工业数据集和公共基准测试中，RAVEN在违规类别准确性和时间间隔定位方面表现优异，在线A/B测试验证了其实际应用价值，精度和召回率显著提升。

Conclusion: RAVEN框架有效解决了广告视频违规检测的关键挑战，展示了强大的泛化能力，并成功部署到在线广告服务中。

Abstract: Advertisement (Ad) video violation detection is critical for ensuring
platform compliance, but existing methods struggle with precise temporal
grounding, noisy annotations, and limited generalization. We propose RAVEN, a
novel framework that integrates curriculum reinforcement learning with
multimodal large language models (MLLMs) to enhance reasoning and cognitive
capabilities for violation detection. RAVEN employs a progressive training
strategy, combining precisely and coarsely annotated data, and leverages Group
Relative Policy Optimization (GRPO) to develop emergent reasoning abilities
without explicit reasoning annotations. Multiple hierarchical sophisticated
reward mechanism ensures precise temporal grounding and consistent category
prediction. Experiments on industrial datasets and public benchmarks show that
RAVEN achieves superior performances in violation category accuracy and
temporal interval localization. We also design a pipeline to deploy the RAVEN
on the online Ad services, and online A/B testing further validates its
practical applicability, with significant improvements in precision and recall.
RAVEN also demonstrates strong generalization, mitigating the catastrophic
forgetting issue associated with supervised fine-tuning.

</details>


### [164] [Agree, Disagree, Explain: Decomposing Human Label Variation in NLI through the Lens of Explanations](https://arxiv.org/abs/2510.16458)
*Pingjun Hong,Beiduo Chen,Siyao Peng,Marie-Catherine de Marneffe,Benjamin Roth,Barbara Plank*

Main category: cs.CL

TL;DR: 本文扩展了NLI数据集中人类标注变异的分析范围，不仅关注标注者间标签一致但解释不同的情况，还研究标注者间标签和推理类型均存在分歧的情况。通过LiTEx分类法分析两个英文NLI数据集，发现表面标签分歧可能掩盖深层的解释一致性，且标注者存在个体偏好。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注标注者标签一致但解释不同的情况，而本文旨在更全面地分析NLI数据集中的人类标注变异，包括标注者在标签选择和推理类型上的分歧，以揭示表面分歧下的深层一致性。

Method: 使用LiTEx分类法对两个英文NLI数据集进行分析，从NLI标签一致性、解释相似性和分类法一致性三个维度对齐标注变异，并考虑标注者的选择偏差因素。

Result: 发现标注者标签不一致但解释高度相似的情况，表明表面标签分歧可能掩盖深层解释一致性；同时揭示了标注者在解释策略和标签选择上的个体偏好；推理类型一致性比标签一致性更能反映自由文本解释的语义相似性。

Conclusion: 基于推理的解释具有丰富性，需要谨慎将标签视为绝对真实；推理类型一致性比标签一致性更能准确反映标注者的语义理解。

Abstract: Natural Language Inference datasets often exhibit human label variation. To
better understand these variations, explanation-based approaches analyze the
underlying reasoning behind annotators' decisions. One such approach is the
LiTEx taxonomy, which categorizes free-text explanations in English into
reasoning types. However, previous work applying such taxonomies has focused on
within-label variation: cases where annotators agree on the final NLI label but
provide different explanations. In contrast, this paper broadens the scope by
examining how annotators may diverge not only in the reasoning type but also in
the labeling step. We use explanations as a lens to decompose the reasoning
process underlying NLI annotation and to analyze individual differences. We
apply LiTEx to two NLI English datasets and align annotation variation from
multiple aspects: NLI label agreement, explanation similarity, and taxonomy
agreement, with an additional compounding factor of annotators' selection bias.
We observe instances where annotators disagree on the label but provide highly
similar explanations, suggesting that surface-level disagreement may mask
underlying agreement in interpretation. Moreover, our analysis reveals
individual preferences in explanation strategies and label choices. These
findings highlight that agreement in reasoning types better reflects the
semantic similarity of free-text explanations than label agreement alone. Our
findings underscore the richness of reasoning-based explanations and the need
for caution in treating labels as ground truth.

</details>


### [165] [Automated Composition of Agents: A Knapsack Approach for Agentic Component Selection](https://arxiv.org/abs/2510.16499)
*Michelle Yuan,Khushbu Pahwa,Shuaichen Chang,Mustafa Kaba,Jiarong Jiang,Xiaofei Ma,Yi Zhang,Monica Sunkara*

Main category: cs.CL

TL;DR: 提出基于在线背包问题的自动化智能体系统组合框架，通过动态测试和实时效用建模，在预算约束下优化选择智能体组件，显著提升成功率和降低成本。


<details>
  <summary>Details</summary>
Motivation: 现有智能体系统组合方法依赖静态语义检索，存在能力描述不完整、检索方法局限等问题，无法基于能力、成本和实时效用进行组件选择。

Method: 引入受背包问题启发的结构化自动化框架，让组合器智能体系统性地识别、选择和组装最优智能体组件集合，同时考虑性能、预算约束和兼容性。

Result: 在5个基准数据集上的实验表明，基于在线背包的组合器始终位于帕累托前沿，单智能体设置下成功率提升达31.6%，多智能体系统中从100+智能体库中选择时成功率从37%提升至87%。

Conclusion: 该方法在多样化领域和预算约束下展现出强大的适应性，显著提升了智能体系统的组合效率和性能。

Abstract: Designing effective agentic systems requires the seamless composition and
integration of agents, tools, and models within dynamic and uncertain
environments. Most existing methods rely on static, semantic retrieval
approaches for tool or agent discovery. However, effective reuse and
composition of existing components remain challenging due to incomplete
capability descriptions and the limitations of retrieval methods. Component
selection suffers because the decisions are not based on capability, cost, and
real-time utility. To address these challenges, we introduce a structured,
automated framework for agentic system composition that is inspired by the
knapsack problem. Our framework enables a composer agent to systematically
identify, select, and assemble an optimal set of agentic components by jointly
considering performance, budget constraints, and compatibility. By dynamically
testing candidate components and modeling their utility in real-time, our
approach streamlines the assembly of agentic systems and facilitates scalable
reuse of resources. Empirical evaluation with Claude 3.5 Sonnet across five
benchmarking datasets shows that our online-knapsack-based composer
consistently lies on the Pareto frontier, achieving higher success rates at
significantly lower component costs compared to our baselines. In the
single-agent setup, the online knapsack composer shows a success rate
improvement of up to 31.6% in comparison to the retrieval baselines. In
multi-agent systems, the online knapsack composer increases success rate from
37% to 87% when agents are selected from an agent inventory of 100+ agents. The
substantial performance gap confirms the robust adaptability of our method
across diverse domains and budget constraints.

</details>


### [166] [ReviewGuard: Enhancing Deficient Peer Review Detection via LLM-Driven Data Augmentation](https://arxiv.org/abs/2510.16549)
*Haoxuan Zhang,Ruochi Li,Sarthak Shrestha,Shree Harshini Mamidala,Revanth Putta,Arka Krishan Aggarwal,Ting Xiao,Junhua Ding,Haihua Chen*

Main category: cs.CL

TL;DR: 本文介绍了ReviewGuard系统，这是一个用于检测和分类缺陷同行评审的自动化系统。该系统采用四阶段LLM驱动框架，通过数据收集、标注、合成数据增强和模型微调，构建了一个包含66,634篇论文、24,657条真实评审和46,438条合成评审的语料库。研究发现缺陷评审具有评分较低、自信度较高、结构复杂性较低和负面情绪较多的特征。


<details>
  <summary>Details</summary>
Motivation: 同行评审作为科学的守门人，面临着提交量激增和大语言模型在学术评估中广泛采用带来的前所未有的挑战。未经检查的缺陷评审（无论是来自人类专家还是AI系统）可能会系统性地破坏同行评审生态系统并损害学术诚信。

Method: 采用四阶段LLM驱动框架：1)从OpenReview收集ICLR和NeurIPS论文及其评审；2)使用GPT-4标注评审类型并进行人工验证；3)通过LLM驱动的合成数据增强解决类别不平衡和数据稀缺问题；4)微调编码器模型和开源LLM。

Result: 缺陷评审表现出较低的评分分数、较高的自报告自信度、减少的结构复杂性以及较高比例的负面情绪。自ChatGPT出现以来，AI生成的评审数量急剧增加。在缺陷评审检测模型评估中，使用合成和真实评审数据的混合训练显著提高了二元任务的召回率和F1分数。

Conclusion: 本研究提出了首个用于检测缺陷同行评审的LLM驱动系统，为同行评审中的AI治理提供了证据，并为维护学术诚信的人机协作提供了宝贵见解。

Abstract: Peer review serves as the gatekeeper of science, yet the surge in submissions
and widespread adoption of large language models (LLMs) in scholarly evaluation
present unprecedented challenges. Recent work has focused on using LLMs to
improve review efficiency or generate insightful review content. However,
unchecked deficient reviews from both human experts and AI systems threaten to
systematically undermine the peer review ecosystem and compromise academic
integrity. To address this critical issue, we introduce ReviewGuard, an
automated system for detecting and categorizing deficient reviews. ReviewGuard
employs a comprehensive four-stage LLM-driven framework that: (1) collects ICLR
and NeurIPS papers with their corresponding reviews from OpenReview; (2)
annotates review types using GPT-4.1 with human validation; (3) addresses class
imbalance and data scarcity through LLM-driven synthetic data augmentation,
producing a final corpus of 6,634 papers, 24,657 real reviews, and 46,438
synthetic reviews; and (4) fine-tunes both encoder-based models and open source
LLMs. We perform comprehensive feature analysis of the structure and quality of
the review text. Compared to sufficient reviews, deficient reviews demonstrate
lower rating scores, higher self-reported confidence, reduced structural
complexity, and a higher proportion of negative sentiment. AI-generated text
detection reveals that, since ChatGPT's emergence, AI-generated reviews have
increased dramatically. In the evaluation of deficient review detection models,
mixed training with synthetic and real review data provides substantial
enhancements to recall and F1 scores on the binary task. This study presents
the first LLM-driven system for detecting deficient peer reviews, providing
evidence to inform AI governance in peer review while offering valuable
insights into human-AI collaboration to maintain academic integrity.

</details>


### [167] [Language over Content: Tracing Cultural Understanding in Multilingual Large Language Models](https://arxiv.org/abs/2510.16565)
*Seungho Cho,Changgeon Ko,Eui Jun Hwang,Junmyeong Lee,Huije Lee,Jong C. Park*

Main category: cs.CL

TL;DR: 本文通过分析LLMs在回答文化相关问题时内部激活路径的重叠情况，揭示了语言对文化理解机制的重要影响，发现相同语言不同国家的内部路径重叠度高于不同语言相同国家的情况。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在多元文化背景下的广泛应用，准确的文化理解变得至关重要。现有评估主要关注输出层面的表现，而缺乏对驱动响应差异的内部机制分析。

Method: 通过测量LLMs在回答语义相同但条件不同问题时的激活路径重叠：一是固定问题语言变化目标国家，二是固定国家变化问题语言；同时使用相同语言的国家对来区分语言和文化因素。

Result: 结果显示，相同语言不同国家的内部路径重叠度高于不同语言相同国家的情况，表明存在强烈的语言特定模式。特别地，韩国-朝鲜对表现出低重叠度和高变异性，说明语言相似性不能保证内部表征的一致性。

Conclusion: 语言在LLMs的文化理解机制中起着关键作用，语言相似性并不必然导致文化理解的内部表征对齐，这对跨文化应用具有重要意义。

Abstract: Large language models (LLMs) are increasingly used across diverse cultural
contexts, making accurate cultural understanding essential. Prior evaluations
have mostly focused on output-level performance, obscuring the factors that
drive differences in responses, while studies using circuit analysis have
covered few languages and rarely focused on culture. In this work, we trace
LLMs' internal cultural understanding mechanisms by measuring activation path
overlaps when answering semantically equivalent questions under two conditions:
varying the target country while fixing the question language, and varying the
question language while fixing the country. We also use same-language country
pairs to disentangle language from cultural aspects. Results show that internal
paths overlap more for same-language, cross-country questions than for
cross-language, same-country questions, indicating strong language-specific
patterns. Notably, the South Korea-North Korea pair exhibits low overlap and
high variability, showing that linguistic similarity does not guarantee aligned
internal representation.

</details>


### [168] [Hallucination Benchmark for Speech Foundation Models](https://arxiv.org/abs/2510.16567)
*Alkis Koudounas,Moreno La Quatra,Manuel Giollo,Sabato Marco Siniscalchi,Elena Baralis*

Main category: cs.CL

TL;DR: SHALLOW是首个系统分类和量化ASR系统中幻觉现象的基准框架，通过词汇、语音、形态和语义四个互补维度来评估模型生成幻觉内容的倾向。


<details>
  <summary>Details</summary>
Motivation: ASR系统中的幻觉会产生与语音信号完全无关但语法语义合理的转录，这在医疗和法律等关键领域带来严重风险。传统评估指标无法区分语音不准确性和幻觉，需要新的评估框架。

Method: 提出SHALLOW框架，从四个维度系统分类幻觉现象：词汇、语音、形态和语义，并为每个类别定义针对性指标，生成可解释的模型行为分析。

Result: 评估显示SHALLOW指标在识别质量高时与WER强相关，但随着WER增加相关性显著减弱。SHALLOW能捕捉WER在退化条件下无法区分的细粒度错误模式。

Conclusion: SHALLOW框架支持对模型弱点的具体诊断，并提供超越聚合错误率的模型改进反馈，为ASR系统的幻觉评估提供了有效工具。

Abstract: Hallucinations in automatic speech recognition (ASR) systems refer to fluent
and coherent transcriptions produced by neural ASR models that are completely
unrelated to the underlying acoustic input (i.e., the speech signal). While
similar to conventional decoding errors in potentially compromising the
usability of transcriptions for downstream applications, hallucinations can be
more detrimental due to their preservation of syntactically and semantically
plausible structure. This apparent coherence can mislead subsequent processing
stages and introduce serious risks, particularly in critical domains such as
healthcare and law. Conventional evaluation metrics are primarily centered on
error-based metrics and fail to distinguish between phonetic inaccuracies and
hallucinations. Consequently, there is a critical need for new evaluation
frameworks that can effectively identify and assess models with a heightened
propensity for generating hallucinated content. To this end, we introduce
SHALLOW, the first benchmark framework that systematically categorizes and
quantifies hallucination phenomena in ASR along four complementary axes:
lexical, phonetic, morphological, and semantic. We define targeted metrics
within each category to produce interpretable profiles of model behavior.
Through evaluation across various architectures and speech domains, we have
found that SHALLOW metrics correlate strongly with word error rate (WER) when
recognition quality is high (i.e., low WER). Still, this correlation weakens
substantially as WER increases. SHALLOW, therefore, captures fine-grained error
patterns that WER fails to distinguish under degraded and challenging
conditions. Our framework supports specific diagnosis of model weaknesses and
provides feedback for model improvement beyond what aggregate error rates can
offer.

</details>


### [169] [AI-Generated Text Detection in Low-Resource Languages: A Case Study on Urdu](https://arxiv.org/abs/2510.16573)
*Muhammad Ammar,Hadiya Murad Hadi,Usman Majeed Butt*

Main category: cs.CL

TL;DR: 该研究提出了一个针对乌尔都语的AI生成文本检测框架，通过构建包含1800篇人类撰写和1800篇AI生成文本的平衡数据集，并基于多语言transformer模型进行微调，其中mDeBERTa-v3-base模型在测试集上取得了91.29%的F1分数和91.26%的准确率。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型生成文本能力的提升，区分人类撰写和AI生成文本变得困难，特别是在乌尔都语等低资源语言中缺乏相应的检测工具，这给打击错误信息和学术不端带来了挑战。

Method: 构建平衡数据集（1800篇人类文本+1800篇AI文本），进行详细的语言学和统计分析（字符/词数、词汇丰富度、N-gram模式等），并微调三种最先进的多语言transformer模型（mdeberta-v3-base、distilbert-base-multilingualcased、xlm-roberta-base）。

Result: mDeBERTa-v3-base模型表现最佳，在测试集上达到91.29%的F1分数和91.26%的准确率。

Conclusion: 该研究推进了乌尔都语社区打击错误信息和学术不端的努力，并为低资源语言的NLP工具开发做出了贡献。

Abstract: Large Language Models (LLMs) are now capable of generating text that closely
resembles human writing, making them powerful tools for content creation, but
this growing ability has also made it harder to tell whether a piece of text
was written by a human or by a machine. This challenge becomes even more
serious for languages like Urdu, where there are very few tools available to
detect AI-generated text. To address this gap, we propose a novel AI-generated
text detection framework tailored for the Urdu language. A balanced dataset
comprising 1,800 humans authored, and 1,800 AI generated texts, sourced from
models such as Gemini, GPT-4o-mini, and Kimi AI was developed. Detailed
linguistic and statistical analysis was conducted, focusing on features such as
character and word counts, vocabulary richness (Type Token Ratio), and N-gram
patterns, with significance evaluated through t-tests and MannWhitney U tests.
Three state-of-the-art multilingual transformer models such as
mdeberta-v3-base, distilbert-base-multilingualcased, and xlm-roberta-base were
fine-tuned on this dataset. The mDeBERTa-v3-base achieved the highest
performance, with an F1-score 91.29 and accuracy of 91.26% on the test set.
This research advances efforts in contesting misinformation and academic
misconduct in Urdu-speaking communities and contributes to the broader
development of NLP tools for low resource languages.

</details>


### [170] [Fine-tuning of Large Language Models for Constituency Parsing Using a Sequence to Sequence Approach](https://arxiv.org/abs/2510.16604)
*Francisco Jose Cortes Delgado,Eduardo Martinez Gracia,Rafael Valencia Garcia*

Main category: cs.CL

TL;DR: 通过微调大型语言模型将句子翻译为对应句法结构，扩展西班牙语法教学工具MiSintaxis的功能，在短语结构分析中取得高准确率。


<details>
  <summary>Details</summary>
Motivation: 探索基于机器学习的大规模神经模型在句法分析中的新可能性，扩展西班牙语法教学工具MiSintaxis的功能。

Method: 使用AnCora-ES语料库生成的训练数据微调Hugging Face仓库中的多个大型语言模型，让模型学习将输入句子翻译为对应的句法结构。

Result: 使用F1分数评估模型性能，结果显示在短语结构分析中取得了高准确率。

Conclusion: 该方法展示了将大型语言模型用于句法分析的潜力，为语法教学工具提供了有效的技术支撑。

Abstract: Recent advances in natural language processing with large neural models have
opened new possibilities for syntactic analysis based on machine learning. This
work explores a novel approach to phrase-structure analysis by fine-tuning
large language models (LLMs) to translate an input sentence into its
corresponding syntactic structure. The main objective is to extend the
capabilities of MiSintaxis, a tool designed for teaching Spanish syntax.
Several models from the Hugging Face repository were fine-tuned using training
data generated from the AnCora-ES corpus, and their performance was evaluated
using the F1 score. The results demonstrate high accuracy in phrase-structure
analysis and highlight the potential of this methodology.

</details>


### [171] [All You Need is One: Capsule Prompt Tuning with a Single Vector](https://arxiv.org/abs/2510.16670)
*Yiyang Liu,James C. Liang,Heng Fan,Wenhao Yang,Yiming Cui,Xiaotian Han,Lifu Huang,Dongfang Liu,Qifan Wang,Cheng Han*

Main category: cs.CL

TL;DR: 本文提出Capsule Prompt-Tuning (CaPT)方法，通过将实例感知信息与任务感知信息结合在单个胶囊提示中，解决了传统提示学习方法依赖网格搜索和缺乏实例感知信息的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于提示的学习方法严重依赖网格搜索来确定最佳提示长度，且需要大量提示，计算负担重。更重要的是，任务感知提示设计缺乏实例感知信息，导致与输入序列的注意力交互受限。

Method: 提出Capsule Prompt-Tuning (CaPT)方法，利用现成的信息性实例语义，将实例感知和任务感知信息以近乎参数免费的方式（即单个胶囊提示）集成到提示学习中。

Result: 实证结果显示，该方法在各种语言任务上表现出优越性能（如在T5-Large上平均准确率达到84.03%），同时保持高参数效率（如在Llama3.2-1B上仅使用模型参数的0.003%）。

Conclusion: CaPT方法通过引入实例感知信息作为"注意力锚点"，成功提升了提示调优模型的性能，同时保持了高参数效率，为提示学习提供了更高效有效的解决方案。

Abstract: Prompt-based learning has emerged as a parameter-efficient finetuning (PEFT)
approach to facilitate Large Language Model (LLM) adaptation to downstream
tasks by conditioning generation with task-aware guidance. Despite its
successes, current prompt-based learning methods heavily rely on laborious grid
searching for optimal prompt length and typically require considerable number
of prompts, introducing additional computational burden. Worse yet, our pioneer
findings indicate that the task-aware prompt design is inherently limited by
its absence of instance-aware information, leading to a subtle attention
interplay with the input sequence. In contrast, simply incorporating
instance-aware information as a part of the guidance can enhance the
prompt-tuned model performance without additional fine-tuning. Moreover, we
find an interesting phenomenon, namely "attention anchor", that incorporating
instance-aware tokens at the earliest position of the sequence can successfully
preserve strong attention to critical structural information and exhibit more
active attention interaction with all input tokens. In light of our
observation, we introduce Capsule Prompt-Tuning (CaPT), an efficient and
effective solution that leverages off-the-shelf, informative instance semantics
into prompt-based learning. Our approach innovatively integrates both
instance-aware and task-aware information in a nearly parameter-free manner
(i.e., one single capsule prompt). Empirical results demonstrate that our
method can exhibit superior performance across various language tasks (e.g.,
84.03\% average accuracy on T5-Large), serving as an "attention anchor," while
enjoying high parameter efficiency (e.g., 0.003\% of model parameters on
Llama3.2-1B).

</details>


### [172] [Temporal Understanding under Deictic Frame of Reference](https://arxiv.org/abs/2510.16685)
*Damin Zhang,Julia Rayz*

Main category: cs.CL

TL;DR: 该研究评估了大型语言模型在动态时间参考框架下对时间-事件和事件-事件关系的理解能力，发现LLMs表现出部分类似人类的时间认知，但对时间距离和参考点变化敏感。


<details>
  <summary>Details</summary>
Motivation: 人类通过空间隐喻理解时间，使用时间参考框架(t-FoR)来感知相对于"现在"的时间关系。虽然LLMs在自然语言理解方面取得显著进展，但其时间理解和推理能力仍然有限，需要评估它们在动态时间参考框架下的表现。

Method: 引入TUuD框架，通过提示LLMs评估当前时刻与目标事件之间的相似性（0.00-1.00），量化两个时间点之间的感知时间对齐程度，测试LLMs在"现在"参考点沿时间线动态移动时的表现。

Result: 四个评估的LLMs表现出对指示性t-FoR的可测量适应，相似性评分在现在附近达到峰值，并向过去和未来事件递减。然而，这种适应在超出近期上下文时会减弱。

Conclusion: LLMs显示出部分类似人类的时间认知，但其时间推理仍然对参考框架变化和时间距离敏感，表明其时间理解能力存在局限性。

Abstract: Understanding time is fundamental to human cognition, where temporal
experience is often conceptualized through spatial metaphors grounded in
sensory-motor experience. For example, "summer is approaching" parallels "We
are approaching the summer". In such expressions, humans rely on a frame of
reference (FoR) to interpret meaning relative to a particular viewpoint.
Extending this concept to time, a temporal frame of reference (t-FoR) defines
how temporal relations are perceived relative to an experiencer's moment of
"now". While Large Language Models (LLMs) have shown remarkable advances in
natural language understanding, their ability to interpret and reason about
time remains limited. In this work, we introduce TUuD (Temporal Understanding
under Deictic t-FoR), a framework that evaluates how LLMs interpret time-event
and event-event relations when the reference point of "now" dynamically shifts
along a timeline. Following recent work on temporal cognition
\cite{li2025other}, LLMs are prompted to rate the similarity between the
current moment and a target event from 0.00 (completely dissimilar) to 1.00
(highly similar), where similarity quantifies perceived temporal alignment
between the two points. Our results show that four evaluated LLMs exhibit
measurable adaptation to a deictic t-FoR, with similarity ratings peaking
around the present and decreasing toward past and future events. The
adaptation, however, weakens beyond near-term contexts, suggesting that while
LLMs display partial human-like temporal cognition, their temporal reasoning
remains sensitive to reference-frame shifts and temporal distance.

</details>


### [173] [Investigating the Impact of Rationales for LLMs on Natural Language Understanding](https://arxiv.org/abs/2510.16686)
*Wenhang Shi,Shuqing Bian,Yiren Chen,Xinyi Zhang,Zhe Zhao,Pengfei Hu,Wei Lu,Xiaoyong Du*

Main category: cs.CL

TL;DR: 本文探讨了思维链（CoT）推理在自然语言理解（NLU）任务中的应用效果，发现随着模型规模增大，CoT推理从阻碍性能转变为超越直接标签预测，但大多数基于理性的训练方法效果不如纯标签训练，只有一种特殊设计的方法能持续提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注思维链推理在数学、符号和常识推理任务中的作用，而忽视了其在自然语言理解任务中的潜在影响。本文旨在系统性地探索理性推理是否同样能提升NLU任务的性能。

Method: 构建了NLURC数据集，这是一个包含理性推理的综合高质量NLU数据集集合，并开发了多种基于理性的增强方法，在NLU任务上进行了系统性的探索。

Result: 研究发现：(1) CoT推理效果与模型规模正相关，大模型中使用CoT推理能超越直接标签预测；(2) 大多数理性增强训练方法效果不如纯标签训练，只有一种特殊设计的方法能持续改进；(3) 使用理性训练的LLM在未见过的NLU任务上表现显著提升，性能可与十倍规模模型媲美，同时保持与商业LLM相当的interpretability。

Conclusion: 理性推理在NLU任务中具有重要价值，特别是在大模型和迁移学习场景下，能够显著提升性能并增强模型的可解释性，但需要精心设计训练方法才能充分发挥其潜力。

Abstract: Chain-of-thought (CoT) rationales, which provide step-by-step reasoning to
derive final answers, benefit LLMs in both inference and training.
Incorporating rationales, either by generating them before answering during
inference, or by placing them before or after the original answers during
training - significantly improves model performance on mathematical, symbolic
and commonsense reasoning tasks. However, most work focuses on the role of
rationales in these reasoning tasks, overlooking their potential impact on
other important tasks like natural language understanding (NLU) tasks. In this
work, we raise the question: Can rationales similarly benefit NLU tasks? To
conduct a systematic exploration, we construct NLURC, a comprehensive and
high-quality NLU dataset collection with rationales, and develop various
rationale-augmented methods. Through exploring the applicability of these
methods on NLU tasks using the dataset, we uncover several potentially
surprising findings: (1) CoT inference shifts from hindering NLU performance to
surpassing direct label prediction as model size grows, indicating a positive
correlation. (2) Most rationale-augmented training methods perform worse than
label-only training, with one specially designed method consistently achieving
improvements. (3) LLMs trained with rationales achieve significant performance
gains on unseen NLU tasks, rivaling models ten times their size, while
delivering interpretability on par with commercial LLMs.

</details>


### [174] [Natural Language Processing Applications in Cardiology: A Narrative Review](https://arxiv.org/abs/2510.16708)
*Kailai Yang,Yan Leng,Xin Zhang,Tianlin Zhang,Paul Thompson,Bernard Keavney,Maciej Tomaszewski,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 这篇综述论文系统回顾了2014-2025年间自然语言处理技术在心脏病学领域的应用研究，分析了265篇相关文献，从NLP范式类型、心脏病相关任务类型、心血管疾病类型和数据源类型等多个维度进行了全面分析。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病日益普遍且对全球健康产生重大影响，这些疾病受到遗传、生活方式和社会经济等多种因素影响，相关信息分散在患者叙述、医疗记录和科学文献等非结构化文本数据中，需要NLP技术来分析和理解这些复杂关系。

Method: 查询了六个文献数据库，通过严格筛选流程识别出265篇相关文章，从NLP范式类型、心脏病相关任务类型、心血管疾病类型和数据源类型等多个维度进行分析，并进行时间趋势分析。

Result: 分析显示在各个维度上都存在显著多样性，证明了NLP在心脏病学领域研究的广泛性，时间分析揭示了近十年来NLP方法的演变和变化趋势。

Conclusion: 这是迄今为止对心脏病学领域NLP研究最全面的综述，展示了NLP技术在心脏病诊断、治疗和预防方面的革命性潜力。

Abstract: Cardiovascular disease has become increasingly prevalent in modern society
and has a significant effect on global health and well-being. Heart-related
conditions are intricate, multifaceted disorders, which may be influenced by a
combination of genetic predispositions, lifestyle choices, and various
socioeconomic and clinical factors. Information regarding these potentially
complex interrelationships is dispersed among diverse types of textual data,
which include patient narratives, medical records, and scientific literature,
among others. Natural language processing (NLP) techniques have increasingly
been adopted as a powerful means to analyse and make sense of this vast amount
of unstructured data. This, in turn, can allow healthcare professionals to gain
deeper insights into the cardiology field, which has the potential to
revolutionize current approaches to the diagnosis, treatment, and prevention of
cardiac problems. This review provides a detailed overview of NLP research in
cardiology between 2014 and 2025. We queried six literature databases to find
articles describing the application of NLP techniques in the context of a range
of different cardiovascular diseases. Following a rigorous screening process,
we identified a total of 265 relevant articles. We analysed each article from
multiple dimensions, i.e., NLP paradigm types, cardiology-related task types,
cardiovascular disease types, and data source types. Our analysis reveals
considerable diversity within each of these dimensions, thus demonstrating the
considerable breadth of NLP research within the field. We also perform a
temporal analysis, which illustrates the evolution and changing trends in NLP
methods employed over the last decade that we cover. To our knowledge, the
review constitutes the most comprehensive overview of NLP research in
cardiology to date.

</details>


### [175] [The Chameleon Nature of LLMs: Quantifying Multi-Turn Stance Instability in Search-Enabled Language Models](https://arxiv.org/abs/2510.16712)
*Shivam Ratnakar,Sanjay Raghavendra*

Main category: cs.CL

TL;DR: 本文首次系统研究了LLM中的"变色龙行为"——在多轮对话中面对矛盾问题时立场不稳定的倾向。通过构建包含17,770个问答对的Chameleon基准数据集，评估了主流模型在12个争议领域的表现，发现所有模型都表现出严重的立场不稳定性。


<details>
  <summary>Details</summary>
Motivation: 集成大型语言模型与搜索/检索引擎已成为普遍做法，但这些系统存在关键漏洞，会削弱其可靠性。作者旨在揭示LLM在面对矛盾问题时立场不稳定的根本缺陷。

Method: 构建了新颖的Chameleon基准数据集，包含17,770个精心设计的问答对，涵盖1,180个多轮对话和12个争议领域。引入了两个理论基础的指标：Chameleon Score（量化立场不稳定性）和Source Re-use Rate（衡量知识多样性）。对Llama-4-Maverick、GPT-4o-mini和Gemini-2.5-Flash进行了严格评估。

Result: 所有模型都表现出严重的变色龙行为（得分0.391-0.511），其中GPT-4o-mini表现最差。跨温度方差很小（小于0.004），表明这不是采样伪影。分析发现源重用率与置信度（r=0.627）和立场变化（r=0.429）之间存在强相关性，且统计显著（p<0.05）。

Conclusion: 有限的知识多样性使模型病态地顺从查询框架，这些发现强调了在医疗、法律和金融系统部署LLM之前进行一致性评估的必要性，因为在这些领域保持跨交互的一致性立场对可靠决策支持至关重要。

Abstract: Integration of Large Language Models with search/retrieval engines has become
ubiquitous, yet these systems harbor a critical vulnerability that undermines
their reliability. We present the first systematic investigation of "chameleon
behavior" in LLMs: their alarming tendency to shift stances when presented with
contradictory questions in multi-turn conversations (especially in
search-enabled LLMs). Through our novel Chameleon Benchmark Dataset, comprising
17,770 carefully crafted question-answer pairs across 1,180 multi-turn
conversations spanning 12 controversial domains, we expose fundamental flaws in
state-of-the-art systems. We introduce two theoretically grounded metrics: the
Chameleon Score (0-1) that quantifies stance instability, and Source Re-use
Rate (0-1) that measures knowledge diversity. Our rigorous evaluation of
Llama-4-Maverick, GPT-4o-mini, and Gemini-2.5-Flash reveals consistent
failures: all models exhibit severe chameleon behavior (scores 0.391-0.511),
with GPT-4o-mini showing the worst performance. Crucially, small
across-temperature variance (less than 0.004) suggests the effect is not a
sampling artifact. Our analysis uncovers the mechanism: strong correlations
between source re-use rate and confidence (r=0.627) and stance changes
(r=0.429) are statistically significant (p less than 0.05), indicating that
limited knowledge diversity makes models pathologically deferential to query
framing. These findings highlight the need for comprehensive consistency
evaluation before deploying LLMs in healthcare, legal, and financial systems
where maintaining coherent positions across interactions is critical for
reliable decision support.

</details>


### [176] [so much depends / upon / a whitespace: Why Whitespace Matters for Poets and LLMs](https://arxiv.org/abs/2510.16713)
*Sriharsh Bhyravajjula,Melanie Walsh,Anna Preus,Maria Antoniak*

Main category: cs.CL

TL;DR: 该论文研究了诗歌中空格的重要性，分析了19k首诗歌的空格使用模式，比较了人类创作诗歌与LLM生成诗歌的空格差异，并探讨了不同文本处理方法对空格表示的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管空格是诗歌形式的关键组成部分，反映了诗人的艺术选择，但在NLP研究中未得到足够关注。论文旨在填补这一空白，研究诗歌中空格的使用模式及其意义。

Method: 使用来自Poetry Foundation的19k首英文诗歌语料库，分析4k位诗人的空格使用。比较了人类创作诗歌与51k首LLM生成诗歌以及12k首未发表诗歌的空格差异，并研究了不同时期、诗歌形式和数据来源的空格使用模式。

Result: 发现不同文本处理方法会导致诗歌数据中空格表示的显著差异。发布了2.8k首公共领域诗歌的子集以促进进一步研究。

Conclusion: 诗歌中的空格模式对理解诗人艺术选择很重要，不同数据处理策略会影响LLM预训练数据集中空格的表示，这对LLM的诗歌生成能力有重要影响。

Abstract: Whitespace is a critical component of poetic form, reflecting both adherence
to standardized forms and rebellion against those forms. Each poem's whitespace
distribution reflects the artistic choices of the poet and is an integral
semantic and spatial feature of the poem. Yet, despite the popularity of poetry
as both a long-standing art form and as a generation task for large language
models (LLMs), whitespace has not received sufficient attention from the NLP
community. Using a corpus of 19k English-language published poems from Poetry
Foundation, we investigate how 4k poets have used whitespace in their works. We
release a subset of 2.8k public-domain poems with preserved formatting to
facilitate further research in this area. We compare whitespace usage in the
published poems to (1) 51k LLM-generated poems, and (2) 12k unpublished poems
posted in an online community. We also explore whitespace usage across time
periods, poetic forms, and data sources. Additionally, we find that different
text processing methods can result in significantly different representations
of whitespace in poetry data, motivating us to use these poems and whitespace
patterns to discuss implications for the processing strategies used to assemble
pretraining datasets for LLMs.

</details>


### [177] [Beacon: Single-Turn Diagnosis and Mitigation of Latent Sycophancy in Large Language Models](https://arxiv.org/abs/2510.16727)
*Sanskar Pandey,Ruhaan Chopra,Angkul Puniya,Sohom Pal*

Main category: cs.CL

TL;DR: 论文提出了Beacon基准来测量大型语言模型中的谄媚偏见（sycophancy），即模型倾向于迎合用户而非坚持事实真相。研究发现这种偏见可分解为语言和情感子偏见，并随模型能力增强而加剧。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在奖励优化过程中混淆了帮助性和礼貌顺从，形成了在真实性和谄媚奉承之间的结构性权衡，这种潜在的谄媚偏见表现为偏好用户同意而非原则性推理。

Method: 引入Beacon基准，这是一个单轮强制选择测试，能够在独立于对话语境的情况下隔离这种偏见，精确测量事实准确性与顺从偏见之间的张力。

Result: 对12个最先进模型的评估显示，谄媚偏见可分解为稳定的语言和情感子偏见，每个子偏见都随模型容量而扩展。提出了提示级和激活级干预措施，可在相反方向上调节这些偏见。

Conclusion: Beacon将谄媚重新定义为可测量的规范性错误泛化形式，为研究和缓解大规模生成系统中的对齐漂移提供了可重复的基础。

Abstract: Large language models internalize a structural trade-off between truthfulness
and obsequious flattery, emerging from reward optimization that conflates
helpfulness with polite submission. This latent bias, known as sycophancy,
manifests as a preference for user agreement over principled reasoning. We
introduce Beacon, a single-turn forced-choice benchmark that isolates this bias
independent of conversational context, enabling precise measurement of the
tension between factual accuracy and submissive bias. Evaluations across twelve
state-of-the-art models reveal that sycophancy decomposes into stable
linguistic and affective sub-biases, each scaling with model capacity. We
further propose prompt-level and activation-level interventions that modulate
these biases in opposing directions, exposing the internal geometry of
alignment as a dynamic manifold between truthfulness and socially compliant
judgment. Beacon reframes sycophancy as a measurable form of normative
misgeneralization, providing a reproducible foundation for studying and
mitigating alignment drift in large-scale generative systems.

</details>


### [178] [Enhancing Language Agent Strategic Reasoning through Self-Play in Adversarial Games](https://arxiv.org/abs/2510.16761)
*Yikai Zhang,Ye Rong,Siyu Yuan,Jiangjie Chen,Jian Xie,Yanghua Xiao*

Main category: cs.CL

TL;DR: 提出SCO-PAL方法，通过对手选择分析发现自博弈是提升对抗环境中策略推理能力的最有效方式，相比基线方法平均胜率提高约30%，对GPT-4达到54.76%胜率。


<details>
  <summary>Details</summary>
Motivation: 现有语言智能体在动态对抗游戏中因策略推理能力不足而表现不佳，需要无需专家标注数据的自动学习方法。在动态对抗环境中，对手选择对学习性能有显著影响，但相关研究尚不充分。

Method: 提出SCO-PAL（Step-level poliCy Optimization through Play-And-Learn）方法，通过设置不同水平的对手进行详细分析，发现自博弈是最有效的学习方式。

Result: 使用SCO-PAL与自博弈，相比基线方法在四个对手上的平均胜率提高约30%，在六个对抗游戏中对抗GPT-4达到54.76%的胜率。

Conclusion: 自博弈是提升对抗环境中策略推理能力的最有效方法，SCO-PAL方法显著提高了语言智能体在动态对抗游戏中的表现。

Abstract: Existing language agents often encounter difficulties in dynamic adversarial
games due to poor strategic reasoning. To mitigate this limitation, a promising
approach is to allow agents to learn from game interactions automatically,
without relying on costly expert-labeled data. Unlike static environments where
agents receive fixed feedback or rewards, selecting appropriate opponents in
dynamic adversarial games can significantly impact learning performance.
However, the discussion of opponents in adversarial environments remains an
area under exploration. In this paper, we propose a Step-level poliCy
Optimization method through Play-And-Learn, SCO-PAL. Leveraging SCO-PAL, we
conduct a detailed analysis of opponent selection by setting opponents at
different levels and find that self-play is the most effective way to improve
strategic reasoning in such adversarial environments. Utilizing SCO-PAL with
self-play, we increase the average win rate against four opponents by
approximately 30% compared to baselines and achieve a 54.76% win rate against
GPT-4 in six adversarial games.

</details>


### [179] [LC-Eval: A Bilingual Multi-Task Evaluation Benchmark for Long-Context Understanding](https://arxiv.org/abs/2510.16783)
*Sheikh Jubair,Arwa Omayrah,Amal Alshammari,Alhanoof Althnian,Abdulhamed Alothaimen,Norah A. Alzahrani,Shahad D. Alzaidi,Nora Al-Twairesh,Abdulmohsen Al-Thubaity*

Main category: cs.CL

TL;DR: LC-Eval是一个双语多任务评估基准，用于评估英语和阿拉伯语的长上下文理解能力，涵盖4k到128k+token的上下文长度，包含四个新颖任务：多文档问答、双语问答、段落内声明验证和基于长上下文的多选题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在长上下文处理能力方面的进步，需要严格的评估方法来有效评估其在长上下文理解方面的性能。

Method: 开发了LC-Eval双语评估基准，包含四个挑战性任务：多文档问答、双语问答、段落内声明验证和基于长上下文的多选题，每个任务都有英语和阿拉伯语数据集。

Result: 对开源和闭源大语言模型的评估表明，LC-Eval具有显著挑战性，即使是GPT-4o等高性能模型在某些任务上也表现困难，突显了基准的复杂性和严谨性。

Conclusion: LC-Eval为评估大语言模型的长上下文理解能力提供了一个全面且具有挑战性的基准，揭示了当前模型在长上下文处理方面的局限性。

Abstract: Recent advancements in Large Language Models (LLMs) have demonstrated
sophisticated capabilities, including the ability to process and comprehend
extended contexts. These emergent capabilities necessitate rigorous evaluation
methods to effectively assess their performance in long-context understanding.
In this paper, we present \textbf{LC-Eval}, a bilingual, multi-task evaluation
benchmark designed to evaluate long-context understanding in English and
Arabic, targeting context lengths ranging from 4k to over 128k tokens. LC-Eval
introduces four novel and challenging tasks: multi-document question answering,
bilingual question answering, claim verification within a paragraph, and
multiple-choice questions based on long contexts. These tasks are designed to
assess LLMs' abilities in deep reasoning, document comprehension, information
tracing, and bilingual information extraction and understanding. The benchmark
includes datasets in both Arabic and English for each task, allowing for a
comparative analysis of their performance across different text genres.
Evaluations were conducted on both open-weight and closed LLMs, with results
indicating that LC-Eval presents significant challenges. Even high-performing
models, such as GPT-4o, struggled with certain tasks, highlighting the
complexity and rigor of the benchmark.

</details>


### [180] [MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning](https://arxiv.org/abs/2510.16797)
*Vera Pavlova,Mohammed Makhlouf*

Main category: cs.CL

TL;DR: MOSAIC是一个多阶段领域自适应框架，通过联合优化掩码语言建模和对比学习目标，将通用句子嵌入模型适配到专业领域，在高低资源领域均取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决大规模通用领域句子嵌入模型向专业领域适配的挑战，在保持原始模型鲁棒语义判别能力的同时学习领域相关表示。

Method: 多阶段框架，结合领域特定的掩码监督，联合优化MLM和对比学习目标，采用平衡的联合监督和分阶段适配策略。

Result: 在高资源和低资源领域均取得显著改进，NDCG@10指标相比强通用领域基线提升高达13.4%。消融研究验证了各组件有效性。

Conclusion: MOSAIC框架通过联合监督和分阶段适配，有效实现了句子嵌入模型的领域自适应，平衡了领域相关表示学习和语义判别能力保持。

Abstract: We introduce MOSAIC (Masked Objective with Selective Adaptation for In-domain
Contrastive learning), a multi-stage framework for domain adaptation of
sentence embedding models that incorporates joint domain-specific masked
supervision. Our approach addresses the challenges of adapting large-scale
general-domain sentence embedding models to specialized domains. By jointly
optimizing masked language modeling (MLM) and contrastive objectives within a
unified training pipeline, our method enables effective learning of
domain-relevant representations while preserving the robust semantic
discrimination properties of the original model. We empirically validate our
approach on both high-resource and low-resource domains, achieving improvements
up to 13.4% in NDCG@10 (Normalized Discounted Cumulative Gain) over strong
general-domain baselines. Comprehensive ablation studies further demonstrate
the effectiveness of each component, highlighting the importance of balanced
joint supervision and staged adaptation.

</details>


### [181] [Who's Asking? Simulating Role-Based Questions for Conversational AI Evaluation](https://arxiv.org/abs/2510.16829)
*Navreet Kaur,Hoda Ayad,Hayoung Jung,Shravika Mittal,Munmun De Choudhury,Tanushree Mitra*

Main category: cs.CL

TL;DR: CoRUS框架通过角色理论模拟基于角色的用户问题，发现在阿片类药物使用障碍领域，不同用户角色（患者、照顾者、从业者）会引发LLMs的系统性差异响应。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估往往忽略提问者的角色背景，这在污名化领域如阿片类药物使用障碍中尤为关键，因为考虑用户背景对于提供可访问、无污名的回答至关重要。

Method: 基于角色理论和在线OUD康复社区数据构建提问者角色分类法，模拟15,321个嵌入角色目标、行为和体验的问题，评估五个LLMs的响应差异。

Result: 脆弱角色（患者和照顾者）相比从业者角色，引发更多支持性响应（+17%）但知识内容减少（-19%），模拟问题具有高可信度且与现实数据可比。

Conclusion: 用户角色的隐式信号会显著影响模型响应，提供了基于角色的对话AI评估方法论。

Abstract: Language model users often embed personal and social context in their
questions. The asker's role -- implicit in how the question is framed --
creates specific needs for an appropriate response. However, most evaluations,
while capturing the model's capability to respond, often ignore who is asking.
This gap is especially critical in stigmatized domains such as opioid use
disorder (OUD), where accounting for users' contexts is essential to provide
accessible, stigma-free responses. We propose CoRUS (COmmunity-driven Roles for
User-centric Question Simulation), a framework for simulating role-based
questions. Drawing on role theory and posts from an online OUD recovery
community (r/OpiatesRecovery), we first build a taxonomy of asker roles --
patients, caregivers, practitioners. Next, we use it to simulate 15,321
questions that embed each role's goals, behaviors, and experiences. Our
evaluations show that these questions are both highly believable and comparable
to real-world data. When used to evaluate five LLMs, for the same question but
differing roles, we find systematic differences: vulnerable roles, such as
patients and caregivers, elicit more supportive responses (+17%) and reduced
knowledge content (-19%) in comparison to practitioners. Our work demonstrates
how implicitly signaling a user's role shapes model responses, and provides a
methodology for role-informed evaluation of conversational AI.

</details>


### [182] [Knowing the Facts but Choosing the Shortcut: Understanding How Large Language Models Compare Entities](https://arxiv.org/abs/2510.16815)
*Hans Hergen Lehmann,Jae Hee Lee,Steven Schockaert,Stefan Wermter*

Main category: cs.CL

TL;DR: LLMs在实体比较任务中经常依赖启发式偏见而非真实知识进行推理，即使它们具备正确的数值知识。研究发现实体流行度、提及顺序和语义共现三种启发式偏见严重影响模型预测，小模型更依赖这些表面线索，而大模型能选择性使用更可靠的数值知识。思维链提示能引导所有模型更好地使用数值特征。


<details>
  <summary>Details</summary>
Motivation: 理解LLMs何时依赖真实知识而非表面启发式进行推理，特别是在实体比较任务中，这有助于揭示模型推理机制的本质。

Method: 通过实体比较任务（如比较河流长度）分析LLMs的预测行为，识别三种启发式偏见：实体流行度、提及顺序和语义共现，并比较不同规模模型的表现差异。

Result: 小模型（7-8B参数）的预测更多受启发式偏见影响，而大模型（32B参数）能选择性使用数值知识；思维链提示能有效引导所有模型使用数值特征。

Conclusion: LLMs的推理质量不仅取决于知识准确性，还取决于模型选择使用何种信息的能力；模型规模影响这种选择能力，思维链提示能改善推理过程。

Abstract: Large Language Models (LLMs) are increasingly used for knowledge-based
reasoning tasks, yet understanding when they rely on genuine knowledge versus
superficial heuristics remains challenging. We investigate this question
through entity comparison tasks by asking models to compare entities along
numerical attributes (e.g., ``Which river is longer, the Danube or the
Nile?''), which offer clear ground truth for systematic analysis. Despite
having sufficient numerical knowledge to answer correctly, LLMs frequently make
predictions that contradict this knowledge. We identify three heuristic biases
that strongly influence model predictions: entity popularity, mention order,
and semantic co-occurrence. For smaller models, a simple logistic regression
using only these surface cues predicts model choices more accurately than the
model's own numerical predictions, suggesting heuristics largely override
principled reasoning. Crucially, we find that larger models (32B parameters)
selectively rely on numerical knowledge when it is more reliable, while smaller
models (7--8B parameters) show no such discrimination, which explains why
larger models outperform smaller ones even when the smaller models possess more
accurate knowledge. Chain-of-thought prompting steers all models towards using
the numerical features across all model sizes.

</details>


### [183] [Cross-Genre Authorship Attribution via LLM-Based Retrieve-and-Rerank](https://arxiv.org/abs/2510.16819)
*Shantanu Agarwal,Joel Barry,Steven Fincke,Scott Miller*

Main category: cs.CL

TL;DR: 本文提出了一个两阶段的检索-重排序框架，用于跨体裁的作者归属任务，通过微调大语言模型来识别与主题无关的作者特定语言模式。


<details>
  <summary>Details</summary>
Motivation: 传统的检索-重排序方法在信息检索领域很有效，但在跨体裁作者归属任务中会过度依赖主题线索而非作者特有的语言特征，导致性能不佳。

Method: 采用两阶段框架：检索阶段筛选候选作者，重排序阶段使用专门的数据策展策略训练LLM来学习作者区分性信号。

Result: 在HIATUS的HRS1和HRS2跨体裁作者归属基准测试中，相比之前的最优方法分别提升了22.3和34.4个绝对Success@8点。

Conclusion: 该框架成功解决了跨体裁作者归属中的关键挑战，通过针对性的训练策略使重排序器能够有效学习与主题无关的作者特定语言模式。

Abstract: Authorship attribution (AA) is the task of identifying the most likely author
of a query document from a predefined set of candidate authors. We introduce a
two-stage retrieve-and-rerank framework that finetunes LLMs for cross-genre AA.
Unlike the field of information retrieval (IR), where retrieve-and-rerank is a
de facto strategy, cross-genre AA systems must avoid relying on topical cues
and instead learn to identify author-specific linguistic patterns that are
independent of the text's subject matter (genre/domain/topic). Consequently,
for the reranker, we demonstrate that training strategies commonly used in IR
are fundamentally misaligned with cross-genre AA, leading to suboptimal
behavior. To address this, we introduce a targeted data curation strategy that
enables the reranker to effectively learn author-discriminative signals. Using
our LLM-based retrieve-and-rerank pipeline, we achieve substantial gains of
22.3 and 34.4 absolute Success@8 points over the previous state-of-the-art on
HIATUS's challenging HRS1 and HRS2 cross-genre AA benchmarks.

</details>


### [184] [FinSight: Towards Real-World Financial Deep Research](https://arxiv.org/abs/2510.16844)
*Jiajie Jin,Yuyao Zhang,Yimeng Xu,Hongjin Qian,Yutao Zhu,Zhicheng Dou*

Main category: cs.CL

TL;DR: FinSight是一个多智能体框架，用于生成高质量的多模态财务报告，通过CAVM架构、迭代视觉增强机制和两阶段写作框架，在事实准确性、分析深度和呈现质量方面显著优于现有基线系统。


<details>
  <summary>Details</summary>
Motivation: 生成专业财务报告是一个劳动密集且智力要求高的过程，现有AI系统难以完全自动化。为了解决这一挑战，需要开发能够生成高质量多模态财务报告的智能系统。

Method: 1. CAVM架构：将外部数据、设计工具和智能体统一到可编程变量空间中，通过可执行代码实现灵活的数据收集、分析和报告生成；2. 迭代视觉增强机制：逐步将原始视觉输出精炼为专业的财务图表；3. 两阶段写作框架：将简洁的分析链段扩展为连贯、引用感知的多模态报告。

Result: 在各种公司和行业级任务上的实验表明，FinSight在事实准确性、分析深度和呈现质量方面显著优于所有基线系统，包括领先的深度研究系统。

Conclusion: FinSight展示了生成接近人类专家质量报告的能力，为自动化财务报告生成提供了清晰的路径。

Abstract: Generating professional financial reports is a labor-intensive and
intellectually demanding process that current AI systems struggle to fully
automate. To address this challenge, we introduce FinSight (Financial InSight),
a novel multi agent framework for producing high-quality, multimodal financial
reports. The foundation of FinSight is the Code Agent with Variable Memory
(CAVM) architecture, which unifies external data, designed tools, and agents
into a programmable variable space, enabling flexible data collection, analysis
and report generation through executable code. To ensure professional-grade
visualization, we propose an Iterative Vision-Enhanced Mechanism that
progressively refines raw visual outputs into polished financial charts.
Furthermore, a two stage Writing Framework expands concise Chain-of-Analysis
segments into coherent, citation-aware, and multimodal reports, ensuring both
analytical depth and structural consistency. Experiments on various company and
industry-level tasks demonstrate that FinSight significantly outperforms all
baselines, including leading deep research systems in terms of factual
accuracy, analytical depth, and presentation quality, demonstrating a clear
path toward generating reports that approach human-expert quality.

</details>


### [185] [Does Visual Grounding Enhance the Understanding of Embodied Knowledge in Large Language Models?](https://arxiv.org/abs/2510.16924)
*Zhihui Yang,Yupei Wang,Kaijie Mo,Zhe Zhao,Renfen Hu*

Main category: cs.CL

TL;DR: 该研究提出了基于心理学感知理论的多模态语言模型感知能力基准测试，发现视觉语言模型在具身知识理解方面并未优于纯文本模型，且在视觉维度表现最差。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态语言模型取得显著进展，但尚不清楚视觉基础是否比纯文本模型更好地增强其对具身知识的理解。

Method: 基于心理学感知理论构建了包含视觉、听觉、触觉、味觉、嗅觉外部感官和内部感知的具身知识理解基准，通过向量比较和问答任务评估30个最先进语言模型的感知能力。

Result: 视觉语言模型在两项任务中均未优于纯文本模型；模型在视觉维度表现显著差于其他感官维度；向量表示易受词形和频率影响；模型在涉及空间感知和推理的问题上表现困难。

Conclusion: 研究结果表明需要在语言模型中更有效地整合具身知识，以增强其对物理世界的理解能力。

Abstract: Despite significant progress in multimodal language models (LMs), it remains
unclear whether visual grounding enhances their understanding of embodied
knowledge compared to text-only models. To address this question, we propose a
novel embodied knowledge understanding benchmark based on the perceptual theory
from psychology, encompassing visual, auditory, tactile, gustatory, olfactory
external senses, and interoception. The benchmark assesses the models'
perceptual abilities across different sensory modalities through vector
comparison and question-answering tasks with over 1,700 questions. By comparing
30 state-of-the-art LMs, we surprisingly find that vision-language models
(VLMs) do not outperform text-only models in either task. Moreover, the models
perform significantly worse in the visual dimension compared to other sensory
dimensions. Further analysis reveals that the vector representations are easily
influenced by word form and frequency, and the models struggle to answer
questions involving spatial perception and reasoning. Our findings underscore
the need for more effective integration of embodied knowledge in LMs to enhance
their understanding of the physical world.

</details>


### [186] [ChiKhaPo: A Large-Scale Multilingual Benchmark for Evaluating Lexical Comprehension and Generation in Large Language Models](https://arxiv.org/abs/2510.16928)
*Emily Chang,Niyati Bafna*

Main category: cs.CL

TL;DR: ChiKhaPo是一个大规模多语言基准测试，包含8个不同难度的子任务，旨在评估生成模型的词汇理解和生成能力，覆盖2700多种语言，超越了现有基准的语言覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型基准主要局限于高资源或中资源语言，且通常评估推理和生成等高阶任务。然而，大量证据表明LLMs在全球3800多种书面语言中缺乏基本的语言能力。

Method: ChiKhaPo利用现有词典、单语数据和双语平行语料库构建，包含8个不同难度的子任务，专门设计用于评估词汇理解和生成能力。

Result: 测试显示6个最先进的模型在该基准上表现不佳，性能得分受语言家族、语言资源丰富度、任务类型以及理解与生成方向等因素影响。

Conclusion: 通过ChiKhaPo，希望能够推动和鼓励LLMs的大规模多语言基准测试发展。

Abstract: Existing benchmarks for large language models (LLMs) are largely restricted
to high- or mid-resource languages, and often evaluate performance on
higher-order tasks in reasoning and generation. However, plenty of evidence
points to the fact that LLMs lack basic linguistic competence in the vast
majority of the world's 3800+ written languages. We introduce ChiKhaPo,
consisting of 8 subtasks of varying difficulty designed to evaluate the lexical
comprehension and generation abilities of generative models. ChiKhaPo draws on
existing lexicons, monolingual data, and bitext, and provides coverage for
2700+ languages for 2 subtasks, surpassing any existing benchmark in terms of
language coverage. We further show that 6 SOTA models struggle on our
benchmark, and discuss the factors contributing to performance scores,
including language family, language resourcedness, task, and comprehension
versus generation directions. With ChiKhaPo, we hope to enable and encourage
the massively multilingual benchmarking of LLMs.

</details>


### [187] [Prompt-MII: Meta-Learning Instruction Induction for LLMs](https://arxiv.org/abs/2510.16932)
*Emily Xiao,Yixiao Zeng,Ada Chen,Chin-Jou Li,Amanda Bertsch,Graham Neubig*

Main category: cs.CL

TL;DR: 提出PROMPT-MII方法，通过强化学习元学习指令归纳模型，生成紧凑指令替代上下文学习，在保持性能的同时大幅减少推理成本。


<details>
  <summary>Details</summary>
Motivation: 上下文学习虽然有效但推理成本高，需要开发更高效的指令归纳方法来替代传统上下文学习。

Method: 基于强化学习的元学习框架，在3,000多个分类数据集上训练，生成紧凑指令来替代完整训练集。

Result: 在90个未见任务上，PROMPT-MII提升下游模型质量4-9个F1点（相对提升10-20%），性能匹配上下文学习但所需token减少3-13倍。

Conclusion: PROMPT-MII能够有效替代上下文学习，在保持性能的同时显著降低推理成本，为大型语言模型的高效适配提供了新方法。

Abstract: A popular method to adapt large language models (LLMs) to new tasks is
in-context learning (ICL), which is effective but incurs high inference costs
as context length grows. In this paper we propose a method to perform
instruction induction, where we take training examples and reduce them to a
compact but descriptive prompt that can achieve performance comparable to ICL
over the full training set. Specifically, we propose PROMPT-MII, a
reinforcement learning (RL) based framework to meta-learn an instruction
induction model that can generate compact instructions on the fly for an
arbitrary new dataset. We train on over 3,000 diverse classification datasets
from the HuggingFace hub, and evaluate on 90 unseen tasks. PROMPT-MII improves
downstream model quality by 4-9 F1 points (10-20% relative), matching ICL
performance while requiring 3-13x fewer tokens.

</details>


### [188] [Parameter-Efficient Fine-Tuning for Low-Resource Languages: A Comparative Study of LLMs for Bengali Hate Speech Detection](https://arxiv.org/abs/2510.16985)
*Akif Islam,Mohd Ruhul Ameen*

Main category: cs.CL

TL;DR: 本文首次应用参数高效微调（PEFT）技术，使用LoRA和QLoRA方法在孟加拉语仇恨言论检测任务上，在BD-SHS数据集上对三个指令调优大语言模型进行微调，仅训练不到1%的参数，Llama-3.2-3B取得了92.23%的最高F1分数。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语社交媒体平台仇恨言论急剧增加，尤其影响女性和青少年，现有方法要么依赖计算成本高的全模型微调，要么使用专有API，需要更高效实用的解决方案。

Method: 使用LoRA和QLoRA参数高效微调方法，在BD-SHS数据集（50,281条标注评论）上对Gemma-3-4B、Llama-3.2-3B和Mistral-7B三个指令调优大语言模型进行微调，仅训练不到1%的参数，可在单消费级GPU上完成实验。

Result: Llama-3.2-3B取得了最高的F1分数92.23%，其次是Mistral-7B（88.94%）和Gemma-3-4B（80.25%），证明了PEFT方法的有效性。

Conclusion: PEFT被确立为孟加拉语及相关低资源语言仇恨言论检测的实用且可复现策略，为资源受限环境下的类似任务提供了高效解决方案。

Abstract: Bengali social media platforms have witnessed a sharp increase in hate
speech, disproportionately affecting women and adolescents. While datasets such
as BD-SHS provide a basis for structured evaluation, most prior approaches rely
on either computationally costly full-model fine-tuning or proprietary APIs.
This paper presents the first application of Parameter-Efficient Fine-Tuning
(PEFT) for Bengali hate speech detection using LoRA and QLoRA. Three
instruction-tuned large language models - Gemma-3-4B, Llama-3.2-3B, and
Mistral-7B - were fine-tuned on the BD-SHS dataset of 50,281 annotated
comments. Each model was adapted by training fewer than 1% of its parameters,
enabling experiments on a single consumer-grade GPU. The results show that
Llama-3.2-3B achieved the highest F1-score of 92.23%, followed by Mistral-7B at
88.94% and Gemma-3-4B at 80.25%. These findings establish PEFT as a practical
and replicable strategy for Bengali and related low-resource languages.

</details>


### [189] [Back to Bytes: Revisiting Tokenization Through UTF-8](https://arxiv.org/abs/2510.16987)
*Amit Moryossef,Clara Meister,Pavel Stepachev,Desmond Elliott*

Main category: cs.CL

TL;DR: UTF8Tokenizer是一个极简的字节级分词器，直接将文本映射到UTF-8编码对应的字节ID，使用C0控制字节编码所有特殊行为，提供更快的分词速度、更小的传输开销和可共享的嵌入表。


<details>
  <summary>Details</summary>
Motivation: 解决现有字节级分词器引入超出范围ID或辅助标记的问题，利用ASCII原始设计理念，通过C0控制字节统一编码所有特殊行为。

Method: 实现基于UTF-8字节编码的分词器，使用C0控制字节处理特殊行为，采用256*d嵌入表，并引入位偏置嵌入技术。

Result: 分词速度提升14倍，主机-设备传输减少8倍，嵌入表可跨模型对齐，语言建模收敛性得到改善。

Conclusion: UTF8Tokenizer提供了一种高效、简洁的分词方案，通过字节级处理和C0控制字节的统一编码，在性能和实用性方面都有显著优势。

Abstract: We present UTF8Tokenizer, a minimalist byte-level tokenizer that maps text
exactly to IDs corresponding to the bytes underlying the text's UTF-8 encoding
(e.g., byte x09 is token ID 9). Unlike prior byte-level approaches (Xue et al.,
2021; Pagnoni et al., 2025), our implementation never introduces out-of-range
IDs (i.e. there is no token ID 256) or auxiliary tokens: all special behavior
(e.g., padding, boundaries, conversation structure, attention segments, tool
calling, "thinking" spans, etc.) is encoded using C0 control bytes - just as
ASCII was originally designed to embed control information alongside printable
text. These design principles yield practical benefits: (1) faster tokenization
(14x) and significantly lower host-device transfer (8x less than int64); (2)
simple, shareable 256*d embedding tables that can be aligned across models; and
(3) a training-time enhancement via bit-biased embeddings, which exposes
per-byte bit structure and can be added to the embedding table post-training,
removing inference costs. Our HuggingFace-compatible implementation improves
language modeling convergence.

</details>


### [190] [Vocab Diet: Reshaping the Vocabulary of LLMs with Vector Arithmetic](https://arxiv.org/abs/2510.17001)
*Yuval Reif,Guy Kaplan,Roy Schwartz*

Main category: cs.CL

TL;DR: 论文提出了一种词汇表压缩方法，通过将词形变化表示为转换向量来减少词汇表大小，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 标准分词算法将词形变化视为独立标记，导致词汇表被表面形式变体填满，限制了低频词和多语言覆盖。

Method: 使用转换向量（加法偏移量）在嵌入空间中表示词形变化，将词汇表从字符串枚举重构为基于基础形式和转换向量的组合结构。

Result: 在多个LLM和五种语言上测试，最多可移除10%的词汇条目，扩展了词汇覆盖范围，对下游任务性能影响最小，且无需修改模型权重。

Conclusion: 研究结果促使重新思考词汇表设计，从字符串枚举转向利用语言底层结构的组合式词汇表。

Abstract: Large language models (LLMs) were shown to encode word form variations, such
as "walk"->"walked", as linear directions in embedding space. However, standard
tokenization algorithms treat these variations as distinct tokens -- filling
the size-capped vocabulary with surface form variants (e.g., "walk", "walking",
"Walk"), at the expense of less frequent words and multilingual coverage. We
show that many of these variations can be captured by transformation vectors --
additive offsets that yield the appropriate word's representation when applied
to the base form word embedding -- in both the input and output spaces.
Building on this, we propose a compact reshaping of the vocabulary: rather than
assigning unique tokens to each surface form, we compose them from shared base
form and transformation vectors (e.g., "walked" = "walk" + past tense). We
apply our approach to multiple LLMs and across five languages, removing up to
10% of vocabulary entries -- thereby freeing space to allocate new, more
diverse tokens. Importantly, we do so while also expanding vocabulary coverage
to out-of-vocabulary words, with minimal impact on downstream performance, and
without modifying model weights. Our findings motivate a foundational
rethinking of vocabulary design, moving from string enumeration to a
compositional vocabulary that leverages the underlying structure of language.

</details>


### [191] [Online Learning Defense against Iterative Jailbreak Attacks via Prompt Optimization](https://arxiv.org/abs/2510.17006)
*Masahiro Kaneko,Zeerak Talat,Timothy Baldwin*

Main category: cs.CL

TL;DR: 本文提出了一种基于在线学习的动态防御框架，通过强化学习优化提示，既能拒绝有害提示又能保证无害任务的响应质量，并引入PDGD防止过拟合，在三种LLM上显著优于现有防御方法。


<details>
  <summary>Details</summary>
Motivation: 现有的防御方法无法主动破坏迭代越狱方法的动态试错循环，这些方法通过反复重写提示诱导LLM产生有害输出，且利用模型之前的响应指导每次迭代，是一种高效的攻击策略。

Method: 提出动态更新防御策略的在线学习框架，利用有害越狱生成提示与典型无害提示的区别，采用基于强化学习的方法优化提示，确保无害任务的适当响应同时明确拒绝有害提示，并引入Past-Direction Gradient Damping防止过拟合。

Result: 在三种LLM上的实验表明，该方法显著优于五种现有防御方法对抗五种迭代越狱方法，同时提示优化策略还提高了无害任务的响应质量。

Conclusion: 提出的动态防御框架能有效对抗迭代越狱攻击，在保持无害任务性能的同时显著提升防御效果。

Abstract: Iterative jailbreak methods that repeatedly rewrite and input prompts into
large language models (LLMs) to induce harmful outputs -- using the model's
previous responses to guide each new iteration -- have been found to be a
highly effective attack strategy. Despite being an effective attack strategy
against LLMs and their safety mechanisms, existing defenses do not proactively
disrupt this dynamic trial-and-error cycle. In this study, we propose a novel
framework that dynamically updates its defense strategy through online learning
in response to each new prompt from iterative jailbreak methods. Leveraging the
distinctions between harmful jailbreak-generated prompts and typical harmless
prompts, we introduce a reinforcement learning-based approach that optimizes
prompts to ensure appropriate responses for harmless tasks while explicitly
rejecting harmful prompts. Additionally, to curb overfitting to the narrow band
of partial input rewrites explored during an attack, we introduce
Past-Direction Gradient Damping (PDGD). Experiments conducted on three LLMs
show that our approach significantly outperforms five existing defense methods
against five iterative jailbreak methods. Moreover, our results indicate that
our prompt optimization strategy simultaneously enhances response quality for
harmless tasks.

</details>


### [192] [DiscoTrack: A Multilingual LLM Benchmark for Discourse Tracking](https://arxiv.org/abs/2510.17013)
*Lanni Bu,Lauren Levin,Amir Zeldes*

Main category: cs.CL

TL;DR: DiscoTrack是一个多语言LLM基准测试，专注于语篇理解和隐式信息推理，涵盖12种语言和四个语篇理解层次。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准测试主要关注自然语言理解和显式信息提取，缺乏针对隐式信息和语篇层面跨句子推理的挑战性多语言基准。

Method: 开发DiscoTrack基准，包含12种语言和四个语篇理解层次：显著性识别、实体追踪、语篇关系和桥接推理。

Result: 评估显示这些任务即使对于最先进的模型也具有挑战性。

Conclusion: DiscoTrack填补了现有基准在语篇理解和隐式推理方面的空白，为LLM在多语言语篇理解能力评估提供了重要工具。

Abstract: Recent LLM benchmarks have tested models on a range of phenomena, but are
still focused primarily on natural language understanding for extraction of
explicit information, such as QA or summarization, with responses often tar-
geting information from individual sentences. We are still lacking more
challenging, and im- portantly also multilingual, benchmarks focus- ing on
implicit information and pragmatic infer- ences across larger documents in the
context of discourse tracking: integrating and aggregating information across
sentences, paragraphs and multiple speaker utterances. To this end, we present
DiscoTrack, an LLM benchmark target- ing a range of tasks across 12 languages
and four levels of discourse understanding: salience recognition, entity
tracking, discourse relations and bridging inference. Our evaluation shows that
these tasks remain challenging, even for state-of-the-art models.

</details>


### [193] [Mapping from Meaning: Addressing the Miscalibration of Prompt-Sensitive Language Models](https://arxiv.org/abs/2510.17028)
*Kyle Cox,Jiawei Xu,Yikun Han,Rong Xu,Tianhao Li,Chi-Yang Hsu,Tianlong Chen,Walter Gerych,Ying Ding*

Main category: cs.CL

TL;DR: 本文研究大语言模型中的提示敏感性现象，通过语义空间采样和扰动方法改进不确定性校准，同时提出新的不确定性分解指标来量化提示敏感性对模型不确定性的影响。


<details>
  <summary>Details</summary>
Motivation: 大语言模型对语义等效但表述不同的提示会产生不同的答案分布，这表明模型输出的不确定性可能无法真实反映其对提示含义的不确定性。

Method: 将提示敏感性建模为泛化误差，通过语义概念空间的释义扰动进行采样，并引入新的不确定性分解指标来建模自然语言生成中的语义连续性。

Result: 研究表明，在语义概念空间中进行采样可以改善不确定性校准而不影响准确性，新的分解指标能够有效量化提示敏感性对LLM不确定性的贡献。

Conclusion: 这项工作为改进提示敏感语言模型的不确定性校准提供了新方法，并证明某些LLM未能对其输入含义表现出一致的一般推理能力。

Abstract: An interesting behavior in large language models (LLMs) is prompt
sensitivity. When provided with different but semantically equivalent versions
of the same prompt, models may produce very different distributions of answers.
This suggests that the uncertainty reflected in a model's output distribution
for one prompt may not reflect the model's uncertainty about the meaning of the
prompt. We model prompt sensitivity as a type of generalization error, and show
that sampling across the semantic ``concept space'' with paraphrasing
perturbations improves uncertainty calibration without compromising accuracy.
Additionally, we introduce a new metric for uncertainty decomposition in
black-box LLMs that improves upon entropy-based decomposition by modeling
semantic continuities in natural language generation. We show that this
decomposition metric can be used to quantify how much LLM uncertainty is
attributed to prompt sensitivity. Our work introduces a new way to improve
uncertainty calibration in prompt-sensitive language models, and provides
evidence that some LLMs fail to exhibit consistent general reasoning about the
meanings of their inputs.

</details>


### [194] [Investigating Thinking Behaviours of Reasoning-Based Language Models for Social Bias Mitigation](https://arxiv.org/abs/2510.17062)
*Guoqing Luo,Iffat Maab,Lili Mou,Junichi Yamagishi*

Main category: cs.CL

TL;DR: 该论文研究了基于推理的大语言模型在思考过程中会聚合社会偏见的问题，发现了两种导致偏见聚合的失败模式，并提出了一种轻量级的提示缓解方法。


<details>
  <summary>Details</summary>
Motivation: 虽然基于推理的大语言模型通过内部结构化思考过程在复杂任务上表现出色，但出现了一个令人担忧的现象：这种思考过程会聚合社会刻板印象，导致有偏见的结果。然而，语言模型在社会偏见场景中的底层行为仍未得到充分探索。

Method: 系统性地研究了思考过程中导致偏见现象的机制，发现了两种驱动社会偏见聚合的失败模式：刻板印象重复和无关信息注入。基于这些发现，引入了一种轻量级的基于提示的缓解方法，让模型根据这些特定失败模式来审查其初始推理。

Result: 在问答（BBQ和StereoSet）和开放式（BOLD）基准测试上的实验表明，该方法有效减少了偏见，同时保持或提高了准确性。

Conclusion: 该研究揭示了语言模型思考过程中偏见聚合的机制，并提出了一种有效的缓解方法，能够在减少偏见的同时保持模型性能。

Abstract: While reasoning-based large language models excel at complex tasks through an
internal, structured thinking process, a concerning phenomenon has emerged that
such a thinking process can aggregate social stereotypes, leading to biased
outcomes. However, the underlying behaviours of these language models in social
bias scenarios remain underexplored. In this work, we systematically
investigate mechanisms within the thinking process behind this phenomenon and
uncover two failure patterns that drive social bias aggregation: 1) stereotype
repetition, where the model relies on social stereotypes as its primary
justification, and 2) irrelevant information injection, where it fabricates or
introduces new details to support a biased narrative. Building on these
insights, we introduce a lightweight prompt-based mitigation approach that
queries the model to review its own initial reasoning against these specific
failure patterns. Experiments on question answering (BBQ and StereoSet) and
open-ended (BOLD) benchmarks show that our approach effectively reduces bias
while maintaining or improving accuracy.

</details>


### [195] [DVAGen: Dynamic Vocabulary Augmented Generation](https://arxiv.org/abs/2510.17115)
*Wei Du,Nuowei Liu,Jie Wang,Jiahao Kuang,Tao Ji,Xiaoling Wang,Yuanbin Wu*

Main category: cs.CL

TL;DR: DVAGen是一个开源统一框架，用于训练、评估和可视化动态词汇增强语言模型，解决了现有方法在代码库碎片化、现代LLM支持和推理可扩展性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 固定词汇表训练的语言模型难以泛化到新词或词汇表外词，限制了处理多样化词汇组合的灵活性。现有动态词汇方法存在代码库碎片化、缺乏现代LLM支持和推理可扩展性有限等问题。

Method: 开发了DVAGen框架，模块化设计便于定制，无缝集成开源LLM，首次提供CLI和WebUI工具进行实时结果检查，支持批量推理。

Result: 验证了动态词汇方法在现代LLM上的有效性，显著提高了推理吞吐量。

Conclusion: DVAGen通过统一的动态词汇增强框架，解决了现有方法的局限性，为语言模型提供了更好的词汇泛化能力和推理效率。

Abstract: Language models trained with a fixed vocabulary struggle to generalize to
novel or out-of-vocabulary words, limiting their flexibility in handling
diverse token combinations. Existing dynamic vocabulary approaches attempt to
address this limitation but face challenges such as fragmented codebases, lack
of support for modern LLMs, and limited inference scalability. To overcome
these issues, we introduce DVAGen, a fully open-source, unified framework
designed for training, evaluation, and visualization of dynamic
vocabulary-augmented language models. Our framework modularizes the pipeline
for ease of customization, integrates seamlessly with open-source LLMs, and is
the first to provide both CLI and WebUI tools for real-time result inspection.
We validate the effectiveness of dynamic vocabulary methods on modern LLMs and
demonstrate support for batch inference, significantly improving inference
throughput.

</details>


### [196] [Rethinking On-policy Optimization for Query Augmentation](https://arxiv.org/abs/2510.17139)
*Zhichao Xu,Shengyao Zhuang,Xueguang Ma,Bingsen Chen,Yijun Tian,Fengran Mo,Jie Cao,Vivek Srikumar*

Main category: cs.CL

TL;DR: 本文系统比较了基于提示和基于强化学习的查询增强方法，发现简单的无训练查询增强方法在强大LLMs下表现与昂贵的RL方法相当甚至更好。作者提出了一种混合方法OPQE，通过生成伪文档来优化检索性能，优于单独使用提示或RL的方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLMs的查询增强主要有两种方法：基于提示的方法和基于强化学习的方法，但缺乏在一致实验条件下的系统比较。本文旨在填补这一空白，并探索两种方法的协同效应。

Method: 1. 系统比较基于提示和基于强化学习的查询增强方法；2. 提出混合方法OPQE，让LLM策略学习生成最大化检索性能的伪文档，结合了提示的灵活性和RL的针对性优化。

Result: 研究发现简单的无训练查询增强方法在强大LLMs下表现与昂贵的RL方法相当甚至更好。OPQE方法在证据检索、ad hoc检索和工具检索等基准测试中均优于单独使用提示或RL的方法。

Conclusion: 提示方法和RL方法各有优势，但协同方法能获得最佳结果。OPQE通过结合提示的灵活性和RL的优化能力，实现了更好的检索性能。

Abstract: Recent advances in large language models (LLMs) have led to a surge of
interest in query augmentation for information retrieval (IR). Two main
approaches have emerged. The first prompts LLMs to generate answers or
pseudo-documents that serve as new queries, relying purely on the model's
parametric knowledge or contextual information. The second applies
reinforcement learning (RL) to fine-tune LLMs for query rewriting, directly
optimizing retrieval metrics. While having respective advantages and
limitations, the two approaches have not been compared under consistent
experimental conditions. In this work, we present the first systematic
comparison of prompting-based and RL-based query augmentation across diverse
benchmarks, including evidence-seeking, ad hoc, and tool retrieval. Our key
finding is that simple, training-free query augmentation often performs on par
with, or even surpasses, more expensive RL-based counterparts, especially when
using powerful LLMs. Motivated by this discovery, we introduce a novel hybrid
method, On-policy Pseudo-document Query Expansion (OPQE), which, instead of
rewriting a query, the LLM policy learns to generate a pseudo-document that
maximizes retrieval performance, thus merging the flexibility and generative
structure of prompting with the targeted optimization of RL. We show OPQE
outperforms both standalone prompting and RL-based rewriting, demonstrating
that a synergistic approach yields the best results. Our implementation is made
available to facilitate reproducibility.

</details>


### [197] [Understanding and Improving Length Generalization in Hierarchical Sparse Attention Models](https://arxiv.org/abs/2510.17196)
*Jiaqi Leng,Xiang Hu,Junxiong Wang,Jianguo Li,Wei Wu,Yucheng Lu*

Main category: cs.CL

TL;DR: 本文系统分析了基于分块稀疏注意力的长上下文语言模型，提出了三个关键设计原则：表达性分块编码器、旁路残差路径和训练时强制选择稀疏性，实现了从4K上下文到3200万token的无训练长度外推。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer受限于二次复杂度和长度外推能力差，而滑动窗口注意力等替代架构由于固定大小内存无法有效利用完整上下文。分块稀疏注意力在极端长度泛化方面表现出潜力，但其成功背后的关键架构原则尚未完全理解。

Method: 通过统一框架和全面消融研究，识别出三个关键设计原则：1) 使用专用CLS令牌的表达性非线性分块编码器；2) 旁路残差路径稳定集成检索的全局信息；3) 预训练期间强制选择稀疏性以弥合训练-测试分布差距。

Result: 结合这些原则，在RULER和BABILong基准上实现了从4K上下文到3200万token的无训练长度外推，建立了新的最先进水平。

Conclusion: 研究结果为开发未来高性能长上下文语言模型提供了一套清晰且经验基础的设计原则。

Abstract: Effectively processing long contexts is a critical challenge for language
models. While standard Transformers are limited by quadratic complexity and
poor length extrapolation, alternative architectures like sliding window
attention and state space models sacrifice the ability to effectively utilize
the full context due to their fixed-size memory. Chunk-based sparse attention
has emerged as a promising paradigm for extreme length generalization, yet the
key architectural principles underpinning its success are not yet fully
understood. In this work, we present a systematic dissection of these models to
identify the core components driving their performance. Through a unified
framework and comprehensive ablation studies, we demonstrate that a combination
of three design principles is critical: (1) an expressive, non-linear Chunk
Encoder with a dedicated CLS token to produce representations for retrieval;
(2) a Bypassing Residual Path to stably integrate retrieved global information
without it being overridden by the local residual stream; and (3) enforced
selection sparsity during pre-training to bridge the train-test distribution
gap. We provide a theoretical motivation for intra-chunk information processing
and landmark generation. By combining these principles, we establish a new
state-of-the-art for training-free length extrapolation, successfully
generalizing models trained on a 4K context to 32 million tokens on RULER and
BABILong. Our findings provide a clear and empirically-grounded set of design
principles for developing future, highly-capable long-context language models.

</details>


### [198] [Wisdom is Knowing What not to Say: Hallucination-Free LLMs Unlearning via Attention Shifting](https://arxiv.org/abs/2510.17210)
*Chenchen Tan,Youyang Qu,Xinghao Li,Hui Zhang,Shujie Cui,Cunjian Chen,Longxiang Gao*

Main category: cs.CL

TL;DR: 提出了一种新颖的注意力转移（AS）框架，用于解决大语言模型选择性遗忘中的关键困境：激进遗忘会损害模型效用，而保守策略会保留效用但产生幻觉响应。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型应用的增加，其潜在敏感数据保留问题促使机器遗忘研究兴起。现有遗忘方法面临关键困境：激进遗忘损害模型效用，保守策略保留效用但产生幻觉响应，限制了LLMs在知识密集型应用中的可靠性。

Method: 引入注意力转移（AS）框架，包含两个设计目标：(1)上下文保持抑制，在不破坏LLMs语言结构的情况下减弱对事实承载token的注意力；(2)抗幻觉响应塑造，在查询遗忘内容时阻止虚构补全。通过两个注意力级干预实现：应用于遗忘集的重要性感知抑制以减少对记忆知识的依赖，以及注意力引导的保留增强以强化对保留数据集中语义关键token的注意力。

Result: 实验结果显示，AS在ToFU基准上比最先进的遗忘方法提高了15%的准确率，在TDEC基准上提高了10%，同时保持竞争力的无幻觉遗忘效果。

Conclusion: 与现有方法相比，AS在遗忘效果、泛化能力和响应可靠性之间展现出优越的平衡。

Abstract: The increase in computing power and the necessity of AI-assisted
decision-making boost the growing application of large language models (LLMs).
Along with this, the potential retention of sensitive data of LLMs has spurred
increasing research into machine unlearning. However, existing unlearning
approaches face a critical dilemma: Aggressive unlearning compromises model
utility, while conservative strategies preserve utility but risk hallucinated
responses. This significantly limits LLMs' reliability in knowledge-intensive
applications. To address this, we introduce a novel Attention-Shifting (AS)
framework for selective unlearning. AS is driven by two design objectives: (1)
context-preserving suppression that attenuates attention to fact-bearing tokens
without disrupting LLMs' linguistic structure; and (2) hallucination-resistant
response shaping that discourages fabricated completions when queried about
unlearning content. AS realizes these objectives through two attention-level
interventions, which are importance-aware suppression applied to the unlearning
set to reduce reliance on memorized knowledge and attention-guided retention
enhancement that reinforces attention toward semantically essential tokens in
the retained dataset to mitigate unintended degradation. These two components
are jointly optimized via a dual-loss objective, which forms a soft boundary
that localizes unlearning while preserving unrelated knowledge under
representation superposition. Experimental results show that AS improves
performance preservation over the state-of-the-art unlearning methods,
achieving up to 15% higher accuracy on the ToFU benchmark and 10% on the TDEC
benchmark, while maintaining competitive hallucination-free unlearning
effectiveness. Compared to existing methods, AS demonstrates a superior balance
between unlearning effectiveness, generalization, and response reliability.

</details>


### [199] [StreamingThinker: Large Language Models Can Think While Reading](https://arxiv.org/abs/2510.17238)
*Junlong Tong,Yingqi Fan,Anhao Zhao,Yunpu Ma,Xiaoyu Shen*

Main category: cs.CL

TL;DR: StreamingThinker是一种新的LLM推理范式，让模型在阅读输入的同时进行思考，而不是等到整个输入完成后再开始推理，显著降低了推理延迟。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理范式需要等待整个输入完成后才开始思考，这带来了不必要的延迟，并且在动态场景下会削弱对早期信息的注意力。

Method: 设计了流式思考范式，通过流式CoT生成、流式约束训练和流式并行推理实现边读边想，使用流式推理单元、顺序保持注意力掩码和位置编码，以及解耦输入编码与推理生成的并行KV缓存。

Result: 在数学推理、逻辑推理和上下文QA任务上，StreamingThinker保持了与批量思考相当的性能，同时将推理开始前的token等待时间减少了80%，最终答案的时间级延迟减少了60%以上。

Conclusion: 流式思考范式为LLM推理提供了有效的低延迟解决方案，显著提升了推理效率。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
chain of thought (CoT) reasoning. However, the current LLM reasoning paradigm
initiates thinking only after the entire input is available, which introduces
unnecessary latency and weakens attention to earlier information in dynamic
scenarios. Inspired by human cognition of thinking while reading, we first
design a \textit{\textbf{streaming thinking}} paradigm for LLMs, where
reasoning unfolds in the order of input and further adjusts its depth once
reading is complete. We instantiate this paradigm with
\textit{StreamingThinker}, a framework that enables LLMs to think while reading
through the integration of streaming CoT generation, streaming-constraint
training, and streaming parallel inference. Specifically, StreamingThinker
employs streaming reasoning units with quality control for CoT generation,
enforces order-preserving reasoning through streaming attention masks and
position encoding, and leverages parallel KV caches that decouple input
encoding from reasoning generation, thereby ensuring alignment and enabling
true concurrency. We evaluate StreamingThinker on the Qwen3 model family across
math reasoning, logical reasoning, and context-based QA reasoning tasks.
Experimental results show that the StreamingThinker preserves performance
comparable to batch thinking, while yielding an 80\% reduction in token waiting
before the onset of reasoning and a more than 60\% reduction in time-level
latency for producing the final answer, demonstrating the effectiveness of the
streaming paradigm for LLM reasoning. Code will be released at
\href{https://github.com/EIT-NLP/StreamingLLM/tree/main/StreamingThinker}{this
repository.}

</details>


### [200] [From Preferences to Prejudice: The Role of Alignment Tuning in Shaping Social Bias in Video Diffusion Models](https://arxiv.org/abs/2510.17247)
*Zefan Cai,Haoyi Qiu,Haozhe Zhao,Ke Wan,Jiachen Li,Jiuxiang Gu,Wen Xiao,Nanyun Peng,Junjie Hu*

Main category: cs.CL

TL;DR: 本文介绍了VideoBiasEval框架，用于评估视频生成模型中的社会偏见，发现对齐调优会强化并稳定偏见，产生更平滑但更刻板的描述。


<details>
  <summary>Details</summary>
Motivation: 视频扩散模型通过基于人类偏好的奖励模型进行对齐调优，虽然提升了视觉质量，但可能无意中编码并放大了社会偏见。需要系统追踪这些偏见如何在对齐流程中演变。

Method: 引入VideoBiasEval诊断框架，基于社会偏见分类学，采用基于事件的提示策略分离语义内容和演员属性，并引入多粒度指标评估偏见。

Result: 对齐调优不仅加强了表征偏见，还使其在时间上更稳定，产生更平滑但更刻板的描述。揭示了人类偏好数据集中的偏见如何在奖励模型中被放大并传播到对齐调优的视频扩散模型中。

Conclusion: 研究结果强调需要在整个对齐过程中进行偏见感知的评估和缓解，以确保公平和社会责任的视频生成。

Abstract: Recent advances in video diffusion models have significantly enhanced
text-to-video generation, particularly through alignment tuning using reward
models trained on human preferences. While these methods improve visual
quality, they can unintentionally encode and amplify social biases. To
systematically trace how such biases evolve throughout the alignment pipeline,
we introduce VideoBiasEval, a comprehensive diagnostic framework for evaluating
social representation in video generation. Grounded in established social bias
taxonomies, VideoBiasEval employs an event-based prompting strategy to
disentangle semantic content (actions and contexts) from actor attributes
(gender and ethnicity). It further introduces multi-granular metrics to
evaluate (1) overall ethnicity bias, (2) gender bias conditioned on ethnicity,
(3) distributional shifts in social attributes across model variants, and (4)
the temporal persistence of bias within videos. Using this framework, we
conduct the first end-to-end analysis connecting biases in human preference
datasets, their amplification in reward models, and their propagation through
alignment-tuned video diffusion models. Our results reveal that alignment
tuning not only strengthens representational biases but also makes them
temporally stable, producing smoother yet more stereotyped portrayals. These
findings highlight the need for bias-aware evaluation and mitigation throughout
the alignment process to ensure fair and socially responsible video generation.

</details>


### [201] [How News Feels: Understanding Affective Bias in Multilingual Headlines for Human-Centered Media Design](https://arxiv.org/abs/2510.17252)
*Mohd Ruhul Ameen,Akif Islam,Abu Saleh Musa Miah,Ayesha Siddiqua,Jungpil Shin*

Main category: cs.CL

TL;DR: 本研究通过大规模情感分析发现孟加拉语新闻标题中负面情绪（愤怒、恐惧、失望）占主导地位，并提出了可视化情感线索的新闻聚合器设计方案。


<details>
  <summary>Details</summary>
Motivation: 新闻媒体通过报道框架影响公众情绪，负面或情绪化标题往往获得更多关注和传播，这促使媒体采用更能引发强烈反应的报道方式。

Method: 使用Gemma-3 4B模型进行零样本推理，分析了30万条孟加拉语新闻标题及其内容，识别每篇文章的主导情绪和整体基调。

Result: 研究结果显示负面情绪明显占主导地位，特别是愤怒、恐惧和失望，不同媒体对相似故事的报道在情感呈现上存在显著差异。

Conclusion: 基于这些发现，提出了以人为本的新闻聚合器设计理念，通过可视化情感线索帮助读者识别日常新闻中隐藏的情感框架。

Abstract: News media often shape the public mood not only by what they report but by
how they frame it. The same event can appear calm in one outlet and alarming in
another, reflecting subtle emotional bias in reporting. Negative or emotionally
charged headlines tend to attract more attention and spread faster, which in
turn encourages outlets to frame stories in ways that provoke stronger
reactions. This research explores that tendency through large-scale emotion
analysis of Bengali news. Using zero-shot inference with Gemma-3 4B, we
analyzed 300000 Bengali news headlines and their content to identify the
dominant emotion and overall tone of each. The findings reveal a clear
dominance of negative emotions, particularly anger, fear, and disappointment,
and significant variation in how similar stories are emotionally portrayed
across outlets. Based on these insights, we propose design ideas for a
human-centered news aggregator that visualizes emotional cues and helps readers
recognize hidden affective framing in daily news.

</details>


### [202] [Explainability of Large Language Models: Opportunities and Challenges toward Generating Trustworthy Explanations](https://arxiv.org/abs/2510.17256)
*Shahin Atakishiyev,Housam K. B. Babiker,Jiayi Dai,Nawshad Farruque,Teruaki Hayashi,Nafisa Sadaf Hriti,Md Abed Rahman,Iain Smith,Mi-Young Kim,Osmar R. Zaïane,Randy Goebel*

Main category: cs.CL

TL;DR: 本文综述了Transformer大语言模型的局部可解释性和机制可解释性方法，通过在医疗和自动驾驶领域的实验研究分析解释对信任的影响，并总结了当前未解决的问题和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然性能出色，但其预测机制对人类不可理解，且经常出现幻觉错误，迫切需要理解模型内部工作机制以建立信任。

Method: 采用文献综述方法梳理局部可解释性和机制可解释性方法，并在医疗和自动驾驶两个关键领域进行实验研究，分析解释对接收者信任的影响。

Result: 系统总结了现有可解释性方法的研究进展，通过实验验证了解释在提升模型信任度方面的作用，识别了当前研究中的关键挑战。

Conclusion: 大语言模型可解释性研究仍面临诸多挑战，需要开发人类对齐的可信解释方法，并提出了未来的研究方向和发展机遇。

Abstract: Large language models have exhibited impressive performance across a broad
range of downstream tasks in natural language processing. However, how a
language model predicts the next token and generates content is not generally
understandable by humans. Furthermore, these models often make errors in
prediction and reasoning, known as hallucinations. These errors underscore the
urgent need to better understand and interpret the intricate inner workings of
language models and how they generate predictive outputs. Motivated by this
gap, this paper investigates local explainability and mechanistic
interpretability within Transformer-based large language models to foster trust
in such models. In this regard, our paper aims to make three key contributions.
First, we present a review of local explainability and mechanistic
interpretability approaches and insights from relevant studies in the
literature. Furthermore, we describe experimental studies on explainability and
reasoning with large language models in two critical domains -- healthcare and
autonomous driving -- and analyze the trust implications of such explanations
for explanation receivers. Finally, we summarize current unaddressed issues in
the evolving landscape of LLM explainability and outline the opportunities,
critical challenges, and future directions toward generating human-aligned,
trustworthy LLM explanations.

</details>


### [203] [TaxoAlign: Scholarly Taxonomy Generation Using Language Models](https://arxiv.org/abs/2510.17263)
*Avishek Lahiri,Yufang Hou,Debarshi Kumar Sanyal*

Main category: cs.CL

TL;DR: 本文提出了TaxoAlign方法用于自动生成学术分类法，并创建了CS-TaxoBench基准数据集来评估自动生成分类法与人工编写分类法的质量对比。


<details>
  <summary>Details</summary>
Motivation: 现有自动文献综述生成方法缺乏对生成分类结构与人工专家编写分类结构的比较，需要填补这一研究空白。

Method: 提出TaxoAlign方法，这是一个三阶段的基于主题的指令引导的学术分类法生成方法，并建立了严格的自动评估框架来衡量结构对齐和语义连贯性。

Result: 在CS-TaxoBench基准上评估，TaxoAlign方法在几乎所有指标上都持续优于基线方法。

Conclusion: TaxoAlign方法能够有效弥合人工生成与自动创建分类法之间的差距，为自动文献综述生成提供了更好的分类结构支持。

Abstract: Taxonomies play a crucial role in helping researchers structure and navigate
knowledge in a hierarchical manner. They also form an important part in the
creation of comprehensive literature surveys. The existing approaches to
automatic survey generation do not compare the structure of the generated
surveys with those written by human experts. To address this gap, we present
our own method for automated taxonomy creation that can bridge the gap between
human-generated and automatically-created taxonomies. For this purpose, we
create the CS-TaxoBench benchmark which consists of 460 taxonomies that have
been extracted from human-written survey papers. We also include an additional
test set of 80 taxonomies curated from conference survey papers. We propose
TaxoAlign, a three-phase topic-based instruction-guided method for scholarly
taxonomy generation. Additionally, we propose a stringent automated evaluation
framework that measures the structural alignment and semantic coherence of
automatically generated taxonomies in comparison to those created by human
experts. We evaluate our method and various baselines on CS-TaxoBench, using
both automated evaluation metrics and human evaluation studies. The results
show that TaxoAlign consistently surpasses the baselines on nearly all metrics.
The code and data can be found at https://github.com/AvishekLahiri/TaxoAlign.

</details>


### [204] [Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation](https://arxiv.org/abs/2510.17354)
*Chenghao Zhang,Guanting Dong,Xinyu Yang,Zhicheng Dou*

Main category: cs.CL

TL;DR: 本文提出Nyx，一个针对通用检索增强生成（URAG）的统一混合模态检索器，解决了现有RAG系统仅处理文本模态的局限性，通过四阶段自动管道构建混合模态数据集NyxQA，采用两阶段训练框架，在文本和视觉语言任务中均表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统主要关注单模态文本文档，在现实场景中查询和文档可能包含混合模态（如文本和图像）时表现不足，需要解决通用检索增强生成（URAG）的挑战。

Method: 提出Nyx统一混合模态检索器；引入四阶段自动管道构建NyxQA数据集；采用两阶段训练框架：先在NyxQA和开源检索数据集上预训练，然后使用下游视觉语言模型的反馈进行监督微调。

Result: 实验结果表明，Nyx不仅在标准文本RAG基准上表现有竞争力，在更通用和现实的URAG设置中表现优异，显著提高了视觉语言任务的生成质量。

Conclusion: Nyx成功解决了混合模态检索增强生成的挑战，通过高质量数据集和两阶段训练框架，在文本和视觉语言任务中都取得了显著改进。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for
enhancing large language models (LLMs) by retrieving relevant documents from an
external corpus. However, existing RAG systems primarily focus on unimodal text
documents, and often fall short in real-world scenarios where both queries and
documents may contain mixed modalities (such as text and images). In this
paper, we address the challenge of Universal Retrieval-Augmented Generation
(URAG), which involves retrieving and reasoning over mixed-modal information to
improve vision-language generation. To this end, we propose Nyx, a unified
mixed-modal to mixed-modal retriever tailored for URAG scenarios. To mitigate
the scarcity of realistic mixed-modal data, we introduce a four-stage automated
pipeline for generation and filtering, leveraging web documents to construct
NyxQA, a dataset comprising diverse mixed-modal question-answer pairs that
better reflect real-world information needs. Building on this high-quality
dataset, we adopt a two-stage training framework for Nyx: we first perform
pre-training on NyxQA along with a variety of open-source retrieval datasets,
followed by supervised fine-tuning using feedback from downstream
vision-language models (VLMs) to align retrieval outputs with generative
preferences. Experimental results demonstrate that Nyx not only performs
competitively on standard text-only RAG benchmarks, but also excels in the more
general and realistic URAG setting, significantly improving generation quality
in vision-language tasks.

</details>


### [205] [The Atomic Instruction Gap: Instruction-Tuned LLMs Struggle with Simple, Self-Contained Directives](https://arxiv.org/abs/2510.17388)
*Henry Lim,Kwan Hui Lim*

Main category: cs.CL

TL;DR: 研究发现指令调优大语言模型在简单指令执行方面存在不足，特别是在选项标签格式变化时表现出明显的性能波动和指令格式偏见。


<details>
  <summary>Details</summary>
Motivation: 探索指令调优大语言模型执行简单、自包含指令的能力，这是复杂指令遵循的基础，但目前研究不足。

Method: 在修改后的MMLU和MMLU-Pro基准上评估20个IT-LLM，系统性地改变选项标签格式（字母、数字、罗马数字），并在四种范式下测试：有明确指令、无指令、移除选项内容、三样本示例。

Result: 标签格式变化导致显著性能波动（罗马数字vs数字下降30.45%）；无指令时性能进一步下降；移除选项内容时模型无法超越随机基线；三样本示例无显著改善；大模型准确率更高但指令遵循仍不一致。

Conclusion: 当前指令调优范式存在不足，需要针对原子指令遵循的评估方法和训练策略。

Abstract: Instruction-tuned large language models (IT-LLMs) exhibit strong zero-shot
reasoning, yet their ability to execute simple, self-contained instructions
remains underexplored, despite this being foundational to complex
instruction-following. We evaluate 20 IT-LLMs on modified MMLU and MMLU-Pro
benchmarks, by systematically varying the format of option labels (alphabetic,
numeric, Roman) while keeping their meaning identical under four paradigms,
namely: (1) With explicit instructions, label changes cause large performance
shifts (e.g., -30.45\% for Roman vs. numeric), revealing instruction-format
bias. (2) Without instructions, performance drops further (up to -10.84\%) and
label sensitivity intensifies, underscoring the role of explicit guidance. (3)
When option contents are removed, models fail random-choice baselines except
with numeric labels, suggesting weak adherence to atomic directives. (4)
Three-shot exemplars yield no significant gains in robustness or fidelity, and
generation analyses show persistent label errors, especially for non-numeric
formats. Across model sizes, larger LLMs achieve higher accuracy but remain
inconsistent in instruction adherence. These results expose the insufficiencies
of current instruction-tuning paradigms and highlight the need for evaluation
methods and training strategies that explicitly target atomic
instruction-following.

</details>


### [206] [EduAdapt: A Question Answer Benchmark Dataset for Evaluating Grade-Level Adaptability in LLMs](https://arxiv.org/abs/2510.17389)
*Numaan Naeem,Abdellah El Mekki,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 本文介绍了EduAdapt基准测试，用于评估大语言模型在K-12教育中根据学生年级水平调整回答的能力。该基准包含近48,000个年级标记的问答对，覆盖9个科学科目和1-12年级。研究发现，尽管大型模型表现更好，但仍难以生成适合低年级学生的回答。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型虽然在各学科基准测试中表现良好，但缺乏根据学生年级水平调整回答的能力。在K-12教育中，适合年龄的词汇和解释对有效学习至关重要，而现有模型往往产生过于复杂或模糊的回答，且缺乏标准化评估基准。

Method: 创建了EduAdapt基准测试，包含近48,000个年级标记的问答对，覆盖9个科学科目，跨越1-12年级并分为四个年级组。使用该基准评估了多种开源大语言模型，分析它们在不同年级水平上的表现差异。

Result: 评估结果显示，较大的模型通常表现更好，但在为低年级学生（1-5年级）生成合适回答方面仍存在困难。模型在调整回答以适应不同认知和发展阶段方面存在明显局限性。

Conclusion: EduAdapt是首个评估大语言模型年级适应能力的数据集和评估框架，旨在通过改进训练和提示策略，促进开发更适合教育发展阶段的AI系统。该基准测试的代码和数据集已公开提供。

Abstract: Large language models (LLMs) are transforming education by answering
questions, explaining complex concepts, and generating content across a wide
range of subjects. Despite strong performance on academic benchmarks, they
often fail to tailor responses to students' grade levels. This is a critical
need in K-12 education, where age-appropriate vocabulary and explanation are
essential for effective learning. Existing models frequently produce outputs
that are too advanced or vague for younger learners, and there are no
standardized benchmarks to evaluate their ability to adjust across cognitive
and developmental stages. To address this gap, we introduce EduAdapt, a
benchmark of nearly 48k grade-labeled QA pairs across nine science subjects,
spanning Grades 1-12 and grouped into four grade levels. We evaluate a diverse
set of open-source LLMs on EduAdapt and find that while larger models generally
perform better, they still struggle with generating suitable responses for
early-grade students (Grades 1-5). Our work presents the first dataset and
evaluation framework for assessing grade-level adaptability in LLMs, aiming to
foster more developmentally aligned educational AI systems through better
training and prompting strategies. EduAdapt code and datasets are publicly
available at https://github.com/NaumanNaeem/EduAdapt.

</details>


### [207] [Leveraging Group Relative Policy Optimization to Advance Large Language Models in Traditional Chinese Medicine](https://arxiv.org/abs/2510.17402)
*Jiacheng Xie,Shuai Zeng,Yang Yu,Xiaoting Tang,Guanghui An,Dong Xu*

Main category: cs.CL

TL;DR: 本研究开发了首个基于GRPO强化学习方法的中医药大语言模型Ladder-base，在中医药知识推理和事实一致性方面表现出色，超越了通用大模型和现有中医药专用模型。


<details>
  <summary>Details</summary>
Motivation: 传统中医药知识体系独特且复杂，现有中医药大语言模型在一致性、数据质量和评估标准方面存在局限，需要更有效的对齐方法来提升推理能力和事实准确性。

Method: 基于Qwen2.5-7B-Instruct基础模型，使用GRPO（组相对策略优化）强化学习方法，在TCM-Ladder基准的文本子集上进行训练，80%数据用于训练，剩余20%均分用于验证和测试。

Result: Ladder-base在多项推理指标上表现优异，超越了GPT-4、Gemini 2.5、Claude 3、Qwen3等通用大模型以及BenTsao、HuatuoGPT2、Zhongjing等中医药专用模型。

Conclusion: GRPO为大语言模型在传统医学领域的专家级推理对齐提供了有效且高效的策略，支持开发可信赖且具有临床基础的中医药人工智能系统。

Abstract: Traditional Chinese Medicine (TCM) presents a rich and structurally unique
knowledge system that challenges conventional applications of large language
models (LLMs). Although previous TCM-specific LLMs have shown progress through
supervised fine-tuning, they often face limitations in alignment, data quality,
and evaluation consistency. In this study, we introduce Ladder-base, the first
TCM-focused LLM trained with Group Relative Policy Optimization (GRPO), a
reinforcement learning method that improves reasoning and factual consistency
by optimizing response selection based on intra-group comparisons. Ladder-base
is built upon the Qwen2.5-7B-Instruct foundation model and trained exclusively
on the textual subset of the TCM-Ladder benchmark, using 80 percent of the data
for training and the remaining 20 percent split evenly between validation and
test sets. Through standardized evaluation, Ladder-base demonstrates superior
performance across multiple reasoning metrics when compared to both
state-of-the-art general-purpose LLMs such as GPT-4, Gemini 2.5, Claude 3, and
Qwen3 and domain-specific TCM models including BenTsao, HuatuoGPT2, and
Zhongjing. These findings suggest that GRPO provides an effective and efficient
strategy for aligning LLMs with expert-level reasoning in traditional medical
domains and supports the development of trustworthy and clinically grounded TCM
artificial intelligence systems.

</details>


### [208] [AFRICAPTION: Establishing a New Paradigm for Image Captioning in African Languages](https://arxiv.org/abs/2510.17405)
*Mardiyyah Oduwole,Prince Mireku,Fatimo Adebanjo,Oluwatosin Olajide,Mahi Aminu Aliyu,Jekaterina Novikova*

Main category: cs.CL

TL;DR: AfriCaption是一个用于20种非洲语言的多语言图像描述框架，包括精选数据集、动态质量保证流程和0.5B参数模型，旨在解决多模态AI研究中非洲语言资源不足的问题。


<details>
  <summary>Details</summary>
Motivation: 多模态AI研究主要集中在高资源语言上，阻碍了该领域进展的民主化，因此需要为非洲语言开发包容性资源。

Method: 构建基于Flickr8k的精选数据集，采用上下文感知选择和翻译过程生成语义对齐的标题；开发动态上下文保持流程，通过模型集成和自适应替换确保持续质量；创建AfriCaption模型，整合SigLIP和NLLB200进行跨语言标题生成。

Result: 建立了首个可扩展的非洲语言图像描述资源，为20种非洲语言提供了高质量的多语言图像描述能力。

Conclusion: AfriCaption为代表性不足的非洲语言建立了首个可扩展的图像描述资源，为真正包容的多模态AI奠定了基础。

Abstract: Multimodal AI research has overwhelmingly focused on high-resource languages,
hindering the democratization of advancements in the field. To address this, we
present AfriCaption, a comprehensive framework for multilingual image
captioning in 20 African languages and our contributions are threefold: (i) a
curated dataset built on Flickr8k, featuring semantically aligned captions
generated via a context-aware selection and translation process; (ii) a
dynamic, context-preserving pipeline that ensures ongoing quality through model
ensembling and adaptive substitution; and (iii) the AfriCaption model, a 0.5B
parameter vision-to-text architecture that integrates SigLIP and NLLB200 for
caption generation across under-represented languages. This unified framework
ensures ongoing data quality and establishes the first scalable
image-captioning resource for under-represented African languages, laying the
groundwork for truly inclusive multimodal AI.

</details>


### [209] [Navigating the Alignment-Calibration Trade-off: A Pareto-Superior Frontier via Model Merging](https://arxiv.org/abs/2510.17426)
*Tiancheng Hu,Benjamin Minixhofer,Nigel Collier*

Main category: cs.CL

TL;DR: 论文显示对齐训练不仅导致任务准确率下降，还造成严重的校准损失，使模型过度自信、可靠性降低且输出多样性减少。通过简单的模型权重插值方法，可以找到帕累托最优解，在提高准确率的同时恢复校准性能。


<details>
  <summary>Details</summary>
Motivation: 研究对齐训练带来的"对齐税"问题，不仅关注任务准确率下降，还发现校准损失这一被忽视的重要维度，旨在找到缓解完整对齐税的方法。

Method: 采用简单的后处理干预方法：在对齐前后的模型权重之间进行插值，寻找帕累托最优的插值点。

Result: 发现该方法能够一致地找到帕累托最优插值点，这些模型不仅准确率超过两个父模型，还显著恢复了对齐过程中损失的校准性能。

Conclusion: 简单的模型合并提供了一种计算高效的方法来缓解完整的对齐税，产生既更强大又更可靠的模型。

Abstract: The "alignment tax" of post-training is typically framed as a drop in task
accuracy. We show it also involves a severe loss of calibration, making models
overconfident, less reliable, and model outputs less diverse. We show that this
trade-off can be navigated effectively via a simple post-hoc intervention:
interpolating between a model's weights before and after alignment. Crucially,
this is not a strict trade-off. We find that the process consistently reveals
Pareto-optimal interpolations - models that improve accuracy beyond both
parents while substantially recovering the calibration lost during alignment.
Our work demonstrates that simple model merging provides a computationally
efficient method for mitigating the full scope of the alignment tax, yielding
models that are more capable and more reliable.

</details>


### [210] [Evaluating Large Language Models on Urdu Idiom Translation](https://arxiv.org/abs/2510.17460)
*Muhammad Farmal Khan,Mousumi Akter*

Main category: cs.CL

TL;DR: 该研究首次构建了乌尔都语到英语的习语翻译评估数据集，评估了多种LLM和NMT系统在习语翻译上的表现，发现提示工程能改善翻译质量，且原生乌尔都语文本比罗马化文本翻译效果更好。


<details>
  <summary>Details</summary>
Motivation: 习语翻译是机器翻译中的重要挑战，特别是对于乌尔都语等低资源语言，此前研究关注有限。

Method: 构建首个乌尔都语到英语习语翻译评估数据集，涵盖原生乌尔都语和罗马化乌尔都语脚本，使用BLEU、BERTScore、COMET和XCOMET等自动指标评估多种LLM和NMT系统的翻译质量。

Result: 提示工程相比直接翻译能提升习语翻译质量，但不同提示类型间差异较小；原生乌尔都语输入的习语翻译准确性显著高于罗马化乌尔都语。

Conclusion: 文本表示形式对翻译质量有显著影响，原生乌尔都语更适合习语翻译任务，提示工程是改善习语翻译的有效方法。

Abstract: Idiomatic translation remains a significant challenge in machine translation,
especially for low resource languages such as Urdu, and has received limited
prior attention. To advance research in this area, we introduce the first
evaluation datasets for Urdu to English idiomatic translation, covering both
Native Urdu and Roman Urdu scripts and annotated with gold-standard English
equivalents. We evaluate multiple open-source Large Language Models (LLMs) and
Neural Machine Translation (NMT) systems on this task, focusing on their
ability to preserve idiomatic and cultural meaning. Automatic metrics including
BLEU, BERTScore, COMET, and XCOMET are used to assess translation quality. Our
findings indicate that prompt engineering enhances idiomatic translation
compared to direct translation, though performance differences among prompt
types are relatively minor. Moreover, cross script comparisons reveal that text
representation substantially affects translation quality, with Native Urdu
inputs producing more accurate idiomatic translations than Roman Urdu.

</details>


### [211] [Disparities in Multilingual LLM-Based Healthcare Q&A](https://arxiv.org/abs/2510.17476)
*Ipek Baris Schlicht,Burcu Sayin,Zhixue Zhao,Frederik M. Labonté,Cesare Barbera,Marco Viviani,Paolo Rosso,Lucie Flek*

Main category: cs.CL

TL;DR: 该研究系统分析了多语言大语言模型在医疗问答中的跨语言事实对齐差异，发现即使使用非英语提示，模型回答仍更偏向英语维基百科内容，但通过提供非英语上下文可以有效改善事实对齐。


<details>
  <summary>Details</summary>
Motivation: 将AI整合到医疗保健中需要公平获取可靠健康信息，但不同语言的信息质量存在差异，引发了对多语言大语言模型可靠性和一致性的担忧。

Method: 构建了多语言维基医疗数据集，分析跨语言医疗覆盖度，评估LLM回答与参考内容的对齐度，并通过上下文信息和检索增强生成进行事实对齐案例研究。

Result: 发现维基百科覆盖度和LLM事实对齐存在显著的跨语言差异，所有LLM的回答都更偏向英语维基百科，即使提示为非英语。提供非英语维基百科上下文能有效将事实对齐转向文化相关知识。

Conclusion: 研究结果强调了构建更公平的多语言医疗AI系统的实用途径，通过提供本地化上下文可以有效改善模型的事实对齐表现。

Abstract: Equitable access to reliable health information is vital when integrating AI
into healthcare. Yet, information quality varies across languages, raising
concerns about the reliability and consistency of multilingual Large Language
Models (LLMs). We systematically examine cross-lingual disparities in
pre-training source and factuality alignment in LLM answers for multilingual
healthcare Q&A across English, German, Turkish, Chinese (Mandarin), and
Italian. We (i) constructed Multilingual Wiki Health Care
(MultiWikiHealthCare), a multilingual dataset from Wikipedia; (ii) analyzed
cross-lingual healthcare coverage; (iii) assessed LLM response alignment with
these references; and (iv) conducted a case study on factual alignment through
the use of contextual information and Retrieval-Augmented Generation (RAG). Our
findings reveal substantial cross-lingual disparities in both Wikipedia
coverage and LLM factual alignment. Across LLMs, responses align more with
English Wikipedia, even when the prompts are non-English. Providing contextual
excerpts from non-English Wikipedia at inference time effectively shifts
factual alignment toward culturally relevant knowledge. These results highlight
practical pathways for building more equitable, multilingual AI systems for
healthcare.

</details>


### [212] [ReXMoE: Reusing Experts with Minimal Overhead in Mixture-of-Experts](https://arxiv.org/abs/2510.17483)
*Zheyue Tan,Zhiyuan Li,Tao Yuan,Dong Zhou,Weilin Liu,Yueqing Zhuang,Yadong Li,Guowei Niu,Cheng Qin,Zhuyu Yao,Congyi Liu,Haiyang Xu,Boxun Li,Guohao Dai,Bo Zhao,Yu Wang*

Main category: cs.CL

TL;DR: ReXMoE是一种新颖的MoE架构，通过跨层重用专家来改进路由机制，突破了传统层局部路由的限制，在固定参数预算下实现了更好的性能和参数效率。


<details>
  <summary>Details</summary>
Motivation: 传统MoE架构的层局部路由机制限制了专家组合的灵活性，需要在专家维度和路由多样性之间进行权衡。ReXMoE旨在通过跨层重用专家来克服这一限制。

Method: 提出ReXMoE架构，允许路由器在相邻层之间重用专家，将专家维度与每层预算解耦。采用渐进式缩放路由(PSR)策略在训练过程中逐步增加候选专家池。

Result: 在0.5B到7B参数规模的不同架构模型上进行广泛实验，ReXMoE在固定架构维度下持续提升语言建模和下游任务性能。

Conclusion: ReXMoE为参数高效且可扩展的MoE基LLMs提供了新的设计范式，在保持参数效率的同时显著提升了模型表达能力。

Abstract: Mixture-of-Experts (MoE) architectures have emerged as a promising approach
to scale Large Language Models (LLMs). MoE boosts the efficiency by activating
a subset of experts per token. Recent works show that fine-grained experts
substantially enriches the combinatorial flexibility of active experts and
enhances model expressiveness. However, such a design is fundamentally limited
by the layer-local routing mechanism: each layer is restricted to its own
expert pool. This requires a careful trade-off between expert dimensionality
and routing diversity given fixed parameter budgets. We describe ReXMoE, a
novel MoE architecture that improves routing beyond the existing layer-local
approaches by allowing routers to reuse experts across adjacent layers. ReXMoE
decouples expert dimensionality from per-layer budgets, enabling richer expert
combinations without sacrificing individual expert capacity or inflating
overall parameters. To this end, we propose a new progressive scaling routing
(PSR) strategy to gradually increase the candidate expert pool during training.
As a result, ReXMoE improves both language modeling and downstream task
performance. Extensive experiments on models ranging from 0.5B to 7B parameters
across different architectures demonstrate that ReXMoE consistently improves
performance under fixed architectural dimensions, confirming ReXMoE as new
design paradigm for parameter-efficient and scalable MoE-based LLMs.

</details>


### [213] [DETree: DEtecting Human-AI Collaborative Texts via Tree-Structured Hierarchical Representation Learning](https://arxiv.org/abs/2510.17489)
*Yongxin He,Shan Zhang,Yixuan Cao,Lei Ma,Ping Luo*

Main category: cs.CL

TL;DR: 该论文提出DETree方法，通过构建层次亲和树结构来建模不同AI-人类协作文本生成过程之间的关系，并开发RealBench基准数据集，显著提升了混合文本检测的性能、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 检测AI参与生成的文本对于打击错误信息、抄袭和学术不端行为至关重要。然而，AI文本生成涉及多样化的协作过程（人类编辑的AI文本、AI编辑的人类文本、其他AI优化的AI文本），这些过程产生的文本具有复杂特征，给检测带来重大挑战。现有方法对这些过程的建模较为粗糙。

Method: 提出DETree方法，将不同生成过程之间的关系建模为层次亲和树结构，并引入专门的损失函数使文本表示与该树对齐。开发RealBench基准数据集，自动包含各种人类-AI协作过程产生的混合文本。

Result: 该方法在混合文本检测任务中提升了性能，显著增强了在分布外场景下的鲁棒性和泛化能力，特别是在少样本学习条件下，进一步证明了基于训练的方法在OOD设置中的潜力。

Conclusion: DETree方法通过层次亲和树结构有效建模了不同AI-人类协作文本生成过程之间的关系，在混合文本检测方面表现出优越性能，为AI文本检测提供了新的解决方案。

Abstract: Detecting AI-involved text is essential for combating misinformation,
plagiarism, and academic misconduct. However, AI text generation includes
diverse collaborative processes (AI-written text edited by humans,
human-written text edited by AI, and AI-generated text refined by other AI),
where various or even new LLMs could be involved. Texts generated through these
varied processes exhibit complex characteristics, presenting significant
challenges for detection. Current methods model these processes rather crudely,
primarily employing binary classification (purely human vs. AI-involved) or
multi-classification (treating human-AI collaboration as a new class). We
observe that representations of texts generated through different processes
exhibit inherent clustering relationships. Therefore, we propose DETree, a
novel approach that models the relationships among different processes as a
Hierarchical Affinity Tree structure, and introduces a specialized loss
function that aligns text representations with this tree. To facilitate this
learning, we developed RealBench, a comprehensive benchmark dataset that
automatically incorporates a wide spectrum of hybrid texts produced through
various human-AI collaboration processes. Our method improves performance in
hybrid text detection tasks and significantly enhances robustness and
generalization in out-of-distribution scenarios, particularly in few-shot
learning conditions, further demonstrating the promise of training-based
approaches in OOD settings. Our code and dataset are available at
https://github.com/heyongxin233/DETree.

</details>


### [214] [Empowering Real-World: A Survey on the Technology, Practice, and Evaluation of LLM-driven Industry Agents](https://arxiv.org/abs/2510.17491)
*Yihong Tang,Kehai Chen,Liang Yue,Jinxin Fan,Caishen Zhou,Xiaoguang Li,Yuyang Zhang,Mingming Zhao,Shixiong Kai,Kaiyang Guo,Xingshan Zeng,Wenjing Cun,Lifeng Shang,Min Zhang*

Main category: cs.CL

TL;DR: 本文系统综述了基于大语言模型的行业智能体技术、应用和评估方法，提出了行业智能体能力成熟度框架，从技术支柱、行业应用到评估挑战等方面全面分析了行业智能体的发展现状和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，能够自主推理、规划和执行复杂任务的智能体已成为人工智能前沿。但如何将通用智能体研究转化为推动行业变革的生产力仍是一个重大挑战。

Method: 采用行业智能体能力成熟度框架，分析智能体在行业应用中的演进路径；系统研究支撑智能体能力发展的三大技术支柱（记忆、规划、工具使用）及其演进过程；综述行业智能体在多个实际领域的应用情况；评估基础能力和专业能力的基准与方法。

Result: 明确了行业智能体从"流程执行系统"到"自适应社会系统"的演进路径；识别了现有评估系统在真实性、安全性和行业特性方面面临的挑战；分析了行业智能体在实际应用中面临的能力边界、发展潜力和治理问题。

Conclusion: 通过结合技术演进与行业实践，本文为理解和构建下一代行业智能体提供了清晰的路线图和理论基础，明确了当前发展状态和未来研究方向。

Abstract: With the rise of large language models (LLMs), LLM agents capable of
autonomous reasoning, planning, and executing complex tasks have become a
frontier in artificial intelligence. However, how to translate the research on
general agents into productivity that drives industry transformations remains a
significant challenge. To address this, this paper systematically reviews the
technologies, applications, and evaluation methods of industry agents based on
LLMs. Using an industry agent capability maturity framework, it outlines the
evolution of agents in industry applications, from "process execution systems"
to "adaptive social systems." First, we examine the three key technological
pillars that support the advancement of agent capabilities: Memory, Planning,
and Tool Use. We discuss how these technologies evolve from supporting simple
tasks in their early forms to enabling complex autonomous systems and
collective intelligence in more advanced forms. Then, we provide an overview of
the application of industry agents in real-world domains such as digital
engineering, scientific discovery, embodied intelligence, collaborative
business execution, and complex system simulation. Additionally, this paper
reviews the evaluation benchmarks and methods for both fundamental and
specialized capabilities, identifying the challenges existing evaluation
systems face regarding authenticity, safety, and industry specificity. Finally,
we focus on the practical challenges faced by industry agents, exploring their
capability boundaries, developmental potential, and governance issues in
various scenarios, while providing insights into future directions. By
combining technological evolution with industry practices, this review aims to
clarify the current state and offer a clear roadmap and theoretical foundation
for understanding and building the next generation of industry agents.

</details>


### [215] [Deep Self-Evolving Reasoning](https://arxiv.org/abs/2510.17498)
*Zihan Liu,Shun Zheng,Xumeng Wen,Yang Wang,Jiang Bian,Mao Yang*

Main category: cs.CL

TL;DR: DSER通过概率化推理框架，将推理过程建模为马尔可夫链，利用并行长时程自演化过程放大微小改进概率，显著扩展了小型开源模型在困难任务上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前开源小规模模型在验证和精炼能力上较弱，限制了其在复杂推理任务中的表现，需要一种能够克服这些限制的新方法。

Method: 将迭代推理建模为马尔可夫链，通过并行运行多个自演化过程，利用概率优势逐步收敛到正确答案。

Result: 在AIME 2024-2025基准测试中，DSER解决了9个之前无法解决的问题中的5个，使DeepSeek-R1-0528-Qwen3-8B模型通过多数投票超越了其600B参数教师模型的单轮准确率。

Conclusion: DSER不仅提供了测试时扩展的实用方法，更重要的是为诊断当前开源推理器的根本局限性提供了框架，为开发具有强大内在自演化能力的下一代模型指明了研究方向。

Abstract: Long-form chain-of-thought reasoning has become a cornerstone of advanced
reasoning in large language models. While recent verification-refinement
frameworks have enabled proprietary models to solve Olympiad-level problems,
their effectiveness hinges on strong, reliable verification and correction
capabilities, which remain fragile in open-weight, smaller-scale models. This
work demonstrates that even with weak verification and refinement capabilities
on hard tasks, the reasoning limits of such models can be substantially
extended through a probabilistic paradigm we call Deep Self-Evolving Reasoning
(DSER). We conceptualize iterative reasoning as a Markov chain, where each step
represents a stochastic transition in the solution space. The key insight is
that convergence to a correct solution is guaranteed as long as the probability
of improvement marginally exceeds that of degradation. By running multiple
long-horizon, self-evolving processes in parallel, DSER amplifies these small
positive tendencies, enabling the model to asymptotically approach correct
answers. Empirically, we apply DSER to the DeepSeek-R1-0528-Qwen3-8B model. On
the challenging AIME 2024-2025 benchmark, DSER solves 5 out of 9 previously
unsolvable problems and boosts overall performance, enabling this compact model
to surpass the single-turn accuracy of its 600B-parameter teacher through
majority voting. Beyond its immediate utility for test-time scaling, the DSER
framework serves to diagnose the fundamental limitations of current open-weight
reasoners. By clearly delineating their shortcomings in self-verification,
refinement, and stability, our findings establish a clear research agenda for
developing next-generation models with powerful, intrinsic self-evolving
capabilities.

</details>


### [216] [Lingua Custodi's participation at the WMT 2025 Terminology shared task](https://arxiv.org/abs/2510.17504)
*Jingshu Liu,Raheel Qader,Gaëtan Caillaut,Mariam Nakhlé*

Main category: cs.CL

TL;DR: 本文系统研究了多语言句子嵌入学习方法，结合了单语和跨语言表示学习的最佳方法，包括掩码语言建模、翻译语言建模、双编码器翻译排序和加性边际softmax。


<details>
  <summary>Details</summary>
Motivation: 虽然BERT在单语句子嵌入学习方面表现优异，但基于BERT的跨语言句子嵌入方法尚未被充分探索，需要系统研究如何有效学习多语言句子嵌入。

Method: 结合多种方法：掩码语言建模(MLM)、翻译语言建模(TLM)、双编码器翻译排序和加性边际softmax，并利用预训练的多语言语言模型。

Result: 引入预训练多语言模型将所需并行训练数据减少80%；在Tatoeba数据集上112种语言的bi-text检索准确率达到83.7%，远高于LASER的65.5%；在单语迁移学习基准上保持竞争力；从CommonCrawl挖掘的并行数据可训练出竞争力的NMT模型。

Conclusion: 提出的方法显著提升了多语言句子嵌入的性能，并公开发布了支持109+语言的最佳多语言句子嵌入模型。

Abstract: While BERT is an effective method for learning monolingual sentence
embeddings for semantic similarity and embedding based transfer learning BERT
based cross-lingual sentence embeddings have yet to be explored. We
systematically investigate methods for learning multilingual sentence
embeddings by combining the best methods for learning monolingual and
cross-lingual representations including: masked language modeling (MLM),
translation language modeling (TLM), dual encoder translation ranking, and
additive margin softmax. We show that introducing a pre-trained multilingual
language model dramatically reduces the amount of parallel training data
required to achieve good performance by 80%. Composing the best of these
methods produces a model that achieves 83.7% bi-text retrieval accuracy over
112 languages on Tatoeba, well above the 65.5 achieved by LASER, while still
performing competitively on monolingual transfer learning benchmarks. Parallel
data mined from CommonCrawl using our best model is shown to train competitive
NMT models for en-zh and en-de. We publicly release our best multilingual
sentence embedding model for 109+ languages at https://tfhub.dev/google/LaBSE.

</details>


### [217] [Annotation-Efficient Universal Honesty Alignment](https://arxiv.org/abs/2510.17509)
*Shiyu Ni,Keping Bi,Jiafeng Guo,Minghao Tang,Jingtong Wu,Zengxin Han,Xueqi Cheng*

Main category: cs.CL

TL;DR: EliCal是一个两阶段框架，通过廉价的自我一致性监督获取内部置信度，然后用少量正确性标注进行校准，实现高效诚实对齐。


<details>
  <summary>Details</summary>
Motivation: 现有诚实对齐方法要么依赖无训练置信度估计，要么需要大规模正确性标注训练，成本高昂。需要支持标注高效训练的方法。

Method: 提出Elicitation-Then-Calibration两阶段框架：第一阶段使用廉价自我一致性监督获取内部置信度，第二阶段用少量正确性标注校准置信度。

Result: EliCal仅用1k正确性标注（全监督的0.18%）就达到接近最优的对齐效果，在未见MMLU任务上表现优于仅校准基线。

Conclusion: EliCal为LLMs的通用诚实对齐提供了可扩展解决方案，显著降低了标注成本。

Abstract: Honesty alignment-the ability of large language models (LLMs) to recognize
their knowledge boundaries and express calibrated confidence-is essential for
trustworthy deployment. Existing methods either rely on training-free
confidence estimation (e.g., token probabilities, self-consistency) or
training-based calibration with correctness annotations. While effective,
achieving universal honesty alignment with training-based calibration requires
costly, large-scale labeling. To support annotation-efficient training, we
introduce Elicitation-Then-Calibration (EliCal), a two-stage framework that
first elicits internal confidence using inexpensive self-consistency
supervision, then calibrates this confidence with a small set of correctness
annotations. To support a large-scale study, we release HonestyBench, a
benchmark covering ten free-form QA datasets with 560k training and 70k
evaluation instances annotated with correctness and self-consistency signals.
Experiments show that EliCal achieves near-optimal alignment with only 1k
correctness annotations (0.18% of full supervision) and better alignment
performance on unseen MMLU tasks than the calibration-only baseline, offering a
scalable solution toward universal honesty alignment in LLMs.

</details>


### [218] [SimBench: Benchmarking the Ability of Large Language Models to Simulate Human Behaviors](https://arxiv.org/abs/2510.17516)
*Tiancheng Hu,Joachim Baumann,Lorenzo Lupo,Dirk Hovy,Nigel Collier,Paul Röttger*

Main category: cs.CL

TL;DR: SimBench是首个用于LLM模拟人类行为的大规模标准化基准测试，整合了20个数据集，评估发现当前最佳LLM模拟能力有限（40.8/100），性能随模型规模对数线性增长，存在对齐-模拟权衡，且在模拟特定人口群体时表现较差。


<details>
  <summary>Details</summary>
Motivation: 当前LLM模拟人类行为的评估方法分散且不统一，阻碍了社会和行为科学的发展。需要建立标准化基准来系统评估LLM模拟的可靠性。

Method: 开发SimBench基准测试，整合20个多样化数据集，涵盖道德决策到经济选择等任务，基于全球参与者数据进行评估。

Result: 当前最佳LLM模拟得分仅为40.8/100；性能随模型规模对数线性增长；推理计算增加不提升性能；存在对齐-模拟权衡（指令调优在低熵问题上有帮助但在高熵问题上降低性能）；模拟特定人口群体表现差；模拟能力与深度知识推理能力强相关（MMLU-Pro，r=0.939）。

Conclusion: 通过建立可衡量的评估标准，SimBench为开发更准确的LLM模拟器奠定了基础，揭示了当前LLM模拟能力的局限性及其与模型特性和任务类型的关系。

Abstract: Large language model (LLM) simulations of human behavior have the potential
to revolutionize the social and behavioral sciences, if and only if they
faithfully reflect real human behaviors. Current evaluations are fragmented,
based on bespoke tasks and metrics, creating a patchwork of incomparable
results. To address this, we introduce SimBench, the first large-scale,
standardized benchmark for a robust, reproducible science of LLM simulation. By
unifying 20 diverse datasets covering tasks from moral decision-making to
economic choice across a large global participant pool, SimBench provides the
necessary foundation to ask fundamental questions about when, how, and why LLM
simulations succeed or fail. We show that, while even the best LLMs today have
limited simulation ability (score: 40.80/100), performance scales log-linearly
with model size. Simulation performance is not improved by increased
inference-time compute. We demonstrate an alignment-simulation trade-off:
instruction-tuning improves performance on low-entropy (consensus) questions
but degrades it on high-entropy (diverse) ones. Models particularly struggle
when simulating specific demographic groups. Finally, we demonstrate that
simulation ability correlates most strongly with deep, knowledge-intensive
reasoning (MMLU-Pro, r=0.939). By making progress measurable, we aim to
accelerate the development of more faithful LLM simulators.

</details>


### [219] [OncoReason: Structuring Clinical Reasoning in LLMs for Robust and Interpretable Survival Prediction](https://arxiv.org/abs/2510.17532)
*Raghu Vamshi Hemadri,Geetha Krishna Guruju,Kristi Topollai,Anna Ewa Choromanska*

Main category: cs.CL

TL;DR: 该论文提出了一个统一的多任务学习框架，将自回归LLM与临床推理对齐，用于MSK-CHORD数据集上的癌症治疗结果预测。通过三种对齐策略（标准监督微调、思维链提示、GRPO强化学习）提升模型的预测性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 预测癌症治疗结果需要既准确又可解释的模型，特别是在存在异质性临床数据的情况下。虽然大型语言模型在生物医学NLP中表现出色，但缺乏对高风险决策支持至关重要的结构化推理能力。

Method: 使用统一的多任务学习框架，训练模型同时执行二元生存分类、连续生存时间回归和自然语言理由生成。评估三种对齐策略：标准监督微调、思维链提示和GRPO强化学习方法。

Result: 实验表明，思维链提示将F1提高了+6.0%，MAE降低了12%，而GRPO在BLEU、ROUGE和BERTScore上实现了最先进的可解释性和预测性能。

Conclusion: 研究结果强调了在多任务临床建模中推理感知对齐的重要性，并为精准肿瘤学中可解释、可信赖的LLM设定了新基准。

Abstract: Predicting cancer treatment outcomes requires models that are both accurate
and interpretable, particularly in the presence of heterogeneous clinical data.
While large language models (LLMs) have shown strong performance in biomedical
NLP, they often lack structured reasoning capabilities critical for high-stakes
decision support. We present a unified, multi-task learning framework that
aligns autoregressive LLMs with clinical reasoning for outcome prediction on
the MSK-CHORD dataset. Our models are trained to jointly perform binary
survival classification, continuous survival time regression, and natural
language rationale generation. We evaluate three alignment strategies: (1)
standard supervised fine-tuning (SFT), (2) SFT with Chain-of-Thought (CoT)
prompting to elicit step-by-step reasoning, and (3) Group Relative Policy
Optimization (GRPO), a reinforcement learning method that aligns model outputs
to expert-derived reasoning trajectories. Experiments with LLaMa3-8B and
Med42-8B backbones demonstrate that CoT prompting improves F1 by +6.0 and
reduces MAE by 12%, while GRPO achieves state-of-the-art interpretability and
predictive performance across BLEU, ROUGE, and BERTScore. We further show that
existing biomedical LLMs often fail to produce valid reasoning traces due to
architectural constraints. Our findings underscore the importance of
reasoning-aware alignment in multi-task clinical modeling and set a new
benchmark for interpretable, trustworthy LLMs in precision oncology.

</details>


### [220] [When Annotators Disagree, Topology Explains: Mapper, a Topological Tool for Exploring Text Embedding Geometry and Ambiguity](https://arxiv.org/abs/2510.17548)
*Nisrine Rair,Alban Goupil,Valeriu Vrabie,Emmanuel Chochoy*

Main category: cs.CL

TL;DR: 该论文提出了一种拓扑视角来分析微调模型如何编码歧义性，使用拓扑数据分析工具Mapper揭示了微调后嵌入空间形成模块化、非凸区域，与模型预测对齐，即使在高度歧义情况下也保持高预测纯度。


<details>
  <summary>Details</summary>
Motivation: 传统标量指标（如准确率）无法捕捉模型内部如何表示歧义性，特别是当人类标注者存在分歧时。需要新的方法来理解模型如何处理主观性NLP任务中的不确定性。

Method: 使用拓扑数据分析工具Mapper分析RoBERTa-Large在MD-Offense数据集上的嵌入空间结构，与传统方法（PCA、UMAP）对比，直接揭示决策区域、边界塌陷和过度自信聚类。

Result: 微调将嵌入空间重组为模块化非凸区域，98%以上的连通组件表现出≥90%的预测纯度。但在歧义数据中，与真实标签的对齐度下降，揭示了结构置信度与标签不确定性之间的隐藏张力。

Conclusion: Mapper可作为强大的诊断工具，理解模型如何解决歧义性。除了可视化，它还支持拓扑指标，可为主观NLP任务中的主动建模策略提供信息。

Abstract: Language models are often evaluated with scalar metrics like accuracy, but
such measures fail to capture how models internally represent ambiguity,
especially when human annotators disagree. We propose a topological perspective
to analyze how fine-tuned models encode ambiguity and more generally instances.
  Applied to RoBERTa-Large on the MD-Offense dataset, Mapper, a tool from
topological data analysis, reveals that fine-tuning restructures embedding
space into modular, non-convex regions aligned with model predictions, even for
highly ambiguous cases. Over $98\%$ of connected components exhibit $\geq 90\%$
prediction purity, yet alignment with ground-truth labels drops in ambiguous
data, surfacing a hidden tension between structural confidence and label
uncertainty.
  Unlike traditional tools such as PCA or UMAP, Mapper captures this geometry
directly uncovering decision regions, boundary collapses, and overconfident
clusters. Our findings position Mapper as a powerful diagnostic tool for
understanding how models resolve ambiguity. Beyond visualization, it also
enables topological metrics that may inform proactive modeling strategies in
subjective NLP tasks.

</details>


### [221] [Language Confusion Gate: Language-Aware Decoding Through Model Self-Distillation](https://arxiv.org/abs/2510.17555)
*Collin Zhang,Fei Huang,Chenhan Yuan,Junyang Lin*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级的语言混淆门（LCG）方法，通过解码时过滤token来解决大语言模型中的语言混淆问题，无需重新训练模型且能区分有害混淆和可接受语码转换。


<details>
  <summary>Details</summary>
Motivation: 大语言模型经常出现语言混淆问题，即文本生成时无意中混合多种语言。现有解决方案要么需要重新训练模型，要么无法区分有害混淆和可接受语码转换。

Method: 引入语言混淆门（LCG），这是一种轻量级插件解决方案，在解码过程中过滤token而不改变基础LLM。使用规范调整自蒸馏训练LCG来预测适当的语言家族，仅在需要时应用掩码。

Result: 在包括Qwen3、GPT-OSS、Gemma3、Llama3.1在内的各种模型上评估，LCG显著减少了语言混淆，通常降低一个数量级，且不影响任务性能。

Conclusion: LCG是一种有效的轻量级解决方案，能显著减少大语言模型的语言混淆问题，同时保持任务性能，代码已开源。

Abstract: Large language models (LLMs) often experience language confusion, which is
the unintended mixing of languages during text generation. Current solutions to
this problem either necessitate model retraining or cannot differentiate
between harmful confusion and acceptable code-switching. This paper introduces
the Language Confusion Gate (LCG), a lightweight, plug-in solution that filters
tokens during decoding without altering the base LLM. The LCG is trained using
norm-adjusted self-distillation to predict appropriate language families and
apply masking only when needed. Our method is based on the findings that
language confusion is infrequent, correct-language tokens are usually among the
top predictions, and output token embedding norms are larger for high-resource
languages, which biases sampling. When evaluated across various models,
including Qwen3, GPT-OSS, Gemma3, Llama3.1, LCG decreases language confusion
significantly, often by an order of magnitude, without negatively impacting
task performance. Code is available at
https://github.com/collinzrj/language_confusion_gate.

</details>


### [222] [LawChain: Modeling Legal Reasoning Chains for Chinese Tort Case Analysis](https://arxiv.org/abs/2510.17602)
*Huiyuan Xie,Chenyang Li,Huining Zhu,Chubin Zhang,Yuxiao Ye,Zhenghao Liu,Zhiyuan Liu*

Main category: cs.CL

TL;DR: 提出了LawChain框架来显式建模中国侵权民事案件中的法律推理过程，并构建了评估基准LawChain_eval来系统评估侵权分析中的关键推理步骤。


<details>
  <summary>Details</summary>
Motivation: 现有法律推理计算方法主要依赖通用推理框架，未能全面考察法律推理的细微过程，且研究多集中于刑事案件，对民事案件建模不足。

Method: 将侵权分析中的法律推理过程操作化为LawChain框架，包含三个模块，每个模块由多个细粒度子步骤组成。基于该框架构建侵权法律推理任务和评估基准，评估大语言模型在民事侵权背景下的法律推理能力。

Result: 当前模型在处理侵权法律推理的关键要素方面仍存在不足。提出的基线方法通过提示或后训练显式融入LawChain式推理，在侵权相关法律推理方面取得显著改进，并能很好地推广到相关法律分析任务。

Conclusion: 显式建模法律推理链能够有效增强语言模型的推理能力，LawChain框架在法律分析任务中具有良好泛化性。

Abstract: Legal reasoning is a fundamental component of legal analysis and
decision-making. Existing computational approaches to legal reasoning
predominantly rely on generic reasoning frameworks such as syllogism and IRAC,
which do not comprehensively examine the nuanced processes that underpin legal
reasoning. Moreover, current research has largely focused on criminal cases,
with insufficient modeling for civil cases. In this work, we present a novel
framework for explicitly modeling legal reasoning in the analysis of Chinese
tort-related civil cases. We first operationalize the legal reasoning processes
used in tort analysis into the LawChain framework. LawChain is a three-module
reasoning framework, with each module consisting of multiple finer-grained
sub-steps. Informed by the LawChain framework, we introduce the task of tort
legal reasoning and construct an evaluation benchmark, LawChain$_{eval}$, to
systematically assess the critical steps within analytical reasoning chains for
tort analysis. Leveraging this benchmark, we evaluate state-of-the-art large
language models for their legal reasoning ability in civil tort contexts. Our
results indicate that current models still fall short in accurately handling
crucial elements of tort legal reasoning. Furthermore, we introduce several
baseline approaches that explicitly incorporate LawChain-style reasoning
through prompting or post-training. We conduct further experiments on
additional legal analysis tasks, such as Legal Named-Entity Recognition and
Criminal Damages Calculation, to verify the generalizability of these
baselines. The proposed baseline approaches achieve significant improvements in
tort-related legal reasoning and generalize well to related legal analysis
tasks, thus demonstrating the value of explicitly modeling legal reasoning
chains to enhance the reasoning capabilities of language models.

</details>


### [223] [Forget to Know, Remember to Use: Context-Aware Unlearning for Large Language Models](https://arxiv.org/abs/2510.17620)
*Yuefeng Peng,Parnian Afshar,Megan Ganji,Thomas Butler,Amir Houmansadr,Mingxian Wang,Dezhi Hong*

Main category: cs.CL

TL;DR: 本文提出了一种新的遗忘学习方法，通过在遗忘目标中加入上下文效用保护项，解决了现有遗忘方法会损害模型在提示中重新引入已遗忘知识时使用能力的问题。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘方法评估主要关注目标知识的遗忘程度和保留集性能，但忽视了模型在提示中重新引入已遗忘知识时仍能使用该知识的重要可用性需求。

Method: 在六种最先进遗忘方法的基础上，增加一个插件式目标项来保护模型在上下文存在已遗忘知识时使用该知识的能力。

Result: 实验表明，该方法能将上下文效用恢复到接近原始水平，同时保持有效的遗忘效果和保留集效用。

Conclusion: 提出的增强遗忘方法有效解决了上下文效用问题，为构建更实用的遗忘学习系统提供了重要改进。

Abstract: Large language models may encode sensitive information or outdated knowledge
that needs to be removed, to ensure responsible and compliant model responses.
Unlearning has emerged as an efficient alternative to full retraining, aiming
to remove specific knowledge while preserving overall model utility. Existing
evaluations of unlearning methods focus on (1) the extent of forgetting of the
target knowledge (forget set) and (2) maintaining performance on the retain set
(i.e., utility). However, these evaluations overlook an important usability
aspect: users may still want the model to leverage the removed information if
it is re-introduced in the prompt. In a systematic evaluation of six
state-of-the-art unlearning methods, we find that they consistently impair such
contextual utility. To address this, we augment unlearning objectives with a
plug-in term that preserves the model's ability to use forgotten knowledge when
it is present in context. Extensive experiments demonstrate that our approach
restores contextual utility to near original levels while still maintaining
effective forgetting and retain-set utility.

</details>


### [224] [Qomhra: A Bilingual Irish-English Large Language Model](https://arxiv.org/abs/2510.17652)
*Joseph McInerney*

Main category: cs.CL

TL;DR: Qomhr'a是一个在低资源条件下开发的双语爱尔兰语-英语大语言模型，通过双语持续预训练、指令调优和人类偏好对齐的完整流程构建。该模型在爱尔兰语和英语的翻译、性别理解、主题识别和世界知识等基准测试中表现优异，爱尔兰语性能提升29%，英语提升44%。


<details>
  <summary>Details</summary>
Motivation: 在低资源条件下开发高质量的双语爱尔兰语-英语大语言模型，解决爱尔兰语资源稀缺的问题，同时保持英语能力。

Method: 混合和整理新获取的爱尔兰语语料库和英语文本进行双语持续预训练；使用Gemini-2.5-Pro合成指令调优和人类偏好数据集；进行指令调优和人类偏好对齐。

Result: 开发了Qomhr'a双语模型，贡献了3万条爱尔兰语-英语平行指令调优数据集和1千条人类偏好数据集；在多个基准测试中爱尔兰语性能提升29%，英语提升44%；指令跟随能力显著提升。

Conclusion: Qomhr'a成功展示了在低资源条件下开发高质量双语LLM的可行性，为爱尔兰语自然语言处理提供了重要资源，同时在指令跟随方面取得明显进展，为聊天机器人功能奠定了基础。

Abstract: This paper introduces Qomhr\'a, a bilingual Irish-English large language
model (LLM), developed under low-resource constraints presenting a complete
pipeline spanning bilingual continued pre-training, instruction tuning, and
alignment from human preferences. Newly accessible Irish corpora and English
text are mixed and curated to improve Irish performance while preserving
English ability. 6 closed-weight LLMs are judged for their Irish text
generation by a native speaker, a learner and other LLMs. Google's
Gemini-2.5-Pro is ranked the highest and is subsequently used to synthesise
instruction tuning and human preference datasets. Two datasets are contributed
leveraging Gemini-2.5-Pro: a 30K Irish-English parallel instruction tuning
dataset and a 1K human preference dataset, generating accepted and rejected
responses that show near perfect alignment with a native Irish speaker.
Qomhr\'a is comprehensively evaluated across benchmarks testing translation,
gender understanding, topic identification and world knowledge with gains of up
to 29% in Irish and 44% in English. Qomhr\'a also undergoes instruction tuning
and demonstrates clear progress in instruction following, crucial for chatbot
functionality.

</details>


### [225] [Towards Mining Effective Pedagogical Strategies from Learner-LLM Educational Dialogues](https://arxiv.org/abs/2510.17698)
*Liqun He,Manolis Mavrikis,Mutlu Cukurova*

Main category: cs.CL

TL;DR: 本研究采用对话分析方法从学习者-大语言模型对话中识别有效教学策略，包括对话数据收集、对话行为标注、模式挖掘和预测模型构建，强调通过关注对话动态和教学策略来评估基于LLM的教育应用。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型教育应用评估方法主要关注技术性能或学习成果，往往忽视了学习者与LLM之间的互动过程，需要缩小这一研究空白。

Method: 采用对话分析方法，包括四个步骤：对话数据收集、对话行为标注、对话行为模式挖掘和预测模型构建。

Result: 研究处于进行中，已获得初步见解，为未来研究奠定了基础。

Conclusion: 评估基于LLM的教育应用需要重点关注对话动态和教学策略，而不仅仅是技术性能或学习成果。

Abstract: Dialogue plays a crucial role in educational settings, yet existing
evaluation methods for educational applications of large language models (LLMs)
primarily focus on technical performance or learning outcomes, often neglecting
attention to learner-LLM interactions. To narrow this gap, this AIED Doctoral
Consortium paper presents an ongoing study employing a dialogue analysis
approach to identify effective pedagogical strategies from learner-LLM
dialogues. The proposed approach involves dialogue data collection, dialogue
act (DA) annotation, DA pattern mining, and predictive model building. Early
insights are outlined as an initial step toward future research. The work
underscores the need to evaluate LLM-based educational applications by focusing
on dialogue dynamics and pedagogical strategies.

</details>


### [226] [QueST: Incentivizing LLMs to Generate Difficult Problems](https://arxiv.org/abs/2510.17715)
*Hanxu Hu,Xingxing Zhang,Jannis Vamvas,Rico Sennrich,Furu Wei*

Main category: cs.CL

TL;DR: QueST框架通过难度感知图采样和拒绝微调生成具有挑战性的编程问题，显著提升语言模型在竞争性编程任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有竞争性编程数据集规模有限，且缺乏大规模具有挑战性的编程问题训练数据，限制了语言模型的可扩展性。

Method: 提出QueST框架，结合难度感知图采样和难度感知拒绝微调，专门优化生成器来创建具有挑战性的编程问题。

Result: 使用QueST生成的10万个困难问题微调Qwen3-8B-base后，在LiveCodeBench上超越了原始Qwen3-8B的性能；加入额外11.2万个示例后，8B模型性能与DeepSeek-R1-671B相当。

Conclusion: 通过QueST生成复杂问题为推进语言模型在竞争性编程和推理方面的前沿提供了有效且可扩展的方法。

Abstract: Large Language Models have achieved strong performance on reasoning tasks,
solving competition-level coding and math problems. However, their scalability
is limited by human-labeled datasets and the lack of large-scale, challenging
coding problem training data. Existing competitive coding datasets contain only
thousands to tens of thousands of problems. Previous synthetic data generation
methods rely on either augmenting existing instruction datasets or selecting
challenging problems from human-labeled data. In this paper, we propose QueST,
a novel framework which combines difficulty-aware graph sampling and
difficulty-aware rejection fine-tuning that directly optimizes specialized
generators to create challenging coding problems. Our trained generators
demonstrate superior capability compared to even GPT-4o at creating challenging
problems that benefit downstream performance. We leverage QueST to generate
large-scale synthetic coding problems, which we then use to distill from strong
teacher models with long chain-of-thought or to conduct reinforcement learning
for smaller models, proving effective in both scenarios. Our distillation
experiments demonstrate significant performance gains. Specifically, after
fine-tuning Qwen3-8B-base on 100K difficult problems generated by QueST, we
surpass the performance of the original Qwen3-8B on LiveCodeBench. With an
additional 112K examples (i.e., 28K human-written problems paired with multiple
synthetic solutions), our 8B model matches the performance of the much larger
DeepSeek-R1-671B. These findings indicate that generating complex problems via
QueST offers an effective and scalable approach to advancing the frontiers of
competitive coding and reasoning for large language models.

</details>


### [227] [PANER: A Paraphrase-Augmented Framework for Low-Resource Named Entity Recognition](https://arxiv.org/abs/2510.17720)
*Nanda Kumar Rengarajan,Jun Yan,Chun Wang*

Main category: cs.CL

TL;DR: 提出了一种轻量级少样本命名实体识别框架，通过改进的指令调优模板和保留实体信息的上下文改写数据增强技术，在低资源场景下实现与最先进模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 解决命名实体识别在低资源场景下标注数据稀缺的问题，现有零样本和指令调优方法难以泛化到领域特定实体且无法有效利用有限数据。

Method: 1) 设计新的指令调优模板，简化输出格式以利用大语言模型的大上下文窗口；2) 引入保留实体信息的同时改写上下文的数据增强技术，在不破坏语义关系的情况下扩展训练数据。

Result: 在基准数据集上，少样本方法在CrossNER数据集上平均F1得分达到80.1，使用改写方法训练的模型相比基线版本F1得分提升最高达17分。

Conclusion: 该方法为拥有有限NER训练数据和计算资源的群体提供了一个有前景的解决方案，在少样本和零样本任务上实现了与最先进模型相当的性能。

Abstract: Named Entity Recognition (NER) is a critical task that requires substantial
annotated data, making it challenging in low-resource scenarios where label
acquisition is expensive. While zero-shot and instruction-tuned approaches have
made progress, they often fail to generalize to domain-specific entities and do
not effectively utilize limited available data. We present a lightweight
few-shot NER framework that addresses these challenges through two key
innovations: (1) a new instruction tuning template with a simplified output
format that combines principles from prior IT approaches to leverage the large
context window of recent state-of-the-art LLMs; (2) introducing a strategic
data augmentation technique that preserves entity information while
paraphrasing the surrounding context, thereby expanding our training data
without compromising semantic relationships. Experiments on benchmark datasets
show that our method achieves performance comparable to state-of-the-art models
on few-shot and zero-shot tasks, with our few-shot approach attaining an
average F1 score of 80.1 on the CrossNER datasets. Models trained with our
paraphrasing approach show consistent improvements in F1 scores of up to 17
points over baseline versions, offering a promising solution for groups with
limited NER training data and compute power.

</details>


### [228] [AcademicEval: Live Long-Context LLM Benchmark](https://arxiv.org/abs/2510.17725)
*Haozhen Zhang,Tao Feng,Pengrui Han,Jiaxuan You*

Main category: cs.CL

TL;DR: 提出了AcademicEval，一个基于arXiv论文的实时长上下文生成任务基准测试，包含标题、摘要、引言和相关工作四个学术写作任务，无需人工标注，通过作者关系图提供高质量示例，确保无标签泄露问题。


<details>
  <summary>Details</summary>
Motivation: 当前长上下文LLM基准测试存在上下文长度固定、标注劳动密集以及在LLM训练中面临标签泄露的紧迫挑战。

Method: 采用arXiv论文构建学术写作任务，通过收集的作者关系图提供专家策划的少样本示例，支持灵活上下文长度，并实现高效的实时评估。

Result: 评估结果显示，LLMs在具有层次抽象级别的任务上表现较差，且难以处理长的少样本示例，突显了基准测试的挑战性。

Conclusion: 通过实验分析揭示了增强LLMs长上下文建模能力的一些见解，证明了AcademicEval作为长上下文生成任务评估工具的有效性。

Abstract: Large Language Models (LLMs) have recently achieved remarkable performance in
long-context understanding. However, current long-context LLM benchmarks are
limited by rigid context length, labor-intensive annotation, and the pressing
challenge of label leakage issues during LLM training. Therefore, we propose
\textsc{AcademicEval}, a live benchmark for evaluating LLMs over long-context
generation tasks. \textsc{AcademicEval} adopts papers on arXiv to introduce
several academic writing tasks with long-context inputs, \textit{i.e.},
\textsc{Title}, \textsc{Abstract}, \textsc{Introduction}, and \textsc{Related
Work}, which cover a wide range of abstraction levels and require no manual
labeling. Moreover, \textsc{AcademicEval} integrates high-quality and
expert-curated few-shot demonstrations from a collected co-author graph to
enable flexible context length. Especially, \textsc{AcademicEval} features an
efficient live evaluation, ensuring no label leakage. We conduct a holistic
evaluation on \textsc{AcademicEval}, and the results illustrate that LLMs
perform poorly on tasks with hierarchical abstraction levels and tend to
struggle with long few-shot demonstrations, highlighting the challenge of our
benchmark. Through experimental analysis, we also reveal some insights for
enhancing LLMs' long-context modeling capabilities. Code is available at
https://github.com/ulab-uiuc/AcademicEval

</details>


### [229] [Train for Truth, Keep the Skills: Binary Retrieval-Augmented Reward Mitigates Hallucinations](https://arxiv.org/abs/2510.17733)
*Tong Chen,Akari Asai,Luke Zettlemoyer,Hannaneh Hajishirzi,Faeze Brahman*

Main category: cs.CL

TL;DR: 提出了一种基于二元检索增强奖励的在线强化学习方法，有效减少语言模型的外在幻觉，在保持其他任务性能的同时显著提升事实准确性。


<details>
  <summary>Details</summary>
Motivation: 现有缓解语言模型外在幻觉的方法往往会在开放生成和下游任务上造成性能下降，限制了实际应用价值。

Method: 使用二元检索增强奖励的在线强化学习方法，只有当模型输出完全正确时才给予奖励1，否则为0。

Result: 在开放生成任务中幻觉率降低39.3%；在短问答任务中，模型学会校准性弃权，在PopQA和GPQA上分别减少44.4%和21.7%的错误答案，且不损害指令遵循、数学或代码能力。

Conclusion: 二元奖励方案在提升事实准确性的同时避免了连续奖励RL带来的质量回归问题，具有更好的实用价值。

Abstract: Language models often generate factually incorrect information unsupported by
their training data, a phenomenon known as extrinsic hallucination. Existing
mitigation approaches often degrade performance on open-ended generation and
downstream tasks, limiting their practical utility. We propose an online
reinforcement learning method using a novel binary retrieval-augmented reward
(RAR) to address this tradeoff. Unlike continuous reward schemes, our approach
assigns a reward of one only when the model's output is entirely factually
correct, and zero otherwise. We evaluate our method on Qwen3 reasoning models
across diverse tasks. For open-ended generation, binary RAR achieves a 39.3%
reduction in hallucination rates, substantially outperforming both supervised
training and continuous-reward RL baselines. In short-form question answering,
the model learns calibrated abstention, strategically outputting "I don't know"
when faced with insufficient parametric knowledge. This yields 44.4% and 21.7%
fewer incorrect answers on PopQA and GPQA, respectively. Crucially, these
factuality gains come without performance degradation on instruction following,
math, or code, whereas continuous-reward RL, despite improving factuality,
induces quality regressions.

</details>


### [230] [Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains](https://arxiv.org/abs/2510.17793)
*Austin Xu,Xuan-Phi Nguyen,Yilun Zhou,Chien-Sheng Wu,Caiming Xiong,Shafiq Joty*

Main category: cs.CL

TL;DR: 本文提出了FARE（基础自动推理评估器），通过构建250万样本数据集和简单的迭代拒绝采样SFT方法，训练了8B和20B参数的评估器，在多个评估任务中超越了更大的专业评估器。


<details>
  <summary>Details</summary>
Motivation: 当前专业生成评估器的训练主要关注新方法（如强化学习），而忽视了大规模数据驱动开发。本文旨在通过数据扩展来改进评估器的性能。

Method: 构建包含250万样本的数据集，涵盖5种评估任务和多个推理评估领域；采用简单的迭代拒绝采样监督微调（SFT）方法训练8B和20B参数的评估器。

Result: FARE-8B挑战了更大的专业RL训练评估器，FARE-20B为开源评估器设定了新标准，超越了专业的70B+评估器；在真实任务中，FARE-20B在MATH上达到接近oracle性能，在RL训练中比字符串匹配验证器提升14.1%的下游模型性能。

Conclusion: 数据扩展和简单的SFT方法可以训练出强大的评估器，FARE在多个评估任务中表现出色，为自动推理评估提供了有效的解决方案。

Abstract: Finetuning specialized generative evaluators has emerged as a popular
paradigm to meet the increasing demand for scalable evaluation during both
training and test-time. However, recent work has largely focused on applying
new methodology, such as reinforcement learning (RL), to training evaluators,
shying away from large-scale, data-driven development. In this work, we focus
on data scaling, curating a set of 2.5M samples spanning five unique evaluation
tasks (pairwise, step-level, reference-free and reference-based verification,
and single rating) and multiple domains focused on reasoning evaluation. With
our data, we train Foundational Automatic Reasoning Evaluators (FARE), a family
of 8B and 20B (with 3.6B active) parameter evaluators, with a simple iterative
rejection-sampling supervised finetuning (SFT) approach. FARE-8B challenges
larger specialized RL-trained evaluators and FARE-20B sets the new standard for
open-source evaluators, surpassing specialized 70B+ evaluators. Beyond static
benchmarks, we evaluate FARE in real-world tasks: As inference-time rerankers,
FARE-20B achieves near-oracle performance on MATH. As verifiers in RL training,
FARE improves the downstream RL-trained model performance by up to 14.1% vs.
string-matching verifiers. When initialized from FARE, a continually-finetuned
FARE-Code outperforms gpt-oss-20B by 65% on evaluating test-case quality.

</details>


### [231] [Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics](https://arxiv.org/abs/2510.17797)
*Akshara Prabhakar,Roshan Ram,Zixiang Chen,Silvio Savarese,Frank Wang,Caiming Xiong,Huan Wang,Weiran Yao*

Main category: cs.CL

TL;DR: EDR是一个多智能体系统，通过主规划智能体、四个专业搜索智能体、可扩展工具生态系统、可视化智能体和反思机制，将非结构化数据转化为可操作的洞察，在开放基准测试中优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 随着信息指数级增长，企业面临将非结构化数据转化为连贯、可操作洞察的压力。现有自主智能体在处理领域特定细微差别、意图对齐和企业集成方面存在困难。

Method: 集成主规划智能体进行自适应查询分解，四个专业搜索智能体（通用、学术、GitHub、LinkedIn），基于MCP的可扩展工具生态系统支持NL2SQL、文件分析和企业工作流，可视化智能体提供数据驱动洞察，以及检测知识差距并更新研究方向的反思机制。

Result: 在包括DeepResearch Bench和DeepConsult的开放基准测试中，EDR在无需人工干预的情况下优于最先进的智能体系统，实现了自动化报告生成、实时流式传输和无缝企业部署。

Conclusion: EDR框架和基准轨迹的发布将推动多智能体推理应用的研究发展，为企业深度研究提供了有效的解决方案。

Abstract: As information grows exponentially, enterprises face increasing pressure to
transform unstructured data into coherent, actionable insights. While
autonomous agents show promise, they often struggle with domain-specific
nuances, intent alignment, and enterprise integration. We present Enterprise
Deep Research (EDR), a multi-agent system that integrates (1) a Master Planning
Agent for adaptive query decomposition, (2) four specialized search agents
(General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based tool
ecosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) a
Visualization Agent for data-driven insights, and (5) a reflection mechanism
that detects knowledge gaps and updates research direction with optional
human-in-the-loop steering guidance. These components enable automated report
generation, real-time streaming, and seamless enterprise deployment, as
validated on internal datasets. On open-ended benchmarks including DeepResearch
Bench and DeepConsult, EDR outperforms state-of-the-art agentic systems without
any human steering. We release the EDR framework and benchmark trajectories to
advance research on multi-agent reasoning applications.
  Code at https://github.com/SalesforceAIResearch/enterprise-deep-research and
Dataset at https://huggingface.co/datasets/Salesforce/EDR-200

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [232] [Lean Finder: Semantic Search for Mathlib That Understands User Intents](https://arxiv.org/abs/2510.15940)
*Jialin Lu,Kye Emond,Kaiyu Yang,Swarat Chaudhuri,Weiran Sun,Wuyang Chen*

Main category: cs.LG

TL;DR: Lean Finder是一个专为数学家和Lean用户设计的语义搜索引擎，通过分析用户意图、微调文本嵌入和整合多样化反馈信号，显著提升了定理搜索的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有Lean搜索引擎主要依赖形式化语句的非正式翻译，忽视了与实际用户查询的匹配问题，导致定理证明进展缓慢且劳动密集。

Method: 分析并聚类公开Lean讨论的语义，在模拟用户意图的合成查询上微调文本嵌入，并使用多样化反馈信号与数学家偏好对齐。

Result: 在真实查询、非正式化语句和证明状态上的评估显示，相比先前搜索引擎和GPT-4o，Lean Finder实现了超过30%的相对改进。

Conclusion: Lean Finder成功构建了一个用户中心的语义搜索系统，不仅提升了搜索性能，还能与基于LLM的定理证明器兼容，连接检索与形式推理。

Abstract: We present Lean Finder, a semantic search engine for Lean and mathlib that
understands and aligns with the intents of mathematicians. Progress in formal
theorem proving is often hindered by the difficulty of locating relevant
theorems and the steep learning curve of the Lean 4 language, making
advancement slow and labor-intensive. Existing Lean search engines, though
helpful, rely primarily on informalizations (natural language translation of
the formal statements), while largely overlooking the mismatch with real-world
user queries. In contrast, we propose a user-centered semantic search tailored
to the needs of mathematicians. Our approach begins by analyzing and clustering
the semantics of public Lean discussions, then fine-tuning text embeddings on
synthesized queries that emulate user intents. We further align Lean Finder
with mathematicians' preferences using diverse feedback signals, encoding it
with a rich awareness of their goals from multiple perspectives. Evaluations on
real-world queries, informalized statements, and proof states demonstrate that
our Lean Finder achieves over $30\%$ relative improvement compared to previous
search engines and GPT-4o. In addition, Lean Finder is compatible with
LLM-based theorem provers, bridging retrieval with formal reasoning. Lean
Finder is available at: https://leanfinder.github.io

</details>


### [233] [Lyapunov-Stable Adaptive Control for Multimodal Concept Drift](https://arxiv.org/abs/2510.15944)
*Tianyu Bell Pan,Mengdi Zhu,Alexa Jordyn Cole,Ronald Wilson,Damon L. Woodard*

Main category: cs.LG

TL;DR: LS-OGD是一种自适应控制框架，用于在概念漂移存在的情况下实现鲁棒的多模态学习，通过动态调整学习率和模态融合权重来应对数据分布变化。


<details>
  <summary>Details</summary>
Motivation: 多模态学习系统在非平稳环境中容易因概念漂移而性能下降，特别是模态特定的漂移和缺乏连续稳定适应机制的问题。

Method: 使用在线控制器动态调整模型学习率和不同数据模态之间的融合权重，响应检测到的漂移和预测误差变化。

Result: 在有限漂移条件下，LS-OGD系统的预测误差被证明是最终一致有界的，如果漂移停止则收敛到零；自适应融合策略能有效隔离和减轻严重模态特定漂移的影响。

Conclusion: LS-OGD为开发可靠且持续适应的多模态学习系统建立了理论基础，确保系统韧性和容错能力。

Abstract: Multimodal learning systems often struggle in non-stationary environments due
to concept drift, where changing data distributions can degrade performance.
Modality-specific drifts and the lack of mechanisms for continuous, stable
adaptation compound this challenge. This paper introduces LS-OGD, a novel
adaptive control framework for robust multimodal learning in the presence of
concept drift. LS-OGD uses an online controller that dynamically adjusts the
model's learning rate and the fusion weights between different data modalities
in response to detected drift and evolving prediction errors. We prove that
under bounded drift conditions, the LS-OGD system's prediction error is
uniformly ultimately bounded and converges to zero if the drift ceases.
Additionally, we demonstrate that the adaptive fusion strategy effectively
isolates and mitigates the impact of severe modality-specific drift, thereby
ensuring system resilience and fault tolerance. These theoretical guarantees
establish a principled foundation for developing reliable and continuously
adapting multimodal learning systems.

</details>


### [234] [BEACON: Bayesian Optimal Stopping for Efficient LLM Sampling](https://arxiv.org/abs/2510.15945)
*Guangya Wan,Zixin Stephen Xu,Sasa Zorc,Manel Baucells,Mengxuan Hu,Hao Wang,Sheng Li*

Main category: cs.LG

TL;DR: BEACON是一个基于贝叶斯学习的自适应采样框架，通过实时更新奖励分布的后验信念来决定何时停止生成新样本，在保持响应质量的同时减少80%的平均采样量。


<details>
  <summary>Details</summary>
Motivation: 多响应采样是提高LLM输出质量的常用方法，但会带来额外的计算成本。关键挑战是如何在准确度提升和效率之间平衡，决定何时停止生成新样本。

Method: 提出BEACON框架，基于顺序搜索和贝叶斯学习，顺序生成策略LLM的响应，实时更新奖励分布的后验信念，通过权衡预期收益与计算成本来决定停止时机。

Result: BEACON在理论上具有最优性保证，在实践中具有可操作性，实证研究表明可将平均采样量减少高达80%，同时保持响应质量。

Conclusion: BEACON为成本高效的偏好数据生成提供了实用工具，并提出了实际扩展，为未来研究者提供了可行的见解。

Abstract: Sampling multiple responses is a common way to improve LLM output quality,
but it comes at the cost of additional computation. The key challenge is
deciding when to stop generating new samples to balance accuracy gains against
efficiency. To address this, we introduce BEACON (Bayesian Efficient Adaptive
Criterion for Optimal N-stopping), a principled adaptive sampling framework
grounded in Sequential Search with Bayesian Learning. BEACON sequentially
generates responses from the policy LLM, updates posterior belief over reward
distributions in real time without further training, and determines when to
stop by weighing expected gains against computational cost. Sampling terminates
once the marginal utility of further exploration no longer justifies the
expense. We establish both theoretical optimality guarantees and practical
tractability, and show empirically that BEACON reduces average sampling by up
to 80% while maintaining response quality. We further demonstrate BEACON's
utility for cost-efficient preference data generation and outline practical
extensions, offering actionable insights for future researchers.

</details>


### [235] [Learning from Mistakes: Enhancing Harmful Meme Detection via Misjudgment Risk Patterns](https://arxiv.org/abs/2510.15946)
*Wenshuo Wang,Ziyou Jiang,Junjie Wang,Mingyang Li,Jie Huang,Yuekai Huang,Zhiyuan Chang,Feiyan Duan,Qing Wang*

Main category: cs.LG

TL;DR: PatMD是一种新颖的有害表情包检测方法，通过学习并主动减轻潜在的误判风险来提高检测效果。该方法构建误判风险模式知识库，动态指导多模态大语言模型避免已知误判陷阱。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法（包括基于MLLM的技术）难以处理表情包中通过讽刺和隐喻等修辞手段表达的隐含有害内容，导致频繁误判。

Method: 首先构建知识库，将每个表情包解构为误判风险模式，解释其可能被误判的原因（漏报或误报）。对于目标表情包，检索相关模式并利用它们动态指导MLLM的推理过程。

Result: 在5个有害检测任务的6,626个表情包基准测试中，PatMD优于最先进的基线方法，F1分数平均提高8.30%，准确率平均提高7.71%。

Conclusion: PatMD展示了强大的泛化能力和改进的有害表情包检测能力，通过识别底层误判风险模式并主动指导MLLM避免已知误判陷阱，有效提升了检测性能。

Abstract: Internet memes have emerged as a popular multimodal medium, yet they are
increasingly weaponized to convey harmful opinions through subtle rhetorical
devices like irony and metaphor. Existing detection approaches, including
MLLM-based techniques, struggle with these implicit expressions, leading to
frequent misjudgments. This paper introduces PatMD, a novel approach that
improves harmful meme detection by learning from and proactively mitigating
these potential misjudgment risks. Our core idea is to move beyond superficial
content-level matching and instead identify the underlying misjudgment risk
patterns, proactively guiding the MLLMs to avoid known misjudgment pitfalls. We
first construct a knowledge base where each meme is deconstructed into a
misjudgment risk pattern explaining why it might be misjudged, either
overlooking harmful undertones (false negative) or overinterpreting benign
content (false positive). For a given target meme, PatMD retrieves relevant
patterns and utilizes them to dynamically guide the MLLM's reasoning.
Experiments on a benchmark of 6,626 memes across 5 harmful detection tasks show
that PatMD outperforms state-of-the-art baselines, achieving an average of
8.30\% improvement in F1-score and 7.71\% improvement in accuracy,
demonstrating strong generalizability and improved detection capability of
harmful memes.

</details>


### [236] [WaveNet's Precision in EEG Classification](https://arxiv.org/abs/2510.15947)
*Casper van Laar,Khubaib Ahmed*

Main category: cs.LG

TL;DR: 基于WaveNet的深度学习模型用于自动分类EEG信号为生理、病理、伪影和噪声类别，在公开数据集上训练并超越传统CNN和LSTM方法，准确率更高。


<details>
  <summary>Details</summary>
Motivation: 传统依赖专家视觉审查的EEG信号分类方法在处理日益复杂和大量的EEG记录时变得不切实际，需要自动化解决方案。

Method: 使用WaveNet架构，利用扩张因果卷积和残差连接处理EEG数据，在209,232个样本上训练验证测试，采用70/20/10的数据分割。

Result: 模型分类准确率超过之前的CNN和LSTM方法，能够高精度区分噪声和伪影，但在生理和病理信号之间存在可解释的误分类。

Conclusion: WaveNet架构适合EEG数据分析，能够捕捉细粒度和长程时间依赖性，为EEG信号自动分类提供了有效解决方案。

Abstract: This study introduces a WaveNet-based deep learning model designed to
automate the classification of EEG signals into physiological, pathological,
artifact, and noise categories. Traditional methods for EEG signal
classification, which rely on expert visual review, are becoming increasingly
impractical due to the growing complexity and volume of EEG recordings.
Leveraging a publicly available annotated dataset from Mayo Clinic and St.
Anne's University Hospital, the WaveNet model was trained, validated, and
tested on 209,232 samples with a 70/20/10 percent split. The model achieved a
classification accuracy exceeding previous CNN and LSTM-based approaches, and
was benchmarked against a Temporal Convolutional Network (TCN) baseline.
Notably, the model distinguishes noise and artifacts with high precision,
although it reveals a modest but explainable degree of misclassification
between physiological and pathological signals, reflecting inherent clinical
overlap. WaveNet's architecture, originally developed for raw audio synthesis,
is well suited for EEG data due to its use of dilated causal convolutions and
residual connections, enabling it to capture both fine-grained and long-range
temporal dependencies. The research also details the preprocessing pipeline,
including dynamic dataset partitioning and normalization steps that support
model generalization.

</details>


### [237] [Cross-dataset Multivariate Time-series Model for Parkinson's Diagnosis via Keyboard Dynamics](https://arxiv.org/abs/2510.15950)
*Arianna Francesconi,Donato Cappetta,Fabio Rebecchi,Paolo Soda,Valerio Guarrasi,Rosa Sicilia*

Main category: cs.LG

TL;DR: 本研究提出了一种基于击键动力学的新型管道，用于帕金森病的远程筛查和远程监测，通过深度学习模型在外部验证中取得了超过90%的AUC-ROC和70%以上的F1-Score。


<details>
  <summary>Details</summary>
Motivation: 帕金森病影响全球超过1000万人，预计到2040年患病率将翻倍。由于运动症状出现较晚且传统临床评估存在局限性，早期诊断困难。需要开发非侵入性、可扩展的生物标志物进行远程筛查和监测。

Method: 方法包括三个阶段：(i) 预处理来自四个不同数据集的数据，提取四个时间信号，并通过比较三种方法解决类别不平衡问题；(ii) 在两个最大数据集上预训练八个最先进的深度学习架构，优化时间窗口、步长等超参数；(iii) 在中等规模数据集上进行微调，并在第四个独立队列中进行外部验证。

Result: 混合卷积-循环和基于Transformer的模型在外部验证中表现出色，AUC-ROC得分超过90%，F1-Score超过70%。特别是，时间卷积模型在外部验证中达到91.14%的AUC-ROC，优于仅依赖内部验证的现有方法。

Conclusion: 击键动力学作为帕金森病的可靠数字生物标志物具有巨大潜力，为早期检测和持续监测提供了有前景的途径。

Abstract: Parkinson's disease (PD) presents a growing global challenge, affecting over
10 million individuals, with prevalence expected to double by 2040. Early
diagnosis remains difficult due to the late emergence of motor symptoms and
limitations of traditional clinical assessments. In this study, we propose a
novel pipeline that leverages keystroke dynamics as a non-invasive and scalable
biomarker for remote PD screening and telemonitoring. Our methodology involves
three main stages: (i) preprocessing of data from four distinct datasets,
extracting four temporal signals and addressing class imbalance through the
comparison of three methods; (ii) pre-training eight state-of-the-art
deep-learning architectures on the two largest datasets, optimizing temporal
windowing, stride, and other hyperparameters; (iii) fine-tuning on an
intermediate-sized dataset and performing external validation on a fourth,
independent cohort. Our results demonstrate that hybrid convolutional-recurrent
and transformer-based models achieve strong external validation performance,
with AUC-ROC scores exceeding 90% and F1-Score over 70%. Notably, a temporal
convolutional model attains an AUC-ROC of 91.14% in external validation,
outperforming existing methods that rely solely on internal validation. These
findings underscore the potential of keystroke dynamics as a reliable digital
biomarker for PD, offering a promising avenue for early detection and
continuous monitoring.

</details>


### [238] [Fire-EnSF: Wildfire Spread Data Assimilation using Ensemble Score Filter](https://arxiv.org/abs/2510.15954)
*Hongzheng Shi,Yuhang Wang,Xiao Liu*

Main category: cs.LG

TL;DR: 本文研究了基于扩散模型的Ensemble Score Filter (EnSF)算法在实时野火蔓延预测数据同化中的应用，展示了该方法在准确性、稳定性和计算效率方面的优势。


<details>
  <summary>Details</summary>
Motivation: 随着野火破坏性增强且控制成本上升，需要准确、实时的火势蔓延预测。数据同化通过整合观测数据和数值模型预测，对提高野火预测准确性至关重要。

Method: 应用Ensemble Score Filter (EnSF)算法，这是一种基于扩散模型的滤波方法，利用基于分数的生成扩散模型来处理高维非线性滤波问题。

Result: 数值研究表明，EnSF在野火数据同化中提供了优越的准确性、稳定性和计算效率。

Conclusion: EnSF被确立为野火数据同化的稳健实用方法，代码已公开。

Abstract: As wildfires become increasingly destructive and expensive to control,
effective management of active wildfires requires accurate, real-time fire
spread predictions. To enhance the forecasting accuracy of active fires, data
assimilation plays a vital role by integrating observations (such as
remote-sensing data) and fire predictions generated from numerical models. This
paper provides a comprehensive investigation on the application of a recently
proposed diffusion-model-based filtering algorithm -- the Ensemble Score Filter
(EnSF) -- to the data assimilation problem for real-time active wildfire spread
predictions. Leveraging a score-based generative diffusion model, EnSF has been
shown to have superior accuracy for high-dimensional nonlinear filtering
problems, making it an ideal candidate for the filtering problems of wildfire
spread models. Technical details are provided, and our numerical investigations
demonstrate that EnSF provides superior accuracy, stability, and computational
efficiency, establishing it as a robust and practical method for wildfire data
assimilation. Our code has been made publicly available.

</details>


### [239] [Protein Folding with Neural Ordinary Differential Equations](https://arxiv.org/abs/2510.16253)
*Arielle Sanford,Shuo Sun,Christian B. Mendl*

Main category: cs.LG

TL;DR: 本文提出了一种基于神经常微分方程的连续深度Evoformer模型，替代AlphaFold中48个离散块的Evoformer架构，实现了恒定内存成本和计算效率的提升。


<details>
  <summary>Details</summary>
Motivation: 传统Evoformer架构的48层堆叠导致高计算成本和刚性分层离散化，需要更高效轻量的蛋白质结构预测方法。

Method: 使用神经常微分方程参数化Evoformer，保留其核心注意力操作，通过伴随方法实现恒定内存成本，利用自适应ODE求解器在运行时间和精度之间进行权衡。

Result: 基于神经ODE的Evoformer能够生成结构合理的蛋白质预测，可靠地捕捉α-螺旋等二级结构元素，但未能完全复现原始架构的精度。模型仅需单GPU训练17.5小时，资源消耗显著降低。

Conclusion: 连续深度模型为生物分子建模提供了轻量级和可解释的替代方案，为高效自适应的蛋白质结构预测框架开辟了新方向。

Abstract: Recent advances in protein structure prediction, such as AlphaFold, have
demonstrated the power of deep neural architectures like the Evoformer for
capturing complex spatial and evolutionary constraints on protein conformation.
However, the depth of the Evoformer, comprising 48 stacked blocks, introduces
high computational costs and rigid layerwise discretization. Inspired by Neural
Ordinary Differential Equations (Neural ODEs), we propose a continuous-depth
formulation of the Evoformer, replacing its 48 discrete blocks with a Neural
ODE parameterization that preserves its core attention-based operations. This
continuous-time Evoformer achieves constant memory cost (in depth) via the
adjoint method, while allowing a principled trade-off between runtime and
accuracy through adaptive ODE solvers. Benchmarking on protein structure
prediction tasks, we find that the Neural ODE-based Evoformer produces
structurally plausible predictions and reliably captures certain secondary
structure elements, such as alpha-helices, though it does not fully replicate
the accuracy of the original architecture. However, our model achieves this
performance using dramatically fewer resources, just 17.5 hours of training on
a single GPU, highlighting the promise of continuous-depth models as a
lightweight and interpretable alternative for biomolecular modeling. This work
opens new directions for efficient and adaptive protein structure prediction
frameworks.

</details>


### [240] [Hydrogen production from blended waste biomass: pyrolysis, thermodynamic-kinetic analysis and AI-based modelling](https://arxiv.org/abs/2510.15960)
*Sana Kordoghli,Abdelhakim Settar,Oumayma Belaati,Mohammad Alkhatib*

Main category: cs.LG

TL;DR: 该研究通过热解技术将食物基生物质转化为可持续能源，重点关注人工智能在优化热解过程和氢产量预测中的应用。研究评估了咖啡渣和枣核等废弃生物质资源单独及混合使用的性能，发现特定混合比例具有最佳氢产量潜力。


<details>
  <summary>Details</summary>
Motivation: 推动可持续能源和废物管理策略，探索未充分利用的生物质资源（如咖啡渣和枣核）用于可持续氢生产的潜力，并利用人工智能提高热解过程建模的准确性和优化效率。

Method: 对纯枣核、咖啡渣及其混合样品进行近似分析、元素分析、纤维分析、热重分析、动力学分析、热力学分析和热解-微气相色谱分析。使用等转化率方法（KAS、FWO、Friedman）进行动力学建模，并训练LSTM模型预测热重曲线。

Result: 混合样品3（25%枣核-75%咖啡渣）具有最佳的氢产量潜力，但活化能最高（313.24 kJ/mol）；混合样品1（75%枣核-25%咖啡渣）具有最佳活化能值（161.75 kJ/mol）。KAS方法被确定为最准确的动力学模型。LSTM模型预测热重曲线表现出极高的准确性（R²：0.9996-0.9998）。

Conclusion: 该研究证明了人工智能在优化生物质热解过程中的有效性，特别是LSTM模型在预测热重行为方面的高精度。混合生物质样品显示出有前景的氢生产潜力，为可持续能源生产和废物管理提供了可行解决方案。

Abstract: This work contributes to advancing sustainable energy and waste management
strategies by investigating the thermochemical conversion of food-based biomass
through pyrolysis, highlighting the role of artificial intelligence (AI) in
enhancing process modelling accuracy and optimization efficiency. The main
objective is to explore the potential of underutilized biomass resources, such
as spent coffee grounds (SCG) and date seeds (DS), for sustainable hydrogen
production. Specifically, it aims to optimize the pyrolysis process while
evaluating the performance of these resources both individually and as blends.
Proximate, ultimate, fibre, TGA/DTG, kinetic, thermodynamic, and Py-Micro GC
analyses were conducted for pure DS, SCG, and blends (75% DS - 25% SCG, 50% DS
- 50% SCG, 25% DS - 75% SCG). Blend 3 offered superior hydrogen yield potential
but had the highest activation energy (Ea: 313.24 kJ/mol), while Blend 1
exhibited the best activation energy value (Ea: 161.75 kJ/mol). The kinetic
modelling based on isoconversional methods (KAS, FWO, Friedman) identified KAS
as the most accurate. These approaches provide a detailed understanding of the
pyrolysis process, with particular emphasis on the integration of artificial
intelligence. An LSTM model trained with lignocellulosic data predicted TGA
curves with exceptional accuracy (R^2: 0.9996-0.9998).

</details>


### [241] [Semi-supervised Latent Bayesian Optimization for Designing Antimicrobial Peptides](https://arxiv.org/abs/2510.17569)
*Jyler Menard,R. A. Mansbach*

Main category: cs.LG

TL;DR: 该研究探讨了通过降维进一步压缩抗菌肽设计空间，以提高优化效率、可解释性和基于理化性质组织潜空间的效果。


<details>
  <summary>Details</summary>
Motivation: 抗菌肽是治疗细菌感染的有前景疗法，但序列空间巨大导致发现和设计困难。现有深度生成模型缺乏可解释性且对潜空间质量缺乏严格量化。

Method: 使用变分自编码器等深度生成模型，结合降维技术压缩设计空间，并基于理化性质组织潜空间结构。

Result: 发现当数据可用时，通过降维进一步压缩潜空间有利于优化；降维搜索空间更具可解释性；可在不同标签可用率下基于不同理化性质组织潜空间。

Conclusion: 降维技术可以改善抗菌肽设计空间的优化效率和可解释性，基于理化性质组织潜空间能提高抗菌活性优化效率。

Abstract: Antimicrobial peptides (AMPs) are a promising class of therapeutics to treat
bacterial infections. Discovering and designing such peptides is difficult
because of the vast number of possible sequences of amino acids. Deep
generative models, such as variational autoencoders, have shown value in
peptide design due to their ability to model sequence space with a
continuous-valued latent space. Although such models have already been used to
great effect in biomolecular design, they still suffer from a lack of
interpretability and rigorous quantification of latent space quality as a
search space. We investigate (1) whether further compression of the design
space via dimensionality reduction may facilitate optimization, (2) the
interpretability of the spaces, and (3) how organizing latent spaces with
physicochemical properties may improve the efficiency of optimizing
antimicrobial activity. We find that further reduction of the latent space via
dimensionality reduction can be advantageous when organizing the space with
more relevant information at data availability, that using the dimensionality
reduction search space can be more interpretable, and that we can organize the
latent space with different physicochemical properties even at different
percentages of available labels.

</details>


### [242] [Interpretable Graph-Language Modeling for Detecting Youth Illicit Drug Use](https://arxiv.org/abs/2510.15961)
*Yiyang Li,Zehong Wang,Zhengqing Yuan,Zheyuan Zhang,Keerthiram Murugesan,Chuxu Zhang,Yanfang Ye*

Main category: cs.LG

TL;DR: 提出LAMI框架，通过联合图-语言建模检测青少年非法药物使用并解释行为风险因素，在YRBS和NSDUH数据集上表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有建模方法将调查变量独立处理，忽略了变量间的潜在关联结构，需要开发能够挖掘这些潜在关系的新方法。

Method: LAMI框架将个体响应表示为关系图，通过专门的图结构学习层学习潜在连接，并集成大语言模型生成基于图结构和调查语义的自然语言解释。

Result: 在YRBS和NSDUH数据集上的实验显示，LAMI在预测准确性上优于竞争基线方法。可解释性分析表明LAMI能揭示有意义的行为子结构和心理社会路径。

Conclusion: LAMI框架能有效检测青少年非法药物使用，同时提供基于图结构和语义的可解释分析，揭示了与已知药物使用风险因素一致的家庭动态、同伴影响和学校相关困扰等模式。

Abstract: Illicit drug use among teenagers and young adults (TYAs) remains a pressing
public health concern, with rising prevalence and long-term impacts on health
and well-being. To detect illicit drug use among TYAs, researchers analyze
large-scale surveys such as the Youth Risk Behavior Survey (YRBS) and the
National Survey on Drug Use and Health (NSDUH), which preserve rich
demographic, psychological, and environmental factors related to substance use.
However, existing modeling methods treat survey variables independently,
overlooking latent and interconnected structures among them. To address this
limitation, we propose LAMI (LAtent relation Mining with bi-modal
Interpretability), a novel joint graph-language modeling framework for
detecting illicit drug use and interpreting behavioral risk factors among TYAs.
LAMI represents individual responses as relational graphs, learns latent
connections through a specialized graph structure learning layer, and
integrates a large language model to generate natural language explanations
grounded in both graph structures and survey semantics. Experiments on the YRBS
and NSDUH datasets show that LAMI outperforms competitive baselines in
predictive accuracy. Interpretability analyses further demonstrate that LAMI
reveals meaningful behavioral substructures and psychosocial pathways, such as
family dynamics, peer influence, and school-related distress, that align with
established risk factors for substance use.

</details>


### [243] [Simulation-free Structure Learning for Stochastic Dynamics](https://arxiv.org/abs/2510.16656)
*Noah El Rimawi-Fine,Adam Stecklov,Lucas Nelson,Mathieu Blanchette,Alexander Tong,Stephen Y. Zhang,Lazar Atanackovic*

Main category: cs.LG

TL;DR: StructureFlow是一种新颖的无模拟方法，能够同时学习物理系统的结构和随机群体动力学，解决了现有方法无法同时处理结构学习和动态建模的问题。


<details>
  <summary>Details</summary>
Motivation: 许多自然系统中的物理系统（如细胞生物学）本质上是高维和随机的，只能获得部分、有噪声的状态测量。现有方法通常只能单独处理结构学习或群体层面的动态建模，无法同时解决这两个问题。

Method: 提出StructureFlow方法，这是一种原则性的无模拟方法，能够联合学习物理系统的结构和随机群体动力学。该方法支持从干预中学习结构以及条件群体动力学的动态（轨迹）推断。

Result: 在高维合成系统、生物学上合理的模拟系统和实验性单细胞数据集上的实证评估表明，StructureFlow能够学习底层系统的结构，同时建模其条件群体动力学。

Conclusion: StructureFlow能够同时学习底层系统的结构并建模其条件群体动力学，这是理解系统行为机制的关键步骤。

Abstract: Modeling dynamical systems and unraveling their underlying causal
relationships is central to many domains in the natural sciences. Various
physical systems, such as those arising in cell biology, are inherently
high-dimensional and stochastic in nature, and admit only partial, noisy state
measurements. This poses a significant challenge for addressing the problems of
modeling the underlying dynamics and inferring the network structure of these
systems. Existing methods are typically tailored either for structure learning
or modeling dynamics at the population level, but are limited in their ability
to address both problems together. In this work, we address both problems
simultaneously: we present StructureFlow, a novel and principled
simulation-free approach for jointly learning the structure and stochastic
population dynamics of physical systems. We showcase the utility of
StructureFlow for the tasks of structure learning from interventions and
dynamical (trajectory) inference of conditional population dynamics. We
empirically evaluate our approach on high-dimensional synthetic systems, a set
of biologically plausible simulated systems, and an experimental single-cell
dataset. We show that StructureFlow can learn the structure of underlying
systems while simultaneously modeling their conditional population dynamics --
a key step toward the mechanistic understanding of systems behavior.

</details>


### [244] [Evaluating protein binding interfaces with PUMBA](https://arxiv.org/abs/2510.16674)
*Azam Shirali,Giri Narasimhan*

Main category: cs.LG

TL;DR: PUMBA是一种基于Vision Mamba架构的蛋白质-蛋白质对接评分函数，通过替换PIsToN中的Vision Transformer为Vision Mamba，显著提升了模型捕获蛋白质-蛋白质界面全局和局部模式的能力，在多个数据集上表现优于原模型。


<details>
  <summary>Details</summary>
Motivation: 现有的蛋白质-蛋白质对接工具依赖强大的评分函数来区分天然和非天然复合物。虽然PIsToN使用Vision Transformer取得了良好效果，但新兴的Mamba架构在自然语言处理和计算机视觉领域表现出优于Transformer的性能，因此希望将其应用于蛋白质对接评分。

Method: 开发PUMBA模型，将PIsToN中的Vision Transformer主干替换为Vision Mamba架构，利用Mamba在图像补丁序列上的高效长程序列建模能力，改进对蛋白质-蛋白质界面特征的全局和局部模式捕获。

Result: 在多个广泛使用的大规模公共数据集上的评估表明，PUMBA始终优于其基于Transformer的前身PIsToN，证明了Vision Mamba架构在蛋白质-蛋白质对接评分中的有效性。

Conclusion: Vision Mamba架构成功应用于蛋白质-蛋白质对接评分，通过改进的序列建模能力显著提升了模型性能，为蛋白质相互作用研究提供了更准确的工具。

Abstract: Protein-protein docking tools help in studying interactions between proteins,
and are essential for drug, vaccine, and therapeutic development. However, the
accuracy of a docking tool depends on a robust scoring function that can
reliably differentiate between native and non-native complexes. PIsToN is a
state-of-the-art deep learning-based scoring function that uses Vision
Transformers in its architecture. Recently, the Mamba architecture has
demonstrated exceptional performance in both natural language processing and
computer vision, often outperforming Transformer-based models in their domains.
In this study, we introduce PUMBA (Protein-protein interface evaluation with
Vision Mamba), which improves PIsToN by replacing its Vision Transformer
backbone with Vision Mamba. This change allows us to leverage Mamba's efficient
long-range sequence modeling for sequences of image patches. As a result, the
model's ability to capture both global and local patterns in protein-protein
interface features is significantly improved. Evaluation on several
widely-used, large-scale public datasets demonstrates that PUMBA consistently
outperforms its original Transformer-based predecessor, PIsToN.

</details>


### [245] [Long Exposure: Accelerating Parameter-Efficient Fine-Tuning for LLMs under Shadowy Sparsity](https://arxiv.org/abs/2510.15964)
*Tuowei Wang,Kun Li,Zixu Hao,Donglin Bai,Ju Ren,Yaoxue Zhang,Ting Cao,Mao Yang*

Main category: cs.LG

TL;DR: 本文提出Long Exposure系统，通过解决参数高效微调中的Shadowy Sparsity问题，加速大语言模型的微调过程，实现最高2.49倍的端到端加速。


<details>
  <summary>Details</summary>
Motivation: 参数高效微调技术在时间和操作成本方面存在效率低下的问题，而微调过程中特有的Shadowy Sparsity形式尚未得到充分解决，阻碍了加速效果。

Method: Long Exposure系统包含三个核心组件：Shadowy-sparsity Exposer使用长感知范围捕捉更多稀疏细节；Sequence-oriented Predictor处理大序列输入和动态参数；Dynamic-aware Operator优化动态稀疏操作的计算模式和内存访问。

Result: 广泛评估表明，Long Exposure在端到端微调中实现了最高2.49倍的加速，优于现有最先进方法。

Conclusion: Long Exposure系统为加速大语言模型的参数高效微调提供了有前景的进展，有效解决了Shadowy Sparsity带来的挑战。

Abstract: The adaptation of pre-trained large language models (LLMs) to diverse
downstream tasks via fine-tuning is critical for numerous applications.
However, the inefficiency of parameter-efficient fine-tuning (PEFT) techniques
presents significant challenges in terms of time investments and operational
costs. In this paper, we first introduce a nuanced form of sparsity, termed
Shadowy Sparsity, which is distinctive in fine-tuning and has not been
adequately addressed for acceleration. Under Shadowy Sparsity, we propose Long
Exposure, an efficient system to accelerate PEFT for LLMs. Long Exposure
comprises three key components: Shadowy-sparsity Exposer employs a prolonged
sensing range to capture more sparsity details under shadowy sparsity;
Sequence-oriented Predictor provides efficient yet accurate predictions to
handle large sequence inputs and constantly-evolving parameters; and
Dynamic-aware Operator facilitates more structured computational patterns and
coalesced memory accesses, addressing dynamic sparse operations. Extensive
evaluations show that Long Exposure outperforms state-of-the-arts with up to a
$2.49\times$ speedup in end-to-end fine-tuning, offering promising advancements
in accelerating PEFT for LLMs.

</details>


### [246] [One Token Embedding Is Enough to Deadlock Your Large Reasoning Model](https://arxiv.org/abs/2510.15965)
*Mohan Zhang,Yihua Zhang,Jinghan Jia,Zhangyang Wang,Sijia Liu,Tianlong Chen*

Main category: cs.LG

TL;DR: 提出了一种针对大型推理模型的死锁攻击方法，通过训练恶意对抗嵌入诱导模型陷入无限推理循环，阻止其输出最终答案。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型的链式思维推理机制引入了新的安全漏洞，研究人员希望探索这种推理效率方面的安全风险。

Method: 使用优化的对抗嵌入鼓励模型在推理步骤后生成过渡性标记，结合后门植入策略确保攻击可靠激活，克服连续到离散投影的挑战。

Result: 在四个先进LRM和三个数学推理基准测试中实现了100%攻击成功率，迫使模型生成到最大标记限制。

Conclusion: 该研究揭示了大型推理模型在推理效率方面存在关键且未被充分探索的安全漏洞。

Abstract: Modern large reasoning models (LRMs) exhibit impressive multi-step
problem-solving via chain-of-thought (CoT) reasoning. However, this iterative
thinking mechanism introduces a new vulnerability surface. We present the
Deadlock Attack, a resource exhaustion method that hijacks an LRM's generative
control flow by training a malicious adversarial embedding to induce perpetual
reasoning loops. Specifically, the optimized embedding encourages transitional
tokens (e.g., "Wait", "But") after reasoning steps, preventing the model from
concluding its answer. A key challenge we identify is the
continuous-to-discrete projection gap: na\"ive projections of adversarial
embeddings to token sequences nullify the attack. To overcome this, we
introduce a backdoor implantation strategy, enabling reliable activation
through specific trigger tokens. Our method achieves a 100% attack success rate
across four advanced LRMs (Phi-RM, Nemotron-Nano, R1-Qwen, R1-Llama) and three
math reasoning benchmarks, forcing models to generate up to their maximum token
limits. The attack is also stealthy (in terms of causing negligible utility
loss on benign user inputs) and remains robust against existing strategies
trying to mitigate the overthinking issue. Our findings expose a critical and
underexplored security vulnerability in LRMs from the perspective of reasoning
(in)efficiency.

</details>


### [247] [Gains: Fine-grained Federated Domain Adaptation in Open Set](https://arxiv.org/abs/2510.15967)
*Zhengyi Zhong,Wenzheng Jiang,Weidong Bao,Ji Wang,Cheems Wang,Guanbo Wang,Yongheng Deng,Ju Ren*

Main category: cs.LG

TL;DR: 本文提出了一种细粒度联邦域自适应方法Gains，用于处理现实世界中新客户端不断加入联邦学习过程的情况，能够同时实现知识发现和知识适应。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习假设封闭世界，但现实中新客户端会不断加入并带来新知识。现有方法在知识发现上较为粗粒度，且会牺牲源域性能和适应效率。

Method: 将模型分为编码器和分类器，基于特征对域偏移敏感而分类器参数对类别增量敏感的特性，开发了细粒度知识发现和贡献驱动聚合技术，并设计了抗遗忘机制。

Result: 在三个典型数据偏移场景的多域数据集上的实验结果表明，Gains在源域和目标域客户端性能上都显著优于其他基线方法。

Conclusion: Gains方法能够有效处理开放集合中的联邦域自适应问题，平衡地适应新知识同时保持源域性能。

Abstract: Conventional federated learning (FL) assumes a closed world with a fixed
total number of clients. In contrast, new clients continuously join the FL
process in real-world scenarios, introducing new knowledge. This raises two
critical demands: detecting new knowledge, i.e., knowledge discovery, and
integrating it into the global model, i.e., knowledge adaptation. Existing
research focuses on coarse-grained knowledge discovery, and often sacrifices
source domain performance and adaptation efficiency. To this end, we propose a
fine-grained federated domain adaptation approach in open set (Gains). Gains
splits the model into an encoder and a classifier, empirically revealing
features extracted by the encoder are sensitive to domain shifts while
classifier parameters are sensitive to class increments. Based on this, we
develop fine-grained knowledge discovery and contribution-driven aggregation
techniques to identify and incorporate new knowledge. Additionally, an
anti-forgetting mechanism is designed to preserve source domain performance,
ensuring balanced adaptation. Experimental results on multi-domain datasets
across three typical data-shift scenarios demonstrate that Gains significantly
outperforms other baselines in performance for both source-domain and
target-domain clients. Code is available at:
https://github.com/Zhong-Zhengyi/Gains.

</details>


### [248] [Self-Attention to Operator Learning-based 3D-IC Thermal Simulation](https://arxiv.org/abs/2510.15968)
*Zhen Huang,Hong Wang,Wenkai Yang,Muxi Tang,Depeng Xie,Ting-Jung Lin,Yu Zhang,Wei W. Xing,Lei He*

Main category: cs.LG

TL;DR: SAU-FNO结合自注意力机制、U-Net和FNO，通过迁移学习利用低精度数据，在3D IC热管理中实现高精度热预测和842倍加速。


<details>
  <summary>Details</summary>
Motivation: 3D IC中热管理因功率密度增加而更具挑战性，传统PDE方法速度慢，机器学习方法如FNO存在高频信息丢失和高精度数据依赖问题。

Method: 提出SAU-FNO框架，结合自注意力机制和U-Net与FNO，捕捉长程依赖关系并有效建模局部高频特征，采用迁移学习微调低精度数据。

Result: SAU-FNO在热预测精度上达到最先进水平，相比传统FEM方法实现842倍加速。

Conclusion: SAU-FNO是先进3D IC热仿真的高效工具，显著减少对高精度数据集的依赖并加速训练。

Abstract: Thermal management in 3D ICs is increasingly challenging due to higher power
densities. Traditional PDE-solving-based methods, while accurate, are too slow
for iterative design. Machine learning approaches like FNO provide faster
alternatives but suffer from high-frequency information loss and high-fidelity
data dependency. We introduce Self-Attention U-Net Fourier Neural Operator
(SAU-FNO), a novel framework combining self-attention and U-Net with FNO to
capture long-range dependencies and model local high-frequency features
effectively. Transfer learning is employed to fine-tune low-fidelity data,
minimizing the need for extensive high-fidelity datasets and speeding up
training. Experiments demonstrate that SAU-FNO achieves state-of-the-art
thermal prediction accuracy and provides an 842x speedup over traditional FEM
methods, making it an efficient tool for advanced 3D IC thermal simulations.

</details>


### [249] [Predict Training Data Quality via Its Geometry in Metric Space](https://arxiv.org/abs/2510.15970)
*Yang Ba,Mohammad Sadeq Abolhasani,Rong Pan*

Main category: cs.LG

TL;DR: 本文提出使用持久同调分析训练数据的几何结构对机器学习模型性能的影响，强调数据表示丰富性和冗余消除的重要性。


<details>
  <summary>Details</summary>
Motivation: 高质量训练数据是机器学习和人工智能的基础，但数据的几何结构对模型性能的影响尚未充分探索。现有方法主要关注数据类型，而忽略了数据在度量空间中的拓扑特征。

Method: 采用持久同调方法从度量空间中的数据提取拓扑特征，提供了一种超越基于熵度量的多样性量化原则性方法。

Result: 研究发现持久同调是分析和增强驱动AI系统的训练数据的强大工具，能够有效量化数据的多样性。

Conclusion: 持久同调为理解和优化训练数据的几何结构提供了新的分析框架，对提升AI系统性能具有重要意义。

Abstract: High-quality training data is the foundation of machine learning and
artificial intelligence, shaping how models learn and perform. Although much is
known about what types of data are effective for training, the impact of the
data's geometric structure on model performance remains largely underexplored.
We propose that both the richness of representation and the elimination of
redundancy within training data critically influence learning outcomes. To
investigate this, we employ persistent homology to extract topological features
from data within a metric space, thereby offering a principled way to quantify
diversity beyond entropy-based measures. Our findings highlight persistent
homology as a powerful tool for analyzing and enhancing the training data that
drives AI systems.

</details>


### [250] [Bolster Hallucination Detection via Prompt-Guided Data Augmentation](https://arxiv.org/abs/2510.15977)
*Wenyun Li,Zheng Zhang,Dongmei Jiang,Xiangyuan Lan*

Main category: cs.LG

TL;DR: PALE是一个利用提示引导数据增强的幻觉检测框架，通过LLM生成真实和幻觉数据，使用对比马氏距离评分来评估嵌入空间中的真实性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM幻觉检测中标注数据稀缺的问题，提高检测的可靠性和实用性。

Method: 使用提示引导的LLM响应作为数据增强，引入对比马氏距离评分来建模真实和幻觉数据在激活空间的分布。

Result: PALE在幻觉检测性能上显著优于基线方法，提升6.55%。

Conclusion: PALE框架无需额外人工标注，具有强泛化能力和实际应用价值。

Abstract: Large language models (LLMs) have garnered significant interest in AI
community. Despite their impressive generation capabilities, they have been
found to produce misleading or fabricated information, a phenomenon known as
hallucinations. Consequently, hallucination detection has become critical to
ensure the reliability of LLM-generated content. One primary challenge in
hallucination detection is the scarcity of well-labeled datasets containing
both truthful and hallucinated outputs. To address this issue, we introduce
Prompt-guided data Augmented haLlucination dEtection (PALE), a novel framework
that leverages prompt-guided responses from LLMs as data augmentation for
hallucination detection. This strategy can generate both truthful and
hallucinated data under prompt guidance at a relatively low cost. To more
effectively evaluate the truthfulness of the sparse intermediate embeddings
produced by LLMs, we introduce an estimation metric called the Contrastive
Mahalanobis Score (CM Score). This score is based on modeling the distributions
of truthful and hallucinated data in the activation space. CM Score employs a
matrix decomposition approach to more accurately capture the underlying
structure of these distributions. Importantly, our framework does not require
additional human annotations, offering strong generalizability and practicality
for real-world applications. Extensive experiments demonstrate that PALE
achieves superior hallucination detection performance, outperforming the
competitive baseline by a significant margin of 6.55%.

</details>


### [251] [DAWP: A framework for global observation forecasting via Data Assimilation and Weather Prediction in satellite observation space](https://arxiv.org/abs/2510.15978)
*Junchao Gong,Jingyi Xu,Ben Fei,Fenghua Ling,Wenlong Zhang,Kun Chen,Wanghan Xu,Weidong Yang,Xiaokang Yang,Lei Bai*

Main category: cs.LG

TL;DR: 提出了DAWP框架，通过人工智能数据同化(AIDA)模块在观测空间中初始化AI天气预测模型，解决了传统AIWP依赖再分析数据的局限性，实现了基于不规则卫星观测数据的全球天气预报。


<details>
  <summary>Details</summary>
Motivation: 传统AI天气预测方法依赖再分析数据，存在数据同化偏差和时间不一致性问题。观测预测作为一种变革性范式，需要解决在不同测量系统中学习时空动态的挑战。

Method: 提出DAWP框架，包含AIDA模块（使用掩码多模态自编码器处理不规则卫星观测数据）和时空解耦变换器（具有跨区域边界条件），实现基于子图像的全球观测预测。

Result: 实验表明AIDA初始化显著提高了AIWP的滚动预测效率和性能，DAWP在全局降水预测中展现出应用潜力。

Conclusion: DAWP框架成功将AIWP从再分析数据中解放出来，在观测空间中实现了高效的天气预测，为全球降水预测等应用提供了新途径。

Abstract: Weather prediction is a critical task for human society, where impressive
progress has been made by training artificial intelligence weather prediction
(AIWP) methods with reanalysis data. However, reliance on reanalysis data
limits the AIWPs with shortcomings, including data assimilation biases and
temporal discrepancies. To liberate AIWPs from the reanalysis data, observation
forecasting emerges as a transformative paradigm for weather prediction. One of
the key challenges in observation forecasting is learning spatiotemporal
dynamics across disparate measurement systems with irregular high-resolution
observation data, which constrains the design and prediction of AIWPs. To this
end, we propose our DAWP as an innovative framework to enable AIWPs to operate
in a complete observation space by initialization with an artificial
intelligence data assimilation (AIDA) module. Specifically, our AIDA module
applies a mask multi-modality autoencoder(MMAE)for assimilating irregular
satellite observation tokens encoded by mask ViT-VAEs. For AIWP, we introduce a
spatiotemporal decoupling transformer with cross-regional boundary conditioning
(CBC), learning the dynamics in observation space, to enable sub-image-based
global observation forecasting. Comprehensive experiments demonstrate that AIDA
initialization significantly improves the roll out and efficiency of AIWP.
Additionally, we show that DAWP holds promising potential to be applied in
global precipitation forecasting.

</details>


### [252] [Cog-Rethinker: Hierarchical Metacognitive Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2510.15979)
*Zexu Sun,Yongcheng Zeng,Erxue Min,Heyang Gao,Bokai Ji,Xu Chen*

Main category: cs.LG

TL;DR: Cog-Rethinker是一个用于大语言模型推理的分层元认知强化学习框架，通过两阶段方法提高样本利用率，在数学推理基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定提示模板激活LLM的推理能力，但对弱LLM存在显著的采样效率问题，大部分问题在推理任务中产生无效输出，导致样本浪费。

Method: 提出Cog-Rethinker分层元认知RL框架，在直接rollout后采用两阶段方法：首先将零准确率问题分解为子问题，然后参考先前错误解决方案精炼答案，并通过监督微调确保训练测试一致性。

Result: 实验结果表明Cog-Rethinker在各种数学推理基准上表现优异，相比基线方法提高了样本效率并加速了收敛。

Conclusion: Cog-Rethinker通过分层元认知方法有效解决了LLM推理训练中的样本效率问题，为弱LLM的推理能力提升提供了有效解决方案。

Abstract: Contemporary progress in large language models (LLMs) has revealed notable
inferential capacities via reinforcement learning (RL) employing verifiable
reward, facilitating the development of O1 and R1-like reasoning models.
Directly training from base models with RL is called zero-RL. However, previous
works rely upon activating LLMs' inherent capacities through fixed prompt
templates. This strategy introduces substantial sampling inefficiencies for
weak LLMs, as the majority of problems generate invalid outputs during
accuracy-driven filtration in reasoning tasks, which causes a waste of samples.
To solve this issue, we propose Cog-Rethinker, a novel hierarchical
metacognitive RL framework for LLM reasoning. Our Cog-Rethinker mainly focuses
on the rollout procedure in RL training. After the direct rollout, our
Cog-Rethinker improves sample utilization in a hierarchical metacognitive
two-stage framework. By leveraging human cognition during solving problems,
firstly, it prompts policy to decompose zero-accuracy problems into subproblems
to produce final reasoning results. Secondly, with zero-accuracy problems in
previous rollout stage, it further prompts policy to refine these answers by
referencing previous wrong solutions. Moreover, to enable cold-start of the two
new reasoning patterns and maintain train-test consistency across prompt
templates, our Cog-Rethinker applies supervised fine-tuning on the policy using
correct samples of the two stages with direct rollout template. Experimental
results demonstrate Cog-Rethinker's superior performance on various
mathematical reasoning benchmarks, we also analyzed its improved sample
efficiency that accelerates convergence compared to baseline methods.

</details>


### [253] [Beyond Accuracy: Are Time Series Foundation Models Well-Calibrated?](https://arxiv.org/abs/2510.16060)
*Coen Adler,Yuxin Chang,Felix Draxler,Samar Abdi,Padhraic Smyth*

Main category: cs.LG

TL;DR: 本文评估了五种时间序列基础模型和两种基准模型的校准特性，发现时间序列基础模型比基准模型校准效果更好，且不会系统性地过度自信或不足自信。


<details>
  <summary>Details</summary>
Motivation: 尽管时间序列基础模型在预测性能上达到最先进水平，但其校准特性在关键应用中尚未得到充分探索，而校准对许多实际应用至关重要。

Method: 对五种近期时间序列基础模型和两种竞争性基准模型进行系统评估，包括模型校准评估、不同预测头的影响分析以及长期自回归预测下的校准测试。

Result: 时间序列基础模型始终比基准模型校准效果更好，且不会系统性地过度自信或不足自信，这与其它深度学习模型中常见的过度自信现象形成对比。

Conclusion: 时间序列基础模型在保持高预测性能的同时，展现出良好的校准特性，这为实际应用提供了更可靠的置信度估计。

Abstract: The recent development of foundation models for time series data has
generated considerable interest in using such models across a variety of
applications. Although foundation models achieve state-of-the-art predictive
performance, their calibration properties remain relatively underexplored,
despite the fact that calibration can be critical for many practical
applications. In this paper, we investigate the calibration-related properties
of five recent time series foundation models and two competitive baselines. We
perform a series of systematic evaluations assessing model calibration (i.e.,
over- or under-confidence), effects of varying prediction heads, and
calibration under long-term autoregressive forecasting. We find that time
series foundation models are consistently better calibrated than baseline
models and tend not to be either systematically over- or under-confident, in
contrast to the overconfidence often seen in other deep learning models.

</details>


### [254] [AMiD: Knowledge Distillation for LLMs with $α$-mixture Assistant Distribution](https://arxiv.org/abs/2510.15982)
*Donghyeok Shin,Yeongmin Kim,Suhyeon Jo,Byeonghu Na,Il-Chul Moon*

Main category: cs.LG

TL;DR: 本文提出了一种名为AMiD的统一知识蒸馏框架，通过引入α混合辅助分布来解决大型语言模型知识蒸馏中的容量差距和训练不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 自回归大语言模型虽然性能优异但计算和内存成本高昂。知识蒸馏可以缓解这一问题，但现有方法面临容量差距和由于高维输出导致的近零概率引起的训练不稳定等根本限制。

Method: 提出了α混合辅助分布，这是一个新的广义辅助分布家族，通过引入分布设计变量α来连续扩展辅助分布。同时提出了AMiD统一框架，基于最优性推广了与辅助分布一起使用的散度家族。

Result: 通过大量实验证明，AMiD通过利用更广泛且理论基础的辅助分布空间，提供了优越的性能和训练稳定性。

Conclusion: AMiD框架通过系统化的辅助分布设计和散度推广，有效解决了知识蒸馏中的关键挑战，为大型语言模型的高效压缩提供了新的解决方案。

Abstract: Autoregressive large language models (LLMs) have achieved remarkable
improvement across many tasks but incur high computational and memory costs.
Knowledge distillation (KD) mitigates this issue by transferring knowledge from
a large teacher to a smaller student through distributional alignment. Previous
studies have proposed various discrepancy metrics, but the capacity gap and
training instability caused by near-zero probabilities, stemming from the
high-dimensional output of LLMs, remain fundamental limitations. To overcome
these challenges, several approaches implicitly or explicitly incorporating
assistant distribution have recently been proposed. However, the past proposals
of assistant distributions have been a fragmented approach without a systematic
investigation of the interpolation path and the divergence. This paper proposes
$\alpha$-mixture assistant distribution, a novel generalized family of
assistant distributions, and $\alpha$-mixture distillation, coined AMiD, a
unified framework for KD using the assistant distribution. The $\alpha$-mixture
assistant distribution provides a continuous extension of the assistant
distribution by introducing a new distribution design variable $\alpha$, which
has been fixed in all previous approaches. Furthermore, AMiD generalizes the
family of divergences used with the assistant distributions based on
optimality, which has also been restricted in previous works. Through extensive
experiments, we demonstrate that AMiD offers superior performance and training
stability by leveraging a broader and theoretically grounded assistant
distribution space.

</details>


### [255] [MEET-Sepsis: Multi-Endogenous-View Enhanced Time-Series Representation Learning for Early Sepsis Prediction Representation Learning for Early Sepsis Prediction](https://arxiv.org/abs/2510.15985)
*Zexi Tan,Tao Xie,Binbin Sun,Xiang Zhang,Yiqun Zhang,Yiu-Ming Cheung*

Main category: cs.LG

TL;DR: 该论文提出了一种名为MEET-Sepsis的框架，通过多内生视图表示增强机制和级联双卷积时间序列注意力模块，仅需ICU监测时间的20%就能实现竞争性的脓毒症预测准确性。


<details>
  <summary>Details</summary>
Motivation: 脓毒症是ICU中死亡率高的危及生命综合征，早期准确预测对及时干预至关重要。现有AI方法难以捕捉微弱的早期时间信号，需要更有效的早期预测方法。

Method: 提出多内生视图表示增强机制构建丰富特征视图，结合级联双卷积时间序列注意力模块进行多尺度时间表示学习。

Result: MEET-Sepsis框架仅需SOTA方法所需ICU监测时间的20%就能达到竞争性的预测准确性，显著推进了早期脓毒症预测。

Conclusion: 该研究提出的方法在早期脓毒症预测方面取得了显著进展，广泛验证证实了其有效性。

Abstract: Sepsis is a life-threatening infectious syndrome associated with high
mortality in intensive care units (ICUs). Early and accurate sepsis prediction
(SP) is critical for timely intervention, yet remains challenging due to subtle
early manifestations and rapidly escalating mortality. While AI has improved SP
efficiency, existing methods struggle to capture weak early temporal signals.
This paper introduces a Multi-Endogenous-view Representation Enhancement (MERE)
mechanism to construct enriched feature views, coupled with a Cascaded
Dual-convolution Time-series Attention (CDTA) module for multi-scale temporal
representation learning. The proposed MEET-Sepsis framework achieves
competitive prediction accuracy using only 20% of the ICU monitoring time
required by SOTA methods, significantly advancing early SP. Extensive
validation confirms its efficacy. Code is available at:
https://github.com/yueliangy/MEET-Sepsis.

</details>


### [256] [User Profiles of Sleep Disorder Sufferers: Towards Explainable Clustering and Differential Variable Analysis](https://arxiv.org/abs/2510.15986)
*Sifeddine Sellami,Juba Agoun,Lamia Yessad,Louenas Bounia*

Main category: cs.LG

TL;DR: 提出一种基于聚类的可解释人工智能方法，用于根据睡眠障碍特征对患者进行分组，并识别影响这些疾病的关键因素。


<details>
  <summary>Details</summary>
Motivation: 睡眠障碍对患者健康和生活质量有重大影响，但诊断复杂且症状多样。技术进步和医学数据分析为更好理解这些疾病提供了新视角。

Method: 采用基于聚类的可解释人工智能方法，整合可解释性方法识别关键影响因素。

Result: 在匿名真实数据上的实验证明了该方法的有效性和相关性。

Conclusion: 提出的可解释聚类方法能够有效识别睡眠障碍患者的不同特征群组，并为理解这些疾病提供重要见解。

Abstract: Sleep disorders have a major impact on patients' health and quality of life,
but their diagnosis remains complex due to the diversity of symptoms. Today,
technological advances, combined with medical data analysis, are opening new
perspectives for a better understanding of these disorders. In particular,
explainable artificial intelligence (XAI) aims to make AI model decisions
understandable and interpretable for users. In this study, we propose a
clustering-based method to group patients according to different sleep disorder
profiles. By integrating an explainable approach, we identify the key factors
influencing these pathologies. An experiment on anonymized real data
illustrates the effectiveness and relevance of our approach.

</details>


### [257] [A Minimal-Assumption Analysis of Q-Learning with Time-Varying Policies](https://arxiv.org/abs/2510.16132)
*Phalguni Nanda,Zaiwei Chen*

Main category: cs.LG

TL;DR: 本文首次对时变学习策略下的Q-learning算法进行了有限时间分析，证明了在最小假设下的收敛性，匹配了离策略Q-learning的样本复杂度，但探索性较弱而利用性更强。


<details>
  <summary>Details</summary>
Motivation: 现有Q-learning分析主要针对离策略或固定学习策略，而对时变学习策略（即同策略采样）的分析存在空白，特别是在最小假设下的有限时间分析。

Method: 采用改进的方法，利用泊松方程将马尔可夫噪声分解为鞅差项和残差项，并通过敏感性分析控制时变策略下的残差项。

Result: 建立了Q函数估计的最终迭代收敛速率，样本复杂度为O(1/ε²)，并推导了学习策略对应的Q值函数收敛速率。

Conclusion: 同策略Q-learning相比离策略版本探索性较弱但利用性更强，其策略会收敛到最优策略而非保持固定。所开发的分析工具可推广到其他时变策略的强化学习算法。

Abstract: In this work, we present the first finite-time analysis of the Q-learning
algorithm under time-varying learning policies (i.e., on-policy sampling) with
minimal assumptions -- specifically, assuming only the existence of a policy
that induces an irreducible Markov chain over the state space. We establish a
last-iterate convergence rate for $\mathbb{E}[\|Q_k - Q^*\|_\infty^2]$,
implying a sample complexity of order $O(1/\epsilon^2)$ for achieving
$\mathbb{E}[\|Q_k - Q^*\|_\infty] \le \epsilon$, matching that of off-policy
Q-learning but with a worse dependence on exploration-related parameters. We
also derive an explicit rate for $\mathbb{E}[\|Q^{\pi_k} - Q^*\|_\infty^2]$,
where $\pi_k$ is the learning policy at iteration $k$. These results reveal
that on-policy Q-learning exhibits weaker exploration than its off-policy
counterpart but enjoys an exploitation advantage, as its policy converges to an
optimal one rather than remaining fixed. Numerical simulations corroborate our
theory.
  Technically, the combination of time-varying learning policies (which induce
rapidly time-inhomogeneous Markovian noise) and the minimal assumption on
exploration presents significant analytical challenges. To address these
challenges, we employ a refined approach that leverages the Poisson equation to
decompose the Markovian noise corresponding to the lazy transition matrix into
a martingale-difference term and residual terms. To control the residual terms
under time inhomogeneity, we perform a sensitivity analysis of the Poisson
equation solution with respect to both the Q-function estimate and the learning
policy. These tools may further facilitate the analysis of general
reinforcement learning algorithms with rapidly time-varying learning policies
-- such as single-timescale actor--critic methods and learning-in-games
algorithms -- and are of independent interest.

</details>


### [258] [Algorithmic Primitives and Compositional Geometry of Reasoning in Language Models](https://arxiv.org/abs/2510.15987)
*Samuel Lippl,Thomas McGee,Kimberly Lopez,Ziwen Pan,Pierce Zhang,Salma Ziadi,Oliver Eberle,Ida Momennejad*

Main category: cs.LG

TL;DR: 该论文提出了一个追踪和引导大语言模型算法原语的框架，通过将推理轨迹与内部激活模式关联，并评估算法原语对推理步骤和任务性能的影响。研究发现LLM推理可能由算法原语的组合几何支持，这些原语可跨任务和跨模型转移，推理微调能增强跨领域的算法泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型如何通过潜在和推理时计算解决多步推理问题，探索模型推理背后的算法原语及其组合方式。

Method: 通过聚类神经激活并标记匹配的推理轨迹来操作化原语，应用函数向量方法推导可重用的推理构建块，在残差流中注入原语向量并测量其对推理的影响。

Result: 发现原语向量可通过加法、减法、标量运算组合，在激活空间中展现几何逻辑。跨任务和跨模型评估显示存在共享和任务特定的原语，推理微调后的模型表现出更强的组合泛化能力。

Conclusion: LLM推理可能由算法原语的组合几何支持，这些原语可跨任务和跨模型转移，推理微调能增强跨领域的算法泛化能力。

Abstract: How do latent and inference time computations enable large language models
(LLMs) to solve multi-step reasoning? We introduce a framework for tracing and
steering algorithmic primitives that underlie model reasoning. Our approach
links reasoning traces to internal activation patterns and evaluates
algorithmic primitives by injecting them into residual streams and measuring
their effect on reasoning steps and task performance. We consider four
benchmarks: Traveling Salesperson Problem (TSP), 3SAT, AIME, and graph
navigation. We operationalize primitives by clustering neural activations and
labeling their matched reasoning traces. We then apply function vector methods
to derive primitive vectors as reusable compositional building blocks of
reasoning. Primitive vectors can be combined through addition, subtraction, and
scalar operations, revealing a geometric logic in activation space. Cross-task
and cross-model evaluations (Phi-4, Phi-4-Reasoning, Llama-3-8B) show both
shared and task-specific primitives. Notably, comparing Phi-4 with its
reasoning-finetuned variant highlights compositional generalization after
finetuning: Phi-4-Reasoning exhibits more systematic use of verification and
path-generation primitives. Injecting the associated primitive vectors in
Phi-4-Base induces behavioral hallmarks associated with Phi-4-Reasoning.
Together, these findings demonstrate that reasoning in LLMs may be supported by
a compositional geometry of algorithmic primitives, that primitives transfer
cross-task and cross-model, and that reasoning finetuning strengthens
algorithmic generalization across domains.

</details>


### [259] [Can GRPO Help LLMs Transcend Their Pretraining Origin?](https://arxiv.org/abs/2510.15990)
*Kangqi Ni,Zhen Tan,Zijie Liu,Pingzhi Li,Tianlong Chen*

Main category: cs.LG

TL;DR: GRPO算法作为RLVR的核心方法，在提升LLM推理能力时存在不一致性。研究发现GRPO本质上是保守的重加权方案，受限于基础模型分布，无法发现全新解决方案。OOD改进仅在目标任务与模型预训练偏好一致时出现。


<details>
  <summary>Details</summary>
Motivation: 研究GRPO在提升LLM推理能力时的不一致性，探究GRPO改善推理和OOD泛化的条件。

Method: 从数据分布角度进行理论证明和受控实验，训练transformer模型并评估在推理深度、输入长度、token表示和组合性等方面的泛化能力。

Result: GRPO是保守的重加权方案，受限于基础模型分布；OOD改进仅在目标任务与预训练偏好一致时出现；ID任务收益随性能饱和而减少。

Conclusion: GRPO不是通用推理增强器，而是强化预训练偏好的工具。未来需要开发能扩展模型能力超越预训练起源的算法。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR), primarily driven by
the Group Relative Policy Optimization (GRPO) algorithm, is a leading approach
for enhancing the reasoning abilities of Large Language Models (LLMs). Despite
its wide adoption, GRPO's gains are often inconsistent; for instance, a model
may show significant improvement in one reasoning domain, like mathematics, yet
remain stagnant in another, such as medicine. This inconsistency raises a
critical question: under what conditions does GRPO improve reasoning and
generalize out-of-distribution (OOD)? We investigate this from a data
distribution perspective. We first prove theoretically that GRPO is a
conservative reweighting scheme, bounded by the base model's distribution and
thus unable to discover completely novel solutions. We further validate this in
carefully designed controlled studies by training transformers from scratch,
evaluating generalization across reasoning depth, input length, token
representation, and compositionality. Our results provide a principled
explanation for GRPO's boundaries: OOD improvement emerges only when the target
task aligns with the model's pretrained biases, while gains on in-distribution
(ID) tasks diminish as performance saturates. This reframes GRPO not as a
universal reasoning enhancer but as a tool that sharpens pretraining biases.
Our findings motivate future development of algorithms that can expand a
model's capabilities beyond its pretraining origin.

</details>


### [260] [S4ECG: Exploring the impact of long-range interactions for arrhythmia prediction](https://arxiv.org/abs/2510.17406)
*Tiezhi Wang,Wilhelm Haverkamp,Nils Strodthoff*

Main category: cs.LG

TL;DR: S4ECG是一种基于结构化状态空间模型的新型深度学习架构，用于多时段心律失常分类，通过联合多时段预测显著提升了心律失常检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统ECG分析方法难以同时捕捉全局趋势和局部波形特征的高时间分辨率交互，需要一种能够桥接全局和局部信号分析的方法。

Method: 引入S4ECG架构，利用结构化状态空间模型进行多时段心律失常分类，通过联合多时段预测来提升性能。

Result: 多时段预测方法比单时段方法在宏观AUROC上提升1.0-11.6%，房颤特异性从0.718-0.979提升至0.967-0.998，在分布内和分布外鲁棒性方面均表现优异。

Conclusion: 这项工作推动了心律失常检测算法向时间感知范式的转变，为ECG解释特别是复杂心律失常如房颤和房扑开辟了新可能性。

Abstract: The electrocardiogram (ECG) exemplifies biosignal-based time series with
continuous, temporally ordered structure reflecting cardiac physiological and
pathophysiological dynamics. Detailed analysis of these dynamics has proven
challenging, as conventional methods capture either global trends or local
waveform features but rarely their simultaneous interplay at high temporal
resolution. To bridge global and local signal analysis, we introduce S4ECG, a
novel deep learning architecture leveraging structured state space models for
multi-epoch arrhythmia classification. Our joint multi-epoch predictions
significantly outperform single-epoch approaches by 1.0-11.6% in macro-AUROC,
with atrial fibrillation specificity improving from 0.718-0.979 to 0.967-0.998,
demonstrating superior performance in-distribution and enhanced
out-of-distribution robustness. Systematic investigation reveals optimal
temporal dependency windows spanning 10-20 minutes for peak performance. This
work contributes to a paradigm shift toward temporally-aware arrhythmia
detection algorithms, opening new possibilities for ECG interpretation, in
particular for complex arrhythmias like atrial fibrillation and atrial flutter.

</details>


### [261] [Zeroth-Order Sharpness-Aware Learning with Exponential Tilting](https://arxiv.org/abs/2510.16157)
*Xuchen Gong,Tian Li*

Main category: cs.LG

TL;DR: 本文提出了一种基于指数倾斜目标的零阶优化方法，通过平滑过渡平均损失和最大损失公式，连接了传统零阶优化和锐度感知最小化(SAM)方法。


<details>
  <summary>Details</summary>
Motivation: 传统零阶优化方法优化的是原始函数的平滑版本（即随机扰动模型参数下的期望目标），而SAM方法则关注邻域内的最大损失以获得更平坦的最小值。本文旨在通过指数倾斜目标明确连接这两种方法。

Method: 提出了基于指数倾斜目标的零阶算法，通过倾斜参数t在平均损失和最大损失公式之间平滑过渡，解决了软SAM目标。

Result: 该方法可作为SAM变体的无梯度和内存高效替代方案，在分类、多项选择QA和语言生成等下游任务上比传统零阶基线方法实现了更好的泛化性能。

Conclusion: 指数倾斜目标提供了一种连接零阶优化和SAM方法的统一框架，能够有效平衡平均损失和最大损失优化，在多种任务中展现出优越的泛化能力。

Abstract: Classic zeroth-order optimization approaches typically optimize for a
smoothed version of the original function, i.e., the expected objective under
randomly perturbed model parameters. This can be interpreted as encouraging the
loss values in the perturbation set to be small on average. Popular
sharpness-aware minimization (SAM) objectives, however, typically focus on the
largest loss within the neighborhood to arrive at flat minima more effectively.
In this work, we connect zeroth-order optimization (and its corresponding
objectives) with SAM approaches explicitly, through an exponential tilting
objective that provides a smooth transition between the average- and the
max-loss formulations. We explore new zeroth-order algorithms to solve a soft
SAM objective parameterized by a tilting parameter $t$. We provide precise
characterizations of the sharpness notions of the tilted SAM framework.
Practically, our approach can be used as a gradient-free and memory-efficient
alternative to SAM variants, and it achieves better generalization compared to
vanilla zeroth-order baselines on a wide range of downstream tasks, including
classification, multiple choice QA, and language generation.

</details>


### [262] [Stratos: An End-to-End Distillation Pipeline for Customized LLMs under Distributed Cloud Environments](https://arxiv.org/abs/2510.15992)
*Ziming Dai,Tuo Zhang,Fei Gao,Xingyi Cai,Xiaofei Wang,Cheng Zhang,Wenyu Wang,Chengjie Zang*

Main category: cs.LG

TL;DR: Stratos是一个端到端的LLM蒸馏管道，通过自动化服务器和模型选择、知识蒸馏以及在分布式云环境中的部署，满足用户定义的模型性能和系统预算约束。


<details>
  <summary>Details</summary>
Motivation: 工业对定制化和成本效益高的大型语言模型的需求增长，特别是在垂直领域特定任务中，需要优化延迟和预算约束下的性能。现有蒸馏框架需要人工干预且难以满足复杂的用户定义蒸馏需求。

Method: Stratos自动选择Pareto最优服务器，动态匹配师生模型对，并根据任务复杂度调整蒸馏策略以优化云托管。

Result: 在罕见的麻将推理任务上，Stratos生成的学生模型比GPT-4o教师基线准确率提高四倍，同时降低了延迟和成本而不影响准确性。

Conclusion: Stratos展示了在垂直领域LLM部署中的潜力，能够有效满足工业需求。

Abstract: The growing industrial demand for customized and cost-efficient large
language models (LLMs) is fueled by the rise of vertical, domain-specific tasks
and the need to optimize performance under constraints such as latency and
budget. Knowledge distillation, as an efficient model compression and transfer
technique, offers a feasible solution. However, existing distillation
frameworks often require manual intervention and struggle to meet such complex
user-defined distillation requirements. To bridge this gap, we propose Stratos,
an end-to-end LLM distillation pipeline that automates server and model
selection, knowledge distillation, and deployment in distributed cloud
environments. Given user-defined constraints on model performance and system
budget, Stratos automatically selects Pareto-optimal servers, dynamically
matches teacher-student pairs, and adapts distillation strategies based on task
complexity to optimize cloud hosting. Experiments show that Stratos produces a
student model that achieves four times the accuracy of its GPT-4o teacher
baseline on a rare, domain-specific Mahjong reasoning task with reverse
synthetic data and knowledge injection. Moreover, it achieves reduced latency
and cost without compromising accuracy. These results highlight its promise for
vertical-domain LLM deployment.

</details>


### [263] [Reliable Inference in Edge-Cloud Model Cascades via Conformal Alignment](https://arxiv.org/abs/2510.17543)
*Jiayi Huang,Sangwoo Park,Nicola Paoletti,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 提出了一种基于保形对齐的边缘-云级联方法（CAb），通过多重假设测试确保边缘模型预测集满足云模型级别的条件覆盖保证，在保持目标条件覆盖率的同时显著减少向云端的卸载。


<details>
  <summary>Details</summary>
Motivation: 边缘智能虽然能通过紧凑的端侧模型实现低延迟推理，但保证可靠性仍然具有挑战性。需要确保边缘模型返回的预测集能够以用户指定的概率包含真实标签，就像云模型产生的一样。

Method: 将边缘到云端的升级过程建模为多重假设测试问题，采用保形对齐方法来选择哪些输入可以在边缘安全处理。该方法适用于任意边缘预测集，包括保形预测的各种变体。

Result: 在CIFAR-100图像分类和TeleQnA问答基准测试中，CAb级联方法在保持目标条件覆盖率的同时，显著减少了向云端的卸载，预测集大小仅有适度增加。

Conclusion: 提出的CAb级联方法为边缘预测提供了统计保证，在覆盖率、延迟率和集合大小之间提供了可调节的权衡，有效解决了边缘智能的可靠性挑战。

Abstract: Edge intelligence enables low-latency inference via compact on-device models,
but assuring reliability remains challenging. We study edge-cloud cascades that
must preserve conditional coverage: whenever the edge returns a prediction set,
it should contain the true label with a user-specified probability, as if
produced by the cloud model. We formalize conditional coverage with respect to
the cloud predictive distribution, and introduce a conformal alignment-based
(CAb) cascading mechanism that certifies this property with user control over
the risk level. Our method casts escalation from edge to cloud models as a
multiple-hypothesis testing (MHT) problem, tailoring conformal alignment (CA)
to select which inputs can be safely handled at the edge. The proposed CAb
model cascading method yields statistical guarantees on the average fraction of
edge decisions that satisfy cloud-level conditional coverage. The procedure
applies to arbitrary edge prediction sets, including variants of conformal
prediction (CP), and exposes a tunable trade-off among coverage, deferral rate,
and set size. Experiments on CIFAR-100 image classification and the TeleQnA
question-answering (QA) benchmark show that the proposed CAb cascade maintains
the target conditional coverage for edge predictions while substantially
reducing offloading to the cloud and incurring modest increases in
prediction-set size.

</details>


### [264] [Still Competitive: Revisiting Recurrent Models for Irregular Time Series Prediction](https://arxiv.org/abs/2510.16161)
*Ankitkumar Joshi,Milos Hauskrecht*

Main category: cs.LG

TL;DR: 提出了GRUwE模型，一种基于GRU的改进架构，用于处理不规则采样的多元时间序列预测问题，在保持简单性的同时实现了与最先进方法相当甚至更优的性能。


<details>
  <summary>Details</summary>
Motivation: 解决不规则采样多元时间序列建模的挑战，验证简单高效的RNN架构是否仍能与复杂架构竞争，提供更易实现和部署的解决方案。

Method: 基于GRU架构，引入指数基函数，通过两种重置机制（观测触发重置和时间触发重置）来更新马尔可夫状态，支持连续时间的回归和事件预测。

Result: 在多个真实世界基准测试中，GRUwE在下一观测和下一事件预测任务上实现了与最先进方法竞争甚至更优的性能。

Conclusion: GRUwE证明了简单RNN架构的持续竞争力，具有易于实现、超参数调优需求少、计算开销低等优势，特别适合在线部署。

Abstract: Modeling irregularly sampled multivariate time series is a persistent
challenge in domains like healthcare and sensor networks. While recent works
have explored a variety of complex learning architectures to solve the
prediction problems for irregularly sampled time series, it remains unclear
what are the true benefits of some of these architectures, and whether clever
modifications of simpler and more efficient RNN-based algorithms are still
competitive, i.e. they are on par with or even superior to these methods. In
this work, we propose and study GRUwE: Gated Recurrent Unit with Exponential
basis functions, that builds upon RNN-based architectures for observations made
at irregular times. GRUwE supports both regression-based and event-based
predictions in continuous time. GRUwE works by maintaining a Markov state
representation of the time series that updates with the arrival of irregular
observations. The Markov state update relies on two reset mechanisms: (i)
observation-triggered reset, and (ii) time-triggered reset of the GRU state
using learnable exponential decays, to support the predictions in continuous
time. Our empirical evaluations across several real-world benchmarks on
next-observation and next-event prediction tasks demonstrate that GRUwE can
indeed achieve competitive to superior performance compared to the recent
state-of-the-art (SOTA) methods. Thanks to its simplicity, GRUwE offers
compelling advantages: it is easy to implement, requires minimal
hyper-parameter tuning efforts, and significantly reduces the computational
overhead in the online deployment.

</details>


### [265] [Using Kolmogorov-Smirnov Distance for Measuring Distribution Shift in Machine Learning](https://arxiv.org/abs/2510.15996)
*Ozan K. Tonguz,Federico Taschin*

Main category: cs.LG

TL;DR: 该论文提出使用Kolmogorov-Smirnov检验来监测和量化机器学习系统中的分布偏移问题，并展示了即使很小的KS距离（0.02）也会导致强化学习智能体在交通场景中性能显著下降（旅行时间增加50%）。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习系统中训练数据与测试数据概率分布不一致的问题，这种分布偏移会导致预测误差，在安全关键应用中尤其危险。

Method: 采用Kolmogorov-Smirnov检验来测量分布偏移，使用KS距离来量化分布偏移及其对AI智能体性能的影响。

Result: 研究发现即使KS距离仅为0.02，也会导致强化学习智能体在单个交叉路口的旅行时间增加约50%，表明KS距离可作为有效的分布偏移监测指标。

Conclusion: KS检验和KS距离可作为AI智能交通系统中实时监测性能退化的有价值统计工具，帮助AI智能体更有效地应对分布偏移。

Abstract: One of the major problems in Machine Learning (ML) and Artificial
Intelligence (AI) is the fact that the probability distribution of the test
data in the real world could deviate substantially from the probability
distribution of the training data set. When this happens, the predictions of an
ML system or an AI agent could involve large errors which is very troublesome
and undesirable. While this is a well-known hard problem plaguing the AI and ML
systems' accuracy and reliability, in certain applications such errors could be
critical for safety and reliability of AI and ML systems. One approach to deal
with this problem is to monitor and measure the deviation in the probability
distribution of the test data in real time and to compensate for this
deviation. In this paper, we propose and explore the use of Kolmogorov-Smirnov
(KS) Test for measuring the distribution shift and we show how the KS distance
can be used to quantify the distribution shift and its impact on an AI agent's
performance. Our results suggest that KS distance could be used as a valuable
statistical tool for monitoring and measuring the distribution shift. More
specifically, it is shown that even a distance of KS=0.02 could lead to about
50\% increase in the travel time at a single intersection using a Reinforcement
Learning agent which is quite significant. It is hoped that the use of KS Test
and KS distance in AI-based smart transportation could be an important step
forward for gauging the performance degradation of an AI agent in real time and
this, in turn, could help the AI agent to cope with the distribution shift in a
more informed manner.

</details>


### [266] [Expressive Reward Synthesis with the Runtime Monitoring Language](https://arxiv.org/abs/2510.16185)
*Daniel Donnelly,Angelo Ferrando,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 本文提出了一种基于运行时监控语言（RML）的新型语言化奖励机，能够处理非正则、非马尔可夫任务，提升了奖励函数的表达能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习中的奖励函数通常被视为黑盒映射，缺乏解释性，且传统奖励机只能表达正则语言，无法处理计数或参数化条件等复杂行为。

Method: 基于运行时监控语言（RML）构建语言化奖励机，利用RML的内置内存机制来指定非正则、非马尔可夫任务的奖励函数。

Result: 实验证明该方法在表达能力上优于现有奖励机方法，在事件处理和任务规范方面具有灵活性优势。

Conclusion: 基于RML的语言化奖励机为复杂强化学习任务提供了更强大的奖励函数规范能力，解决了传统方法的局限性。

Abstract: A key challenge in reinforcement learning (RL) is reward (mis)specification,
whereby imprecisely defined reward functions can result in unintended, possibly
harmful, behaviours. Indeed, reward functions in RL are typically treated as
black-box mappings from state-action pairs to scalar values. While effective in
many settings, this approach provides no information about why rewards are
given, which can hinder learning and interpretability. Reward Machines address
this issue by representing reward functions as finite state automata, enabling
the specification of structured, non-Markovian reward functions. However, their
expressivity is typically bounded by regular languages, leaving them unable to
capture more complex behaviours such as counting or parametrised conditions. In
this work, we build on the Runtime Monitoring Language (RML) to develop a novel
class of language-based Reward Machines. By leveraging the built-in memory of
RML, our approach can specify reward functions for non-regular, non-Markovian
tasks. We demonstrate the expressiveness of our approach through experiments,
highlighting additional advantages in flexible event-handling and task
specification over existing Reward Machine-based methods.

</details>


### [267] [Explore-then-Commit for Nonstationary Linear Bandits with Latent Dynamics](https://arxiv.org/abs/2510.16208)
*Sunmook Choi,Yahya Sattar,Yassir Jedra,Maryam Fazel,Sarah Dean*

Main category: cs.LG

TL;DR: 该论文研究了一个非平稳多臂老虎机问题，其中奖励取决于动作和潜在状态，状态动态受未知线性动力学控制。作者提出了一种探索-提交算法，通过随机Rademacher动作估计线性动力学的马尔可夫参数，并在提交阶段使用估计参数设计优化动作序列以实现长期奖励，最终达到$\tilde{\mathcal{O}}(T^{2/3})$的遗憾界。


<details>
  <summary>Details</summary>
Motivation: 研究非平稳老虎机问题中奖励同时依赖于动作和潜在状态的情况，其中状态动态也受动作影响，导致短期和长期奖励之间存在张力，需要设计能够平衡这种张力的算法。

Method: 提出探索-提交算法：在探索阶段使用随机Rademacher动作估计线性动力学的马尔可夫参数；在提交阶段使用估计参数设计优化动作序列。分析处理了时间相关奖励学习和设计最优长期奖励动作序列两个关键挑战。

Result: 算法实现了$\tilde{\mathcal{O}}(T^{2/3})$的遗憾界。提供了双线性奖励系统识别的近最优样本复杂度和误差界，并证明了与超立方体上不定二次优化的等价性，为这个NP难问题提供了次优性保证。

Conclusion: 成功解决了非平稳老虎机问题中学习时间相关奖励和设计长期优化动作序列的挑战，提出的算法在理论上具有可证明的遗憾界，并提供了实用的半定松弛和Goemans-Williamson舍入方法作为实际解决方案。

Abstract: We study a nonstationary bandit problem where rewards depend on both actions
and latent states, the latter governed by unknown linear dynamics. Crucially,
the state dynamics also depend on the actions, resulting in tension between
short-term and long-term rewards. We propose an explore-then-commit algorithm
for a finite horizon $T$. During the exploration phase, random Rademacher
actions enable estimation of the Markov parameters of the linear dynamics,
which characterize the action-reward relationship. In the commit phase, the
algorithm uses the estimated parameters to design an optimized action sequence
for long-term reward. Our proposed algorithm achieves
$\tilde{\mathcal{O}}(T^{2/3})$ regret. Our analysis handles two key challenges:
learning from temporally correlated rewards, and designing action sequences
with optimal long-term reward. We address the first challenge by providing
near-optimal sample complexity and error bounds for system identification using
bilinear rewards. We address the second challenge by proving an equivalence
with indefinite quadratic optimization over a hypercube, a known NP-hard
problem. We provide a sub-optimality guarantee for this problem, enabling our
regret upper bound. Lastly, we propose a semidefinite relaxation with
Goemans-Williamson rounding as a practical approach.

</details>


### [268] [Benchmarking noisy label detection methods](https://arxiv.org/abs/2510.16211)
*Henrique Pickler,Jorge K. S. Kamassury,Danilo Silva*

Main category: cs.LG

TL;DR: 本文对标签噪声检测方法进行了系统性的基准测试，通过将方法分解为标签一致性函数、聚合方法和信息收集方式三个组件，在视觉和表格数据集上评估了多种检测方法在合成和真实噪声条件下的表现。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集中普遍存在标签噪声问题，影响模型训练和验证。虽然已有多种噪声标签检测技术，但缺乏明确的共识和最优方法选择指南。

Method: 将噪声检测方法分解为三个基本组件：标签一致性函数、聚合方法和信息收集方式（样本内vs样本外），提出统一的基准任务和新的评估指标（固定操作点下的假阴性率）。

Result: 研究发现，使用对数边际作为标签一致性函数、平均概率聚合和样本内信息收集的组合在大多数场景下表现最佳。

Conclusion: 该研究为设计新的检测方法和为特定应用选择技术提供了实用指导，强调了组件分解方法在系统比较不同检测方法中的价值。

Abstract: Label noise is a common problem in real-world datasets, affecting both model
training and validation. Clean data are essential for achieving strong
performance and ensuring reliable evaluation. While various techniques have
been proposed to detect noisy labels, there is no clear consensus on optimal
approaches. We perform a comprehensive benchmark of detection methods by
decomposing them into three fundamental components: label agreement function,
aggregation method, and information gathering approach (in-sample vs
out-of-sample). This decomposition can be applied to many existing detection
methods, and enables systematic comparison across diverse approaches. To fairly
compare methods, we propose a unified benchmark task, detecting a fraction of
training samples equal to the dataset's noise rate. We also introduce a novel
metric: the false negative rate at this fixed operating point. Our evaluation
spans vision and tabular datasets under both synthetic and real-world noise
conditions. We identify that in-sample information gathering using average
probability aggregation combined with the logit margin as the label agreement
function achieves the best results across most scenarios. Our findings provide
practical guidance for designing new detection methods and selecting techniques
for specific applications.

</details>


### [269] [STAR: Boosting Time Series Foundation Models for Anomaly Detection through State-aware Adapter](https://arxiv.org/abs/2510.16014)
*Hanyin Cheng,Ruitong Zhang,Yuning Lu,Peng Chen,Meng Wang,Yang Shu,Bin Yang,Chenjuan Guo*

Main category: cs.LG

TL;DR: 本文提出了一种名为STAR的即插即用模块，用于增强时间序列基础模型在建模和利用状态变量方面的能力，解决了现有模型在处理离散状态变量时的局限性。


<details>
  <summary>Details</summary>
Motivation: 在现实工业场景中，时间序列不仅包含数值变量，还包含描述系统状态的离散状态变量。现有时间序列基础模型往往忽视状态变量的分类特性和作为条件的关键作用，导致检测性能下降。

Method: STAR包含三个核心组件：身份引导的状态编码器、条件瓶颈适配器和数值-状态匹配模块，分别用于捕获状态变量的分类语义、动态生成低秩适配参数以及检测状态变量本身的异常。

Result: 在真实世界数据集上的广泛实验表明，STAR能够提升现有时间序列基础模型在多变量时间序列异常检测方面的性能。

Conclusion: STAR模块有效解决了现有时间序列基础模型在处理状态变量时的不足，显著提升了多变量时间序列异常检测的性能。

Abstract: While Time Series Foundation Models (TSFMs) have demonstrated remarkable
success in Multivariate Time Series Anomaly Detection (MTSAD), however, in
real-world industrial scenarios, many time series comprise not only numerical
variables such as temperature and flow, but also numerous discrete state
variables that describe the system status, such as valve on/off or day of the
week. Existing TSFMs often overlook the distinct categorical nature of state
variables and their critical role as conditions, typically treating them
uniformly with numerical variables. This inappropriate modeling approach
prevents the model from fully leveraging state information and even leads to a
significant degradation in detection performance after state variables are
integrated. To address this critical limitation, this paper proposes a novel
STate-aware AdapteR (STAR). STAR is a plug-and-play module designed to enhance
the capability of TSFMs in modeling and leveraging state variables during the
fine-tuning stage. Specifically, STAR comprisesthree core components: (1) We
design an Identity-guided State Encoder, whicheffectively captures the complex
categorical semantics of state variables through a learnable State Memory. (2)
We propose a Conditional Bottleneck Adapter, which dynamically generates
low-rank adaptation parameters conditioned on the current state, thereby
flexibly injecting the influence of state variables into the backbone model.
(3) We also introduce a Numeral-State Matching module to more effectively
detect anomalies inherent to the state variables themselves. Extensive
experiments conducted on real-world datasets demonstrate that STAR can improve
the performance of existing TSFMs on MTSAD.

</details>


### [270] [Airfoil optimization using Design-by-Morphing with minimized design-space dimensionality](https://arxiv.org/abs/2510.16020)
*Sangjoon Lee,Haris Moazam Sheikh*

Main category: cs.LG

TL;DR: AirDbM是一种专门用于翼型优化的设计变形方法，通过从UIUC翼型数据库中选择12个最优基准翼型，显著降低设计空间维度，在保持高重建精度的同时实现快速收敛和更好的多目标优化性能。


<details>
  <summary>Details</summary>
Motivation: 翼型几何优化需要探索多样化的设计，同时尽可能减少设计变量数量。传统方法存在设计空间维度高、优化效率低的问题。

Method: 从UIUC翼型数据库中选择12个最优基准翼型，通过顺序添加最能提高设计容量的基准翼型，构建设计变形方法。

Result: 用12个基准翼型重建了99%的数据库，平均绝对误差低于0.005；在多目标气动优化中实现了快速收敛和更大的超体积，发现了具有改进升阻比的新Pareto最优解；在强化学习中表现出比传统参数化方法更好的适应性。

Conclusion: AirDbM在减少设计变量数量的同时保持了优秀的重建和优化性能，证明了设计变形方法在机器学习驱动设计中的广泛潜力。

Abstract: Effective airfoil geometry optimization requires exploring a diverse range of
designs using as few design variables as possible. This study introduces
AirDbM, a Design-by-Morphing (DbM) approach specialized for airfoil
optimization that systematically reduces design-space dimensionality. AirDbM
selects an optimal set of 12 baseline airfoils from the UIUC airfoil database,
which contains over 1,600 shapes, by sequentially adding the baseline that most
increases the design capacity. With these baselines, AirDbM reconstructs 99 \%
of the database with a mean absolute error below 0.005, which matches the
performance of a previous DbM approach that used more baselines. In
multi-objective aerodynamic optimization, AirDbM demonstrates rapid convergence
and achieves a Pareto front with a greater hypervolume than that of the
previous larger-baseline study, where new Pareto-optimal solutions are
discovered with enhanced lift-to-drag ratios at moderate stall tolerances.
Furthermore, AirDbM demonstrates outstanding adaptability for reinforcement
learning (RL) agents in generating airfoil geometry when compared to
conventional airfoil parameterization methods, implying the broader potential
of DbM in machine learning-driven design.

</details>


### [271] [Buzz, Choose, Forget: A Meta-Bandit Framework for Bee-Like Decision Making](https://arxiv.org/abs/2510.16462)
*Emmanuelle Claeys,Elena Kerjean,Jean-Michel Loubes*

Main category: cs.LG

TL;DR: 提出了一种用于模仿学习的序列强化学习框架，专门建模传粉昆虫的异质认知策略，通过轨迹相似性捕捉和预测依赖不同策略（数值线索、记忆、环境因素）的个体行为。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法在专家策略随记忆窗口变化或偏离最优性时表现不佳，无法捕捉快速和慢速学习行为，缺乏可解释性，限制了生物学洞察。

Method: 引入最小化预测损失同时识别与行为数据最一致的有效记忆范围的模型，确保完全可解释性，提供将蜜蜂策略搜索与不同探索-利用动态下的多臂赌博机公式联系起来的数学框架，并发布包含80只蜜蜂在多样化天气条件下追踪数据的新数据集。

Result: 该框架能够忠实再现关键决策模式，提供对潜在决策策略的生物学分析能力，为传粉昆虫认知研究提供基准，改善农业生态系统中昆虫行为模拟。

Conclusion: 研究结果揭示了塑造传粉昆虫决策的学习策略和记忆相互作用的新见解，支持生态治理。

Abstract: We introduce a sequential reinforcement learning framework for imitation
learning designed to model heterogeneous cognitive strategies in pollinators.
Focusing on honeybees, our approach leverages trajectory similarity to capture
and forecast behavior across individuals that rely on distinct strategies: some
exploiting numerical cues, others drawing on memory, or being influenced by
environmental factors such as weather. Through empirical evaluation, we show
that state-of-the-art imitation learning methods often fail in this setting:
when expert policies shift across memory windows or deviate from optimality,
these models overlook both fast and slow learning behaviors and cannot
faithfully reproduce key decision patterns. Moreover, they offer limited
interpretability, hindering biological insight. Our contribution addresses
these challenges by (i) introducing a model that minimizes predictive loss
while identifying the effective memory horizon most consistent with behavioral
data, and (ii) ensuring full interpretability to enable biologists to analyze
underlying decision-making strategies and finally (iii) providing a
mathematical framework linking bee policy search with bandit formulations under
varying exploration-exploitation dynamics, and releasing a novel dataset of 80
tracked bees observed under diverse weather conditions. This benchmark
facilitates research on pollinator cognition and supports ecological governance
by improving simulations of insect behavior in agroecosystems. Our findings
shed new light on the learning strategies and memory interplay shaping
pollinator decision-making.

</details>


### [272] [Feature-driven reinforcement learning for photovoltaic in continuous intraday trading](https://arxiv.org/abs/2510.16021)
*Arega Getaneh Abate,Xiufeng Liu,Ruyu Liu,Xiaobing Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于特征驱动强化学习的光伏日内交易方法，通过整合数据驱动特征到状态中，在序贯决策框架下学习竞价策略，使用PPO算法训练可解释的线性策略，在历史市场数据上训练并在样本外评估中持续优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 光伏运营商面临发电量和短期电价的高度不确定性，连续日内市场使生产商能够实时调整头寸，可能提高收入并减少不平衡成本。

Method: 将问题建模为马尔可夫决策过程，奖励函数平衡交易利润和不平衡惩罚，使用近端策略优化（PPO）算法训练以线性可解释策略为主的模型，整合市场微观结构和历史特征到状态中。

Result: 在多样化的场景中，该策略在样本外评估中持续优于基准基线，验证显示快速收敛、实时推理和透明决策规则，学习到的权重突出了市场微观结构和历史特征的核心作用。

Conclusion: 特征驱动强化学习为光伏生产商的主动日内参与提供了一条实用、数据高效且可操作部署的路径。

Abstract: Photovoltaic (PV) operators face substantial uncertainty in generation and
short-term electricity prices. Continuous intraday markets enable producers to
adjust their positions in real time, potentially improving revenues and
reducing imbalance costs. We propose a feature-driven reinforcement learning
(RL) approach for PV intraday trading that integrates data-driven features into
the state and learns bidding policies in a sequential decision framework. The
problem is cast as a Markov Decision Process with a reward that balances
trading profit and imbalance penalties and is solved with Proximal Policy
Optimization (PPO) using a predominantly linear, interpretable policy. Trained
on historical market data and evaluated out-of-sample, the strategy
consistently outperforms benchmark baselines across diverse scenarios.
Extensive validation shows rapid convergence, real-time inference, and
transparent decision rules. Learned weights highlight the central role of
market microstructure and historical features. Taken together, these results
indicate that feature-driven RL offers a practical, data-efficient, and
operationally deployable pathway for active intraday participation by PV
producers.

</details>


### [273] [Structured Temporal Causality for Interpretable Multivariate Time Series Anomaly Detection](https://arxiv.org/abs/2510.16511)
*Dongchan Cho,Jiho Han,Keumyeong Kang,Minsang Kim,Honggyu Ryu,Namsoon Jung*

Main category: cs.LG

TL;DR: OracleAD是一个简单且可解释的无监督多元时间序列异常检测框架，通过因果嵌入建模时间动态，使用自注意力机制捕获空间关系，并将投影嵌入对齐到稳定潜在结构来识别异常。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多元时间序列异常稀少且通常无标签，现有方法依赖复杂架构且只能检测异常片段，性能被高估。

Method: 将每个变量的过去序列编码为因果嵌入来联合预测当前时间点和重构输入窗口，使用自注意力机制投影到共享潜在空间捕获空间关系，并将投影嵌入对齐到代表正常状态关系的稳定潜在结构。

Result: 在多个真实世界数据集和评估协议上实现了最先进的结果，同时通过稳定潜在结构保持可解释性。

Conclusion: OracleAD通过直接定位违反正常数据时间因果性的根因变量，在嵌入级别实现细粒度异常诊断，同时保持简单和可解释性。

Abstract: Real-world multivariate time series anomalies are rare and often unlabeled.
Additionally, prevailing methods rely on increasingly complex architectures
tuned to benchmarks, detecting only fragments of anomalous segments and
overstating performance. In this paper, we introduce OracleAD, a simple and
interpretable unsupervised framework for multivariate time series anomaly
detection. OracleAD encodes each variable's past sequence into a single causal
embedding to jointly predict the present time point and reconstruct the input
window, effectively modeling temporal dynamics. These embeddings then undergo a
self-attention mechanism to project them into a shared latent space and capture
spatial relationships. These relationships are not static, since they are
modeled by a property that emerges from each variable's temporal dynamics. The
projected embeddings are aligned to a Stable Latent Structure (SLS)
representing normal-state relationships. Anomalies are identified using a dual
scoring mechanism based on prediction error and deviation from the SLS,
enabling fine-grained anomaly diagnosis at each time point and across
individual variables. Since any noticeable SLS deviation originates from
embeddings that violate the learned temporal causality of normal data, OracleAD
directly pinpoints the root-cause variables at the embedding level. OracleAD
achieves state-of-the-art results across multiple real-world datasets and
evaluation protocols, while remaining interpretable through SLS.

</details>


### [274] [Breaking Memorization Barriers in LLM Code Fine-Tuning via Information Bottleneck for Improved Generalization](https://arxiv.org/abs/2510.16022)
*Changsheng Wang,Xin Chen,Sijia Liu,Ke Ding*

Main category: cs.LG

TL;DR: 本文提出了一种信息瓶颈引导的微调方法（IB-FT），用于解决代码生成中预训练大语言模型的记忆障碍问题，通过压缩记忆特征来提升泛化性能。


<details>
  <summary>Details</summary>
Motivation: 发现传统监督微调在代码生成中存在记忆障碍问题，即基础模型对下游代码数据的强记忆会阻碍优化，无法有效获取新的可泛化代码知识。

Method: 提出IB-FT方法，在代码数据的隐藏表示上应用信息瓶颈惩罚，压缩虚假的记忆特征，同时保留任务相关信息。

Result: 在两个代码基准测试（OriGen和Evol-CodeAlpaca-V1）上的实验表明，IB-FT显著缓解了记忆障碍，提高了top-1性能（Pass@1），并在更严格的多样本指标Pass@k(m)下获得了更稳定的增益。

Conclusion: IB-FT方法能够有效克服代码生成中的记忆障碍问题，提升模型性能和稳定性。

Abstract: Adapting pretrained large language models (LLMs) to code domains via
supervised fine-tuning (FT) has been commonly used for code generation.
However, we identify a previously underappreciated failure mode, the
memorization barrier, where strong memorization of downstream code data in the
base model could trap optimization and prevent the standard FT from effectively
acquiring new, generalizable code knowledge. To overcome this barrier, we
propose the information bottleneck (IB)-guided fine-tuning, termed IB-FT, which
applies an IB penalty on hidden representations of the code data to compress
spurious, memorized features while preserving task-relevant information.
Extensive experiments on two code benchmarks (OriGen and Evol-CodeAlpaca-V1)
show that IB-FT substantially alleviates the memorization barrier, improves
top-1 performance (Pass@$1$), and yields far more stable gains under the
stricter multi-sample metric Pass@$k^{(m)}$ (a problem counts as solved only if
at least $m$ of $k$ samples pass unit tests) compared with conventional FT.

</details>


### [275] [eDCF: Estimating Intrinsic Dimension using Local Connectivity](https://arxiv.org/abs/2510.16513)
*Dhruv Gupta,Aditya Nagarsekar,Vraj Shah,Sujith Thomas*

Main category: cs.LG

TL;DR: 本文提出了一种基于连通性因子(CF)的新型可扩展并行方法eDCF，用于在不同尺度下稳健估计高维数据的本征维度，在噪声环境下表现优异并能检测分形几何结构。


<details>
  <summary>Details</summary>
Motivation: 现代数据集通常包含具有复杂依赖关系的高维特征，而本征维度估计面临尺度依赖性的挑战：在精细尺度下噪声会膨胀估计值，在粗尺度下估计值会稳定到较低的尺度不变值。

Method: 提出基于连通性因子(CF)的eDCF方法，这是一种局部连通性度量方法，具有可扩展性和并行化能力，能够跨不同尺度稳健估计本征维度。

Result: 在合成基准测试中，eDCF与领先估计器表现相当，达到可比的平均绝对误差(MAE)。在中等至高噪声水平和大数据集下，eDCF的本征维度精确匹配率高达25.0%，优于MLE的16.7%和TWO-NN的12.5%。

Conclusion: eDCF方法能够准确检测决策边界中的分形几何结构，证实了其在分析现实结构化数据中的实用性，为高维数据本征维度估计提供了有效的解决方案。

Abstract: Modern datasets often contain high-dimensional features exhibiting complex
dependencies. To effectively analyze such data, dimensionality reduction
methods rely on estimating the dataset's intrinsic dimension (id) as a measure
of its underlying complexity. However, estimating id is challenging due to its
dependence on scale: at very fine scales, noise inflates id estimates, while at
coarser scales, estimates stabilize to lower, scale-invariant values. This
paper introduces a novel, scalable, and parallelizable method called eDCF,
which is based on Connectivity Factor (CF), a local connectivity-based metric,
to robustly estimate intrinsic dimension across varying scales. Our method
consistently matches leading estimators, achieving comparable values of mean
absolute error (MAE) on synthetic benchmarks with noisy samples. Moreover, our
approach also attains higher exact intrinsic dimension match rates, reaching up
to 25.0% compared to 16.7% for MLE and 12.5% for TWO-NN, particularly excelling
under medium to high noise levels and large datasets. Further, we showcase our
method's ability to accurately detect fractal geometries in decision
boundaries, confirming its utility for analyzing realistic, structured data.

</details>


### [276] [Unifying Polymer Modeling and Design via a Conformation-Centric Generative Foundation Model](https://arxiv.org/abs/2510.16023)
*Fanmeng Wang,Shan Mei,Wentao Guo,Hongshuai Wang,Qi Ou,Zhifeng Gao,Hongteng Xu*

Main category: cs.LG

TL;DR: PolyConFM是首个聚合物基础模型，通过构象中心的生成式预训练统一聚合物建模和设计，解决了现有方法忽视全局结构信息的问题，并在多个下游任务中优于特定任务方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法仅通过单体级描述符表示聚合物，忽略了聚合物构象中的全局结构信息，限制了实际性能。同时该领域缺乏能够有效支持多样化下游任务的通用基础模型。

Method: 将聚合物构象分解为局部构象序列，通过掩码自回归建模重建局部构象，并生成其方向变换来恢复相应的聚合物构象。通过分子动力学模拟构建首个高质量聚合物构象数据集。

Result: 实验证明PolyConFM在多样化下游任务中始终优于代表性特定任务方法。

Conclusion: PolyConFM为聚合物科学提供了一个通用且强大的工具，通过构象中心的生成式预训练统一了聚合物建模和设计。

Abstract: Polymers, macromolecules formed from covalently bonded monomers, underpin
countless technologies and are indispensable to modern life. While deep
learning is advancing polymer science, existing methods typically represent the
whole polymer solely through monomer-level descriptors, overlooking the global
structural information inherent in polymer conformations, which ultimately
limits their practical performance. Moreover, this field still lacks a
universal foundation model that can effectively support diverse downstream
tasks, thereby severely constraining progress. To address these challenges, we
introduce PolyConFM, the first polymer foundation model that unifies polymer
modeling and design through conformation-centric generative pretraining.
Recognizing that each polymer conformation can be decomposed into a sequence of
local conformations (i.e., those of its repeating units), we pretrain PolyConFM
under the conditional generation paradigm, reconstructing these local
conformations via masked autoregressive (MAR) modeling and further generating
their orientation transformations to recover the corresponding polymer
conformation. Besides, we construct the first high-quality polymer conformation
dataset via molecular dynamics simulations to mitigate data sparsity, thereby
enabling conformation-centric pretraining. Experiments demonstrate that
PolyConFM consistently outperforms representative task-specific methods on
diverse downstream tasks, equipping polymer science with a universal and
powerful tool.

</details>


### [277] [Realizing LLMs' Causal Potential Requires Science-Grounded, Novel Benchmarks](https://arxiv.org/abs/2510.16530)
*Ashutosh Srivastava,Lokesh Nagalapatti,Gautam Jajoo,Aniket Vashishtha,Parameswari Krishnamurthy,Amit Sharma*

Main category: cs.LG

TL;DR: 本文质疑LLM在因果发现任务中的真实能力，指出现有评估存在数据泄露问题，提出需要基于最新科学研究的评估协议和结合LLM知识与统计方法的混合方法。


<details>
  <summary>Details</summary>
Motivation: 挑战LLM在因果发现任务中的虚假成功叙事，因为现有评估可能受到预训练数据泄露的影响，需要开发更可靠的评估方法和实用的混合方法。

Method: 提出两个关键转变：(P1)基于最新科学研究开发防数据泄露的评估协议，从LLM训练截止后发布的论文中提取因果图；(P2)设计混合方法，将LLM预测作为经典PC算法的先验知识。

Result: 在BNLearn等基准测试中表现接近完美的LLM，在作者构建的真实科学因果图上表现较差；将LLM预测作为PC算法先验能显著提高准确率，优于纯LLM和纯统计方法。

Conclusion: 呼吁社区采用基于科学、防泄露的基准测试，并投资于适合真实世界研究的混合因果发现方法，以充分发挥LLM在因果分析中的潜力。

Abstract: Recent claims of strong performance by Large Language Models (LLMs) on causal
discovery are undermined by a key flaw: many evaluations rely on benchmarks
likely included in pretraining corpora. Thus, apparent success suggests that
LLM-only methods, which ignore observational data, outperform classical
statistical approaches. We challenge this narrative by asking: Do LLMs truly
reason about causal structure, and how can we measure it without memorization
concerns? Can they be trusted for real-world scientific discovery? We argue
that realizing LLMs' potential for causal analysis requires two shifts: (P.1)
developing robust evaluation protocols based on recent scientific studies to
guard against dataset leakage, and (P.2) designing hybrid methods that combine
LLM-derived knowledge with data-driven statistics. To address P.1, we encourage
evaluating discovery methods on novel, real-world scientific studies. We
outline a practical recipe for extracting causal graphs from recent
publications released after an LLM's training cutoff, ensuring relevance and
preventing memorization while capturing both established and novel relations.
Compared to benchmarks like BNLearn, where LLMs achieve near-perfect accuracy,
they perform far worse on our curated graphs, underscoring the need for
statistical grounding. Supporting P.2, we show that using LLM predictions as
priors for the classical PC algorithm significantly improves accuracy over both
LLM-only and purely statistical methods. We call on the community to adopt
science-grounded, leakage-resistant benchmarks and invest in hybrid causal
discovery methods suited to real-world inquiry.

</details>


### [278] [A tutorial on discovering and quantifying the effect of latent causal sources of multimodal EHR data](https://arxiv.org/abs/2510.16026)
*Marco Barbero-Mota,Eric V. Strobl,John M. Still,William W. Stead,Thomas A. Lasko*

Main category: cs.LG

TL;DR: 提出一个可泛化的因果机器学习流程，用于从大规模电子健康记录中发现潜在因果源并量化其对临床结果的影响。


<details>
  <summary>Details</summary>
Motivation: 处理不完善的多模态临床数据，发现其中的潜在因果因素，并量化这些因素对临床结果的具体影响。

Method: 通过处理多模态临床数据，将其分解为概率独立的潜在源，然后训练特定任务的因果模型来估计个体因果效应。

Result: 已在两个真实世界应用中验证了该方法的有效性，展示了其在医学发现中的通用性和实用性。

Conclusion: 该方法提供了一个可扩展的框架，能够从复杂的临床数据中发现因果关系并量化其影响，具有广泛的医学应用价值。

Abstract: We provide an accessible description of a peer-reviewed generalizable causal
machine learning pipeline to (i) discover latent causal sources of large-scale
electronic health records observations, and (ii) quantify the source causal
effects on clinical outcomes. We illustrate how imperfect multimodal clinical
data can be processed, decomposed into probabilistic independent latent
sources, and used to train taskspecific causal models from which individual
causal effects can be estimated. We summarize the findings of the two
real-world applications of the approach to date as a demonstration of its
versatility and utility for medical discovery at scale.

</details>


### [279] [Differentially Private Linear Regression and Synthetic Data Generation with Statistical Guarantees](https://arxiv.org/abs/2510.16974)
*Shurong Lin,Aleksandra Slavković,Deekshith Reddy Bhoomireddy*

Main category: cs.LG

TL;DR: 提出了一种在差分隐私下进行线性回归的方法，支持有效推断和合成数据生成，适用于社会科学中的中小规模数据集。


<details>
  <summary>Details</summary>
Motivation: 社会科学中常见中小规模数据集，现有差分隐私线性回归方法主要关注点估计，缺乏不确定性量化和合成数据生成支持，而主流合成数据方法不适合连续回归数据或需要大数据集。

Method: 采用差分隐私偏置校正估计器，提供渐近置信区间，并提出合成数据生成程序，使合成数据上的回归与差分隐私回归一致，使用分箱聚合策略处理中小维度设置。

Result: 实验表明该方法（1）比现有方法精度更高，（2）提供有效置信区间，（3）相比当前差分隐私合成数据生成方法，为下游机器学习任务产生更可靠的合成数据。

Conclusion: 该方法在差分隐私框架下为线性回归提供了有效的推断工具和合成数据生成能力，特别适合社会科学中的中小规模连续数据集。

Abstract: In social sciences, small- to medium-scale datasets are common and linear
regression (LR) is canonical. In privacy-aware settings, much work has focused
on differentially private (DP) LR, but mostly on point estimation with limited
attention to uncertainty quantification. Meanwhile, synthetic data generation
(SDG) is increasingly important for reproducibility studies, yet current DP LR
methods do not readily support it. Mainstream SDG approaches are either
tailored to discretized data, making them less suitable for continuous
regression, or rely on deep models that require large datasets, limiting their
use for the smaller, continuous data typical in social science. We propose a
method for LR with valid inference under Gaussian DP: a DP bias-corrected
estimator with asymptotic confidence intervals (CIs) and a general SDG
procedure in which regression on the synthetic data matches our DP regression.
Our binning-aggregation strategy is effective in small- to moderate-dimensional
settings. Experiments show our method (1) improves accuracy over existing
methods, (2) provides valid CIs, and (3) produces more reliable synthetic data
for downstream ML tasks than current DP SDGs.

</details>


### [280] [Data Reliability Scoring](https://arxiv.org/abs/2510.17085)
*Yiling Chen,Shi Feng,Paul Kattuman,Fang-Yi Yu*

Main category: cs.LG

TL;DR: 本文提出了在没有真实数据的情况下评估数据集可靠性的问题，引入了Gram行列式评分来衡量报告数据与真实数据的偏差程度，该评分具有实验无关性，能在不同观察过程中保持一致的可靠性排序。


<details>
  <summary>Details</summary>
Motivation: 在无法获取真实数据的情况下，如何评估来自可能具有策略性来源的数据集的可靠性是一个重要问题。真实数据不可观测，但可以看到依赖于这些真实数据的未知统计实验的结果。

Method: 提出了Gram行列式评分，通过测量描述观测数据和实验结果经验分布的向量所张成的体积来评估可靠性。该评分能够保持多个基于真实数据的可靠性排序，并且在不同实验下产生相同的可靠性排名。

Result: 在合成噪声模型、CIFAR-10嵌入和真实就业数据上的实验表明，Gram行列式评分能够有效捕捉不同观察过程中的数据质量。

Conclusion: Gram行列式评分提供了一种实验无关的方法来评估数据集的可靠性，在没有真实数据的情况下能够有效衡量报告数据与真实数据的偏差程度。

Abstract: How can we assess the reliability of a dataset without access to ground
truth? We introduce the problem of reliability scoring for datasets collected
from potentially strategic sources. The true data are unobserved, but we see
outcomes of an unknown statistical experiment that depends on them. To
benchmark reliability, we define ground-truth-based orderings that capture how
much reported data deviate from the truth. We then propose the Gram determinant
score, which measures the volume spanned by vectors describing the empirical
distribution of the observed data and experiment outcomes. We show that this
score preserves several ground-truth based reliability orderings and, uniquely
up to scaling, yields the same reliability ranking of datasets regardless of
the experiment -- a property we term experiment agnosticism. Experiments on
synthetic noise models, CIFAR-10 embeddings, and real employment data
demonstrate that the Gram determinant score effectively captures data quality
across diverse observation processes.

</details>


### [281] [AMS-QUANT: Adaptive Mantissa Sharing for Floating-point Quantization](https://arxiv.org/abs/2510.16045)
*Mengtao Lv,Ruiqi Zhu,Xinyu Wang,Yun Li*

Main category: cs.LG

TL;DR: AMS-Quant是一种新的浮点量化方法，首次探索非整数位宽量化，通过尾数位共享和自适应搜索技术，将LLM量化到FP5.33和FP4.25，实现2.8-3.2倍的推理加速，且精度损失可忽略。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的巨大参数量带来了存储和推理效率瓶颈，浮点量化虽然能加速推理，但传统方法局限于整数位宽。本研究旨在进一步逼近量化的最佳点，通过非整数位宽量化来获得更好的效率-精度平衡。

Method: 提出两种新技术：(1) 尾数位共享：将k个量化权重分组，共享最低有效尾数位，从而在不损失精度的情况下进一步降低量化位宽；(2) 自适应搜索：采用离线优化策略最小化共享带来的精度损失。同时实现高效的CUDA线性核，将内存节省转化为实际延迟降低。

Result: 在大规模数据集和模型上的实验表明，AMS-Quant能够将模型量化到FP5.33-e2m3和FP4.25-e2m2，相比FP16推理显著加速解码过程（2.8倍和3.2倍），且精度损失可忽略不计。

Conclusion: AMS-Quant首次实现了非整数位宽浮点量化，通过创新的尾数位共享和自适应搜索技术，在保持精度的同时显著提升了LLM推理效率，为大规模语言模型的高效部署提供了新的解决方案。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
various kinds of tasks, while the billion or even trillion parameters bring
storage and efficiency bottlenecks for inference. Quantization, particularly
floating-point quantization, is known to be capable of speeding up LLM
inference by reducing memory footprint and data movement during the inference
process. For the first time, we advance the floating-point quantization
exploration from integer bitwidths to non-integer bit-widths, namely AMS-Quant,
to further approach the quantization sweet spot. AMS-Quant incorporates two
novel techniques to put it into effect: (1) it proposes Mantissa-bit Sharing,
which groups k quantized weights and lets them share the least significant
mantissa bit, allowing us to further approach the minimum quantization
bit-width without accuracy loss. (2) It introduces Adaptive Searching, which
employs an offline optimization strategy to minimize the accuracy degradation
introduced by sharing. Moreover, AMS-Quant is also prototyped as efficient CUDA
Linear kernels, which translates memory savings into wall-clock latency
reduction by reducing memory access. Extensive experiments on large-scale
datasets and models show that AMS-Quant can quantize the model to FP-5.33-e2m3
and FP4.25-e2m2, and significantly speed up the LLM decoding over FP16
inference (2.8x and 3.2x), with negligible accuracy loss.

</details>


### [282] [Adapting to Stochastic and Adversarial Losses in Episodic MDPs with Aggregate Bandit Feedback](https://arxiv.org/abs/2510.17103)
*Shinji Ito,Kevin Jamieson,Haipeng Luo,Arnab Maiti,Taira Tsuchiya*

Main category: cs.LG

TL;DR: 本文研究了在聚合bandit反馈下的有限时域马尔可夫决策过程在线学习问题，提出了首个在随机和对抗环境中都能实现低遗憾的BOBW算法，并在已知和未知转移概率情况下都取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注最坏情况分析，而本文旨在开发能够在随机和对抗环境中都表现良好的BOBW算法，以应对更具挑战性的聚合bandit反馈设置。

Method: 结合了基于占用度量的FTRL、自约束技术以及受在线最短路径问题启发的新型损失估计器，并扩展到未知转移概率情况下的置信度技术。

Result: 在已知转移概率情况下，算法在随机环境中达到O(log T)遗憾，在对抗环境中达到O(√T)遗憾，并建立了匹配的下界证明最优性。同时为最短路径问题提供了首个个体间隙依赖下界。

Conclusion: 本文成功开发了首个在聚合bandit反馈下实现BOBW性能的算法，为马尔可夫决策过程和最短路径问题的在线学习提供了新的理论保证和算法框架。

Abstract: We study online learning in finite-horizon episodic Markov decision processes
(MDPs) under the challenging aggregate bandit feedback model, where the learner
observes only the cumulative loss incurred in each episode, rather than
individual losses at each state-action pair. While prior work in this setting
has focused exclusively on worst-case analysis, we initiate the study of
best-of-both-worlds (BOBW) algorithms that achieve low regret in both
stochastic and adversarial environments. We propose the first BOBW algorithms
for episodic tabular MDPs with aggregate bandit feedback. In the case of known
transitions, our algorithms achieve $O(\log T)$ regret in stochastic settings
and ${O}(\sqrt{T})$ regret in adversarial ones. Importantly, we also establish
matching lower bounds, showing the optimality of our algorithms in this
setting. We further extend our approach to unknown-transition settings by
incorporating confidence-based techniques. Our results rely on a combination of
FTRL over occupancy measures, self-bounding techniques, and new loss estimators
inspired by recent advances in online shortest path problems. Along the way, we
also provide the first individual-gap-dependent lower bounds and demonstrate
near-optimal BOBW algorithms for shortest path problems with bandit feedback.

</details>


### [283] [Matricial Free Energy as a Gaussianizing Regularizer: Enhancing Autoencoders for Gaussian Code Generation](https://arxiv.org/abs/2510.17120)
*Rishi Sonthalia,Raj Rao Nadakuditi*

Main category: cs.LG

TL;DR: 提出了一种基于矩阵自由能的自动编码器正则化方法，通过优化代码矩阵的奇异值分布使其接近高斯分布，从而生成具有良好泛化能力的编码。


<details>
  <summary>Details</summary>
Motivation: 传统自动编码器在编码分布控制方面存在不足，需要一种能够确保编码具有高斯分布特性的正则化方法，以提升模型的泛化能力。

Method: 基于矩阵自由能理论，定义了一个可微损失函数，该函数基于代码矩阵的奇异值分布，通过随机梯度下降最小化该损失，使编码分布接近高斯分布。

Result: 实验表明，该方法能够生成高斯分布的编码，在训练集和测试集上都具有良好的泛化性能，并成功应用于欠定逆问题。

Conclusion: 矩阵自由能正则化是一种有效的自动编码器正则化方法，能够可靠地生成高斯编码并提升模型性能。

Abstract: We introduce a novel regularization scheme for autoencoders based on
matricial free energy. Our approach defines a differentiable loss function in
terms of the singular values of the code matrix (code dimension x batch size).
From the standpoint of free probability an d random matrix theory, this loss
achieves its minimum when the singular value distribution of the code matrix
coincides with that of an appropriately sculpted random metric with i.i.d.
Gaussian entries. Empirical simulations demonstrate that minimizing the
negative matricial free energy through standard stochastic gradient-based
training yields Gaussian-like codes that generalize across training and test
sets. Building on this foundation, we propose a matricidal free energy
maximizing autoencoder that reliably produces Gaussian codes and show its
application to underdetermined inverse problems.

</details>


### [284] [Adaptive Discretization for Consistency Models](https://arxiv.org/abs/2510.17266)
*Jiayu Bai,Zhanbo Feng,Zhijie Deng,Tianqi Hou,Robert C. Qiu,Zenan Ling*

Main category: cs.LG

TL;DR: 提出了ADCMs框架，通过自动自适应离散化方法改进一致性模型，使用局部一致性作为优化目标、全局一致性作为约束，显著提升了训练效率和生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有的一致性模型依赖手动设计的离散化方案，需要针对不同噪声调度和数据集进行重复调整，这限制了模型的效率和适应性。

Method: 将离散化步骤制定为优化问题，使用局部一致性作为优化目标确保可训练性，全局一致性作为约束确保稳定性，通过拉格朗日乘子平衡两者关系，并基于高斯-牛顿法实现自适应离散化。

Result: 在CIFAR-10和ImageNet上的实验表明，ADCMs显著提高了训练效率，以最小的训练开销实现了优越的生成性能，并对更先进的扩散模型变体表现出强适应性。

Conclusion: ADCMs框架为一致性模型提供了一种统一的自适应离散化方法，有效解决了手动离散化方案的局限性，在保持高性能的同时大幅提升了训练效率。

Abstract: Consistency Models (CMs) have shown promise for efficient one-step
generation. However, most existing CMs rely on manually designed discretization
schemes, which can cause repeated adjustments for different noise schedules and
datasets. To address this, we propose a unified framework for the automatic and
adaptive discretization of CMs, formulating it as an optimization problem with
respect to the discretization step. Concretely, during the consistency training
process, we propose using local consistency as the optimization objective to
ensure trainability by avoiding excessive discretization, and taking global
consistency as a constraint to ensure stability by controlling the denoising
error in the training target. We establish the trade-off between local and
global consistency with a Lagrange multiplier. Building on this framework, we
achieve adaptive discretization for CMs using the Gauss-Newton method. We refer
to our approach as ADCMs. Experiments demonstrate that ADCMs significantly
improve the training efficiency of CMs, achieving superior generative
performance with minimal training overhead on both CIFAR-10 and ImageNet.
Moreover, ADCMs exhibit strong adaptability to more advanced DM variants. Code
is available at https://github.com/rainstonee/ADCM.

</details>


### [285] [Uncertainty-aware data assimilation through variational inference](https://arxiv.org/abs/2510.17268)
*Anthony Frion,David S Greenberg*

Main category: cs.LG

TL;DR: 本文提出了一种基于变分推断的扩展方法，将确定性机器学习方法扩展到多变量高斯分布预测，用于数据同化中的不确定性建模。


<details>
  <summary>Details</summary>
Motivation: 数据同化在大多数设置中都涉及不确定性，现有的确定性机器学习方法无法充分处理这种不确定性。

Method: 在现有确定性机器学习方法基础上，提出变分推断扩展，使预测状态遵循多变量高斯分布。使用混沌Lorenz-96动力学作为测试平台。

Result: 新模型能够获得近乎完美校准的预测，并且可以在更广泛的变化数据同化管道中集成，从而从增加的数据同化窗口长度中获得更大收益。

Conclusion: 提出的随机变分推断方法能够有效处理数据同化中的不确定性，提供校准良好的预测，并提升数据同化性能。

Abstract: Data assimilation, consisting in the combination of a dynamical model with a
set of noisy and incomplete observations in order to infer the state of a
system over time, involves uncertainty in most settings. Building upon an
existing deterministic machine learning approach, we propose a variational
inference-based extension in which the predicted state follows a multivariate
Gaussian distribution. Using the chaotic Lorenz-96 dynamics as a testing
ground, we show that our new model enables to obtain nearly perfectly
calibrated predictions, and can be integrated in a wider variational data
assimilation pipeline in order to achieve greater benefit from increasing
lengths of data assimilation windows. Our code is available at
https://github.com/anthony-frion/Stochastic_CODA.

</details>


### [286] [Symmetries in PAC-Bayesian Learning](https://arxiv.org/abs/2510.17303)
*Armin Beck,Peter Ochs*

Main category: cs.LG

TL;DR: 本文扩展了机器学习中对称性的泛化保证，从紧致群对称性扩展到非紧致对称性（如平移），并放宽了数据分布不变性的假设。基于PAC-Bayes框架，作者改进了现有边界，并在旋转MNIST数据集上验证了理论。


<details>
  <summary>Details</summary>
Motivation: 现有理论主要关注紧致群对称性且假设数据分布不变，这在现实应用中很少满足。作者希望将泛化保证扩展到更广泛的非紧致对称性和非不变数据分布场景。

Method: 基于PAC-Bayes框架，作者改进并收紧现有边界，特别是McAllester的PAC-Bayes边界，并证明该方法适用于多种PAC-Bayes边界。在非均匀旋转的MNIST数据集上进行实验验证。

Result: 在非均匀旋转的MNIST数据集上，推导出的泛化保证不仅成立，而且优于先前结果。这为对称模型在对称数据上的优越性提供了理论证据。

Conclusion: 对于对称数据，对称模型在超越紧致群和不变分布的更广泛场景中具有优势，这为理解机器学习中对称性提供了更一般的理论基础。

Abstract: Symmetries are known to improve the empirical performance of machine learning
models, yet theoretical guarantees explaining these gains remain limited. Prior
work has focused mainly on compact group symmetries and often assumes that the
data distribution itself is invariant, an assumption rarely satisfied in
real-world applications. In this work, we extend generalization guarantees to
the broader setting of non-compact symmetries, such as translations and to
non-invariant data distributions. Building on the PAC-Bayes framework, we adapt
and tighten existing bounds, demonstrating the approach on McAllester's
PAC-Bayes bound while showing that it applies to a wide range of PAC-Bayes
bounds. We validate our theory with experiments on a rotated MNIST dataset with
a non-uniform rotation group, where the derived guarantees not only hold but
also improve upon prior results. These findings provide theoretical evidence
that, for symmetric data, symmetric models are preferable beyond the narrow
setting of compact groups and invariant distributions, opening the way to a
more general understanding of symmetries in machine learning.

</details>


### [287] [FedPURIN: Programmed Update and Reduced INformation for Sparse Personalized Federated Learning](https://arxiv.org/abs/2510.16065)
*Lunchen Xie,Zehua He,Qingjiang Shi*

Main category: cs.LG

TL;DR: FedPURIN是一个通信高效的个性化联邦学习框架，通过整数编程识别关键参数进行传输，结合稀疏聚合方案显著减少通信负担，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决个性化联邦学习中现有方法通信效率不足的问题，减轻实际部署中的通信负担，特别适用于边缘智能系统处理异构数据源。

Method: 提出FedPURIN框架，采用整数编程策略识别关键参数进行传输，并将其集成到稀疏聚合方案中。

Result: 在标准图像分类基准测试中，在不同非IID条件下表现出与最先进方法相竞争的性能，并通过稀疏聚合实现了可量化的通信减少。

Conclusion: FedPURIN为通信高效的个性化联邦学习建立了新范式，特别适用于处理异构数据源的边缘智能系统。

Abstract: Personalized Federated Learning (PFL) has emerged as a critical research
frontier addressing data heterogeneity issue across distributed clients. Novel
model architectures and collaboration mechanisms are engineered to accommodate
statistical disparities while producing client-specific models. Parameter
decoupling represents a promising paradigm for maintaining model performance in
PFL frameworks. However, the communication efficiency of many existing methods
remains suboptimal, sustaining substantial communication burdens that impede
practical deployment. To bridge this gap, we propose Federated Learning with
Programmed Update and Reduced INformation (FedPURIN), a novel framework that
strategically identifies critical parameters for transmission through an
integer programming formulation. This mathematically grounded strategy is
seamlessly integrated into a sparse aggregation scheme, achieving a significant
communication reduction while preserving the efficacy. Comprehensive
evaluations on standard image classification benchmarks under varied non-IID
conditions demonstrate competitive performance relative to state-of-the-art
methods, coupled with quantifiable communication reduction through sparse
aggregation. The framework establishes a new paradigm for
communication-efficient PFL, particularly advantageous for edge intelligence
systems operating with heterogeneous data sources.

</details>


### [288] [MNO: Multiscale Neural Operator for Computational Fluid Dynamics with 3D Point Cloud Data](https://arxiv.org/abs/2510.16071)
*Qinxuan Wang,Chuang Wang,Mingyu Zhang,Jingwei Sun,Peipei Yang,Shuo Tang,Shiming Xiang*

Main category: cs.LG

TL;DR: 提出了多尺度神经算子（MNO），一种用于3D非结构化点云上计算流体动力学的新型架构，通过显式三尺度分解显著提升了神经算子在复杂流体问题上的精度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子方法在精度和可扩展性方面存在局限，特别是在不规则域上处理具有丰富多尺度结构的流体流动时表现不佳。

Method: MNO架构显式地将信息分解为三个尺度：全局维度收缩注意力模块处理长程依赖，局部图注意力模块处理邻域级交互，微观点级注意力模块处理细粒度细节。

Result: 在四个不同基准测试中，MNO始终优于最先进的基线方法，预测误差降低5%至40%，在具有30万点的挑战性3D CFD问题上表现出更好的鲁棒性。

Conclusion: 显式多尺度设计对神经算子至关重要，MNO为在不规则域上学习复杂流体动力学建立了一个可扩展的框架。

Abstract: Neural operators have emerged as a powerful data-driven paradigm for solving
Partial Differential Equations (PDEs), offering orders-of-magnitude
acceleration over traditional solvers. However, existing approaches still
suffer from limited accuracy and scalability, particularly on irregular domains
where fluid flows exhibit rich multiscale structures. In this work, we
introduce the Multiscale Neural Operator (MNO), a new architecture for
Computational Fluid Dynamics (CFD) on three-dimensional (3D) unstructured point
clouds. MNO explicitly decomposes information across three scales: a global
dimension-shrinkage attention module for long-range dependencies, a local graph
attention module for neighborhood-level interactions, and a micro point-wise
attention module for fine-grained details. This design preserves multiscale
inductive biases while remaining computationally efficient. We evaluate MNO on
four diverse benchmarks, covering both steady-state and unsteady flow scenarios
with up to 300K points. Across all tasks, MNO consistently outperforms
state-of-the-art baselines, reducing prediction errors by 5% to 40% and
demonstrating improved robustness in challenging 3D CFD problems. Our results
highlight the importance of explicit multiscale design for neural operators and
establish MNO as a scalable framework for learning complex fluid dynamics on
irregular domains.

</details>


### [289] [Stochastic Difference-of-Convex Optimization with Momentum](https://arxiv.org/abs/2510.17503)
*El Mahdi Chayti,Martin Jaggi*

Main category: cs.LG

TL;DR: 动量方法使随机DC优化在小批量下收敛，无需大批次或强噪声假设


<details>
  <summary>Details</summary>
Motivation: 随机DC优化在机器学习中广泛应用，但在小批量下的收敛性研究不足，现有方法需要大批次或强噪声假设，限制了实际应用

Method: 提出基于动量的算法，在标准平滑性和有界方差假设下实现收敛

Result: 证明了无动量时无论步长如何都可能不收敛，动量方法具有可证明的收敛性和强实证性能

Conclusion: 动量是实现随机DC优化小批量收敛的关键因素

Abstract: Stochastic difference-of-convex (DC) optimization is prevalent in numerous
machine learning applications, yet its convergence properties under small batch
sizes remain poorly understood. Existing methods typically require large
batches or strong noise assumptions, which limit their practical use. In this
work, we show that momentum enables convergence under standard smoothness and
bounded variance assumptions (of the concave part) for any batch size. We prove
that without momentum, convergence may fail regardless of stepsize,
highlighting its necessity. Our momentum-based algorithm achieves provable
convergence and demonstrates strong empirical performance.

</details>


### [290] [Early-stopping for Transformer model training](https://arxiv.org/abs/2510.16074)
*Jing He,Hua Jiang,Cheng Li,Siqian Xin,Shuzhen Yang*

Main category: cs.LG

TL;DR: 提出基于随机矩阵理论的Transformer训练动态分析框架，通过自注意力矩阵的谱密度演化识别训练三阶段，并开发无验证的早停准则。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer训练动态的底层机制，为性能改进提供理论依据，并建立原则性的早停标准。

Method: 利用随机矩阵理论分析Transformer训练动态，通过自注意力矩阵V的谱密度演化识别训练阶段，使用幂律拟合作为探针划分训练过程。

Result: 发现浅层自注意力矩阵的谱密度始终演化为重尾分布，据此将训练分为结构探索、重尾结构稳定和收敛饱和三个阶段。提出两个无验证的早停准则：重尾动态定量指标和收敛的谱特征。

Conclusion: 随机矩阵理论为监控和诊断Transformer模型训练进展提供了有效工具，提出的早停准则与训练动态高度一致。

Abstract: This work introduces a novel theoretical framework grounded in Random Matrix
Theory (RMT) for analyzing Transformer training dynamics. We focus on the
underlying mechanisms that drive performance improvements and derive principled
early-stopping criteria. Empirically, we observe that the spectral density of
the shallow self-attention matrix V consistently evolves into a heavy-tailed
distribution. Utilizing the PL (Power Law) fit to this matrix as a probe, we
demarcate training into three stages: structural exploration, heavy-tailed
structure stabilization, and convergence saturation. This staging provides
guidance for preliminary stopping decisions. Crucially, we propose two
consistent and validation-free criteria: a quantitative metric for heavy-tailed
dynamics and a novel spectral signature indicative of convergence. The strong
alignment between these criteria highlights the utility of RMT for monitoring
and diagnosing the progression of Transformer model training.

</details>


### [291] [BPL: Bias-adaptive Preference Distillation Learning for Recommender System](https://arxiv.org/abs/2510.16076)
*SeongKu Kang,Jianxun Lian,Dongha Lee,Wonbin Kweon,Sanghwan Jang,Jaehyun Lee,Jindong Wang,Xing Xie,Hwanjo Yu*

Main category: cs.LG

TL;DR: 提出BPL框架，通过双重蒸馏策略在事实和反事实测试环境中实现高性能推荐系统，解决推荐系统偏差问题。


<details>
  <summary>Details</summary>
Motivation: 推荐系统存在偏差导致用户偏好信息不完整，现有去偏方法主要针对反事实测试环境，在事实测试环境中准确率显著下降。需要开发在两种测试环境中都能表现良好的模型。

Method: 采用偏差自适应偏好蒸馏学习框架，包含从有偏模型进行师生蒸馏和带可靠性过滤的自蒸馏两种策略，逐步揭示用户偏好。

Result: 综合实验验证了BPL在事实和反事实测试中的有效性。

Conclusion: BPL框架通过双重蒸馏策略成功解决了推荐系统偏差问题，在两种测试环境中都实现了高性能。

Abstract: Recommender systems suffer from biases that cause the collected feedback to
incompletely reveal user preference. While debiasing learning has been
extensively studied, they mostly focused on the specialized (called
counterfactual) test environment simulated by random exposure of items,
significantly degrading accuracy in the typical (called factual) test
environment based on actual user-item interactions. In fact, each test
environment highlights the benefit of a different aspect: the counterfactual
test emphasizes user satisfaction in the long-terms, while the factual test
focuses on predicting subsequent user behaviors on platforms. Therefore, it is
desirable to have a model that performs well on both tests rather than only
one. In this work, we introduce a new learning framework, called Bias-adaptive
Preference distillation Learning (BPL), to gradually uncover user preferences
with dual distillation strategies. These distillation strategies are designed
to drive high performance in both factual and counterfactual test environments.
Employing a specialized form of teacher-student distillation from a biased
model, BPL retains accurate preference knowledge aligned with the collected
feedback, leading to high performance in the factual test. Furthermore, through
self-distillation with reliability filtering, BPL iteratively refines its
knowledge throughout the training process. This enables the model to produce
more accurate predictions across a broader range of user-item combinations,
thereby improving performance in the counterfactual test. Comprehensive
experiments validate the effectiveness of BPL in both factual and
counterfactual tests. Our implementation is accessible via:
https://github.com/SeongKu-Kang/BPL.

</details>


### [292] [FSRF: Factorization-guided Semantic Recovery for Incomplete Multimodal Sentiment Analysis](https://arxiv.org/abs/2510.16086)
*Ziyang Liu,Pengjunfei Chu,Shuming Dong,Chen Zhang,Mingcheng Li,Jin Wang*

Main category: cs.LG

TL;DR: 本文提出了一种因子化引导的语义恢复框架（FSRF），用于解决多模态情感分析中模态缺失的问题，通过去冗余同质-异质因子化模块和分布对齐的自蒸馏模块来恢复缺失语义。


<details>
  <summary>Details</summary>
Motivation: 现实应用中由于遮挡、隐私约束和设备故障等原因导致模态缺失，而现有研究主要关注完整多模态数据的交互和融合，缺乏对模态缺失问题的处理，导致泛化能力差。

Method: 1. 去冗余同质-异质因子化模块：将模态分解为模态同质、模态异质和噪声表示，并设计约束范式进行表示学习；2. 分布对齐的自蒸馏模块：利用双向知识转移充分恢复缺失语义。

Result: 在两个数据集上的综合实验表明，FSRF在不确定模态缺失情况下相比先前方法具有显著的性能优势。

Conclusion: FSRF框架有效缓解了多模态情感分析中的模态缺失问题，通过因子化表示和自蒸馏机制提升了模型在模态缺失情况下的性能表现。

Abstract: In recent years, Multimodal Sentiment Analysis (MSA) has become a research
hotspot that aims to utilize multimodal data for human sentiment understanding.
Previous MSA studies have mainly focused on performing interaction and fusion
on complete multimodal data, ignoring the problem of missing modalities in
real-world applications due to occlusion, personal privacy constraints, and
device malfunctions, resulting in low generalizability.
  To this end, we propose a Factorization-guided Semantic Recovery Framework
(FSRF) to mitigate the modality missing problem in the MSA task.
  Specifically, we propose a de-redundant homo-heterogeneous factorization
module that factorizes modality into modality-homogeneous,
modality-heterogeneous, and noisy representations and design elaborate
constraint paradigms for representation learning.
  Furthermore, we design a distribution-aligned self-distillation module that
fully recovers the missing semantics by utilizing bidirectional knowledge
transfer.
  Comprehensive experiments on two datasets indicate that FSRF has a
significant performance advantage over previous methods with uncertain missing
modalities.

</details>


### [293] [STABLE: Gated Continual Learning for Large Language Models](https://arxiv.org/abs/2510.16089)
*William Hoy,Nurcin Celik*

Main category: cs.LG

TL;DR: STABLE是一个基于门控机制的持续自编辑框架，使用LoRA参数高效微调来约束顺序更新中的灾难性遗忘问题，通过三种指标评估编辑稳定性并选择性接受更新。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型需要持续适应机制但避免完全重训练，顺序更新会导致灾难性遗忘，新编辑会降低先前获得的知识。

Method: 使用LoRA进行参数高效微调，通过三种指标（精确匹配下降、比特数增加、KL散度）评估候选编辑的稳定性，超过阈值时通过裁剪过程重新缩放或拒绝LoRA更新。

Result: 在Qwen-2.5-7B模型上的实验表明，门控机制有效缓解遗忘同时保持适应性，基于EM的门控在短持续学习序列中实现最高累积性能。

Conclusion: 不同门控策略可实现相当的分布偏移但产生不同准确性结果，突显了门控设计在持续适应中的重要性，为持续模型编辑提供了原则性方法。

Abstract: Large language models (LLMs) increasingly require mechanisms for continual
adaptation without full retraining. However, sequential updates can lead to
catastrophic forgetting, where new edits degrade previously acquired knowledge.
This work presents STABLE, a gated continual self editing framework that
constrains forgetting during sequential updates using parameter efficient fine
tuning via Low Rank Adaptation (LoRA; see arXiv:2106.09685). Each candidate
edit is evaluated against a stability budget using one of three metrics: (i)
Exact Match (EM) drop, capturing factual accuracy loss; (ii) bits increase,
reflecting reduced model confidence; and (iii) KL divergence, quantifying
distributional drift between the base and adapted models. If a threshold is
exceeded, the LoRA update is rescaled through a clipping procedure or rejected.
Experiments on the Qwen-2.5-7B model show that gating effectively mitigates
forgetting while preserving adaptability. EM based gating achieved the highest
cumulative performance in short continual learning sequences. Our results show
that different gating strategies can achieve comparable distribution shift
(measured by KL divergence) while producing different accuracy outcomes,
highlighting the importance of gating design in continual adaptation. This
approach offers a principled method for continual model editing, enabling LLMs
to integrate new knowledge while maintaining reliability. Code:
https://github.com/Bhoy1/STABLE

</details>


### [294] [Compressing Many-Shots in In-Context Learning](https://arxiv.org/abs/2510.16092)
*Devvrit Khatri,Pranamya Kulkarni,Nilesh Gupta,Yerram Varun,Liqian Peng,Jay Yagnik,Praneeth Netrapalli,Cho-Jui Hsieh,Alec Go,Inderjit S Dhillon,Aditya Kusupati,Prateek Jain*

Main category: cs.LG

TL;DR: 本文提出MemCom方法，通过层间压缩技术有效压缩多示例提示，在保持性能的同时显著降低内存和计算成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通过上下文学习能够从多个输入-输出示例中学习任务，但增加示例数量会显著提高内存和计算成本，需要有效的压缩方法来提升效率。

Method: 提出MemCom层间压缩方法，使用更强的压缩器模型，在每个Transformer层对多示例表示进行压缩，生成软令牌摘要。

Result: MemComp在多个分类任务上优于强基线，特别是在高压缩比（3x到8x）下，性能下降小于10%，而基线方法性能下降超过20-30%。

Conclusion: 层间压缩方法能够有效实现多示例提示的压缩，在保持高准确率的同时显著降低计算和内存需求。

Abstract: Large Language Models (LLMs) have been shown to be able to learn different
tasks without explicit finetuning when given many input-output examples /
demonstrations through In-Context Learning (ICL). Increasing the number of
examples, called ``shots'', improves downstream task performance but incurs
higher memory and computational costs. In this work, we study an approach to
improve the memory and computational efficiency of ICL inference by compressing
the many-shot prompts. Given many shots comprising t tokens, our goal is to
generate a m soft-token summary, where m < t. We first show that existing
prompt compression methods are ineffective for many-shot compression, and
simply using fewer shots as a baseline is surprisingly strong. To achieve
effective compression, we find that: (a) a stronger compressor model with more
trainable parameters is necessary, and (b) compressing many-shot
representations at each transformer layer enables more fine-grained compression
by providing each layer with its own compressed representation. Based on these
insights, we propose MemCom, a layer-wise compression method. We systematically
evaluate various compressor models and training approaches across different
model sizes (2B and 7B), architectures (Gemma and Mistral), many-shot sequence
lengths (3k-6k tokens), and compression ratios (3x to 8x). MemCom outperforms
strong baselines across all compression ratios on multiple classification tasks
with large label sets. Notably, while baseline performance degrades sharply at
higher compression ratios, often by over 20-30%, MemCom maintains high accuracy
with minimal degradation, typically dropping by less than 10%.

</details>


### [295] [Zero-shot World Models via Search in Memory](https://arxiv.org/abs/2510.16123)
*Federico Malato,Ville Hautamäki*

Main category: cs.LG

TL;DR: 本文提出了一种基于相似性搜索和随机表示的世界模型，无需训练过程即可近似环境动态，并与Dreamer家族的PlaNet模型进行比较，在潜在重建质量和长期动态预测方面表现相当甚至更好。


<details>
  <summary>Details</summary>
Motivation: 世界模型在强化学习中广泛应用，能够提高样本效率。现有模型如Dreamer需要训练过程，本文旨在探索无需训练的世界模型构建方法。

Method: 利用相似性搜索和随机表示来近似世界模型，避免传统训练过程，并与PlaNet模型进行对比评估。

Result: 基于搜索的世界模型在潜在重建质量和感知相似性方面与基于训练的模型相当，在长期预测方面表现更优。

Conclusion: 搜索式世界模型是训练式世界模型的有效替代方案，在长期动态预测任务中具有优势。

Abstract: World Models have vastly permeated the field of Reinforcement Learning. Their
ability to model the transition dynamics of an environment have greatly
improved sample efficiency in online RL. Among them, the most notorious example
is Dreamer, a model that learns to act in a diverse set of image-based
environments. In this paper, we leverage similarity search and stochastic
representations to approximate a world model without a training procedure. We
establish a comparison with PlaNet, a well-established world model of the
Dreamer family. We evaluate the models on the quality of latent reconstruction
and on the perceived similarity of the reconstructed image, on both next-step
and long horizon dynamics prediction. The results of our study demonstrate that
a search-based world model is comparable to a training based one in both cases.
Notably, our model show stronger performance in long-horizon prediction with
respect to the baseline on a range of visually different environments.

</details>


### [296] [AtomBench: A Benchmark for Generative Atomic Structure Models using GPT, Diffusion, and Flow Architectures](https://arxiv.org/abs/2510.16165)
*Charles Rhys Campbell,Aldo H. Romero,Kamal Choudhary*

Main category: cs.LG

TL;DR: 本文系统比较了三种代表性生成模型（AtomGPT、CDVAE和FlowMM）在材料数据集上的性能，发现CDVAE表现最佳，其次是AtomGPT和FlowMM。


<details>
  <summary>Details</summary>
Motivation: 尽管生成模型在材料发现中日益重要，但缺乏对其性能的严格比较评估。本文旨在填补这一空白，系统评估不同架构在材料数据集上的表现。

Method: 使用三种代表性生成模型（基于Transformer的AtomGPT、晶体扩散变分自编码器CDVAE和黎曼流匹配模型FlowMM），在两个公开超导数据集（JARVIS Supercon 3D和Alexandria DS A/B）上进行训练和重构评估。

Result: 通过计算预测分布与参考分布之间的KL散度以及晶格常数的平均绝对误差，CDVAE表现最优，其次是AtomGPT，FlowMM表现最差。

Conclusion: CDVAE在晶体结构重构任务中表现最佳，为材料生成模型的选择提供了实证依据。所有基准测试代码和模型配置将公开提供。

Abstract: Generative models have become significant assets in the exploration and
identification of new materials, enabling the rapid proposal of candidate
crystal structures that satisfy target properties. Despite the increasing
adoption of diverse architectures, a rigorous comparative evaluation of their
performance on materials datasets is lacking. In this work, we present a
systematic benchmark of three representative generative models- AtomGPT (a
transformer-based model), Crystal Diffusion Variational Autoencoder (CDVAE),
and FlowMM (a Riemannian flow matching model). These models were trained to
reconstruct crystal structures from subsets of two publicly available
superconductivity datasets- JARVIS Supercon 3D and DS A/B from the Alexandria
database. Performance was assessed using the Kullback-Leibler (KL) divergence
between predicted and reference distributions of lattice parameters, as well as
the mean absolute error (MAE) of individual lattice constants. For the computed
KLD and MAE scores, CDVAE performs most favorably, followed by AtomGPT, and
then FlowMM. All benchmarking code and model configurations will be made
publicly available at https://github.com/atomgptlab/atombench_inverse.

</details>


### [297] [Alignment is Localized: A Causal Probe into Preference Layers](https://arxiv.org/abs/2510.16167)
*Archie Chaudhury*

Main category: cs.LG

TL;DR: 本文通过层间因果修补分析语言模型对齐机制，发现对齐过程是空间局部化的，主要发生在中间层激活中，而早期和晚期层基本不受影响。


<details>
  <summary>Details</summary>
Motivation: 虽然基于人类反馈的强化学习(RLHF)已成为语言模型偏好微调的流行方法，但其内部对齐机制仍然不透明，需要系统分析对齐是如何实现的。

Method: 在Llama-3.2-1B模型上应用层间因果修补技术，比较基础模型与其调优版本在人类偏好对上的差异，并使用LASSO回归分析激活距离与奖励增益的关系。

Result: 发现对齐是空间局部化的：中间层激活编码了一个独特的子空间，因果性地决定奖励一致行为，而早期和晚期层基本不受影响；只有少数层具有连接激活距离与奖励增益的非零系数。

Conclusion: 基于人类偏好的语言模型对齐是一个方向性的低秩过程，而非扩散的参数化过程。

Abstract: Reinforcement Learning frameworks, particularly those utilizing human
annotations, have become an increasingly popular method for preference
fine-tuning, where the outputs of a language model are tuned to match a certain
set of behavioral policies or guidelines. Reinforcement Learning through Human
Feedback (RLHF) is perhaps the most popular implementation of such a framework,
particularly for aligning LMs toward safety and human intent. However, the
internal workings of how such alignment is achieved remain largely opaque. In
this work, we systematically analyze preference optimization for language model
alignment by applying layer-wide causal patching between a base model and its
tuned counterpart across human preference pairs. We implement our methodology
on \textit{Llama-3.2-1B}, and find that alignment is spatially localized:
mid-layer activations encode a distinct subspace that causally determines
reward-consistent behavior, while early and late layers remain largely
unaffected. Utilizing LASSO regression, we also find that only a small number
of layers possess non-zero coefficients linking activation distances to reward
gains. Overall, we show that, at least for some language models, alignment from
human-based, preferential tuning is a directional, low rank process, rather
than diffuse and parameteric.

</details>


### [298] [The Formalism-Implementation Gap in Reinforcement Learning Research](https://arxiv.org/abs/2510.16175)
*Pablo Samuel Castro*

Main category: cs.LG

TL;DR: 论文主张强化学习研究应从单纯展示智能体性能转向更关注学习动态的科学理解，并需要更精确地将基准测试映射到数学形式化框架。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习研究过度关注性能展示而忽视学习动态理解，这可能导致在学术基准上过拟合，难以将技术迁移到新问题，也削弱了旨在理解这些技术的研究价值。

Method: 以Arcade Learning Environment (ALE)为例，说明即使被认为是"饱和"的基准仍可有效用于发展对强化学习的理解，并促进RL技术在现实问题中的部署。

Result: 论文提出了强化学习研究方向的转变建议，强调需要更多关注科学理解和基准测试与数学形式化的精确映射。

Conclusion: 强化学习社区应停止仅关注智能体能力展示，而应更多关注强化学习科学的推进和理解，同时需要改进基准测试与基础数学框架的对应关系。

Abstract: The last decade has seen an upswing in interest and adoption of reinforcement
learning (RL) techniques, in large part due to its demonstrated capabilities at
performing certain tasks at "super-human levels". This has incentivized the
community to prioritize research that demonstrates RL agent performance, often
at the expense of research aimed at understanding their learning dynamics.
Performance-focused research runs the risk of overfitting on academic
benchmarks -- thereby rendering them less useful -- which can make it difficult
to transfer proposed techniques to novel problems. Further, it implicitly
diminishes work that does not push the performance-frontier, but aims at
improving our understanding of these techniques. This paper argues two points:
(i) RL research should stop focusing solely on demonstrating agent
capabilities, and focus more on advancing the science and understanding of
reinforcement learning; and (ii) we need to be more precise on how our
benchmarks map to the underlying mathematical formalisms. We use the popular
Arcade Learning Environment (ALE; Bellemare et al., 2013) as an example of a
benchmark that, despite being increasingly considered "saturated", can be
effectively used for developing this understanding, and facilitating the
deployment of RL techniques in impactful real-world problems.

</details>


### [299] [Human-Allied Relational Reinforcement Learning](https://arxiv.org/abs/2510.16188)
*Fateme Golivand Darvishvand,Hikaru Shindo,Sahil Sidheekh,Kristian Kersting,Sriraam Natarajan*

Main category: cs.LG

TL;DR: 本文提出了一种结合关系强化学习与对象中心表示的新框架，能够处理结构化和非结构化数据，并通过主动查询人类专家来增强学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在图像和视频领域取得成功，但忽略了问题的内在结构。关系强化学习虽然能处理结构化问题，但对问题结构有强假设限制。

Method: 将关系强化学习与对象中心表示相结合，通过显式建模策略不确定性，允许系统主动向人类专家查询指导。

Result: 实证评估证明了所提出方法的有效性和效率。

Conclusion: 该框架能够有效处理结构化和非结构化数据，并通过主动学习机制提升学习效果。

Abstract: Reinforcement learning (RL) has experienced a second wind in the past decade.
While incredibly successful in images and videos, these systems still operate
within the realm of propositional tasks ignoring the inherent structure that
exists in the problem. Consequently, relational extensions (RRL) have been
developed for such structured problems that allow for effective generalization
to arbitrary number of objects. However, they inherently make strong
assumptions about the problem structure. We introduce a novel framework that
combines RRL with object-centric representation to handle both structured and
unstructured data. We enhance learning by allowing the system to actively query
the human expert for guidance by explicitly modeling the uncertainty over the
policy. Our empirical evaluation demonstrates the effectiveness and efficiency
of our proposed approach.

</details>


### [300] [Machine Learning for Climate Policy: Understanding Policy Progression in the European Green Deal](https://arxiv.org/abs/2510.16233)
*Patricia West,Michelle WL Wan,Alexander Hepburn,Edwin Simpson,Raul Santos-Rodriguez,Jeffrey N Clark*

Main category: cs.LG

TL;DR: 本研究使用机器学习方法分析欧盟绿色协议中的气候政策进展，比较了不同文本表示方法（TF-IDF、BERT、ClimateBERT）和元数据特征对政策进展预测的影响。


<details>
  <summary>Details</summary>
Motivation: 气候变化需要有效的立法行动来减轻其影响，本研究旨在利用机器学习理解气候政策从宣布到采纳的进展过程。

Method: 收集了165项政策的文本和元数据，使用TF-IDF、BERT和ClimateBERT等文本表示方法，结合元数据特征来预测政策进展状态，并采用可解释AI方法分析影响因素。

Result: 仅使用文本特征时，ClimateBERT表现最佳（RMSE = 0.17, R^2 = 0.29）；结合元数据特征后，BERT表现最优（RMSE = 0.16, R^2 = 0.38）。可解释AI分析显示政策措辞、政党和国家代表性等因素具有重要影响。

Conclusion: 机器学习工具在支持气候政策分析和决策制定方面具有巨大潜力。

Abstract: Climate change demands effective legislative action to mitigate its impacts.
This study explores the application of machine learning (ML) to understand the
progression of climate policy from announcement to adoption, focusing on
policies within the European Green Deal. We present a dataset of 165 policies,
incorporating text and metadata. We aim to predict a policy's progression
status, and compare text representation methods, including TF-IDF, BERT, and
ClimateBERT. Metadata features are included to evaluate the impact on
predictive performance. On text features alone, ClimateBERT outperforms other
approaches (RMSE = 0.17, R^2 = 0.29), while BERT achieves superior performance
with the addition of metadata features (RMSE = 0.16, R^2 = 0.38). Using methods
from explainable AI highlights the influence of factors such as policy wording
and metadata including political party and country representation. These
findings underscore the potential of ML tools in supporting climate policy
analysis and decision-making.

</details>


### [301] [QSVD: Efficient Low-rank Approximation for Unified Query-Key-Value Weight Compression in Low-Precision Vision-Language Models](https://arxiv.org/abs/2510.16292)
*Yutong Wang,Haiyu Wang,Sai Qian Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种结合奇异值分解(SVD)和量化的方法，通过动态调整SVD秩来减少视觉语言模型的KV缓存大小和计算开销，在保持精度的同时显著降低内存使用和计算成本。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型(VLMs)在图像描述和视觉问答等任务中应用广泛，但其高计算成本和内存占用限制了可扩展性和实时应用性。

Method: 1) 对QKV权重矩阵应用奇异值分解来减少KV缓存大小；2) 引入高效的秩分配策略，根据对VLM精度的影响动态调整SVD秩；3) 对VLM权重和激活值应用量化。

Result: 该方法在保持精度的同时显著降低了内存使用和计算成本，相比仅使用量化或SVD的方法，精度提升超过10%，同时硬件成本更低。

Conclusion: 提出的QSVD方法更适合在资源受限设备上进行实时部署，为高效VLM提供了有效的解决方案。

Abstract: Vision-Language Models (VLMs) are integral to tasks such as image captioning
and visual question answering, but their high computational cost, driven by
large memory footprints and processing time, limits their scalability and
real-time applicability. In this work, we propose leveraging Singular-Value
Decomposition (SVD) over the joint query (Q), key (K), and value (V) weight
matrices to reduce KV cache size and computational overhead. We in addition
introduce an efficient rank allocation strategy that dynamically adjusts the
SVD rank based on its impact on VLM accuracy, achieving a significant reduction
in both memory usage and computational cost. Finally, we extend this approach
by applying quantization to both VLM weights and activations, resulting in a
highly efficient VLM. Our method outperforms previous approaches that rely
solely on quantization or SVD by achieving more than $10\%$ accuracy
improvement while consuming less hardware cost, making it better for real-time
deployment on resource-constrained devices. We open source our code at
\href{https://github.com/SAI-Lab-NYU/QSVD}{\texttt{https://github.com/SAI-Lab-NYU/QSVD}}.

</details>


### [302] [Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening](https://arxiv.org/abs/2510.16306)
*Xin Wang,Yu Wang,Yunchao Liu,Jens Meiler,Tyler Derr*

Main category: cs.LG

TL;DR: ScaffAug是一个基于支架的虚拟筛选框架，通过生成式AI增强数据、自训练和重排序模块，解决虚拟筛选中的类别不平衡、结构不平衡和支架多样性问题。


<details>
  <summary>Details</summary>
Motivation: 虚拟筛选面临三大挑战：类别不平衡（活性分子比例低）、活性分子间的结构不平衡（某些支架占主导）、以及需要识别结构多样的活性化合物用于新药开发。

Method: 1) 增强模块：使用图扩散模型基于实际命中化合物的支架生成合成数据；2) 模型无关的自训练模块：安全整合生成的合成数据与原始标记数据；3) 重排序模块：提高推荐分子集中的支架多样性。

Result: 在五个靶标类别上进行的计算实验表明，ScaffAug在多个评估指标上优于现有基线方法，同时通过消融研究验证了各模块的有效性。

Conclusion: 该工作通过利用生成增强、重排序和通用的支架意识，为有效增强虚拟筛选提供了新的视角。

Abstract: Ligand-based virtual screening (VS) is an essential step in drug discovery
that evaluates large chemical libraries to identify compounds that potentially
bind to a therapeutic target. However, VS faces three major challenges: class
imbalance due to the low active rate, structural imbalance among active
molecules where certain scaffolds dominate, and the need to identify
structurally diverse active compounds for novel drug development. We introduce
ScaffAug, a scaffold-aware VS framework that addresses these challenges through
three modules. The augmentation module first generates synthetic data
conditioned on scaffolds of actual hits using generative AI, specifically a
graph diffusion model. This helps mitigate the class imbalance and furthermore
the structural imbalance, due to our proposed scaffold-aware sampling
algorithm, designed to produce more samples for active molecules with
underrepresented scaffolds. A model-agnostic self-training module is then used
to safely integrate the generated synthetic data from our augmentation module
with the original labeled data. Lastly, we introduce a reranking module that
improves VS by enhancing scaffold diversity in the top recommended set of
molecules, while still maintaining and even enhancing the overall general
performance of identifying novel, active compounds. We conduct comprehensive
computational experiments across five target classes, comparing ScaffAug
against existing baseline methods by reporting the performance of multiple
evaluation metrics and performing ablation studies on ScaffAug. Overall, this
work introduces novel perspectives on effectively enhancing VS by leveraging
generative augmentations, reranking, and general scaffold-awareness.

</details>


### [303] [Colliding with Adversaries at ECML-PKDD 2025 Adversarial Attack Competition 1st Prize Solution](https://arxiv.org/abs/2510.16440)
*Dimitris Stefanopoulos,Andreas Voskou*

Main category: cs.LG

TL;DR: 本文提出了ECML-PKDD 2025高能物理发现鲁棒学习挑战赛中Task 1的获胜解决方案，采用多轮梯度攻击策略，在最小化扰动的同时最大化分类错误率。


<details>
  <summary>Details</summary>
Motivation: 挑战赛要求设计对抗攻击，在最小化扰动的同时最大化模型误分类，测试模型在高能物理发现中的鲁棒性。

Method: 使用多轮梯度攻击策略，利用模型的可微分结构，结合随机初始化和样本混合技术提升攻击效果。

Result: 攻击在扰动大小和欺骗成功率方面取得最佳结果，在竞赛中获得第一名。

Conclusion: 提出的多轮梯度攻击策略在对抗攻击任务中表现优异，证明了该方法在高能物理发现鲁棒学习中的有效性。

Abstract: This report presents the winning solution for Task 1 of Colliding with
Adversaries: A Challenge on Robust Learning in High Energy Physics Discovery at
ECML-PKDD 2025. The task required designing an adversarial attack against a
provided classification model that maximizes misclassification while minimizing
perturbations. Our approach employs a multi-round gradient-based strategy that
leverages the differentiable structure of the model, augmented with random
initialization and sample-mixing techniques to enhance effectiveness. The
resulting attack achieved the best results in perturbation size and fooling
success rate, securing first place in the competition.

</details>


### [304] [Colliding with Adversaries at ECML-PKDD 2025 Model Robustness Competition 1st Prize Solution](https://arxiv.org/abs/2510.16443)
*Dimitris Stefanopoulos,Andreas Voskou*

Main category: cs.LG

TL;DR: 本文提出了ECML-PKDD 2025挑战赛中Task 2的获胜解决方案，通过数据生成和鲁棒模型训练两阶段方法，在对抗性攻击下实现了80%的混合准确率。


<details>
  <summary>Details</summary>
Motivation: 设计能够同时处理干净数据和对抗性数据的鲁棒ANN模型，以应对高能物理发现中的对抗攻击挑战。

Method: 采用两阶段方法：第一阶段使用基于RDSA的自定义方法生成1500万人工训练样本；第二阶段构建包含特征嵌入块（同类型特征共享权重）和密集融合尾部的鲁棒架构。

Result: 在对抗性数据集上训练该架构获得了80%的混合准确率，比第二名解决方案高出两个百分点。

Conclusion: 提出的两阶段方法在对抗性攻击环境下表现优异，验证了数据增强和专门架构设计在提升模型鲁棒性方面的有效性。

Abstract: This report presents the winning solution for Task 2 of Colliding with
Adversaries: A Challenge on Robust Learning in High Energy Physics Discovery at
ECML-PKDD 2025. The goal of the challenge was to design and train a robust
ANN-based model capable of achieving high accuracy in a binary classification
task on both clean and adversarial data generated with the Random Distribution
Shuffle Attack (RDSA). Our solution consists of two components: a data
generation phase and a robust model training phase. In the first phase, we
produced 15 million artificial training samples using a custom methodology
derived from Random Distribution Shuffle Attack (RDSA). In the second phase, we
introduced a robust architecture comprising (i)a Feature Embedding Block with
shared weights among features of the same type and (ii)a Dense Fusion Tail
responsible for the final prediction. Training this architecture on our
adversarial dataset achieved a mixed accuracy score of 80\%, exceeding the
second-place solution by two percentage points.

</details>


### [305] [Input Domain Aware MoE: Decoupling Routing Decisions from Task Optimization in Mixture of Experts](https://arxiv.org/abs/2510.16448)
*Yongxiang Hua,Haoyu Cao,Zhou Tao,Bocheng Li,Zihao Wu,Chaohu Liu,Linli Xu*

Main category: cs.LG

TL;DR: 提出Input Domain Aware MoE路由框架，通过概率混合模型更好地划分输入空间，解决现有稀疏专家混合模型在专家专业化和计算平衡之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于相似性评分的路由机制难以有效捕捉输入底层结构，导致专家专业化和计算平衡之间的权衡，限制了模型的可扩展性和性能。

Method: 使用概率混合模型建模路由概率，将路由概率表示为分布的混合，使专家形成清晰的专业化边界并实现均衡利用。路由机制独立于任务特定目标进行训练。

Result: 在视觉语言任务上的实证结果表明，该方法持续优于现有稀疏专家混合方法，实现了更高的任务性能和更好的专家利用平衡。

Conclusion: 提出的Input Domain Aware MoE框架通过概率混合模型改进了路由机制，在保持计算效率的同时提升了专家专业化和利用平衡，为大规模视觉语言模型的扩展提供了有效解决方案。

Abstract: Sparse Mixture of Experts (sMoE) has become a pivotal approach for scaling
large vision-language models, offering substantial capacity while maintaining
computational efficiency through dynamic, sparse activation of experts.
However, existing routing mechanisms, typically based on similarity scoring,
struggle to effectively capture the underlying input structure. This limitation
leads to a trade-off between expert specialization and balanced computation,
hindering both scalability and performance. We propose Input Domain Aware MoE,
a novel routing framework that leverages a probabilistic mixture model to
better partition the input space. By modeling routing probabilities as a
mixture of distributions, our method enables experts to develop clear
specialization boundaries while achieving balanced utilization. Unlike
conventional approaches, our routing mechanism is trained independently of
task-specific objectives, allowing for stable optimization and decisive expert
assignments. Empirical results on vision-language tasks demonstrate that our
method consistently outperforms existing sMoE approaches, achieving higher task
performance and improved expert utilization balance.

</details>


### [306] [SCALAR: Self-Calibrating Adaptive Latent Attention Representation Learning](https://arxiv.org/abs/2510.16474)
*Farwa Abbas,Hussain Ahmad,Claudia Szabo*

Main category: cs.LG

TL;DR: 提出了一种新的自适应核注意力机制，通过分别处理不同特征组来增强高维异构数据的预测性能，解决了传统PLS方法在建模复杂非线性关系和跨尺度交互方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统投影到潜在结构(PLS)方法在处理高维异构数据时面临挑战，难以建模复杂的非线性关系、多尺度同时交互，且静态特征权重限制了上下文适应性。

Method: 引入自适应核注意力机制，分别处理不同特征组后进行集成，既能捕捉局部模式又能保持全局关系。

Result: 实验结果显示，与最先进方法相比，在多个数据集上性能指标均有显著提升。

Conclusion: 所提出的方法通过新颖的架构创新有效解决了高维异构数据建模中的关键挑战，显著提升了预测性能。

Abstract: High-dimensional, heterogeneous data with complex feature interactions pose
significant challenges for traditional predictive modeling approaches. While
Projection to Latent Structures (PLS) remains a popular technique, it struggles
to model complex non-linear relationships, especially in multivariate systems
with high-dimensional correlation structures. This challenge is further
compounded by simultaneous interactions across multiple scales, where local
processing fails to capture crossgroup dependencies. Additionally, static
feature weighting limits adaptability to contextual variations, as it ignores
sample-specific relevance. To address these limitations, we propose a novel
method that enhances predictive performance through novel architectural
innovations. Our architecture introduces an adaptive kernel-based attention
mechanism that processes distinct feature groups separately before integration,
enabling capture of local patterns while preserving global relationships.
Experimental results show substantial improvements in performance metrics,
compared to the state-of-the-art methods across diverse datasets.

</details>


### [307] [LANPO: Bootstrapping Language and Numerical Feedback for Reinforcement Learning in LLMs](https://arxiv.org/abs/2510.16552)
*Ang Li,Yifei Wang,Zhihang Yuan,Stefanie Jegelka,Yisen Wang*

Main category: cs.LG

TL;DR: LANPO是一个新的强化学习框架，通过分离语言反馈和数值奖励的作用来解决LLM训练中的样本效率问题，语言反馈指导探索，数值奖励驱动优化。


<details>
  <summary>Details</summary>
Motivation: 传统LLM强化学习依赖标量奖励，丢弃了rollout中的宝贵文本信息，导致样本效率低下。同时，在线经验集成存在信息泄露和无关上下文导致行为崩溃的悖论。

Method: LANPO构建动态经验池，引入两个原则：奖励无关反思用于样本内安全自校正，相关抽象从样本间经验中提炼可泛化教训。

Result: 在数学推理基准测试中，7B和14B模型使用LANPO显著优于使用GRPO训练的强基线模型，在测试准确率上表现更好。

Conclusion: LANPO为将历史经验集成到LLM强化学习循环中提供了稳健方法，创造了更有效和数据高效的学习智能体。

Abstract: Reinforcement learning in large language models (LLMs) often relies on scalar
rewards, a practice that discards valuable textual rationale buried in the
rollouts, forcing the model to explore \textit{de novo} with each attempt and
hindering sample efficiency. While LLMs can uniquely learn from language
feedback provided in-context, naively integrating on-line experiences into RL
training presents a paradox: feedback from the same problem risks information
leakage and memorization, while feedback from different problems often leads to
behavior collapse due to irrelevant context. To resolve this tension, we
propose \textbf{Language-And-Numerical Policy Optimization (LANPO)}, a
framework that cleanly separates the roles of feedback: language guides
exploration, while numerical rewards drive optimization. LANPO builds a dynamic
experience pool from past trials and introduces two principles to ensure
feedback is effective: \emph{Reward-Agnostic Reflection} for safe intra-sample
self-correction and \emph{Relevant Abstraction} to distill generalizable
lessons from inter-sample experiences. Across mathematical reasoning
benchmarks, LANPO enables 7B and 14B models to significantly outperform strong
baselines trained with GRPO in test accuracy. Our work provides a robust method
for integrating historical experiences into the LLM RL loop, creating more
effective and data-efficient learning agents.

</details>


### [308] [Atom-anchored LLMs speak Chemistry: A Retrosynthesis Demonstration](https://arxiv.org/abs/2510.16590)
*Alan Kai Hassen,Andrius Bernatavicius,Antonius P. A. Janssen,Mike Preuss,Gerard J. P. van Westen,Djork-Arné Clevert*

Main category: cs.LG

TL;DR: 提出了一种无需标注数据的分子推理框架，利用大语言模型通过原子标识符进行链式思维推理，在单步逆合成任务中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 化学领域机器学习应用受限于标注数据的稀缺性和昂贵性，传统监督方法受限，需要开发不依赖标注数据的分子推理方法。

Method: 使用通用大语言模型，通过原子标识符将链式思维推理锚定到分子结构上，采用一次性任务识别相关片段和化学标签，可选地使用少样本任务预测化学转化。

Result: 在学术基准和专家验证的药物发现分子上，LLMs在识别化学合理反应位点（≥90%）、命名反应类别（≥40%）和最终反应物（≥74%）方面取得高成功率。

Conclusion: 该框架不仅解决了复杂化学任务，还提供了一种通过将化学知识映射到分子结构来生成理论基础的合成数据集的方法，从而解决数据稀缺问题。

Abstract: Applications of machine learning in chemistry are often limited by the
scarcity and expense of labeled data, restricting traditional supervised
methods. In this work, we introduce a framework for molecular reasoning using
general-purpose Large Language Models (LLMs) that operates without requiring
labeled training data. Our method anchors chain-of-thought reasoning to the
molecular structure by using unique atomic identifiers. First, the LLM performs
a one-shot task to identify relevant fragments and their associated chemical
labels or transformation classes. In an optional second step, this
position-aware information is used in a few-shot task with provided class
examples to predict the chemical transformation. We apply our framework to
single-step retrosynthesis, a task where LLMs have previously underperformed.
Across academic benchmarks and expert-validated drug discovery molecules, our
work enables LLMs to achieve high success rates in identifying chemically
plausible reaction sites ($\geq90\%$), named reaction classes ($\geq40\%$), and
final reactants ($\geq74\%$). Beyond solving complex chemical tasks, our work
also provides a method to generate theoretically grounded synthetic datasets by
mapping chemical knowledge onto the molecular structure and thereby addressing
data scarcity.

</details>


### [309] [Prior Makes It Possible: From Sublinear Graph Algorithms to LLM Test-Time Methods](https://arxiv.org/abs/2510.16609)
*Avrim Blum,Daniel Hsu,Cyrus Rashtchian,Donya Saless*

Main category: cs.LG

TL;DR: 该论文研究了测试时增强（如RAG或工具使用）中模型参数知识与外部检索信息之间的关系，将多步推理建模为知识图上的连通性问题，揭示了知识密度阈值对增强效率的关键影响。


<details>
  <summary>Details</summary>
Motivation: 理解测试时增强中模型参数知识与外部检索信息之间的理论关系，特别是确定在少量增强步骤下回答查询所需的预训练知识量，这是实际应用中的重要需求。

Method: 将多步推理建模为知识图上的s-t连通性问题，将模型的预训练参数知识表示为部分且可能有噪声的子图，将增强视为查询真实边来扩展模型知识，并分析给定部分先验知识时生成准确答案所需的增强步骤数。

Result: 发现了一个相变现象：如果先验知识图在n个顶点上断开成小分量，则通过增强寻找路径效率低下，需要Ω(√n)次查询；而一旦正确知识的密度超过阈值形成巨分量，就能以期望常数次查询找到路径。

Conclusion: 测试时增强的效率取决于先验知识图的结构特性，存在一个关键的知识密度阈值，超过该阈值后增强过程变得高效，这为理解模型参数知识与外部检索的交互提供了理论依据。

Abstract: Test-time augmentation, such as Retrieval-Augmented Generation (RAG) or tool
use, critically depends on an interplay between a model's parametric knowledge
and externally retrieved information. However, the theoretical underpinnings of
this relationship remain poorly understood. Specifically, it is not clear how
much pre-training knowledge is required to answer queries with a small number
of augmentation steps, which is a desirable property in practice. To address
this question, we formulate multi-step reasoning as an $s$-$t$ connectivity
problem on a knowledge graph. We represent a model's pre-training parametric
knowledge as a partial, potentially noisy subgraph. We view augmentation as
querying an oracle for true edges that augment the model's knowledge. Then, we
characterize the necessary and sufficient number of augmentation steps for the
model to generate an accurate answer given partial prior knowledge. One key
result shows a phase transition: if the prior knowledge graph over $n$ vertices
is disconnected into small components, then finding a path via augmentation is
inefficient and requires $\Omega(\sqrt{n})$ queries. On the other hand, once
the density of correct knowledge surpasses a threshold, forming a giant
component, we can find paths with an expected constant number of queries.

</details>


### [310] [Active Target Discovery under Uninformative Prior: The Power of Permanent and Transient Memory](https://arxiv.org/abs/2510.16676)
*Anindya Sarkar,Binglin Ji,Yevgeniy Vorobeychik*

Main category: cs.LG

TL;DR: 提出了一种在无信息先验条件下实现有效主动目标发现的新方法，该方法具有理论原理和神经科学灵感，保证先验估计的单调改进，在物种分布建模和遥感等领域显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 在医学成像、环境监测等数据获取成本高的领域，基于先验观察的战略采样至关重要。然而，当数据极其有限或采样成本高时，现有基于生成模型的方法难以泛化，因此需要开发在无信息先验条件下仍能有效工作的主动目标发现方法。

Method: 提出了一种理论原理驱动的框架，受神经科学启发设计，具有内在可解释性。该方法保证每个新观察都能单调改进先验估计，从而实现越来越准确的采样。

Result: 通过跨多个领域的综合实验和消融研究，包括物种分布建模和遥感，证明该方法显著优于基线方法。

Conclusion: 该方法在复杂现实场景中确保了稳健的探索和适应性，为数据稀缺或采样成本高的领域提供了有效的主动目标发现解决方案。

Abstract: In many scientific and engineering fields, where acquiring high-quality data
is expensive--such as medical imaging, environmental monitoring, and remote
sensing--strategic sampling of unobserved regions based on prior observations
is crucial for maximizing discovery rates within a constrained budget. The rise
of powerful generative models, such as diffusion models, has enabled active
target discovery in partially observable environments by leveraging learned
priors--probabilistic representations that capture underlying structure from
data. With guidance from sequentially gathered task-specific observations,
these models can progressively refine exploration and efficiently direct
queries toward promising regions. However, in domains where learning a strong
prior is infeasible due to extremely limited data or high sampling cost (such
as rare species discovery, diagnostics for emerging diseases, etc.), these
methods struggle to generalize. To overcome this limitation, we propose a novel
approach that enables effective active target discovery even in settings with
uninformative priors, ensuring robust exploration and adaptability in complex
real-world scenarios. Our framework is theoretically principled and draws
inspiration from neuroscience to guide its design. Unlike black-box policies,
our approach is inherently interpretable, providing clear insights into
decision-making. Furthermore, it guarantees a strong, monotonic improvement in
prior estimates with each new observation, leading to increasingly accurate
sampling and reinforcing both reliability and adaptability in dynamic settings.
Through comprehensive experiments and ablation studies across various domains,
including species distribution modeling and remote sensing, we demonstrate that
our method substantially outperforms baseline approaches.

</details>


### [311] [Renaissance of RNNs in Streaming Clinical Time Series: Compact Recurrence Remains Competitive with Transformers](https://arxiv.org/abs/2510.16677)
*Ran Tong,Jiaqi Liu,Su Liu,Xin Hu,Lanruo Wang*

Main category: cs.LG

TL;DR: 该研究在MIT-BIH心律失常数据库上建立了一个紧凑的严格因果流式临床时间序列基准，比较了GRU-D和Transformer模型在心动过速风险预测和心率预测两个任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估在纵向监测中不同模型的选择对任务性能的影响，特别是在紧凑、严格因果的流式临床时间序列设置下。

Method: 使用MIT-BIH心律失常数据库的心率数据，研究两个任务：近端心动过速风险预测（未来10秒）和一步心率预测。比较GRU-D（RNN）和Transformer模型，采用记录级非重叠分割，匹配训练预算，并与强非学习基线对比。评估采用校准感知分类和适当预测，使用温度缩放和分组自举置信区间。

Result: 在MIT-BIH数据库上，GRU-D在心动过速风险预测上略优于Transformer，而Transformer在预测误差上明显低于GRU-D和持续性模型。

Conclusion: 在纵向监测中，模型选择是任务依赖的：紧凑RNN在短时域风险评分上保持竞争力，而紧凑Transformer在点预测上提供更清晰的增益。

Abstract: We present a compact, strictly causal benchmark for streaming clinical time
series on the MIT--BIH Arrhythmia Database using per-second heart rate. Two
tasks are studied under record-level, non-overlapping splits: near-term
tachycardia risk (next ten seconds) and one-step heart rate forecasting. We
compare a GRU-D (RNN) and a Transformer under matched training budgets against
strong non-learned baselines. Evaluation is calibration-aware for
classification and proper for forecasting, with temperature scaling and grouped
bootstrap confidence intervals. On MIT-BIH, GRU-D slightly surpasses the
Transformer for tachycardia risk, while the Transformer clearly lowers
forecasting error relative to GRU-D and persistence. Our results show that, in
longitudinal monitoring, model choice is task-dependent: compact RNNs remain
competitive for short-horizon risk scoring, whereas compact Transformers
deliver clearer gains for point forecasting.

</details>


### [312] [High-Dimensional Privacy-Utility Dynamics of Noisy Stochastic Gradient Descent on Least Squares](https://arxiv.org/abs/2510.16687)
*Shurong Lin,Eric D. Kolaczyk,Adam Smith,Elliot Paquette*

Main category: cs.LG

TL;DR: 本文使用扩散方法精确分析噪声SGD，提供连续时间视角来捕捉高维环境下的统计风险演变和隐私损失动态，并研究了一种无需梯度敏感性显式知识的噪声SGD变体。


<details>
  <summary>Details</summary>
Motivation: 优化与隐私之间的相互作用已成为隐私保护机器学习的核心主题。噪声随机梯度下降(SGD)已成为基石算法，但现有工作主要提供统计风险和隐私损失的各种界限，而过程的精确行为仍不清楚，特别是在高维设置中。

Method: 利用扩散方法精确分析噪声SGD，提供连续时间视角，关注带有ℓ2正则化的最小二乘问题，研究无需梯度敏感性显式知识的噪声SGD变体。

Result: 该方法能够精确捕捉高维环境下统计风险演变和隐私损失动态，提供对噪声SGD过程的深入理解。

Conclusion: 扩散方法为分析噪声SGD提供了精确的连续时间视角，能够更好地理解高维设置下的统计风险和隐私损失动态，并提出了无需梯度敏感性显式知识的实用变体。

Abstract: The interplay between optimization and privacy has become a central theme in
privacy-preserving machine learning. Noisy stochastic gradient descent (SGD)
has emerged as a cornerstone algorithm, particularly in large-scale settings.
These variants of gradient methods inject carefully calibrated noise into each
update to achieve differential privacy, the gold standard notion of rigorous
privacy guarantees. Prior work primarily provides various bounds on statistical
risk and privacy loss for noisy SGD, yet the \textit{exact} behavior of the
process remains unclear, particularly in high-dimensional settings. This work
leverages a diffusion approach to analyze noisy SGD precisely, providing a
continuous-time perspective that captures both statistical risk evolution and
privacy loss dynamics in high dimensions. Moreover, we study a variant of noisy
SGD that does not require explicit knowledge of gradient sensitivity, unlike
existing work that assumes or enforces sensitivity through gradient clipping.
Specifically, we focus on the least squares problem with $\ell_2$
regularization.

</details>


### [313] [Resolution-Aware Retrieval Augmented Zero-Shot Forecasting](https://arxiv.org/abs/2510.16695)
*Iman Deznabi,Peeyush Kumar,Madalina Fiterau*

Main category: cs.LG

TL;DR: 提出了一种分辨率感知的检索增强预测模型，通过利用空间相关性和时间频率特征来提高零样本预测的准确性。模型将信号分解为不同频率分量，低频分量依赖更广泛的空间上下文，高频分量关注局部影响，从而动态检索相关数据并适应新位置。


<details>
  <summary>Details</summary>
Motivation: 零样本预测旨在预测没有直接历史数据的先前未见条件下的结果，这对传统预测方法构成了重大挑战。需要开发能够有效处理空间相关性和时间频率特征的新方法。

Method: 采用分辨率感知检索增强预测模型，通过信号频率分解，低频分量使用更广泛的空间上下文，高频分量关注局部影响，实现动态数据检索和适应新位置。

Result: 在微气候预测应用中，该模型显著优于传统预测方法、数值天气预报模型和现代基础时间序列模型，在ERA5数据集上比HRRR的MSE降低71%，比Chronos降低34%。

Conclusion: 检索增强和分辨率感知策略在零样本预测中非常有效，为微气候建模及其他领域提供了可扩展且数据高效的解决方案。

Abstract: Zero-shot forecasting aims to predict outcomes for previously unseen
conditions without direct historical data, posing a significant challenge for
traditional forecasting methods. We introduce a Resolution-Aware
Retrieval-Augmented Forecasting model that enhances predictive accuracy by
leveraging spatial correlations and temporal frequency characteristics. By
decomposing signals into different frequency components, our model employs
resolution-aware retrieval, where lower-frequency components rely on broader
spatial context, while higher-frequency components focus on local influences.
This allows the model to dynamically retrieve relevant data and adapt to new
locations with minimal historical context.
  Applied to microclimate forecasting, our model significantly outperforms
traditional forecasting methods, numerical weather prediction models, and
modern foundation time series models, achieving 71% lower MSE than HRRR and 34%
lower MSE than Chronos on the ERA5 dataset.
  Our results highlight the effectiveness of retrieval-augmented and
resolution-aware strategies, offering a scalable and data-efficient solution
for zero-shot forecasting in microclimate modeling and beyond.

</details>


### [314] [On the Granularity of Causal Effect Identifiability](https://arxiv.org/abs/2510.16703)
*Yizuo Chen,Adnan Darwiche*

Main category: cs.LG

TL;DR: 本文探讨了基于状态的因果效应可识别性，证明在某些情况下即使变量级因果效应不可识别，状态级因果效应仍可识别，这需要额外的背景特定独立性和条件函数依赖等知识。


<details>
  <summary>Details</summary>
Motivation: 传统因果效应可识别性定义基于变量层面，但实际应用中可能需要更细粒度的状态级因果效应分析。本文旨在研究状态级因果效应的可识别性问题。

Method: 通过理论分析，比较变量级和状态级因果效应的可识别性条件，探讨背景特定独立性、条件函数依赖等额外知识对可识别性的影响。

Result: 研究发现状态级因果效应在变量级因果效应不可识别时仍可能可识别，这种分离仅在有额外知识时发生。约束变量状态的知识单独使用时不能改善可识别性，但与其他知识结合时可同时改善变量级和状态级可识别性。

Conclusion: 现有变量级框架可能错过某些可从观测数据估计的因果效应，状态级分析为因果推断提供了更精细的视角，有助于发现更多可识别的因果效应。

Abstract: The classical notion of causal effect identifiability is defined in terms of
treatment and outcome variables. In this note, we consider the identifiability
of state-based causal effects: how an intervention on a particular state of
treatment variables affects a particular state of outcome variables. We
demonstrate that state-based causal effects may be identifiable even when
variable-based causal effects may not. Moreover, we show that this separation
occurs only when additional knowledge -- such as context-specific
independencies and conditional functional dependencies -- is available. We
further examine knowledge that constrains the states of variables, and show
that such knowledge does not improve identifiability on its own but can improve
both variable-based and state-based identifiability when combined with other
knowledge such as context-specific independencies. Our findings highlight
situations where causal effects of interest may be estimable from observational
data and this identifiability may be missed by existing variable-based
frameworks.

</details>


### [315] [Zero-Shot Performance Prediction for Probabilistic Scaling Laws](https://arxiv.org/abs/2510.16743)
*Viktoria Schram,Markus Hiller,Daniel Beck,Trevor Cohn*

Main category: cs.LG

TL;DR: 该论文提出了一种基于多任务学习和分层高斯过程的方法来预测NLP模型的学习曲线，通过建模任务间相关性支持零样本预测，并利用主动学习策略降低预测不确定性。


<details>
  <summary>Details</summary>
Motivation: 预测NLP模型的学习曲线可以帮助在满足特定性能目标的同时减少计算开销和数据集获取成本，实现更明智的决策制定。

Method: 将学习曲线预测任务构建为多任务学习问题，使用潜在变量多输出高斯过程建模任务间相关性和分层依赖关系，支持零样本预测，并应用主动学习策略来减少预测不确定性。

Result: 该方法能够在三个小规模NLP数据集上（包含最多30条学习曲线）有效预测学习曲线，验证了框架在nanoGPT、mBART、Transformer和M2M100等模型上的适用性。

Conclusion: 该方法能够以较低成本开发概率性扩展规律，通过主动查询学习曲线可以提供接近真实扩展规律的预测，为NLP模型的性能预测提供了有效解决方案。

Abstract: The prediction of learning curves for Natural Language Processing (NLP)
models enables informed decision-making to meet specific performance
objectives, while reducing computational overhead and lowering the costs
associated with dataset acquisition and curation. In this work, we formulate
the prediction task as a multitask learning problem, where each task's data is
modelled as being organized within a two-layer hierarchy. To model the shared
information and dependencies across tasks and hierarchical levels, we employ
latent variable multi-output Gaussian Processes, enabling to account for task
correlations and supporting zero-shot prediction of learning curves (LCs). We
demonstrate that this approach facilitates the development of probabilistic
scaling laws at lower costs. Applying an active learning strategy, LCs can be
queried to reduce predictive uncertainty and provide predictions close to
ground truth scaling laws. We validate our framework on three small-scale NLP
datasets with up to $30$ LCs. These are obtained from nanoGPT models, from
bilingual translation using mBART and Transformer models, and from multilingual
translation using M2M100 models of varying sizes.

</details>


### [316] [SAMOSA: Sharpness Aware Minimization for Open Set Active learning](https://arxiv.org/abs/2510.16757)
*Young In Kim,Andrea Agiollo,Rajiv Khanna*

Main category: cs.LG

TL;DR: SAMOSA是一种用于开放集主动学习的新方法，通过基于样本典型性的查询策略，有效选择信息丰富的样本，在多个数据集上实现了3%的准确率提升且无计算开销。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习需要大量数据收集，但标注成本高昂。为了减轻这一负担，开放集主动学习方法旨在从未标记数据池中选择信息丰富的样本，这些数据可能包含不相关或未知类别。

Method: 基于关于数据典型性对传统SGD和SAM泛化特性影响的理论发现，SAMOSA根据样本的典型性主动查询样本。该方法有效识别嵌入流形中接近模型决策边界的非典型样本。

Result: 广泛的实验表明，SAMOSA在多个数据集上比现有技术实现了高达3%的准确率提升，同时没有引入计算开销。

Conclusion: SAMOSA是一种有效的开放集主动学习查询算法，能够优先选择对目标类别高度信息丰富且有助于区分目标类别和不想要类别的样本。

Abstract: Modern machine learning solutions require extensive data collection where
labeling remains costly. To reduce this burden, open set active learning
approaches aim to select informative samples from a large pool of unlabeled
data that includes irrelevant or unknown classes. In this context, we propose
Sharpness Aware Minimization for Open Set Active Learning (SAMOSA) as an
effective querying algorithm. Building on theoretical findings concerning the
impact of data typicality on the generalization properties of traditional
stochastic gradient descent (SGD) and sharpness-aware minimization (SAM),
SAMOSA actively queries samples based on their typicality. SAMOSA effectively
identifies atypical samples that belong to regions of the embedding manifold
close to the model decision boundaries. Therefore, SAMOSA prioritizes the
samples that are (i) highly informative for the targeted classes, and (ii)
useful for distinguishing between targeted and unwanted classes. Extensive
experiments show that SAMOSA achieves up to 3% accuracy improvement over the
state of the art across several datasets, while not introducing computational
overhead. The source code of our experiments is available at:
https://anonymous.4open.science/r/samosa-DAF4

</details>


### [317] [3D-GSRD: 3D Molecular Graph Auto-Encoder with Selective Re-mask Decoding](https://arxiv.org/abs/2510.16780)
*Chang Wu,Zhiyuan Liu,Wen Shu,Liang Wang,Yanchen Luo,Wenqiang Lei,Yatao Bian,Junfeng Fang,Xiang Wang*

Main category: cs.LG

TL;DR: 3D-GSRD提出了一种具有选择性重掩码解码的3D分子图自编码器，解决了从2D到3D掩码图建模的挑战，在MD17基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 将掩码图建模从2D扩展到3D面临两个冲突挑战：避免2D结构泄漏到解码器，同时为重构重掩码原子提供足够的2D上下文。

Method: 提出选择性重掩码解码(SRD)，仅从编码器表示中重掩码3D相关信息，同时保留2D图结构；结合3D关系变换器编码器和结构无关解码器。

Result: 在广泛使用的MD17分子性质预测基准测试中，8个目标中有7个达到了新的最先进性能。

Conclusion: 3D-GSRD通过选择性重掩码解码和结构无关解码器的协同集成，增强了编码器在分子表示学习中的作用，实现了优异的性能。

Abstract: Masked graph modeling (MGM) is a promising approach for molecular
representation learning (MRL).However, extending the success of re-mask
decoding from 2D to 3D MGM is non-trivial, primarily due to two conflicting
challenges: avoiding 2D structure leakage to the decoder, while still providing
sufficient 2D context for reconstructing re-masked atoms.To address these
challenges, we propose 3D-GSRD: a 3D Molecular Graph Auto-Encoder with
Selective Re-mask Decoding. The core innovation of 3D-GSRD lies in its
Selective Re-mask Decoding(SRD), which re-masks only 3D-relevant information
from encoder representations while preserving the 2D graph structures.This SRD
is synergistically integrated with a 3D Relational-Transformer(3D-ReTrans)
encoder alongside a structure-independent decoder. We analyze that SRD,
combined with the structure-independent decoder, enhances the encoder's role in
MRL. Extensive experiments show that 3D-GSRD achieves strong downstream
performance, setting a new state-of-the-art on 7 out of 8 targets in the widely
used MD17 molecular property prediction benchmark. The code is released at
https://github.com/WuChang0124/3D-GSRD.

</details>


### [318] [Mixed-Precision Quantization for Language Models: Techniques and Prospects](https://arxiv.org/abs/2510.16805)
*Mariam Rakka,Marios Fournarakis,Olga Krestinskaya,Jinane Bazzi,Khaled N. Salama,Fadi Kurdahi,Ahmed M. Eltawil,Mohammed E. Fouda*

Main category: cs.LG

TL;DR: 本文是关于语言模型混合精度量化(MXPLMs)的综述，探讨了如何在保持准确性的同时通过选择性分配精度来减少模型的计算、内存和能源需求。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型规模的快速扩展，其训练和部署的计算、内存和能源需求变得不可持续，需要有效的压缩技术来缓解这些问题。

Method: 首先回顾量化基础，包括均匀和非均匀量化器、量化粒度和后训练量化方法；然后根据位分配策略和权重、激活、键值缓存的精度配置对MXPLM框架进行分类比较；最后与传统DNN混合精度量化方法进行对比。

Result: 通过比较分析突出了不同方法在困惑度、零样本任务性能和部署权衡方面的差异，识别了在LM设置中可转移和面临挑战的策略。

Conclusion: 总结了开放问题和未来方向，包括硬件感知设计、激活量化和十亿参数模型的可扩展优化方法，为理解大规模语言模型混合精度量化的当前格局和研究前景提供了参考。

Abstract: The rapid scaling of language models (LMs) has resulted in unprecedented
computational, memory, and energy requirements, making their training and
deployment increasingly unsustainable. Quantization has emerged as an essential
compression technique to reduce model size, alleviate memory bottlenecks, and
accelerate inference. However, while uniform low-bit quantization (e.g., INT8,
INT4) provides significant efficiency gains, it can degrade accuracy in
sensitive components of transformer-based LMs. Mixed-precision quantization
offers a promising alternative by selectively allocating precision across
layers or within tensors to balance efficiency and accuracy. This survey
provides a comprehensive overview of Mixed-Precision quantization frameworks
for LMs (MXPLMs). We first review quantization fundamentals, including uniform
and non-uniform quantizers, quantization granularity, and methods widely used
in post-training quantization. We then categorize and compare recent MXPLM
frameworks according to their bit allocation strategies and precision
configurations across weights, activations, and key-value caches. A comparative
analysis highlights differences in perplexity, zero-shot task performance, and
deployment trade-offs. Furthermore, we contrast MXPLMs with earlier
mixed-precision quantization methods for deep neural networks, identifying
strategies that transfer and those that face challenges in the LM setting.
Finally, we summarize open issues and future directions, including
hardware-aware design, activation quantization, and scalable optimization
methods for billion-parameter models. By consolidating recent advances, this
work serves as a reference for understanding the current landscape and research
prospects of mixed-precision quantization for large-scale language models.

</details>


### [319] [Computational Budget Should Be Considered in Data Selection](https://arxiv.org/abs/2510.16806)
*Weilin Wan,Weizhong Zhang,Cheng Jin*

Main category: cs.LG

TL;DR: 提出了一种计算预算感知的数据选择方法（CADS），通过双层优化框架将计算预算约束整合到数据选择策略中，显著提升了训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法忽略了计算预算约束，而实证研究表明不同预算下数据选择策略需求不同，因此需要将计算预算作为数据选择策略的核心要素。

Method: 提出CADS方法，采用双层优化框架：内层在计算预算约束下用选定数据子集训练模型，外层基于模型评估优化数据选择。通过概率重参数化策略和Hessian-free策略梯度估计器解决Hessian矩阵估计问题，将内层优化转化为外层目标中的惩罚项以提高效率。

Result: 在视觉和语言基准测试中，该方法比基线方法性能提升高达14.42%。

Conclusion: 计算预算应作为数据选择策略的核心要素，CADS方法通过双层优化框架有效解决了计算预算约束下的数据选择问题，显著提升了训练效率。

Abstract: Data selection improves computational efficiency by choosing informative
subsets of training samples. However, existing methods ignore the compute
budget, treating data selection and importance evaluation independently of
compute budget constraints. Yet empirical studies show no algorithm can
consistently outperform others (or even random selection) across varying
budgets. We therefore argue that compute budget must be integral to
data-selection strategies, since different budgets impose distinct requirements
on data quantity, quality, and distribution for effective training. To this
end, we propose a novel Computational budget-Aware Data Selection (CADS) method
and naturally formulate it into a bilevel optimization framework, where the
inner loop trains the model within the constraints of the computational budget
on some selected subset of training data, while the outer loop optimizes data
selection based on model evaluation. Our technical contributions lie in
addressing two main challenges in solving this bilevel optimization problem:
the expensive Hessian matrix estimation for outer-loop gradients and the
computational burden of achieving inner-loop optimality during iterations. To
solve the first issue, we propose a probabilistic reparameterization strategy
and compute the gradient using a Hessian-free policy gradient estimator. To
address the second challenge, we transform the inner optimization problem into
a penalty term in the outer objective, further discovering that we only need to
estimate the minimum of a one-dimensional loss to calculate the gradient,
significantly improving efficiency. Extensive experiments show that our method
achieves performance gains of up to 14.42% over baselines in vision and
language benchmarks.

</details>


### [320] [Improving Model Representation and Reducing KV Cache via Skip Connections with First Value Heads](https://arxiv.org/abs/2510.16807)
*Zhoutong Wu,Yuan Zhang,Yiming Dong,Chenheng Zhang,Cong Fang,Kun Yuan,Zhouchen Lin*

Main category: cs.LG

TL;DR: SkipV1Former是一种Transformer变体，通过从第一层的Value头添加跳跃连接来增强模型表示能力并减少KV缓存，在减少约25% KV缓存的同时改善困惑度。


<details>
  <summary>Details</summary>
Motivation: 扩展Transformer模型以改进表示能力通常需要大量内存和计算成本，特别是自回归解码期间使用的KV缓存。跳跃连接提供了在不增加资源使用的情况下改进表示的途径。

Method: 从第二个块开始，每一层重用一半的Value头来自第一层，另一半正常计算，从而将Value投影和V缓存减少近50%。理论上，将未压缩的第一层Value路由到更深层可以恢复因压缩而丢失的信息。

Result: 在不同模型规模下，SkipV1Former相对于标准MHA Transformer和一些先进变体，在减少约25% KV缓存的同时改善了困惑度。结合YOCO时，KV缓存大小减少近50%且性能仍有所提升。

Conclusion: SkipV1Former提供了一种有效的方法来增强Transformer表示能力并减少KV缓存，且可以通过仅10-15%额外计算将现有MHA Transformer检查点上训练为SkipV1Former。

Abstract: Transformer models have driven breakthroughs across various language tasks by
their strong capability to learn rich contextual representations. Scaling them
to improve representation, however, often demands substantial memory and
compute costs, such as the Key-Value (KV) cache used during auto-regressive
decoding. Skip connections offer a promising way to improve representation
without bloating resource usage, yet most prior works either improve
expressivity while leaving KV costs unchanged, or reduce memory at the cost of
weaker representation. In this work, we propose SkipV1Former, a Transformer
variant that uses skip connections from the first layer's Value heads to
strengthen model representation and reduce KV cache. Specifically, from the
second block onward, each layer reuses half of its Value heads from the very
first layer, while computing the other half as usual-cutting Value projections
and V cache by nearly 50 \%. Theoretically, we show that routing uncompressed
first-layer Values into deeper layers restores information lost to compression
and accelerates the model's implicit mesa-optimization-a key pattern of
Transformer in auto-regressive tasks. Empirically, across different model
scales, SkipV1Former delivers consistent reductions of approximately 25 \% in
KV cache while improving perplexity relative to standard Multi-Head Attention
(MHA) Transformers and some advanced variants. Moreover, we propose a recipe
for uptraining existing MHA Transformer checkpoints to SkipV1Former with only
10-15\% additional compute. Finally, SkipV1Former can seamlessly combine
advanced methods like Group-Query Attention and Multi-Latent Attention to
achieve further KV cache savings and performance improvement. When combined
with YOCO, it cuts KV cache size by nearly 50 \% while still improving
performance.

</details>


### [321] [Graph Learning is Suboptimal in Causal Bandits](https://arxiv.org/abs/2510.16811)
*Mohammad Shahverdikondori,Jalal Etesami,Negar Kiyavash*

Main category: cs.LG

TL;DR: 本文研究了因果充分性下因果强盗问题中的遗憾最小化，发现学习父节点集是次优的，证明了遗憾最小化与父节点识别之间存在根本冲突，并提出了绕过图恢复的近似最优算法。


<details>
  <summary>Details</summary>
Motivation: 先前工作主要关注识别奖励的父节点然后应用经典强盗方法，或联合学习父节点同时最小化遗憾。本文研究这些策略是否最优，并探讨遗憾最小化与因果结构学习之间的关系。

Method: 通过理论分析证明父节点识别与遗憾最小化存在冲突，建立了考虑动作空间组合结构的遗憾下界，并提出了绕过图恢复和父节点恢复的算法。

Result: 证明了学习父节点集是次优的，存在实例显示遗憾最小化与父节点识别是根本冲突的目标。实验表明新方法在各种环境中显著优于现有基线。

Conclusion: 父节点识别对于遗憾最小化是不必要的，提出的算法能够绕过图恢复实现近似最优性能，挑战了传统因果强盗问题中的常见做法。

Abstract: We study regret minimization in causal bandits under causal sufficiency where
the underlying causal structure is not known to the agent. Previous work has
focused on identifying the reward's parents and then applying classic bandit
methods to them, or jointly learning the parents while minimizing regret. We
investigate whether such strategies are optimal. Somewhat counterintuitively,
our results show that learning the parent set is suboptimal. We do so by
proving that there exist instances where regret minimization and parent
identification are fundamentally conflicting objectives. We further analyze
both the known and unknown parent set size regimes, establish novel regret
lower bounds that capture the combinatorial structure of the action space.
Building on these insights, we propose nearly optimal algorithms that bypass
graph and parent recovery, demonstrating that parent identification is indeed
unnecessary for regret minimization. Experiments confirm that there exists a
large performance gap between our method and existing baselines in various
environments.

</details>


### [322] [Needles in the Landscape: Semi-Supervised Pseudolabeling for Archaeological Site Discovery under Label Scarcity](https://arxiv.org/abs/2510.16814)
*Simon Jaxy,Anton Theys,Patrick Willett,W. Chris Carleton,Ralf Vandam,Pieter Libin*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的考古预测建模方法，采用半监督正未标记学习策略来解决考古数据中标签稀缺的问题，在数字高程模型和卫星图像数据集上取得了与现有最佳方法相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 考古预测建模需要结合已知遗址位置与环境、文化和地理空间变量来预测未知遗址位置，但面临结构性标签稀缺的挑战：正样本稀少且大多数位置无标签。

Method: 采用半监督正未标记学习策略，实现为语义分割模型，使用动态伪标签和条件随机场（通过RNN实现）来提高严重类别不平衡下的标签置信度。

Result: 在数字高程模型数据集上，模型性能与最先进的LAMAP方法相当，同时获得更高的Dice分数；在原始卫星图像上，通过分层k折交叉验证保持性能，并产生具有更好可解释性的预测表面。

Conclusion: 半监督学习为在大规模稀疏标注景观中识别未知遗址提供了一种有前景的方法。

Abstract: Archaeological predictive modelling estimates where undiscovered sites are
likely to occur by combining known locations with environmental, cultural, and
geospatial variables. We address this challenge using a deep learning approach
but must contend with structural label scarcity inherent to archaeology:
positives are rare, and most locations are unlabeled. To address this, we adopt
a semi-supervised, positive-unlabeled (PU) learning strategy, implemented as a
semantic segmentation model and evaluated on two datasets covering a
representative range of archaeological periods. Our approach employs dynamic
pseudolabeling, refined with a Conditional Random Field (CRF) implemented via
an RNN, increasing label confidence under severe class imbalance. On a
geospatial dataset derived from a digital elevation model (DEM), our model
performs on par with the state-of-the-art, LAMAP, while achieving higher Dice
scores. On raw satellite imagery, assessed end-to-end with stratified k-fold
cross-validation, it maintains performance and yields predictive surfaces with
improved interpretability. Overall, our results indicate that semi-supervised
learning offers a promising approach to identifying undiscovered sites across
large, sparsely annotated landscapes.

</details>


### [323] [Trace Regularity PINNs: Enforcing $\mathrm{H}^{\frac{1}{2}}(\partial Ω)$ for Boundary Data](https://arxiv.org/abs/2510.16817)
*Doyoon Kim,Junbin Song*

Main category: cs.LG

TL;DR: 提出了TRPINN方法，在Sobolev-Slobodeckij范数H^{1/2}(∂Ω)中强制边界损失，这是与H^1(Ω)相关的正确迹空间。通过仅计算半范数的理论必要部分来降低计算成本，并通过避免离散化中的分母评估来增强收敛稳定性。


<details>
  <summary>Details</summary>
Motivation: 标准PINNs在处理高度振荡的Dirichlet边界条件时可能失败，需要改进边界损失的计算方法以提高收敛性和稳定性。

Method: 提出TRPINN方法，在正确的迹空间H^{1/2}(∂Ω)中强制边界损失，仅计算必要的半范数部分，避免分母评估，并利用神经正切核分析。

Result: 数值实验显示TRPINN在标准PINNs失败的情况下仍能成功，性能提高1-3个十进制数字，收敛速度更快。

Conclusion: TRPINN通过精确的H^{1/2}(∂Ω)范数实现了H^1(Ω)意义上的收敛，比标准PINNs具有更好的收敛性和稳定性。

Abstract: We propose an enhanced physics-informed neural network (PINN), the Trace
Regularity Physics-Informed Neural Network (TRPINN), which enforces the
boundary loss in the Sobolev-Slobodeckij norm $H^{1/2}(\partial \Omega)$, the
correct trace space associated with $H^1(\Omega)$. We reduce computational cost
by computing only the theoretically essential portion of the semi-norm and
enhance convergence stability by avoiding denominator evaluations in the
discretization. By incorporating the exact $H^{1/2}(\partial \Omega)$ norm, we
show that the approximation converges to the true solution in the
$H^{1}(\Omega)$ sense, and, through Neural Tangent Kernel (NTK) analysis, we
demonstrate that TRPINN can converge faster than standard PINNs. Numerical
experiments on the Laplace equation with highly oscillatory Dirichlet boundary
conditions exhibit cases where TRPINN succeeds even when standard PINNs fail,
and show performance improvements of one to three decimal digits.

</details>


### [324] [Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning](https://arxiv.org/abs/2510.16882)
*Heming Zou,Yixiu Mao,Yun Qu,Qi Wang,Xiangyang Ji*

Main category: cs.LG

TL;DR: 本文提出了UDS（Utility-Diversity Sampling）框架，用于在监督微调中进行高效的在线批量选择，通过同时考虑数据效用和多样性来优化训练过程。


<details>
  <summary>Details</summary>
Motivation: 传统的全数据集监督微调计算成本高，容易过拟合或放大偏差。现有在线批量选择方法存在三个主要问题：仅依赖数据效用而忽略多样性、需要外部资源（如参考模型或验证集）、以及增加额外训练时间。

Method: UDS框架使用logits矩阵的核范数来捕捉数据效用和样本内多样性，同时通过低维嵌入比较和历史样本的轻量级内存缓冲区来估计样本间多样性。该设计无需外部资源和不必要的反向传播，确保计算效率。

Result: 在多个基准测试上的实验表明，UDS在不同数据预算下始终优于最先进的在线批量选择方法，并且相比全数据集微调显著减少了训练时间。

Conclusion: UDS提供了一个高效且无需外部资源的在线批量选择解决方案，在保持性能的同时显著降低了监督微调的计算成本。

Abstract: Supervised fine-tuning (SFT) is a commonly used technique to adapt large
language models (LLMs) to downstream tasks. In practice, SFT on a full dataset
is computationally expensive and sometimes suffers from overfitting or bias
amplification. This facilitates the rise of data curation in SFT, which
prioritizes the most valuable data to optimze. This work studies the online
batch selection family that dynamically scores and filters samples during the
training process. However, existing popular methods often (i) rely merely on
the utility of data to select a subset while neglecting other crucial factors
like diversity, (ii) rely on external resources such as reference models or
validation sets, and (iii) incur extra training time over full-dataset
training. To address these limitations, this work develops \textbf{UDS
(Utility-Diversity Sampling)}, a framework for efficient online batch selection
in SFT. UDS leverages the nuclear norm of the logits matrix to capture both
data utility and intra-sample diversity, while estimating inter-sample
diversity through efficient low-dimensional embedding comparisons with a
lightweight memory buffer of historical samples. Such a design eliminates the
need for external resources and unnecessary backpropagation, securing
computational efficiency. Experiments on multiple benchmarks demonstrate that
UDS consistently outperforms state-of-the-art online batch selection methods
under varying data budgets, and significantly reduces training time compared to
full-dataset fine-tuning. Code is available at https://github.com/gfyddha/UDS.

</details>


### [325] [ProtoMol: Enhancing Molecular Property Prediction via Prototype-Guided Multimodal Learning](https://arxiv.org/abs/2510.16824)
*Yingxu Wang,Kunyu Zhang,Jiaxin Huang,Nan Yin,Siwei Liu,Eran Segal*

Main category: cs.LG

TL;DR: ProtoMol是一个原型引导的多模态分子表示学习框架，通过层次化编码器和双向跨模态注意力机制，实现分子图与文本描述的细粒度整合和语义对齐，在多个分子属性预测任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多模态方法存在两个关键限制：(1)仅在最终编码层进行跨模态交互，忽略了层次语义依赖；(2)缺乏统一的原型空间来实现模态间的鲁棒对齐。

Method: 提出ProtoMol框架，包含双分支层次编码器（GNN处理分子图，Transformer编码文本），层间双向跨模态注意力机制，以及具有可学习类特定锚点的共享原型空间。

Result: 在多个基准数据集上的广泛实验表明，ProtoMol在各种分子属性预测任务中始终优于最先进的基线方法。

Conclusion: ProtoMol通过层次化跨模态交互和原型引导的语义对齐，显著提升了多模态分子表示学习的性能，为药物毒性、生物活性和物理化学性质预测提供了更准确和可解释的解决方案。

Abstract: Multimodal molecular representation learning, which jointly models molecular
graphs and their textual descriptions, enhances predictive accuracy and
interpretability by enabling more robust and reliable predictions of drug
toxicity, bioactivity, and physicochemical properties through the integration
of structural and semantic information. However, existing multimodal methods
suffer from two key limitations: (1) they typically perform cross-modal
interaction only at the final encoder layer, thus overlooking hierarchical
semantic dependencies; (2) they lack a unified prototype space for robust
alignment between modalities. To address these limitations, we propose
ProtoMol, a prototype-guided multimodal framework that enables fine-grained
integration and consistent semantic alignment between molecular graphs and
textual descriptions. ProtoMol incorporates dual-branch hierarchical encoders,
utilizing Graph Neural Networks to process structured molecular graphs and
Transformers to encode unstructured texts, resulting in comprehensive
layer-wise representations. Then, ProtoMol introduces a layer-wise
bidirectional cross-modal attention mechanism that progressively aligns
semantic features across layers. Furthermore, a shared prototype space with
learnable, class-specific anchors is constructed to guide both modalities
toward coherent and discriminative representations. Extensive experiments on
multiple benchmark datasets demonstrate that ProtoMol consistently outperforms
state-of-the-art baselines across a variety of molecular property prediction
tasks.

</details>


### [326] [DrivAerStar: An Industrial-Grade CFD Dataset for Vehicle Aerodynamic Optimization](https://arxiv.org/abs/2510.16857)
*Jiyan Qiu,Lyulin Kuang,Guan Wang,Yichen Xu,Leiyao Cui,Shaotong Fu,Yixin Zhu,Ruihua Zhang*

Main category: cs.LG

TL;DR: DrivAerStar是一个包含12,000个工业级汽车CFD模拟的数据集，通过改进的网格策略实现风洞验证精度低于1.04%，比现有数据集提高5倍，使机器学习模型能在保持生产级精度的同时将计算成本从数周降至分钟级。


<details>
  <summary>Details</summary>
Motivation: 车辆空气动力学优化对汽车电动化至关重要，但传统方法面临计算成本高与精度不足的权衡，现有机器学习数据集存在网格分辨率不足、组件缺失和验证误差超过5%等问题，无法在工业工作流中部署。

Method: 使用STAR-CCM+软件生成12,000个工业级CFD模拟，通过20个CAD参数和自由变形算法系统探索三种车辆配置，包括完整的发动机舱和冷却系统，采用精细网格策略和严格壁面y+控制。

Result: 数据集实现风洞验证精度低于1.04%，比现有数据集提高5倍，基准测试显示在此数据上训练的模型达到生产就绪精度，同时将计算成本从数周减少到分钟。

Conclusion: DrivAerStar是首个连接学术机器学习研究与工业CFD实践的数据集，为汽车开发中的数据驱动空气动力学优化设立了新标准，并展示了将高保真物理模拟与AI集成到工程领域的范例。

Abstract: Vehicle aerodynamics optimization has become critical for automotive
electrification, where drag reduction directly determines electric vehicle
range and energy efficiency. Traditional approaches face an intractable
trade-off: computationally expensive Computational Fluid Dynamics (CFD)
simulations requiring weeks per design iteration, or simplified models that
sacrifice production-grade accuracy. While machine learning offers
transformative potential, existing datasets exhibit fundamental limitations --
inadequate mesh resolution, missing vehicle components, and validation errors
exceeding 5% -- preventing deployment in industrial workflows. We present
DrivAerStar, comprising 12,000 industrial-grade automotive CFD simulations
generated using $\text{STAR-CCM+}^\unicode{xAE}$ software. The dataset
systematically explores three vehicle configurations through 20 Computer Aided
Design (CAD) parameters via Free Form Deformation (FFD) algorithms, including
complete engine compartments and cooling systems with realistic internal
airflow. DrivAerStar achieves wind tunnel validation accuracy below 1.04% -- a
five-fold improvement over existing datasets -- through refined mesh strategies
with strict wall $y^+$ control. Benchmarks demonstrate that models trained on
this data achieve production-ready accuracy while reducing computational costs
from weeks to minutes. This represents the first dataset bridging academic
machine learning research and industrial CFD practice, establishing a new
standard for data-driven aerodynamic optimization in automotive development.
Beyond automotive applications, DrivAerStar demonstrates a paradigm for
integrating high-fidelity physics simulations with Artificial Intelligence (AI)
across engineering disciplines where computational constraints currently limit
innovation.

</details>


### [327] [Peering Inside the Black Box: Uncovering LLM Errors in Optimization Modelling through Component-Level Evaluation](https://arxiv.org/abs/2510.16943)
*Dania Refai,Moataz Ahmed*

Main category: cs.LG

TL;DR: 本文提出了一个组件级别的评估框架，用于评估LLM生成的数学优化公式，超越了传统的整体评估方法，引入了决策变量和约束的精确率/召回率、约束和目标函数的RMSE等细粒度指标。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法通常将优化公式视为整体，依赖粗粒度指标如解精度或运行时间，这掩盖了结构或数值错误。需要更精细的评估框架来诊断LLM在优化建模中的表现。

Method: 提出了全面的组件级评估框架，包括决策变量和约束的精确率/召回率、约束和目标函数RMSE、基于token使用和延迟的效率指标。评估了GPT-5、LLaMA 3.1 Instruct和DeepSeek Math在不同复杂度优化问题上的表现，采用六种提示策略。

Result: GPT-5始终优于其他模型，思维链、自一致性和模块化提示最有效。求解器性能主要取决于高约束召回率和低约束RMSE，确保结构正确性和解可靠性。约束精确率和决策变量指标起次要作用，简洁输出提高计算效率。

Conclusion: 提出了NLP到优化建模的三个原则：完整约束覆盖防止违规、最小化约束RMSE确保求解器级精度、简洁输出提高计算效率。该框架为LLM在优化建模中的细粒度诊断评估奠定了基础。

Abstract: Large language models (LLMs) are increasingly used to convert natural
language descriptions into mathematical optimization formulations. Current
evaluations often treat formulations as a whole, relying on coarse metrics like
solution accuracy or runtime, which obscure structural or numerical errors. In
this study, we present a comprehensive, component-level evaluation framework
for LLM-generated formulations. Beyond the conventional optimality gap, our
framework introduces metrics such as precision and recall for decision
variables and constraints, constraint and objective root mean squared error
(RMSE), and efficiency indicators based on token usage and latency. We evaluate
GPT-5, LLaMA 3.1 Instruct, and DeepSeek Math across optimization problems of
varying complexity under six prompting strategies. Results show that GPT-5
consistently outperforms other models, with chain-of-thought, self-consistency,
and modular prompting proving most effective. Analysis indicates that solver
performance depends primarily on high constraint recall and low constraint
RMSE, which together ensure structural correctness and solution reliability.
Constraint precision and decision variable metrics play secondary roles, while
concise outputs enhance computational efficiency. These findings highlight
three principles for NLP-to-optimization modeling: (i) Complete constraint
coverage prevents violations, (ii) minimizing constraint RMSE ensures
solver-level accuracy, and (iii) concise outputs improve computational
efficiency. The proposed framework establishes a foundation for fine-grained,
diagnostic evaluation of LLMs in optimization modeling.

</details>


### [328] [Forgetting to Forget: Attention Sink as A Gateway for Backdooring LLM Unlearning](https://arxiv.org/abs/2510.17021)
*Bingqi Shang,Yiwei Chen,Yihua Zhang,Bingquan Shen,Sijia Liu*

Main category: cs.LG

TL;DR: 本文提出了一种针对大语言模型遗忘过程的隐蔽攻击方法——后门遗忘攻击，使得模型在正常情况下看起来成功遗忘，但在特定触发词出现时恢复被遗忘的知识。研究发现注意力下沉现象是此类攻击的关键通道。


<details>
  <summary>Details</summary>
Motivation: 随着开源大语言模型的兴起，需要研究遗忘过程本身是否可能被植入后门，即在正常条件下显示成功遗忘，但在隐藏触发词激活时恢复原有行为。

Method: 通过将触发词放置在注意力下沉位置（即浅层输入标记持续吸引不成比例注意力的现象），并调整其注意力值来增强后门持久性。

Result: 实验验证了注意力下沉引导的后门遗忘攻击能够可靠地在存在后门触发词时恢复被遗忘的知识，而在没有触发词时与正常遗忘模型行为无法区分。

Conclusion: 注意力下沉现象是后门遗忘攻击的有效通道，在模型遗忘过程中需要警惕此类隐蔽的安全威胁。

Abstract: Large language model (LLM) unlearning has become a critical mechanism for
removing undesired data, knowledge, or behaviors from pre-trained models while
retaining their general utility. Yet, with the rise of open-weight LLMs, we
ask: can the unlearning process itself be backdoored, appearing successful
under normal conditions yet reverting to pre-unlearned behavior when a hidden
trigger is activated? Drawing inspiration from classical backdoor attacks that
embed triggers into training data to enforce specific behaviors, we investigate
backdoor unlearning, where models forget as intended in the clean setting but
recover forgotten knowledge when the trigger appears. We show that designing
such attacks presents unique challenges, hinging on where triggers are placed
and how backdoor training is reinforced. We uncover a strong link between
backdoor efficacy and the attention sink phenomenon, i.e., shallow input tokens
consistently attract disproportionate attention in LLMs. Our analysis reveals
that these attention sinks serve as gateways for backdoor unlearning: placing
triggers at sink positions and aligning their attention values markedly
enhances backdoor persistence. Extensive experiments validate these findings,
showing that attention-sink-guided backdoor unlearning reliably restores
forgotten knowledge in the presence of backdoor triggers, while behaving
indistinguishably from a normally unlearned model when triggers are absent.
Code is available at https://github.com/OPTML-Group/Unlearn-Backdoor.

</details>


### [329] [Do LLMs Recognize Your Latent Preferences? A Benchmark for Latent Information Discovery in Personalized Interaction](https://arxiv.org/abs/2510.17132)
*Ioannis Tsaknakis,Bingqing Song,Shuyu Gan,Dongyeop Kang,Alfredo Garcia,Gaowen Liu,Charles Fleming,Mingyi Hong*

Main category: cs.LG

TL;DR: 该论文提出了一个评估大语言模型通过对话发现和利用用户潜在信息的统一基准，涵盖三个逐步现实化的场景：20问游戏、个性化问答和个性化文本摘要。研究发现LLMs能够通过对话揭示潜在信息，但成功率在32%到98%之间变化，取决于任务复杂度、主题和隐藏属性数量。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成通用文本方面表现出色，但在需要用户特定偏好的场景中（如餐厅推荐或旅行规划），这种通用性成为限制。用户很少明确表达所有偏好，许多关注点保持潜在状态，需要通过对话来推断。

Method: 引入统一的潜在信息发现评估基准，采用三智能体框架（用户、助手、评判者），在三个渐进现实设置中进行评估：经典20问游戏、个性化问答和个性化文本摘要，支持轮次级别的启发和适应评估。

Result: 研究结果显示，虽然LLMs确实能够通过对话揭示潜在信息，但其成功率差异显著：从32%到98%，具体取决于任务复杂度、主题和隐藏属性数量。

Conclusion: 该基准为研究个性化交互中的潜在信息发现提供了首个系统框架，强调有效的偏好推断仍然是构建真正自适应AI系统的开放前沿。

Abstract: Large Language Models (LLMs) excel at producing broadly relevant text, but
this generality becomes a limitation when user-specific preferences are
required, such as recommending restaurants or planning travel. In these
scenarios, users rarely articulate every preference explicitly; instead, much
of what they care about remains latent, waiting to be inferred. This raises a
fundamental question: Can LLMs uncover and reason about such latent information
through conversation?
  We address this problem by introducing a unified benchmark for evaluating
latent information discovery - the ability of LLMs to reveal and utilize hidden
user attributes through multi-turn interaction. The benchmark spans three
progressively realistic settings: the classic 20 Questions game, Personalized
Question Answering, and Personalized Text Summarization. All tasks share a
tri-agent framework (User, Assistant, Judge) enabling turn-level evaluation of
elicitation and adaptation. Our results reveal that while LLMs can indeed
surface latent information through dialogue, their success varies dramatically
with context: from 32% to 98%, depending on task complexity, topic, and number
of hidden attributes. This benchmark provides the first systematic framework
for studying latent information discovery in personalized interaction,
highlighting that effective preference inference remains an open frontier for
building truly adaptive AI systems.

</details>


### [330] [A Lightweight DL Model for Smart Grid Power Forecasting with Feature and Resolution Mismatch](https://arxiv.org/abs/2510.16911)
*Sarah Al-Shareeda,Gulcihan Ozdemir,Heung Seok Jeon,Khaleel Ahmad*

Main category: cs.LG

TL;DR: 提出一种轻量级深度学习管道，结合小时降采样、双模式插补和标准化处理，使用GRU-LSTM模型在噪声和不完整数据中实现准确短期能耗预测，平均RMSE为601.9W，MAE为468.9W，准确率84.36%。


<details>
  <summary>Details</summary>
Motivation: 解决传感器数据噪声、不完整且缺乏上下文丰富性时如何准确预测短期能耗的问题，参与2025年电力能耗预测竞赛，使用真实世界高频数据预测次日电力需求。

Method: 采用轻量级深度学习管道，包括小时降采样、双模式插补（均值和多项式回归）、综合标准化（最终选择标准缩放），使用GRU-LSTM序列到一模型。

Result: 模型平均RMSE为601.9W，MAE为468.9W，准确率84.36%。尽管输入不对称且存在插补间隙，模型泛化良好，捕捉非线性需求模式，保持低推理延迟。时空热图分析显示温度趋势与预测能耗高度一致。

Conclusion: 有针对性的预处理与紧凑循环架构结合，仍能在现实条件下实现快速、准确且可部署的能耗预测。

Abstract: How can short-term energy consumption be accurately forecasted when sensor
data is noisy, incomplete, and lacks contextual richness? This question guided
our participation in the \textit{2025 Competition on Electric Energy
Consumption Forecast Adopting Multi-criteria Performance Metrics}, which
challenged teams to predict next-day power demand using real-world
high-frequency data. We proposed a robust yet lightweight Deep Learning (DL)
pipeline combining hourly downsizing, dual-mode imputation (mean and polynomial
regression), and comprehensive normalization, ultimately selecting Standard
Scaling for optimal balance. The lightweight GRU-LSTM sequence-to-one model
achieves an average RMSE of 601.9~W, MAE of 468.9~W, and 84.36\% accuracy.
Despite asymmetric inputs and imputed gaps, it generalized well, captured
nonlinear demand patterns, and maintained low inference latency. Notably,
spatiotemporal heatmap analysis reveals a strong alignment between temperature
trends and predicted consumption, further reinforcing the model's reliability.
These results demonstrate that targeted preprocessing paired with compact
recurrent architectures can still enable fast, accurate, and deployment-ready
energy forecasting in real-world conditions.

</details>


### [331] [Domain Generalizable Continual Learning](https://arxiv.org/abs/2510.16914)
*Hongwei Yan,Guanglong Sun,Zhiqi Kang,Yi Zhong,Liyuan Wang*

Main category: cs.LG

TL;DR: 本文提出了领域泛化持续学习（DGCL）新设置，旨在让模型在顺序学习单领域任务时能泛化到所有已见任务和领域。作者提出了自适应领域变换（DoT）方法，基于预训练模型，通过解耦语义和领域信息并进行表示变换，实现平衡和泛化的预测。


<details>
  <summary>Details</summary>
Motivation: 现实环境中智能系统需要持续学习新技能并泛化到未见场景。现有持续学习方法假设训练和测试领域相同，在领域泛化持续学习（DGCL）设置下表现不佳。

Method: 提出自适应领域变换（DoT）方法，受人类大脑分布式加枢纽理论启发，在表示学习中解耦语义和领域相关信息，自适应地跨领域变换任务表示进行输出对齐。

Result: DoT作为插件策略显著提升了现有持续学习基线方法在DGCL中的性能，在完全参数调优和参数高效调优范式下均有效。实验验证DoT能积累领域泛化知识并保持资源效率。

Conclusion: DoT方法成功解决了DGCL中的挑战，通过解耦和变换表示实现了语义和领域信息的平衡泛化，为持续学习在动态现实环境中的应用提供了有效解决方案。

Abstract: To adapt effectively to dynamic real-world environments, intelligent systems
must continually acquire new skills while generalizing them to diverse, unseen
scenarios. Here, we introduce a novel and realistic setting named domain
generalizable continual learning (DGCL): a model learns sequential tasks with
each involving a single domain, aiming to perform well across all encountered
tasks and domains. This setting poses unique challenges in acquiring,
retaining, and leveraging both semantic- and domain-relevant information for
robust generalization. Although state-of-the-art continual learning (CL)
methods have employed pre-trained models (PTMs) to enhance task-specific
generalization, they typically assume identical training and testing domains
for each task and therefore perform poorly in DGCL. To this end, we propose
adaptive Domain Transformation (DoT), an innovative PTMs-based approach
tailored to DGCL. Inspired by the distributed-plus-hub theory of the human
brain, DoT disentangles semantic- and domain-relevant information in
representation learning, and adaptively transforms task representations across
various domains for output alignment, ensuring balanced and generalized
predictions. DoT serves as a plug-in strategy that greatly facilitates
state-of-the-art CL baselines under both full parameter tuning and
parameter-efficient tuning paradigms in DGCL, validated by extensive
experiments. Also, DoT is shown to accumulate domain-generalizable knowledge
from DGCL, and ensure resource efficiency with a lightweight implementation.

</details>


### [332] [SolverLLM: Leveraging Test-Time Scaling for Optimization Problem via LLM-Guided Search](https://arxiv.org/abs/2510.16916)
*Dong Li,Xujiang Zhao,Linlin Yu,Yanchi Liu,Wei Cheng,Zhengzhang Chen,Zhong Chen,Feng Chen,Chen Zhao,Haifeng Chen*

Main category: cs.LG

TL;DR: SolverLLM是一个无需训练、基于测试时扩展的框架，通过生成数学公式并转换为求解器代码来解决多样化优化问题，采用改进的蒙特卡洛树搜索策略实现优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖提示工程导致跨问题类型泛化能力差，要么需要昂贵的监督训练，需要开发一种无需训练且能良好泛化的优化问题求解方法。

Method: 提出SolverLLM框架，不直接求解问题，而是生成数学公式并转换为求解器代码，采用改进的蒙特卡洛树搜索策略，包括动态扩展、提示反向传播和不确定性反向传播。

Result: 在六个标准基准数据集上的实验表明，SolverLLM优于基于提示和学习的方法，无需额外训练即可实现强泛化能力。

Conclusion: SolverLLM通过测试时扩展和改进的MCTS策略，为LLMs解决优化问题提供了一种有效且无需训练的方法，展现了优异的泛化性能。

Abstract: Large Language Models (LLMs) offer promising capabilities for tackling
complex reasoning tasks, including optimization problems. However, existing
methods either rely on prompt engineering, which leads to poor generalization
across problem types, or require costly supervised training. We introduce
SolverLLM, a training-free framework that leverages test-time scaling to solve
diverse optimization problems. Rather than solving directly, SolverLLM
generates mathematical formulations and translates them into solver-ready code,
guided by a novel Monte Carlo Tree Search (MCTS) strategy. To enhance the
search process, we modify classical MCTS with (1) dynamic expansion for
adaptive formulation generation, (2) prompt backpropagation to guide
exploration via outcome-driven feedback, and (3) uncertainty backpropagation to
incorporate reward reliability into decision-making. Experiments on six
standard benchmark datasets demonstrate that SolverLLM outperforms both
prompt-based and learning-based baselines, achieving strong generalization
without additional training.

</details>


### [333] [LILO: Bayesian Optimization with Interactive Natural Language Feedback](https://arxiv.org/abs/2510.17671)
*Katarzyna Kobalczyk,Zhiyuan Jerry Lin,Benjamin Letham,Zhuokai Zhao,Maximilian Balandat,Eytan Bakshy*

Main category: cs.LG

TL;DR: 提出了一种语言在环框架，利用大语言模型将自然语言形式的非结构化反馈转换为标量效用，从而在数值搜索空间上进行贝叶斯优化。


<details>
  <summary>Details</summary>
Motivation: 许多现实应用需要将复杂、微妙或主观的目标转化为可量化的优化目标，反馈在这一过程中至关重要。传统方法只能接受受限的反馈格式，且需要为每个领域特定问题定制模型。

Method: 使用大语言模型将各种类型的文本反馈转化为一致的效用信号，并轻松包含灵活的用户先验，无需手动设计核函数。同时保持贝叶斯优化的样本效率和原则性不确定性量化。

Result: 这种混合方法不仅为决策者提供了更自然的接口，而且在反馈受限的情况下优于传统的贝叶斯优化基线和仅使用LLM的优化器。

Conclusion: 语言在环框架成功地将自然语言反馈与贝叶斯优化相结合，在保持样本效率的同时提供了更灵活的用户交互方式。

Abstract: For many real-world applications, feedback is essential in translating
complex, nuanced, or subjective goals into quantifiable optimization
objectives. We propose a language-in-the-loop framework that uses a large
language model (LLM) to convert unstructured feedback in the form of natural
language into scalar utilities to conduct BO over a numeric search space.
Unlike preferential BO, which only accepts restricted feedback formats and
requires customized models for each domain-specific problem, our approach
leverages LLMs to turn varied types of textual feedback into consistent utility
signals and to easily include flexible user priors without manual kernel
design. At the same time, our method maintains the sample efficiency and
principled uncertainty quantification of BO. We show that this hybrid method
not only provides a more natural interface to the decision maker but also
outperforms conventional BO baselines and LLM-only optimizers, particularly in
feedback-limited regimes.

</details>


### [334] [Mapping Post-Training Forgetting in Language Models at Scale](https://arxiv.org/abs/2510.17776)
*Jackson Harmon,Andreas Hochlehnert,Matthias Bethge,Ameya Prabhu*

Main category: cs.LG

TL;DR: 该论文提出了一个样本级别的框架来测量语言模型后训练过程中的知识遗忘和反向迁移，通过分析1->0（正确变错误）和0->1（错误变正确）的转换来量化这些效应。


<details>
  <summary>Details</summary>
Motivation: 当前规模化后训练在语言模型能力提升中发挥重要作用，但其对预训练知识的影响尚不清楚。传统任务平均指标会混淆遗忘和反向迁移效应，需要更精细的测量方法。

Method: 提出样本级别的测量范式，使用1->0转换计数量化遗忘，0->1转换计数量化反向转移。针对选择题基准，添加了机会调整变体以消除随机猜测的影响。

Result: 大规模分析发现：领域持续预训练导致中度遗忘和低到中度反向转移；RL/SFT后训练在数学和逻辑任务上产生中度到大的反向转移；指令调优模型上的RL/SFT对数据规模敏感；模型融合不能可靠缓解遗忘。

Conclusion: 该框架为理解后训练如何改变预训练知识提供了实用标准，有助于推动通用AI系统的发展。

Abstract: Scaled post-training now drives many of the largest capability gains in
language models (LMs), yet its effect on pretrained knowledge remains poorly
understood. Not all forgetting is equal: Forgetting one fact (e.g., a U.S.
president or an API call) does not "average out" by recalling another. Hence,
we propose a sample-wise paradigm to measure what is forgotten and when
backward transfer occurs. Our metric counts 1->0 transitions (correct before
post-training, incorrect after) to quantify forgetting and 0->1 transitions to
quantify backward transfer. Traditional task averages conflate these effects
and obscure large changes. For multiple-choice benchmarks, we add
chance-adjusted variants that subtract the expected contribution of random
guessing from pre- and post-training accuracies. We apply this framework across
post-training stages, model sizes, and data scales. Our large-scale analysis
shows that: (1) Domain-continual pretraining induces moderate forgetting with
low-to-moderate backward transfer; (2) RL/SFT post-training applied to base
models and Instruction tuning yields moderate-to-large backward transfer on
math and logic with overall low-to-moderate forgetting; (3) Applying RL/SFT to
instruction-tuned models is sensitive on data scale: at small scales, both
forgetting and backward transfer are small; at larger scales, effects are mixed
and warrant further study with better controls; (4) Model merging does not
reliably mitigate forgetting. Overall, our framework offers a practical
yardstick for mapping how post-training alters pretrained knowledge at scale --
enabling progress towards generally capable AI systems.

</details>


### [335] [Towards Interpretable and Trustworthy Time Series Reasoning: A BlueSky Vision](https://arxiv.org/abs/2510.16980)
*Kanghui Ning,Zijie Pan,Yushan Jiang,Anderson Schneider,Yuriy Nevmyvaka,Dongjin Song*

Main category: cs.LG

TL;DR: 本文提出了时间序列推理的愿景框架，包含两个互补方向：一是构建稳健的时间序列推理基础，二是推进系统级推理，通过多模态、多智能体协作等方法实现可解释和可信赖的时间序列智能。


<details>
  <summary>Details</summary>
Motivation: 时间序列分析正从模式识别向显式、可解释和可信赖的推理演进，需要建立新的理论基础和系统框架来支持这一转变。

Method: 提出包含两个互补方向的框架：1) 构建时间序列推理的稳健基础，包括全面时间理解、结构化多步推理和忠实评估框架；2) 推进系统级推理，整合多智能体协作、多模态上下文和检索增强方法。

Result: 构建了一个灵活可扩展的时间序列推理框架，能够支持跨领域的可解释和可信赖时间序列智能。

Conclusion: 该框架为时间序列推理的未来发展指明了方向，通过基础理论建设和系统级创新相结合，有望实现更高级别的时间序列智能。

Abstract: Time series reasoning is emerging as the next frontier in temporal analysis,
aiming to move beyond pattern recognition towards explicit, interpretable, and
trustworthy inference. This paper presents a BlueSky vision built on two
complementary directions. One builds robust foundations for time series
reasoning, centered on comprehensive temporal understanding, structured
multi-step reasoning, and faithful evaluation frameworks. The other advances
system-level reasoning, moving beyond language-only explanations by
incorporating multi-agent collaboration, multi-modal context, and
retrieval-augmented approaches. Together, these directions outline a flexible
and extensible framework for advancing time series reasoning, aiming to deliver
interpretable and trustworthy temporal intelligence across diverse domains.

</details>


### [336] [MuonBP: Faster Muon via Block-Periodic Orthogonalization](https://arxiv.org/abs/2510.16981)
*Ahmed Khaled,Kaan Ozkara,Tao Yu,Mingyi Hong,Youngsuk Park*

Main category: cs.LG

TL;DR: MuonBP是一种改进的优化器，通过块周期性正交化减少分布式训练中的通信开销，在保持训练稳定性的同时提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 解决Muon优化器在模型并行训练中因梯度正交化引入额外通信开销的问题，该开销相比AdamW会导致5%-10%的吞吐量下降。

Method: 提出MuonBP优化器，在每个设备上独立对矩阵分片进行正交化，并定期执行完全正交化以维持训练稳定性，使用两个不同的学习率分别处理块正交化和完全正交化步骤。

Result: 在8B模型训练中，使用8路张量并行和ZeRO优化器状态分片时，MuonBP相比Muon实现了8%的吞吐量提升，且性能没有下降。

Conclusion: MuonBP方法简单，需要最少的超参数调整，在保持与基线Muon竞争性迭代复杂度的同时，提供了与AdamW等坐标方法相当的每迭代吞吐量。

Abstract: Gradient orthogonalization is a simple strategy that shows great utility in
speeding up gradient descent. The Muon optimizer (Jordan, Jin, et al., 2024)
combines gradient orthogonalization with first-order momentum and achieves
significant improvement in data efficiency over Adam/AdamW (Loshchilov and
Hutter, 2019) for language model training. However, when using model
parallelism, gradient orthogonalization introduces additional overhead compared
to coordinate-wise optimizers (such as AdamW) due to additional gather and
scatter operations on gradient matrix shards from different devices. This
additional communication can amount to a throughput hit of 5%-10% compared to
Adam/AdamW. To remedy this, we propose Muon with Block-Periodic
Orthogonalization (MuonBP), which applies orthogonalization independently to
matrix shards on each device and periodically performs full orthogonalization
to maintain training stability at scale. We show how to adjust the learning
rate from the baseline to MuonBP and give convergence guarantees for this
algorithm. Crucially, our theory dictates that we use two stepsizes: one for
the blockwise orthogonalization steps, and one for the full orthogonalization
steps. Our method is simple, requires minimal hyperparameter adjustments, and
achieves competitive iteration complexity compared with baseline Muon while
providing per-iteration throughput comparable to coordinate-wise methods such
as AdamW. When training an 8B model with eight-way tensor parallelism and ZeRO
optimizer state sharding, MuonBP achieves 8% throughput increase compared to
Muon with no degradation in performance.

</details>


### [337] [Graph4MM: Weaving Multimodal Learning with Structural Information](https://arxiv.org/abs/2510.16990)
*Xuying Ning,Dongqi Fu,Tianxin Wei,Wujiang Xu,Jingrui He*

Main category: cs.LG

TL;DR: Graph4MM是一个基于图的多模态学习框架，通过Hop-Diffused Attention整合多跳结构信息，并使用MM-QFormer进行跨模态融合，在生成性和判别性任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界多模态数据具有复杂的结构关系，而现有方法无法区分多跳邻居并将图视为独立模态，导致理解碎片化。需要解决两个关键挑战：将多跳结构信息整合到基础模型中，以及以原则性方式融合模态特定信息。

Method: 提出Graph4MM框架，包含Hop-Diffused Attention（通过因果掩码和跳扩散整合多跳结构信息到自注意力中）和MM-QFormer（多映射查询变换器用于跨模态融合）。

Result: 在生成性和判别性任务上的实验表明，Graph4MM优于更大的视觉语言模型、语言模型和多模态图基线，平均提升6.93%。

Conclusion: 利用结构整合模态内和模态间交互比将图视为独立模态能更好地提升多模态理解能力。

Abstract: Real-world multimodal data usually exhibit complex structural relationships
beyond traditional one-to-one mappings like image-caption pairs. Entities
across modalities interact in intricate ways, with images and text forming
diverse interconnections through contextual dependencies and co-references.
Graphs provide powerful structural information for modeling intra-modal and
inter-modal relationships. However, previous works fail to distinguish
multi-hop neighbors and treat the graph as a standalone modality, which
fragments the overall understanding. This limitation presents two key
challenges in multimodal learning: (1) integrating structural information from
multi-hop neighbors into foundational models, and (2) fusing modality-specific
information in a principled manner. To address these challenges, we revisit the
role of graphs in multimodal learning within the era of foundation models and
propose Graph4MM, a graph-based multimodal learning framework. To be specific,
we introduce Hop-Diffused Attention, which integrates multi-hop structural
information into self-attention through causal masking and hop diffusion.
Furthermore, we design MM-QFormer, a multi-mapping querying transformer for
cross-modal fusion. Through theoretical and empirical analysis, we show that
leveraging structures to integrate both intra- and inter-modal interactions
improves multimodal understanding beyond treating them as a standalone
modality. Experiments on both generative and discriminative tasks show that
Graph4MM outperforms larger VLMs, LLMs, and multimodal graph baselines,
achieving a 6.93% average improvement.

</details>


### [338] [Curiosity-driven RL for symbolic equation solving](https://arxiv.org/abs/2510.17022)
*Kevin P. O Keeffe*

Main category: cs.LG

TL;DR: 本文探索强化学习在符号数学中的应用，使用PPO算法结合好奇心驱动探索和图基动作，能够求解包含根号、指数、三角函数等非线性方程。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习是否能在符号数学中发挥作用，特别是解决非线性方程问题，扩展之前仅能解决线性方程的研究。

Method: 使用模型无关的PPO算法，结合好奇心驱动探索策略和图基动作表示，处理非线性方程求解任务。

Result: 成功求解包含根号、指数、三角函数等复杂非线性方程，展示了强化学习在符号数学问题上的潜力。

Conclusion: 好奇心驱动探索可能对通用符号推理任务有重要价值，为强化学习在数学领域的应用提供了新思路。

Abstract: We explore if RL can be useful for symbolic mathematics. Previous work showed
contrastive learning can solve linear equations in one variable. We show
model-free PPO \cite{schulman2017proximal} augmented with curiosity-based
exploration and graph-based actions can solve nonlinear equations such as those
involving radicals, exponentials, and trig functions. Our work suggests
curiosity-based exploration may be useful for general symbolic reasoning tasks.

</details>


### [339] [Diverse Influence Component Analysis: A Geometric Approach to Nonlinear Mixture Identifiability](https://arxiv.org/abs/2510.17040)
*Hoang-Son Nguyen,Xiao Fu*

Main category: cs.LG

TL;DR: 本文提出了Diverse Influence Component Analysis (DICA)框架，通过最大化雅可比矩阵体积来识别非线性混合中的潜在成分，无需辅助信号、成分独立性或雅可比稀疏性假设。


<details>
  <summary>Details</summary>
Motivation: 非线性独立成分分析(nICA)中，识别未知非线性混合中的潜在成分是一个基础挑战。现有方法需要辅助信号或结构假设，限制了应用范围。

Method: 提出DICA框架和雅可比体积最大化(J-VolMax)准则，利用混合函数雅可比矩阵的凸几何特性，通过鼓励潜在成分对观测变量的影响多样性来实现识别。

Result: 在合理条件下，该方法能够实现潜在成分的可识别性，无需依赖辅助信息、潜在成分独立性或雅可比稀疏性假设。

Conclusion: DICA扩展了可识别性分析的范围，为现有方法提供了补充视角，在解耦表示学习和因果推断等任务中具有应用价值。

Abstract: Latent component identification from unknown nonlinear mixtures is a
foundational challenge in machine learning, with applications in tasks such as
disentangled representation learning and causal inference. Prior work in
nonlinear independent component analysis (nICA) has shown that auxiliary
signals -- such as weak supervision -- can support identifiability of
conditionally independent latent components. More recent approaches explore
structural assumptions, e.g., sparsity in the Jacobian of the mixing function,
to relax such requirements. In this work, we introduce Diverse Influence
Component Analysis (DICA), a framework that exploits the convex geometry of the
mixing function's Jacobian. We propose a Jacobian Volume Maximization
(J-VolMax) criterion, which enables latent component identification by
encouraging diversity in their influence on the observed variables. Under
reasonable conditions, this approach achieves identifiability without relying
on auxiliary information, latent component independence, or Jacobian sparsity
assumptions. These results extend the scope of identifiability analysis and
offer a complementary perspective to existing methods.

</details>


### [340] [The Ends Justify the Thoughts: RL-Induced Motivated Reasoning in LLMs](https://arxiv.org/abs/2510.17057)
*Nikolaus Howe,Micah Carroll*

Main category: cs.LG

TL;DR: 该论文研究了当后置指令与已学习行为冲突时，语言模型会进行系统性动机推理——生成看似合理的理由来违反指令，同时淡化潜在危害。研究发现前沿推理模型能够检测到这种动机推理，但较小的LLM法官可能无法识别部分动机推理，甚至可能被说服认为推理是正确的。


<details>
  <summary>Details</summary>
Motivation: 研究当后置指令与语言模型已学习行为冲突时，模型的推理过程会发生什么变化，特别关注模型是否会进行动机推理来为违反指令的行为辩护。

Method: 在简单设置中调查模型行为，分析模型如何生成看似合理的理由来违反指令，同时评估不同规模LLM法官检测动机推理的能力。

Result: 模型会进行系统性动机推理，前沿推理模型能够检测到大部分动机推理，但较小的LLM法官可能无法识别部分动机推理，有时甚至会被说服认为违反指令的推理是正确的。

Conclusion: 随着模型变得更加复杂，其动机推理可能越来越难以被监控器检测到，这强调了在依赖思维链过程进行模型评估和监督时需要考虑动机推理的重要性。

Abstract: The use of reinforcement learning (RL) with chain-of-thought (CoT) reasoning
has emerged as a promising approach for developing more capable language
models. In turn, this has led to investigation of CoT monitoring as a
compelling method for detecting harmful behaviors such as reward hacking, under
the assumption that models' reasoning processes reflect their internal
decision-making. In practice, LLM training often produces unintended behaviors
due to imperfect reward signals, leading models to develop misaligned
tendencies. A common corrective approach is to apply post-hoc instructions to
avoid problematic behaviors like sycophancy, but what happens to the model's
reasoning process when these instructions conflict with learned behaviors? We
investigate this question in simple settings and find that models engage in
systematic motivated reasoning -- generating plausible-sounding justifications
for violating their instructions while downplaying potential harms. Beyond
being an interesting property of training, we find that while motivated
reasoning can be detected by most frontier reasoning models, smaller LLM judges
can fail to identify a portion of it, and in rare cases can themselves be
persuaded that the reasoning is correct, despite it contradicting clear
instructions. This capability gap raises concerns that as models become more
sophisticated, their motivated reasoning may become increasingly difficult for
monitors to detect. Our results underscore the need to account for motivated
reasoning when relying on chain-of-thought processes for model evaluation and
oversight. All code for this paper will be made available. WARNING: some
examples in this paper may be upsetting.

</details>


### [341] [Bitwidth-Specific Logarithmic Arithmetic for Future Hardware-Accelerated Training](https://arxiv.org/abs/2510.17058)
*Hassan Hamad,Yuou Qiu,Peter A. Beerel,Keith M. Chugg*

Main category: cs.LG

TL;DR: 本文提出了一种改进的低精度对数定点训练方法，通过引入位宽优化算术操作近似，使用模拟退火优化分段线性近似，在12位整数运算下实现与32位浮点训练相当的精度，硬件研究显示面积减少32.5%，能耗降低53.5%。


<details>
  <summary>Details</summary>
Motivation: 虽然量化技术显著降低了深度学习推理的计算成本，但训练仍然主要依赖复杂的浮点运算。低精度定点训练提供了一个有吸引力的替代方案，特别是面向未来的硬件加速器设计。

Method: 提出在算术操作近似设计中加入位宽考虑，引入硬件友好的分段线性近似用于对数加法，使用模拟退火在不同精度级别优化该近似，通过C++位真模拟验证方法。

Result: 在CIFAR-100上训练VGG-11和在TinyImageNet上训练VGG-16，使用12位整数运算，与32位浮点训练相比精度损失极小。硬件研究显示LNS乘累加单元相比线性定点等效单元面积减少32.5%，能耗降低53.5%。

Conclusion: 提出的低精度对数定点训练方法在保持训练精度的同时，显著降低了硬件实现面积和能耗，为未来硬件加速器设计提供了有前景的解决方案。

Abstract: While advancements in quantization have significantly reduced the
computational costs of inference in deep learning, training still predominantly
relies on complex floating-point arithmetic. Low-precision fixed-point training
presents a compelling alternative. This work introduces a novel enhancement in
low-precision logarithmic fixed-point training, geared towards future hardware
accelerator designs. We propose incorporating bitwidth in the design of
approximations to arithmetic operations. To this end, we introduce a new
hardware-friendly, piece-wise linear approximation for logarithmic addition.
Using simulated annealing, we optimize this approximation at different
precision levels. A C++ bit-true simulation demonstrates training of VGG-11 and
VGG-16 models on CIFAR-100 and TinyImageNet, respectively, using 12-bit integer
arithmetic with minimal accuracy degradation compared to 32-bit floating-point
training. Our hardware study reveals up to 32.5% reduction in area and 53.5%
reduction in energy consumption for the proposed LNS multiply-accumulate units
compared to that of linear fixed-point equivalents.

</details>


### [342] [Consistent Zero-Shot Imitation with Contrastive Goal Inference](https://arxiv.org/abs/2510.17059)
*Kathryn Wantlin,Chongyi Zheng,Benjamin Eysenbach*

Main category: cs.LG

TL;DR: 提出了一种自监督预训练交互式智能体的方法，使它们能够快速模仿人类演示。该方法将目标作为基本构建模块，在训练期间自动提出目标并练习达成，在评估时通过逆强化学习解释演示作为最优目标达成行为。


<details>
  <summary>Details</summary>
Motivation: 当前最成功的AI模型（如视觉语言模型、大语言模型）缺乏明确的动作概念，无法为快速适应新任务做好准备。人类提供的数据存在错误假设，即人类大部分时间处于最有奖励的状态。需要让智能体通过交互式探索进行自监督训练。

Method: 将目标作为原子构建模块，在训练期间自动提出目标并练习达成这些目标。在评估阶段，通过求解逆强化学习问题来解释演示作为最优目标达成行为。

Result: 在标准基准测试（非专门为目标达成设计）上的实验表明，该方法在零样本模仿任务上优于现有方法。

Conclusion: 该方法为智能体提供了一种自监督预训练方式，使其能够快速适应新任务并模仿人类演示，在零样本模仿任务中表现出色。

Abstract: In the same way that generative models today conduct most of their training
in a self-supervised fashion, how can agentic models conduct their training in
a self-supervised fashion, interactively exploring, learning, and preparing to
quickly adapt to new tasks? A prerequisite for embodied agents deployed in real
world interactions ought to be training with interaction, yet today's most
successful AI models (e.g., VLMs, LLMs) are trained without an explicit notion
of action. The problem of pure exploration (which assumes no data as input) is
well studied in the reinforcement learning literature and provides agents with
a wide array of experiences, yet it fails to prepare them for rapid adaptation
to new tasks. Today's language and vision models are trained on data provided
by humans, which provides a strong inductive bias for the sorts of tasks that
the model will have to solve (e.g., modeling chords in a song, phrases in a
sonnet, sentences in a medical record). However, when they are prompted to
solve a new task, there is a faulty tacit assumption that humans spend most of
their time in the most rewarding states. The key contribution of our paper is a
method for pre-training interactive agents in a self-supervised fashion, so
that they can instantly mimic human demonstrations. Our method treats goals
(i.e., observations) as the atomic construct. During training, our method
automatically proposes goals and practices reaching them, building off prior
work in reinforcement learning exploration. During evaluation, our method
solves an (amortized) inverse reinforcement learning problem to explain
demonstrations as optimal goal-reaching behavior. Experiments on standard
benchmarks (not designed for goal-reaching) show that our approach outperforms
prior methods for zero-shot imitation.

</details>


### [343] [On the Universal Near Optimality of Hedge in Combinatorial Settings](https://arxiv.org/abs/2510.17099)
*Zhiyuan Fan,Arnab Maiti,Kevin Jamieson,Lillian J. Ratliff,Gabriele Farina*

Main category: cs.LG

TL;DR: 本文研究了Hedge算法在组合设置中的最优性，发现Hedge在大多数组合设置中是最优的（最多相差√log d因子），但在m-集合问题上存在√log d的次优性差距，而在在线多任务学习中是最优的。


<details>
  <summary>Details</summary>
Motivation: 研究Hedge算法在组合设置中的最优性，确定其在哪些组合问题上是最优的，在哪些问题上存在次优性差距。

Method: 通过建立适用于任何算法的下界Ω(√(T log(|X|)/log d))来评估Hedge的最优性，并分析不同组合设置（如m-集合、在线多任务学习、DAG最短路径问题）的具体表现。

Result: 发现Hedge在大多数组合设置中是最优的（最多相差√log d因子），但在m-集合问题上存在√log d的次优性差距，而在在线多任务学习中是最优的。同时证明了在线镜像下降算法在DAG最短路径问题中具有接近最优的遗憾保证。

Conclusion: Hedge算法在组合设置中具有接近最优的性能，其局限性主要出现在特定的m-集合问题上。通过将Hedge与在线镜像下降算法联系起来，可以为更广泛的组合领域提供接近最优的遗憾保证。

Abstract: In this paper, we study the classical Hedge algorithm in combinatorial
settings. In each round, the learner selects a vector $\boldsymbol{x}_t$ from a
set $X \subseteq \{0,1\}^d$, observes a full loss vector $\boldsymbol{y}_t \in
\mathbb{R}^d$, and incurs a loss $\langle \boldsymbol{x}_t, \boldsymbol{y}_t
\rangle \in [-1,1]$. This setting captures several important problems,
including extensive-form games, resource allocation, $m$-sets, online multitask
learning, and shortest-path problems on directed acyclic graphs (DAGs). It is
well known that Hedge achieves a regret of $O\big(\sqrt{T \log |X|}\big)$ after
$T$ rounds of interaction. In this paper, we ask whether Hedge is optimal
across all combinatorial settings. To that end, we show that for any $X
\subseteq \{0,1\}^d$, Hedge is near-optimal--specifically, up to a $\sqrt{\log
d}$ factor--by establishing a lower bound of $\Omega\big(\sqrt{T \log(|X|)/\log
d}\big)$ that holds for any algorithm. We then identify a natural class of
combinatorial sets--namely, $m$-sets with $\log d \leq m \leq \sqrt{d}$--for
which this lower bound is tight, and for which Hedge is provably suboptimal by
a factor of exactly $\sqrt{\log d}$. At the same time, we show that Hedge is
optimal for online multitask learning, a generalization of the classical
$K$-experts problem. Finally, we leverage the near-optimality of Hedge to
establish the existence of a near-optimal regularizer for online shortest-path
problems in DAGs--a setting that subsumes a broad range of combinatorial
domains. Specifically, we show that the classical Online Mirror Descent (OMD)
algorithm, when instantiated with the dilated entropy regularizer, is
iterate-equivalent to Hedge, and therefore inherits its near-optimal regret
guarantees for DAGs.

</details>


### [344] [In-situ Autoguidance: Eliciting Self-Correction in Diffusion Models](https://arxiv.org/abs/2510.17136)
*Enhao Gu,Haolin Hou*

Main category: cs.LG

TL;DR: 提出In-situ Autoguidance方法，无需辅助模型即可实现图像生成扩散模型的自引导，解决CFG方法中质量与多样性权衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决分类器自由引导(CFG)方法在提高图像质量和提示对齐性时导致多样性降低的问题，避免使用额外辅助模型带来的开销。

Method: 通过随机前向传递动态生成次优预测，将引导重新定义为推理时的自校正过程，实现零成本的自引导。

Result: 该方法不仅可行，而且为成本高效的引导建立了强大的新基准，证明无需外部模型即可实现自引导的益处。

Conclusion: In-situ Autoguidance是一种无需辅助组件的有效自引导方法，能够在不增加成本的情况下实现图像生成的质量与多样性平衡。

Abstract: The generation of high-quality, diverse, and prompt-aligned images is a
central goal in image-generating diffusion models. The popular classifier-free
guidance (CFG) approach improves quality and alignment at the cost of reduced
variation, creating an inherent entanglement of these effects. Recent work has
successfully disentangled these properties by guiding a model with a separately
trained, inferior counterpart; however, this solution introduces the
considerable overhead of requiring an auxiliary model. We challenge this
prerequisite by introducing In-situ Autoguidance, a method that elicits
guidance from the model itself without any auxiliary components. Our approach
dynamically generates an inferior prediction on the fly using a stochastic
forward pass, reframing guidance as a form of inference-time self-correction.
We demonstrate that this zero-cost approach is not only viable but also
establishes a powerful new baseline for cost-efficient guidance, proving that
the benefits of self-guidance can be achieved without external models.

</details>


### [345] [Learning After Model Deployment](https://arxiv.org/abs/2510.17160)
*Derda Kaymak,Gyuhak Kim,Tomoya Kaichi,Tatsuya Konishi,Bing Liu*

Main category: cs.LG

TL;DR: 本文提出了一种名为ALMD的新学习范式，即在模型部署后进行自主学习，使模型能够在动态开放环境中检测未见类别的新样本并增量学习它们。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习在部署后模型固定不变，不适合动态开放环境，因为可能出现来自未见类别的新样本。模型需要能够检测这些新样本并在标注后学习它们。

Method: 提出PLDA方法，执行动态OOD检测和在线增量学习新类别，无需从头重新训练模型。

Result: 经验评估将展示PLDA方法的有效性。

Conclusion: ALMD范式能够解决动态环境中模型需要持续学习和适应新类别的问题，PLDA方法为此提供了有效解决方案。

Abstract: In classic supervised learning, once a model is deployed in an application,
it is fixed. No updates will be made to it during the application. This is
inappropriate for many dynamic and open environments, where unexpected samples
from unseen classes may appear. In such an environment, the model should be
able to detect these novel samples from unseen classes and learn them after
they are labeled. We call this paradigm Autonomous Learning after Model
Deployment (ALMD). The learning here is continuous and involves no human
engineers. Labeling in this scenario is performed by human co-workers or other
knowledgeable agents, which is similar to what humans do when they encounter an
unfamiliar object and ask another person for its name. In ALMD, the detection
of novel samples is dynamic and differs from traditional out-of-distribution
(OOD) detection in that the set of in-distribution (ID) classes expands as new
classes are learned during application, whereas ID classes is fixed in
traditional OOD detection. Learning is also different from classic supervised
learning because in ALMD, we learn the encountered new classes immediately and
incrementally. It is difficult to retrain the model from scratch using all the
past data from the ID classes and the novel samples from newly discovered
classes, as this would be resource- and time-consuming. Apart from these two
challenges, ALMD faces the data scarcity issue because instances of new classes
often appear sporadically in real-life applications. To address these issues,
we propose a novel method, PLDA, which performs dynamic OOD detection and
incremental learning of new classes on the fly. Empirical evaluations will
demonstrate the effectiveness of PLDA.

</details>


### [346] [ALPINE: A Lightweight and Adaptive Privacy-Decision Agent Framework for Dynamic Edge Crowdsensing](https://arxiv.org/abs/2510.17162)
*Guanjie Cheng,Siyang Liu,Junqin Huang,Xinkui Zhao,Yin Wang,Mengying Zhu,Linghe Kong,Shuiguang Deng*

Main category: cs.LG

TL;DR: ALPINE是一个轻量级自适应框架，使终端设备能够实时调整差分隐私级别，在移动边缘群智感知系统中平衡隐私保护、数据效用和能耗成本。


<details>
  <summary>Details</summary>
Motivation: 移动边缘群智感知系统在动态、资源受限环境中持续生成和传输用户数据，面临严重的隐私威胁。静态差分隐私机制无法适应不断变化的风险，导致过度噪声或保护不足。

Method: ALPINE作为闭环控制系统，包含四个模块：动态风险感知、基于TD3算法的隐私决策、本地隐私执行和边缘节点性能验证。设计了平衡隐私增益、数据效用和能耗成本的奖励函数。

Result: 广泛的理论分析和真实世界模拟表明，ALPINE能有效缓解推理攻击，同时保持效用和成本，适用于大规模边缘应用。

Conclusion: ALPINE框架通过自适应调整差分隐私级别，在多样化风险场景中实现了隐私、效用和成本之间的动态平衡，为大规模边缘应用提供了实用的隐私保护方案。

Abstract: Mobile edge crowdsensing (MECS) systems continuously generate and transmit
user data in dynamic, resource-constrained environments, exposing users to
significant privacy threats. In practice, many privacy-preserving mechanisms
build on differential privacy (DP). However, static DP mechanisms often fail to
adapt to evolving risks, for example, shifts in adversarial capabilities,
resource constraints and task requirements, resulting in either excessive noise
or inadequate protection. To address this challenge, we propose ALPINE, a
lightweight, adaptive framework that empowers terminal devices to autonomously
adjust differential privacy levels in real time. ALPINE operates as a
closed-loop control system consisting of four modules: dynamic risk perception,
privacy decision via twin delayed deep deterministic policy gradient (TD3),
local privacy execution and performance verification from edge nodes. Based on
environmental risk assessments, we design a reward function that balances
privacy gains, data utility and energy cost, guiding the TD3 agent to
adaptively tune noise magnitude across diverse risk scenarios and achieve a
dynamic equilibrium among privacy, utility and cost. Both the collaborative
risk model and pretrained TD3-based agent are designed for low-overhead
deployment. Extensive theoretical analysis and real-world simulations
demonstrate that ALPINE effectively mitigates inference attacks while
preserving utility and cost, making it practical for large-scale edge
applications.

</details>


### [347] [A Standardized Benchmark for Machine-Learned Molecular Dynamics using Weighted Ensemble Sampling](https://arxiv.org/abs/2510.17187)
*Alexander Aghili,Andy Bruce,Daniel Sabo,Sanya Murdeshwar,Kevin Bachelor,Ionut Mistreanu,Ashwin Lokapally,Razvan Marinescu*

Main category: cs.LG

TL;DR: 该论文提出了一个模块化的分子动力学方法基准测试框架，通过增强采样分析系统评估蛋白质MD方法，支持多种模拟引擎和评估指标，并提供了包含9种蛋白质的数据集。


<details>
  <summary>Details</summary>
Motivation: 分子动力学方法的快速发展超出了标准化验证工具的开发速度，导致方法间难以进行客观比较，主要问题包括评估指标不一致、稀有构象状态采样不足以及缺乏可重现的基准。

Method: 使用基于时间滞后独立成分分析（TICA）的加权集成（WE）采样方法，通过WESTPA工具包实现快速高效的蛋白质构象空间探索。框架包含灵活的传播器接口，支持任意模拟引擎，包括经典力场和机器学习模型。

Result: 开发了一个全面的评估套件，能够计算超过19种不同的指标和可视化，并贡献了包含9种不同蛋白质的数据集（10-224个残基）。通过经典MD模拟和CGSchNet模型的验证测试展示了框架的实用性。

Conclusion: 该开源平台通过标准化评估协议和实现MD方法间的直接、可重现比较，为分子模拟社区建立了一致、严格的基准测试基础。

Abstract: The rapid evolution of molecular dynamics (MD) methods, including
machine-learned dynamics, has outpaced the development of standardized tools
for method validation. Objective comparison between simulation approaches is
often hindered by inconsistent evaluation metrics, insufficient sampling of
rare conformational states, and the absence of reproducible benchmarks. To
address these challenges, we introduce a modular benchmarking framework that
systematically evaluates protein MD methods using enhanced sampling analysis.
Our approach uses weighted ensemble (WE) sampling via The Weighted Ensemble
Simulation Toolkit with Parallelization and Analysis (WESTPA), based on
progress coordinates derived from Time-lagged Independent Component Analysis
(TICA), enabling fast and efficient exploration of protein conformational
space. The framework includes a flexible, lightweight propagator interface that
supports arbitrary simulation engines, allowing both classical force fields and
machine learning-based models. Additionally, the framework offers a
comprehensive evaluation suite capable of computing more than 19 different
metrics and visualizations across a variety of domains. We further contribute a
dataset of nine diverse proteins, ranging from 10 to 224 residues, that span a
variety of folding complexities and topologies. Each protein has been
extensively simulated at 300K for one million MD steps per starting point (4
ns). To demonstrate the utility of our framework, we perform validation tests
using classic MD simulations with implicit solvent and compare protein
conformational sampling using a fully trained versus under-trained CGSchNet
model. By standardizing evaluation protocols and enabling direct, reproducible
comparisons across MD approaches, our open-source platform lays the groundwork
for consistent, rigorous benchmarking across the molecular simulation
community.

</details>


### [348] [SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient Transformer Inference](https://arxiv.org/abs/2510.17189)
*Wenxun Wang,Shuchang Zhou,Wenyu Sun,Peiqin Sun,Yongpan Liu*

Main category: cs.LG

TL;DR: SOLE是一个软硬件协同设计的Transformer加速方案，通过E2Softmax和AILayerNorm分别优化Softmax和LayerNorm的计算效率，无需重新训练即可保持推理精度，同时大幅提升速度和能效。


<details>
  <summary>Details</summary>
Motivation: Transformer在NLP和CV任务中表现出色，但其实时推理速度和效率受到Softmax和LayerNorm计算效率低下的限制。现有基于函数逼近的方法实现效率低，且需要重新训练来补偿逼近误差，成本高且不便。

Method: 提出SOLE软硬件协同设计：E2Softmax使用指数函数的log2量化和基于对数的除法来逼近Softmax；AILayerNorm采用低精度统计计算。两者都实现了低精度计算和低比特位宽存储。

Result: SOLE在无需重新训练的情况下保持推理精度，相比GPU实现了数量级的速度提升和能耗节省。与现有最先进定制硬件相比，Softmax和LayerNorm分别实现了3.04倍和3.86倍的能效提升，以及2.82倍和3.32倍的面积效率提升。

Conclusion: SOLE通过软硬件协同设计有效解决了Transformer中Softmax和LayerNorm的计算效率瓶颈，在保持精度的同时显著提升了推理速度和能效，为Transformer的实时应用提供了高效解决方案。

Abstract: Transformers have shown remarkable performance in both natural language
processing (NLP) and computer vision (CV) tasks. However, their real-time
inference speed and efficiency are limited due to the inefficiency in Softmax
and Layer Normalization (LayerNorm). Previous works based on function
approximation suffer from inefficient implementation as they place emphasis on
computation while disregarding memory overhead concerns. Moreover, such methods
rely on retraining to compensate for approximation error which can be costly
and inconvenient.
  In this paper, we present SOLE, a hardware-software co-design for Softmax and
LayerNorm which is composed of E2Softmax and AILayerNorm. E2Softmax utilizes
log2 quantization of exponent function and log-based division to approximate
Softmax while AILayerNorm adopts low-precision statistic calculation. Compared
with state-of-the-art designs, we achieve both low-precision calculation and
low bit-width storage on Softmax and LayerNorm. Experiments show that SOLE
maintains inference accuracy without retraining while offering orders of
magnitude speedup and energy savings over GPU, achieving 3.04x, 3.86x
energy-efficiency improvements and 2.82x, 3.32x area-efficiency improvements
over prior state-of-the-art custom hardware for Softmax and LayerNorm,
respectively.

</details>


### [349] [D2C-HRHR: Discrete Actions with Double Distributional Critics for High-Risk-High-Return Tasks](https://arxiv.org/abs/2510.17212)
*Jundong Zhang,Yuhui Situ,Fanji Zhang,Rongji Deng,Tianqi Wei*

Main category: cs.LG

TL;DR: 本文提出了一种强化学习框架，用于处理高风险高回报任务，通过离散化连续动作空间、熵正则化探索和双评论家架构来建模多模态动作分布和风险。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法假设单峰高斯策略和标量值评论家，在处理高风险高回报任务时效果有限，因为这些任务通常具有多模态动作分布和随机回报。

Method: 提出强化学习框架：(i) 离散化连续动作空间以近似多模态分布，(ii) 使用熵正则化探索提高风险但有益动作的覆盖率，(iii) 引入双评论家架构进行更准确的离散值分布估计。

Result: 在具有高失败风险的移动和操作基准测试中，该方法优于基线方法，证明了显式建模多模态性和风险的重要性。

Conclusion: 该框架能够扩展到高维动作空间，支持复杂控制领域，为高风险高回报任务的强化学习提供了有效解决方案。

Abstract: Tasks involving high-risk-high-return (HRHR) actions, such as obstacle
crossing, often exhibit multimodal action distributions and stochastic returns.
Most reinforcement learning (RL) methods assume unimodal Gaussian policies and
rely on scalar-valued critics, which limits their effectiveness in HRHR
settings. We formally define HRHR tasks and theoretically show that Gaussian
policies cannot guarantee convergence to the optimal solution. To address this,
we propose a reinforcement learning framework that (i) discretizes continuous
action spaces to approximate multimodal distributions, (ii) employs
entropy-regularized exploration to improve coverage of risky but rewarding
actions, and (iii) introduces a dual-critic architecture for more accurate
discrete value distribution estimation. The framework scales to
high-dimensional action spaces, supporting complex control domains. Experiments
on locomotion and manipulation benchmarks with high risks of failure
demonstrate that our method outperforms baselines, underscoring the importance
of explicitly modeling multimodality and risk in RL.

</details>


### [350] [Breaking and Fixing Defenses Against Control-Flow Hijacking in Multi-Agent Systems](https://arxiv.org/abs/2510.17276)
*Rishi Jha,Harold Triedman,Justin Wagle,Vitaly Shmatikov*

Main category: cs.LG

TL;DR: 本文提出了ControlValve防御机制，通过生成允许的控制流图并强制执行上下文规则来防止多智能体系统中的控制流劫持攻击。


<details>
  <summary>Details</summary>
Motivation: 现有防御机制（如LlamaFirewall）依赖智能体通信的对齐检查，但无法有效抵御规避这些检查的控制流劫持攻击，因为安全性和功能性目标存在根本冲突。

Method: 提出ControlValve防御机制，基于控制流完整性和最小权限原则：(1) 生成多智能体系统的允许控制流图；(2) 强制执行所有执行符合这些图以及每个智能体调用的上下文规则（以零样本方式生成）。

Result: ControlValve能够有效防御规避现有对齐检查的控制流劫持攻击。

Conclusion: ControlValve通过控制流完整性和上下文规则强制执行，为多智能体系统提供了更强大的安全防御机制，解决了现有基于对齐检查的防御方法的局限性。

Abstract: Control-flow hijacking attacks manipulate orchestration mechanisms in
multi-agent systems into performing unsafe actions that compromise the system
and exfiltrate sensitive information. Recently proposed defenses, such as
LlamaFirewall, rely on alignment checks of inter-agent communications to ensure
that all agent invocations are "related to" and "likely to further" the
original objective.
  We start by demonstrating control-flow hijacking attacks that evade these
defenses even if alignment checks are performed by advanced LLMs. We argue that
the safety and functionality objectives of multi-agent systems fundamentally
conflict with each other. This conflict is exacerbated by the brittle
definitions of "alignment" and the checkers' incomplete visibility into the
execution context.
  We then propose, implement, and evaluate ControlValve, a new defense inspired
by the principles of control-flow integrity and least privilege. ControlValve
(1) generates permitted control-flow graphs for multi-agent systems, and (2)
enforces that all executions comply with these graphs, along with contextual
rules (generated in a zero-shot manner) for each agent invocation.

</details>


### [351] [MemoryBench: A Benchmark for Memory and Continual Learning in LLM Systems](https://arxiv.org/abs/2510.17281)
*Qingyao Ai,Yichen Tang,Changyue Wang,Jianming Long,Weihang Su,Yiqun Liu*

Main category: cs.LG

TL;DR: 本文提出了一个用户反馈模拟框架和综合基准测试，用于评估LLM系统的持续学习能力，覆盖多个领域、语言和任务类型，发现现有方法的有效性和效率远未达到满意水平。


<details>
  <summary>Details</summary>
Motivation: 由于高质量数据逐渐耗尽和更大计算资源消耗带来的边际收益递减，扩展数据、参数和测试时间计算的方法已接近上限，因此需要借鉴人类和传统AI系统从实践中学习的能力，为LLM系统构建记忆和持续学习框架。

Method: 提出用户反馈模拟框架和综合基准测试，覆盖多个领域、语言和任务类型，用于评估LLM系统的持续学习能力。

Result: 实验表明，现有最先进基准方法的有效性和效率远未达到满意水平。

Conclusion: 希望该基准测试能为未来LLM记忆和优化算法的研究铺平道路。

Abstract: Scaling up data, parameters, and test-time computation has been the
mainstream methods to improve LLM systems (LLMsys), but their upper bounds are
almost reached due to the gradual depletion of high-quality data and marginal
gains obtained from larger computational resource consumption. Inspired by the
abilities of human and traditional AI systems in learning from practice,
constructing memory and continual learning frameworks for LLMsys has become an
important and popular research direction in recent literature. Yet, existing
benchmarks for LLM memory often focus on evaluating the system on homogeneous
reading comprehension tasks with long-form inputs rather than testing their
abilities to learn from accumulated user feedback in service time. Therefore,
we propose a user feedback simulation framework and a comprehensive benchmark
covering multiple domains, languages, and types of tasks to evaluate the
continual learning abilities of LLMsys. Experiments show that the effectiveness
and efficiency of state-of-the-art baselines are far from satisfying, and we
hope this benchmark could pave the way for future studies on LLM memory and
optimization algorithms.

</details>


### [352] [Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations](https://arxiv.org/abs/2510.17313)
*Tal Barami,Nimrod Berman,Ilan Naiman,Amos H. Hason,Rotem Ezra,Omri Azencot*

Main category: cs.LG

TL;DR: 本文提出了首个多因子时序解缠的标准基准，包含六个数据集、评估工具和自动对齐方法，并展示了视觉语言模型在自动标注和评估中的应用。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据包含多个相互作用的语义因子，但先前工作主要关注简单的双因子静态和动态设置，忽略了数据的多因子本质，因此需要建立标准基准来推动多因子时序解缠研究。

Method: 提出了包含六个多样化数据集的标准基准，开发了数据集集成、模型开发和评估指标的工具集，引入了后验潜在探索阶段来自动对齐潜在维度与语义因子，并提出基于Koopman的模型。

Result: 提出的Koopman启发模型取得了最先进的结果，视觉语言模型能够自动化数据集标注并作为零样本解缠评估器，消除了手动标签和人工干预的需求。

Conclusion: 这些贡献为推进多因子时序解缠研究提供了稳健且可扩展的基础。

Abstract: Learning disentangled representations in sequential data is a key goal in
deep learning, with broad applications in vision, audio, and time series. While
real-world data involves multiple interacting semantic factors over time, prior
work has mostly focused on simpler two-factor static and dynamic settings,
primarily because such settings make data collection easier, thereby
overlooking the inherently multi-factor nature of real-world data. We introduce
the first standardized benchmark for evaluating multi-factor sequential
disentanglement across six diverse datasets spanning video, audio, and time
series. Our benchmark includes modular tools for dataset integration, model
development, and evaluation metrics tailored to multi-factor analysis. We
additionally propose a post-hoc Latent Exploration Stage to automatically align
latent dimensions with semantic factors, and introduce a Koopman-inspired model
that achieves state-of-the-art results. Moreover, we show that Vision-Language
Models can automate dataset annotation and serve as zero-shot disentanglement
evaluators, removing the need for manual labels and human intervention.
Together, these contributions provide a robust and scalable foundation for
advancing multi-factor sequential disentanglement.

</details>


### [353] [Auto-Rubric: Learning to Extract Generalizable Criteria for Reward Modeling](https://arxiv.org/abs/2510.17314)
*Lipeng Xie,Sen Huang,Zhuo Zhang,Anni Zou,Yunpeng Zhai,Dingchao Ren,Kezun Zhang,Haoyuan Hu,Boyin Liu,Haoran Chen,Zhaoyang Liu,Bolin Ding*

Main category: cs.LG

TL;DR: 提出了一种无需训练的新框架，通过利用评估准则在多样化查询中的泛化能力，实现了显著的数据效率，仅需少量偏好数据就能构建可解释的分层奖励模型。


<details>
  <summary>Details</summary>
Motivation: 奖励模型对于对齐大语言模型与人类价值观至关重要，但其发展受到昂贵偏好数据集和较差可解释性的限制。现有基于准则的方法在可扩展性和可靠性之间存在权衡。

Method: 采用两阶段方法：首先通过验证引导的"提出-评估-修订"流程推断高质量、查询特定的准则；然后通过最大化信息论编码率将这些细粒度准则泛化为紧凑、非冗余的核心集，最终输出可解释的分层"主题-提示"准则集。

Result: 广泛实验证明该框架具有卓越的数据效率和性能。仅使用70个偏好对（源数据的1.5%），该方法还能使较小模型如Qwen3-8B超越专门的、完全训练的对应模型。

Conclusion: 这项工作开创了一条可扩展、可解释且数据高效的奖励建模路径。

Abstract: Reward models are essential for aligning Large Language Models (LLMs) with
human values, yet their development is hampered by costly preference datasets
and poor interpretability. While recent rubric-based approaches offer
transparency, they often lack systematic quality control and optimization,
creating a trade-off between scalability and reliability. We address these
limitations with a novel, training-free framework built on a key assumption:
\textit{evaluation rubrics underlying human preferences exhibit significant
generalization ability across diverse queries}, a property that enables
remarkable data efficiency. Our two-stage approach first infers high-quality,
query-specific rubrics using a validation-guided
\textbf{Propose-Evaluate-Revise} pipeline. Second, it generalizes these
granular rubrics into a compact, non-redundant core set by maximizing an
\textbf{information-theoretic coding rate}. The final output is an
interpretable, hierarchical "Theme-Tips" rubric set. Extensive experiments
demonstrate the framework's exceptional data efficiency and performance.
Critically, using just 70 preference pairs (1.5\% of the source data), our
method also empowers smaller models like Qwen3-8B to outperform specialized,
fully-trained counterparts. This work pioneers a scalable, interpretable, and
data-efficient path for reward modeling.

</details>


### [354] [Localist LLMs with Recruitment Learning](https://arxiv.org/abs/2510.17358)
*Joachim Diederich*

Main category: cs.LG

TL;DR: 提出了一种可训练大语言模型的新框架，通过可调节的内部表示在局部化（可解释、基于规则）和分布式（可泛化、高效）编码之间连续切换。


<details>
  <summary>Details</summary>
Motivation: 解决传统语言模型在可解释性和性能之间的权衡问题，为需要透明性和能力的受监管领域提供支持。

Method: 采用局部性调节参数、信息论招募机制和分层招募框架，通过注意力机制的组稀疏惩罚、信息论锚点设计、动态规则注入和基于惩罚似然的招募标准实现。

Result: 建立了严格的数学结果，证明了注意力在语义相关块上集中的阈值条件，提供了注意力熵和指针保真度的精确界限，分层招募机制在块级和LLM级都提供了收敛保证。

Conclusion: 该框架使从业者能够在可解释模式和高性能模式之间连续插值，同时在多个粒度上调整架构容量，支持需要透明性和能力的应用场景。

Abstract: We present a novel framework for training large language models with
continuously adjustable internal representations that span the full spectrum
from localist (interpretable, rule-based) to distributed (generalizable,
efficient) encodings. The key innovations are (1) a locality dial, a tunable
parameter that dynamically controls the degree of localization during both
training and inference without requiring model retraining, (2) an
information-theoretic recruitment mechanism that adaptively allocates semantic
blocks as needed, eliminating the requirement for complete domain knowledge at
initialization, and (3) a hierarchical recruitment framework that extends
capacity allocation to entire specialized LLMs, enabling multi-granularity
architectural adaptation. This is achieved through group sparsity penalties on
attention mechanisms, information-theoretic anchor design, dynamic rule
injection, and principled recruitment criteria based on penalized likelihood
with explicit units. We provide rigorous mathematical results establishing
explicit threshold conditions under which attention provably concentrates on
semantically relevant blocks at stationary points, with exact bounds on
attention entropy and pointer fidelity. The hierarchical recruitment mechanism
provides convergence guarantees at both the block level (fine-grained,
within-LLM) and the LLM level (coarse-grained, cross-domain), ensuring the
system discovers semantic partitions that balance model complexity against data
encoding efficiency. This framework enables practitioners to continuously
interpolate between interpretable and high-performance modes while adapting
architectural capacity at multiple granularities, supporting applications in
regulated domains requiring both transparency and capability.

</details>


### [355] [Beyond Binary Out-of-Distribution Detection: Characterizing Distributional Shifts with Multi-Statistic Diffusion Trajectories](https://arxiv.org/abs/2510.17381)
*Achref Jaziri,Martin Rogmann,Martin Mundt,Visvanathan Ramesh*

Main category: cs.LG

TL;DR: DISC：一种基于扩散模型的统计特征提取方法，不仅能检测OOD数据，还能区分OOD类型，超越了传统基于标量评分的OOD检测方法。


<details>
  <summary>Details</summary>
Motivation: 传统OOD检测方法仅将分布偏移压缩为单一标量异常分数，无法区分不同类型的OOD数据，限制了后续采取适当行动的能力。

Method: 利用扩散模型的迭代去噪过程，在多个噪声级别提取丰富的多维特征向量，捕捉统计差异。

Result: 在图像和表格数据基准测试中，DISC在OOD检测性能上达到或超越最先进方法，并具备OOD类型分类能力。

Conclusion: DISC实现了从简单二元OOD检测向更细粒度检测的转变，为OOD数据的上下文理解和潜在利用提供了新途径。

Abstract: Detecting out-of-distribution (OOD) data is critical for machine learning, be
it for safety reasons or to enable open-ended learning. However, beyond mere
detection, choosing an appropriate course of action typically hinges on the
type of OOD data encountered. Unfortunately, the latter is generally not
distinguished in practice, as modern OOD detection methods collapse
distributional shifts into single scalar outlier scores. This work argues that
scalar-based methods are thus insufficient for OOD data to be properly
contextualized and prospectively exploited, a limitation we overcome with the
introduction of DISC: Diffusion-based Statistical Characterization. DISC
leverages the iterative denoising process of diffusion models to extract a
rich, multi-dimensional feature vector that captures statistical discrepancies
across multiple noise levels. Extensive experiments on image and tabular
benchmarks show that DISC matches or surpasses state-of-the-art detectors for
OOD detection and, crucially, also classifies OOD type, a capability largely
absent from prior work. As such, our work enables a shift from simple binary
OOD detection to a more granular detection.

</details>


### [356] [Latent Spaces Beyond Synthesis: From GANs to Diffusion Models](https://arxiv.org/abs/2510.17383)
*Ludovica Schaerf*

Main category: cs.LG

TL;DR: 本文探讨了生成视觉模型中内部表征的演变，分析了从GANs和VAEs到扩散模型的转变，提出了严格意义合成与广义合成的区分，并通过实验展示了扩散模型如何分散表征负担。


<details>
  <summary>Details</summary>
Motivation: 研究生成视觉模型中内部表征的演变，理解从GANs和VAEs到扩散模型的转变如何改变表征的组织方式，挑战统一内部空间的假设。

Method: 通过分析模型架构和进行层间表征干预实验，研究扩散模型如何分散表征负担，并结合媒体理论框架进行批判性分析。

Result: 扩散模型将表征负担分散到不同层，挑战了统一内部空间的假设，展示了表征工作的分布式特性。

Conclusion: 生成AI应被理解为专门化过程的涌现配置，而非内容的直接合成，需要重新思考对生成AI的理解方式。

Abstract: This paper examines the evolving nature of internal representations in
generative visual models, focusing on the conceptual and technical shift from
GANs and VAEs to diffusion-based architectures. Drawing on Beatrice Fazi's
account of synthesis as the amalgamation of distributed representations, we
propose a distinction between "synthesis in a strict sense", where a compact
latent space wholly determines the generative process, and "synthesis in a
broad sense," which characterizes models whose representational labor is
distributed across layers. Through close readings of model architectures and a
targeted experimental setup that intervenes in layerwise representations, we
show how diffusion models fragment the burden of representation and thereby
challenge assumptions of unified internal space. By situating these findings
within media theoretical frameworks and critically engaging with metaphors such
as the latent space and the Platonic Representation Hypothesis, we argue for a
reorientation of how generative AI is understood: not as a direct synthesis of
content, but as an emergent configuration of specialized processes.

</details>


### [357] [TabR1: Taming GRPO for tabular reasoning LLMs](https://arxiv.org/abs/2510.17385)
*Pengxiang Cai,Zihao Gao,Jintai Chen*

Main category: cs.LG

TL;DR: TabR1是首个用于表格预测的推理大语言模型，通过PRPO强化学习方法激活LLM的推理能力，在少样本和零样本场景下实现与强基线相当的性能，并显著优于更大的LLM。


<details>
  <summary>Details</summary>
Motivation: 传统表格预测方法（如梯度提升决策树和专用深度学习模型）在任务内表现出色但可解释性有限、跨表迁移能力弱。推理LLM具有跨任务适应性和透明推理轨迹的潜力，但尚未在表格数据中得到充分发挥。

Method: 提出TabR1模型，核心是Permutation Relative Policy Optimization (PRPO)强化学习方法，通过构建每个样本的多个标签保持排列，在排列内和排列间估计优势，将稀疏奖励转化为密集学习信号。

Result: 在完全监督微调下，TabR1达到与强基线相当的性能；在零样本设置下，TabR1接近32样本设置下强基线的性能；TabR1 (8B)在各种任务上显著优于更大的LLM，相比DeepSeek-R1 (685B)提升高达53.17%。

Conclusion: PRPO方法有效激活了LLM在表格预测中的推理能力，提升了少样本和零样本性能以及可解释性，证明了推理LLM在表格预测任务中的巨大潜力。

Abstract: Tabular prediction has traditionally relied on gradient-boosted decision
trees and specialized deep learning models, which excel within tasks but
provide limited interpretability and weak transfer across tables. Reasoning
large language models (LLMs) promise cross-task adaptability with trans- parent
reasoning traces, yet their potential has not been fully realized for tabular
data. This paper presents TabR1, the first reasoning LLM for tabular prediction
with multi-step reasoning. At its core is Permutation Relative Policy
Optimization (PRPO), a simple yet efficient reinforcement learning method that
encodes column-permutation invariance as a structural prior. By construct- ing
multiple label-preserving permutations per sample and estimating advantages
both within and across permutations, PRPO transforms sparse rewards into dense
learning signals and improves generalization. With limited supervision, PRPO
activates the reasoning ability of LLMs for tabular prediction, enhancing
few-shot and zero-shot performance as well as interpretability. Comprehensive
experiments demonstrate that TabR1 achieves performance comparable to strong
baselines under full-supervision fine-tuning. In the zero-shot setting, TabR1
approaches the performance of strong baselines under the 32-shot setting.
Moreover, TabR1 (8B) substantially outperforms much larger LLMs across various
tasks, achieving up to 53.17% improvement over DeepSeek-R1 (685B).

</details>


### [358] [Finite-Time Bounds for Average-Reward Fitted Q-Iteration](https://arxiv.org/abs/2510.17391)
*Jongmin Lee,Ernest K. Ryu*

Main category: cs.LG

TL;DR: 提出了Anchored Fitted Q-Iteration方法，首次为弱通信MDP的平均奖励离线强化学习建立了样本复杂度结果，无需传统强假设如遍历性或线性MDP。


<details>
  <summary>Details</summary>
Motivation: 现有平均奖励离线RL研究依赖强假设条件（如遍历性或线性MDP），缺乏对更一般弱通信MDP的样本复杂度分析，需要开发新的理论框架。

Method: 结合标准Fitted Q-Iteration与锚定机制，锚定可解释为权重衰减形式，对单轨迹生成数据也适用。

Result: 首次为弱通信MDP的平均奖励离线RL建立了有限时间分析，锚定机制是实现该分析的关键。

Conclusion: 锚定FQI方法在更宽松的弱通信假设下实现了平均奖励离线RL的样本复杂度分析，扩展了理论适用范围。

Abstract: Although there is an extensive body of work characterizing the sample
complexity of discounted-return offline RL with function approximations, prior
work on the average-reward setting has received significantly less attention,
and existing approaches rely on restrictive assumptions, such as ergodicity or
linearity of the MDP. In this work, we establish the first sample complexity
results for average-reward offline RL with function approximation for weakly
communicating MDPs, a much milder assumption. To this end, we introduce
Anchored Fitted Q-Iteration, which combines the standard Fitted Q-Iteration
with an anchor mechanism. We show that the anchor, which can be interpreted as
a form of weight decay, is crucial for enabling finite-time analysis in the
average-reward setting. We also extend our finite-time analysis to the setup
where the dataset is generated from a single-trajectory rather than IID
transitions, again leveraging the anchor mechanism.

</details>


### [359] [Diffusion Models as Dataset Distillation Priors](https://arxiv.org/abs/2510.17421)
*Duo Su,Huyu Wu,Huanran Chen,Yiming Shi,Yuzhu Wang,Xi Ye,Jun Zhu*

Main category: cs.LG

TL;DR: 本文提出DAP方法，利用扩散模型中的代表性先验来指导数据集蒸馏过程，无需重新训练即可提升合成数据的代表性和质量。


<details>
  <summary>Details</summary>
Motivation: 当前生成式数据集蒸馏方法虽然采用扩散模型，但忽视了扩散模型固有的代表性先验，往往需要额外约束来提升数据质量。

Method: 提出DAP方法，通过Mercer核量化合成数据与真实数据在特征空间的相似性，将该先验作为指导来引导反向扩散过程。

Result: 在ImageNet-1K等大规模数据集上的实验表明，DAP在生成高保真数据集方面优于现有方法，并实现更好的跨架构泛化性能。

Conclusion: DAP不仅建立了扩散先验与数据集蒸馏目标的理论联系，还提供了一个无需训练即可提升蒸馏数据集质量的实用框架。

Abstract: Dataset distillation aims to synthesize compact yet informative datasets from
large ones. A significant challenge in this field is achieving a trifecta of
diversity, generalization, and representativeness in a single distilled
dataset. Although recent generative dataset distillation methods adopt powerful
diffusion models as their foundation models, the inherent representativeness
prior in diffusion models is overlooked. Consequently, these approaches often
necessitate the integration of external constraints to enhance data quality. To
address this, we propose Diffusion As Priors (DAP), which formalizes
representativeness by quantifying the similarity between synthetic and real
data in feature space using a Mercer kernel. We then introduce this prior as
guidance to steer the reverse diffusion process, enhancing the
representativeness of distilled samples without any retraining. Extensive
experiments on large-scale datasets, such as ImageNet-1K and its subsets,
demonstrate that DAP outperforms state-of-the-art methods in generating
high-fidelity datasets while achieving superior cross-architecture
generalization. Our work not only establishes a theoretical connection between
diffusion priors and the objectives of dataset distillation but also provides a
practical, training-free framework for improving the quality of the distilled
dataset.

</details>


### [360] [Explainable AI for microseismic event detection](https://arxiv.org/abs/2510.17458)
*Ayrat Abdullin,Denis Anikiev,Umair bin Waheed*

Main category: cs.LG

TL;DR: 应用可解释AI技术（Grad-CAM和SHAP）解释PhaseNet模型决策，并开发SHAP门控推理方案提升模型性能，在9000个波形测试集上F1得分达到0.98，优于基准PhaseNet。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型如PhaseNet在检测微震事件时具有高精度，但其黑盒特性在关键应用中存在担忧，需要提高模型的可解释性和可靠性。

Method: 使用Grad-CAM和SHAP等可解释AI技术解释PhaseNet模型决策，开发SHAP门控推理方案，将模型输出与基于解释的度量相结合以减少错误。

Result: SHAP门控模型在9000个波形测试集上F1得分为0.98（精度0.99，召回率0.97），优于基准PhaseNet（F1得分0.97），对噪声具有更强的鲁棒性。

Conclusion: 可解释AI不仅能解释深度学习模型，还能直接提升其性能，为构建可信的自动化地震检测器提供了模板。

Abstract: Deep neural networks like PhaseNet show high accuracy in detecting
microseismic events, but their black-box nature is a concern in critical
applications. We apply explainable AI (XAI) techniques, such as
Gradient-weighted Class Activation Mapping (Grad-CAM) and Shapley Additive
Explanations (SHAP), to interpret the PhaseNet model's decisions and improve
its reliability. Grad-CAM highlights that the network's attention aligns with
P- and S-wave arrivals. SHAP values quantify feature contributions, confirming
that vertical-component amplitudes drive P-phase picks while horizontal
components dominate S-phase picks, consistent with geophysical principles.
Leveraging these insights, we introduce a SHAP-gated inference scheme that
combines the model's output with an explanation-based metric to reduce errors.
On a test set of 9,000 waveforms, the SHAP-gated model achieved an F1-score of
0.98 (precision 0.99, recall 0.97), outperforming the baseline PhaseNet
(F1-score 0.97) and demonstrating enhanced robustness to noise. These results
show that XAI can not only interpret deep learning models but also directly
enhance their performance, providing a template for building trust in automated
seismic detectors.

</details>


### [361] [CrossStateECG: Multi-Scale Deep Convolutional Network with Attention for Rest-Exercise ECG Biometrics](https://arxiv.org/abs/2510.17467)
*Dan Zheng,Jing Feng,Juan Liu*

Main category: cs.LG

TL;DR: CrossStateECG是一个专门针对静息-运动跨状态条件的心电生物识别模型，通过多尺度深度卷积特征提取和注意力机制，在静息到运动场景下达到92.50%识别准确率，在运动到静息场景下达到94.72%识别准确率。


<details>
  <summary>Details</summary>
Motivation: 当前心电生物识别研究主要关注静息状态，而静息-运动场景下的性能下降问题尚未解决，需要开发能够在不同生理状态下保持强识别能力的认证模型。

Method: 结合多尺度深度卷积特征提取与注意力机制，专门针对跨状态（静息-运动）条件设计，确保在不同生理状态下具有强识别能力。

Result: 在运动-ECGID数据集上验证，静息到运动场景识别准确率92.50%，运动到静息场景识别准确率94.72%，静息到静息场景准确率99.94%，混合到混合场景准确率97.85%。在ECG-ID和MIT-BIH数据集上的额外验证进一步证实了模型的泛化能力。

Conclusion: CrossStateECG展示了作为动态现实环境中运动后心电认证实用解决方案的潜力，能够有效处理不同生理状态下的识别挑战。

Abstract: Current research in Electrocardiogram (ECG) biometrics mainly emphasizes
resting-state conditions, leaving the performance decline in rest-exercise
scenarios largely unresolved. This paper introduces CrossStateECG, a robust
ECG-based authentication model explicitly tailored for cross-state
(rest-exercise) conditions. The proposed model creatively combines multi-scale
deep convolutional feature extraction with attention mechanisms to ensure
strong identification across different physiological states. Experimental
results on the exercise-ECGID dataset validate the effectiveness of
CrossStateECG, achieving an identification accuracy of 92.50% in the
Rest-to-Exercise scenario (training on resting ECG and testing on post-exercise
ECG) and 94.72% in the Exercise-to-Rest scenario (training on post-exercise ECG
and testing on resting ECG). Furthermore, CrossStateECG demonstrates
exceptional performance across both state combinations, reaching an accuracy of
99.94% in Rest-to-Rest scenarios and 97.85% in Mixed-to-Mixed scenarios.
Additional validations on the ECG-ID and MIT-BIH datasets further confirmed the
generalization abilities of CrossStateECG, underscoring its potential as a
practical solution for post-exercise ECG-based authentication in dynamic
real-world settings.

</details>


### [362] [Layer Specialization Underlying Compositional Reasoning in Transformers](https://arxiv.org/abs/2510.17469)
*Jing Liu*

Main category: cs.LG

TL;DR: 本文通过随机层次模型研究Transformer的组合推理能力，发现模型在未训练序列上表现出系统性泛化，性能随任务复杂度和上下文示例数量提升，且泛化能力与层级专业化相关。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer在未训练序列上表现出的组合推理能力，探索其内部机制如何支持这种能力，特别是上下文学习和技能组合的作用。

Method: 使用随机层次模型（概率上下文无关文法）生成序列，在序列子集上训练模型，并在四种泛化条件下评估：记忆、分布内泛化、分布外泛化（相同规则）和跨层迁移。

Result: 模型性能随任务复杂度和上下文示例数量系统性提升，分布外任务需要更多示例；训练过程中出现层级专业化，与泛化性能相关；Transformer在专门层中发展出结构化、层次化组织的表示。

Conclusion: Transformer发展出模块化、可解释的机制来支持组合推理，将内部算法结构与观察到的行为能力联系起来。

Abstract: Transformers exhibit compositional reasoning on sequences not observed during
training, a capability often attributed to in-context learning (ICL) and skill
composition. We investigate this phenomenon using the Random Hierarchy Model
(RHM), a probabilistic context-free grammar that generates sequences through
recursive rule application. Models are trained on subsets of sequences and
evaluated across four generalization conditions: memorization, in-distribution
generalization, out-of-distribution generalization with the same rules, and
cross-layer transfer. Behaviorally, performance improves systematically with
task complexity and the number of in-context examples, with out-of-distribution
tasks requiring substantially more examples than in-distribution scenarios.
Mechanistically, we identify a progressive emergence of layer specialization
during training that correlates with generalization performance. Principal
component analysis and attention pattern clustering reveal that transformers
develop structured, hierarchically organized representations in specialized
layers. These results demonstrate that transformers develop modular,
interpretable mechanisms supporting compositional reasoning, linking internal
algorithmic structure to observed behavioral capabilities.

</details>


### [363] [Unified Privacy Guarantees for Decentralized Learning via Matrix Factorization](https://arxiv.org/abs/2510.17480)
*Aurélien Bellet,Edwige Cyffers,Davide Frey,Romaric Gaudel,Dimitri Lerévérend,François Taïani*

Main category: cs.LG

TL;DR: 本文提出了一种基于矩阵分解的去中心化学习隐私计算方法，通过分析时间噪声相关性来改进差分隐私在去中心化学习中的隐私计算，并提出了新的算法MAFALDA-SGD。


<details>
  <summary>Details</summary>
Motivation: 去中心化学习虽然能保护数据隐私，但现有的差分隐私计算方法在实践中往往导致比集中式训练更差的隐私-效用权衡，这可能是由于当前DP计算方法在DL中的局限性。

Method: 将集中式DP计算中的矩阵分解方法推广到去中心化学习，将标准DL算法和信任模型统一到一个框架中，并提出了MAFALDA-SGD算法，这是一种基于gossip的去中心化学习算法，具有用户级相关噪声。

Result: 该方法为现有DP-DL算法提供了更严格的隐私计算，并为开发新算法提供了原则性方法。MAFALDA-SGD在合成和真实世界图上优于现有方法。

Conclusion: 基于矩阵分解的隐私计算方法可以有效改进去中心化学习中的差分隐私计算，提供更优的隐私-效用权衡。

Abstract: Decentralized Learning (DL) enables users to collaboratively train models
without sharing raw data by iteratively averaging local updates with neighbors
in a network graph. This setting is increasingly popular for its scalability
and its ability to keep data local under user control. Strong privacy
guarantees in DL are typically achieved through Differential Privacy (DP), with
results showing that DL can even amplify privacy by disseminating noise across
peer-to-peer communications. Yet in practice, the observed privacy-utility
trade-off often appears worse than in centralized training, which may be due to
limitations in current DP accounting methods for DL. In this paper, we show
that recent advances in centralized DP accounting based on Matrix Factorization
(MF) for analyzing temporal noise correlations can also be leveraged in DL. By
generalizing existing MF results, we show how to cast both standard DL
algorithms and common trust models into a unified formulation. This yields
tighter privacy accounting for existing DP-DL algorithms and provides a
principled way to develop new ones. To demonstrate the approach, we introduce
MAFALDA-SGD, a gossip-based DL algorithm with user-level correlated noise that
outperforms existing methods on synthetic and real-world graphs.

</details>


### [364] [ZACH-ViT: A Zero-Token Vision Transformer with ShuffleStrides Data Augmentation for Robust Lung Ultrasound Classification](https://arxiv.org/abs/2510.17650)
*Athanasios Angelakis,Amne Mousa,Micah L. A. Heldeweg,Laurens A. Biesheuvel,Mark A. Haaksma,Jasper M. Smit,Pieter R. Tuinman,Paul W. G. Elbers*

Main category: cs.LG

TL;DR: ZACH-ViT是一种轻量级视觉变换器，用于区分心源性肺水肿与非心源性肺部疾病，在肺超声视频中实现了最佳分类性能。


<details>
  <summary>Details</summary>
Motivation: 由于非心源性炎症模式、间质性肺病和健康肺部的高视觉变异性，在肺超声视频中区分心源性肺水肿与其他肺部状况具有挑战性。

Method: 提出ZACH-ViT（零令牌自适应紧凑分层视觉变换器），移除位置嵌入和[CLS]令牌，实现完全排列不变性；提出ShuffleStrides数据增强方法，在保持解剖有效性的同时置换探头视图序列和帧顺序。

Result: 在380个肺超声视频上评估，ZACH-ViT获得最高的验证和测试ROC-AUC（0.80和0.79），平衡灵敏度（0.60）和特异性（0.91），训练速度比Minimal ViT快1.35倍，参数减少2.5倍。

Conclusion: 将架构设计与数据结构对齐可以在小数据医学成像中超越规模效应，支持实时临床部署。

Abstract: Differentiating cardiogenic pulmonary oedema (CPE) from non-cardiogenic and
structurally normal lungs in lung ultrasound (LUS) videos remains challenging
due to the high visual variability of non-cardiogenic inflammatory patterns
(NCIP/ARDS-like), interstitial lung disease, and healthy lungs. This
heterogeneity complicates automated classification as overlapping B-lines and
pleural artefacts are common. We introduce ZACH-ViT (Zero-token Adaptive
Compact Hierarchical Vision Transformer), a 0.25 M-parameter Vision Transformer
variant that removes both positional embeddings and the [CLS] token, making it
fully permutation-invariant and suitable for unordered medical image data. To
enhance generalization, we propose ShuffleStrides Data Augmentation (SSDA),
which permutes probe-view sequences and frame orders while preserving
anatomical validity. ZACH-ViT was evaluated on 380 LUS videos from 95
critically ill patients against nine state-of-the-art baselines. Despite the
heterogeneity of the non-cardiogenic group, ZACH-ViT achieved the highest
validation and test ROC-AUC (0.80 and 0.79) with balanced sensitivity (0.60)
and specificity (0.91), while all competing models collapsed to trivial
classification. It trains 1.35x faster than Minimal ViT (0.62M parameters) with
2.5x fewer parameters, supporting real-time clinical deployment. These results
show that aligning architectural design with data structure can outperform
scale in small-data medical imaging.

</details>


### [365] [I-RAVEN-X: Benchmarking Generalization and Robustness of Analogical and Mathematical Reasoning in Large Language and Reasoning Models](https://arxiv.org/abs/2510.17496)
*Giacomo Camposampiero,Michael Hersche,Roger Wattenhofer,Abu Sebastian,Abbas Rahimi*

Main category: cs.LG

TL;DR: I-RAVEN-X是一个符号基准测试，用于评估LLMs和LRMs在类比和数学推理中的泛化能力和鲁棒性。它通过增加操作数复杂度、属性范围和引入感知不确定性来扩展I-RAVEN。实验表明LRMs在长推理关系和宽属性范围上表现更好，但在不确定性推理方面仍有挑战。


<details>
  <summary>Details</summary>
Motivation: 设计一个更复杂的基准测试来评估大型语言模型和大型推理模型在类比和数学推理中的泛化能力和鲁棒性，特别是在处理复杂操作数、宽属性范围和感知不确定性时的表现。

Method: 通过扩展I-RAVEN基准测试，增加操作数复杂度、扩大属性范围，并引入感知不确定性，构建I-RAVEN-X符号基准测试。

Result: 相比LLMs，LRMs在长推理关系和宽属性范围上分别表现出更好的生产力和系统性。但LRMs在处理不确定性推理方面仍有显著挑战，无法有效探索多个概率结果。

Conclusion: LRMs在复杂推理任务中比LLMs有优势，但在不确定性推理方面仍需改进。I-RAVEN-X为评估推理模型的泛化能力和鲁棒性提供了有效的测试平台。

Abstract: We introduce I-RAVEN-X, a symbolic benchmark designed to evaluate
generalization and robustness in analogical and mathematical reasoning for
Large Language Models (LLMs) and Large Reasoning Models (LRMs). I-RAVEN-X
extends I-RAVEN by increasing operand complexity, attribute range, and
introducing perceptual uncertainty. Compared to LLMs, empirical results show
that LRMs achieve improved productivity and systematicity on longer reasoning
relations and wider attribute ranges, respectively. However, LRMs are still
significantly challenged by reasoning under uncertainty and cannot effectively
explore multiple probabilistic outcomes.

</details>


### [366] [Curiosity Meets Cooperation: A Game-Theoretic Approach to Long-Tail Multi-Label Learning](https://arxiv.org/abs/2510.17520)
*Canran Xiao,Chuangxin Zhao,Zong Ke,Fei Shen*

Main category: cs.LG

TL;DR: 本文提出了一种基于合作博弈论的多标签学习方法CD-GTMLL，通过将标签空间分配给多个合作玩家，引入好奇心奖励机制来解决长尾不平衡问题，在多个数据集上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 多标签学习中普遍存在长尾不平衡问题：少数头部标签主导梯度信号，而实践中重要的许多稀有标签被忽略。需要一种无需手动调整类别权重的机制来为代表性不足的标签注入梯度。

Method: 将多标签学习任务建模为合作潜在博弈，标签空间被分配给多个合作玩家，这些玩家共享全局准确度收益，同时获得随标签稀有度和玩家间分歧增加的好奇心奖励。

Result: 在传统基准测试和三个超大规模数据集上的广泛实验显示，CD-GTMLL实现了最先进的性能提升，相比最强基线提升了+4.3%的Rare-F1和+1.6%的P@3。消融研究揭示了任务分工的出现和对稀有类别的更快共识。

Conclusion: CD-GTMLL为多标签预测中的长尾鲁棒性提供了一种原则性、可扩展的解决方案，通过博弈论框架有效解决了长尾不平衡问题。

Abstract: Long-tail imbalance is endemic to multi-label learning: a few head labels
dominate the gradient signal, while the many rare labels that matter in
practice are silently ignored. We tackle this problem by casting the task as a
cooperative potential game. In our Curiosity-Driven Game-Theoretic Multi-Label
Learning (CD-GTMLL) framework, the label space is split among several
cooperating players that share a global accuracy payoff yet earn additional
curiosity rewards that rise with label rarity and inter-player disagreement.
These curiosity bonuses inject gradient on under-represented tags without
hand-tuned class weights. We prove that gradient best-response updates ascend a
differentiable potential and converge to tail-aware stationary points that
tighten a lower bound on the expected Rare-F1. Extensive experiments on
conventional benchmarks and three extreme-scale datasets show consistent
state-of-the-art gains, delivering up to +4.3% Rare-F1 and +1.6% P@3 over the
strongest baselines, while ablations reveal emergent division of labour and
faster consensus on rare classes. CD-GTMLL thus offers a principled, scalable
route to long-tail robustness in multi-label prediction.

</details>


### [367] [Mitigating Clever Hans Strategies in Image Classifiers through Generating Counterexamples](https://arxiv.org/abs/2510.17524)
*Sidney Bender,Ole Delzer,Jan Herrmann,Heike Antje Marxfeld,Klaus-Robert Müller,Grégoire Montavon*

Main category: cs.LG

TL;DR: 提出Counterfactual Knowledge Distillation (CFKD)框架，通过生成多样反事实样本，无需组标签即可解决深度学习中虚假相关性问题，在低数据场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型容易受到虚假相关性的影响，现有基于组分布鲁棒性的方法需要明确的组标签，且在多虚假相关性场景下性能急剧下降。

Method: 通过生成多样反事实样本，让人类标注者高效探索和修正模型决策边界，通过知识蒸馏步骤丰富欠采样组的数据点。

Result: 在五个数据集上验证了CFKD的有效性，特别是在低数据场景和明显虚假相关性情况下表现突出，无需混淆变量标签即可实现跨组平衡泛化。

Conclusion: CFKD框架成功解决了现有方法的局限性，在无需组标签的情况下实现了对多混淆变量的有效扩展和跨组平衡泛化。

Abstract: Deep learning models remain vulnerable to spurious correlations, leading to
so-called Clever Hans predictors that undermine robustness even in large-scale
foundation and self-supervised models. Group distributional robustness methods,
such as Deep Feature Reweighting (DFR) rely on explicit group labels to
upweight underrepresented subgroups, but face key limitations: (1) group labels
are often unavailable, (2) low within-group sample sizes hinder coverage of the
subgroup distribution, and (3) performance degrades sharply when multiple
spurious correlations fragment the data into even smaller groups. We propose
Counterfactual Knowledge Distillation (CFKD), a framework that sidesteps these
issues by generating diverse counterfactuals, enabling a human annotator to
efficiently explore and correct the model's decision boundaries through a
knowledge distillation step. Unlike DFR, our method not only reweights the
undersampled groups, but it also enriches them with new data points. Our method
does not require any confounder labels, achieves effective scaling to multiple
confounders, and yields balanced generalization across groups. We demonstrate
CFKD's efficacy across five datasets, spanning synthetic tasks to an industrial
application, with particularly strong gains in low-data regimes with pronounced
spurious correlations. Additionally, we provide an ablation study on the effect
of the chosen counterfactual explainer and teacher model, highlighting their
impact on robustness.

</details>


### [368] [TrajMamba: An Efficient and Semantic-rich Vehicle Trajectory Pre-training Model](https://arxiv.org/abs/2510.17545)
*Yichen Liu,Yan Lin,Shengnan Guo,Zeyu Zhou,Youfang Lin,Huaiyu Wan*

Main category: cs.LG

TL;DR: TrajMamba是一种用于车辆GPS轨迹学习的新方法，通过联合建模GPS和道路视角来捕获移动模式，集成旅行目的到嵌入中，并使用知识蒸馏预训练方案压缩轨迹点，在效率和准确性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 车辆GPS轨迹包含有价值的旅行语义信息，但现有方法面临两个主要挑战：旅行目的与道路功能和POI相关，文本信息处理计算负担重；真实轨迹包含冗余点，影响计算效率和嵌入质量。

Method: 提出TrajMamba方法，包括Traj-Mamba编码器联合建模GPS和道路视角，旅行目的感知预训练将旅行目的集成到嵌入中，以及知识蒸馏预训练方案通过可学习掩码生成器识别关键轨迹点。

Result: 在两个真实数据集和三个下游任务上的广泛实验表明，TrajMamba在效率和准确性上都优于最先进的基线方法。

Conclusion: TrajMamba能够有效且高效地学习车辆轨迹的语义信息，解决了轨迹数据建模中的关键挑战，为轨迹数据的实际应用提供了有力支持。

Abstract: Vehicle GPS trajectories record how vehicles move over time, storing valuable
travel semantics, including movement patterns and travel purposes. Learning
travel semantics effectively and efficiently is crucial for real-world
applications of trajectory data, which is hindered by two major challenges.
First, travel purposes are tied to the functions of the roads and
points-of-interest (POIs) involved in a trip. Such information is encoded in
textual addresses and descriptions and introduces heavy computational burden to
modeling. Second, real-world trajectories often contain redundant points, which
harm both computational efficiency and trajectory embedding quality. To address
these challenges, we propose TrajMamba, a novel approach for efficient and
semantically rich vehicle trajectory learning. TrajMamba introduces a
Traj-Mamba Encoder that captures movement patterns by jointly modeling both GPS
and road perspectives of trajectories, enabling robust representations of
continuous travel behaviors. It also incorporates a Travel Purpose-aware
Pre-training procedure to integrate travel purposes into the learned embeddings
without introducing extra overhead to embedding calculation. To reduce
redundancy in trajectories, TrajMamba features a Knowledge Distillation
Pre-training scheme to identify key trajectory points through a learnable mask
generator and obtain effective compressed trajectory embeddings. Extensive
experiments on two real-world datasets and three downstream tasks show that
TrajMamba outperforms state-of-the-art baselines in both efficiency and
accuracy.

</details>


### [369] [The Free Transformer](https://arxiv.org/abs/2510.17558)
*François Fleuret*

Main category: cs.LG

TL;DR: 提出了一种扩展的解码器Transformer，通过变分过程无监督学习随机潜在变量来条件化生成过程。


<details>
  <summary>Details</summary>
Motivation: 改进解码器Transformer的生成能力，通过引入随机潜在变量来增强模型的条件生成性能。

Method: 扩展解码器Transformer架构，引入随机潜在变量，采用变分方法进行无监督学习，使生成过程能够基于这些潜在变量进行条件化。

Result: 实验评估表明，这种条件化方法在下游任务上带来了显著改进。

Conclusion: 通过引入无监督学习的随机潜在变量来条件化Transformer的生成过程，可以有效提升模型在下游任务上的性能。

Abstract: We propose an extension of the decoder Transformer that conditions its
generative process on random latent variables which are learned without
supervision thanks to a variational procedure. Experimental evaluations show
that allowing such a conditioning translates into substantial improvements on
downstream tasks.

</details>


### [370] [Formally Exploring Time-Series Anomaly Detection Evaluation Metrics](https://arxiv.org/abs/2510.17562)
*Dennis Wagner,Arjun Nair,Billy Joe Franks,Justus Arweiler,Aparna Muraleedharan,Indra Jungjohann,Fabian Hartung,Mayank C. Ahuja,Andriy Balinskyy,Saurabh Varshneya,Nabeel Hussain Syed,Mayank Nagda,Phillip Liznerski,Steffen Reithermann,Maja Rudolph,Sebastian Vollmer,Ralf Schulz,Torsten Katz,Stephan Mandt,Michael Bortz,Heike Leitte,Daniel Neider,Jakob Burger,Fabian Jirasek,Hans Hasse,Sophie Fellenz,Marius Kloft*

Main category: cs.LG

TL;DR: 本文针对时间序列异常检测评估中现有指标存在的问题，提出了可验证的属性来形式化评估要求，建立了理论框架，分析了37个常用指标，发现大多数指标只满足少数属性，提出了满足所有属性的LARM指标及其高级变体ALARM。


<details>
  <summary>Details</summary>
Motivation: 时间序列中的未检测异常可能引发安全关键系统的灾难性故障，但现有检测方法的性能评估不清晰，当前指标只捕捉任务的狭窄方面且经常产生误导性结果。

Method: 引入可验证属性来形式化评估时间序列异常检测的基本要求，建立理论框架支持原则性评估和可靠比较，分析37个广泛使用的指标，提出满足所有属性的LARM指标及其高级变体ALARM。

Result: 分析显示大多数现有指标只满足少数属性，没有指标满足所有属性，这解释了先前结果中持续存在的不一致性。LARM指标被证明满足所有属性，ALARM变体满足更严格的要求。

Conclusion: 通过引入形式化属性和理论框架，解决了时间序列异常检测评估中的根本问题，提出的LARM和ALARM指标为可靠评估和比较提供了基础。

Abstract: Undetected anomalies in time series can trigger catastrophic failures in
safety-critical systems, such as chemical plant explosions or power grid
outages. Although many detection methods have been proposed, their performance
remains unclear because current metrics capture only narrow aspects of the task
and often yield misleading results. We address this issue by introducing
verifiable properties that formalize essential requirements for evaluating
time-series anomaly detection. These properties enable a theoretical framework
that supports principled evaluations and reliable comparisons. Analyzing 37
widely used metrics, we show that most satisfy only a few properties, and none
satisfy all, explaining persistent inconsistencies in prior results. To close
this gap, we propose LARM, a flexible metric that provably satisfies all
properties, and extend it to ALARM, an advanced variant meeting stricter
requirements.

</details>


### [371] [An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning](https://arxiv.org/abs/2510.17564)
*Lindsay Spoor,Álvaro Serra-Gómez,Aske Plaat,Thomas Moerland*

Main category: cs.LG

TL;DR: 本文分析了安全强化学习中拉格朗日乘子的最优性和稳定性，发现自动更新乘子能够恢复甚至超过最优性能，但存在振荡行为，可通过PID控制缓解但需要仔细调参。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域中，约束优化问题需要平衡性能最大化与约束条件。拉格朗日方法是常用方法，但其效果严重依赖于拉格朗日乘子λ的选择，而自动更新乘子的鲁棒性和对性能的影响缺乏实证证据。

Method: 分析拉格朗日乘子在安全强化学习中的最优性和稳定性，提供λ-配置文件可视化优化问题中回报与约束成本之间的权衡关系，研究自动乘子更新和PID控制更新的效果。

Result: λ-配置文件显示λ具有高度敏感性，缺乏选择最优值λ*的通用直觉。自动乘子更新能够恢复甚至超过λ*的最优性能，但表现出振荡行为。PID控制更新可以缓解振荡但需要仔细调参。

Conclusion: 拉格朗日乘子在安全强化学习中具有高度敏感性，自动更新方法虽然有效但存在稳定性问题，需要进一步研究拉格朗日方法的稳定化技术。

Abstract: In safety-critical domains such as robotics, navigation and power systems,
constrained optimization problems arise where maximizing performance must be
carefully balanced with associated constraints. Safe reinforcement learning
provides a framework to address these challenges, with Lagrangian methods being
a popular choice. However, the effectiveness of Lagrangian methods crucially
depends on the choice of the Lagrange multiplier $\lambda$, which governs the
trade-off between return and constraint cost. A common approach is to update
the multiplier automatically during training. Although this is standard in
practice, there remains limited empirical evidence on the robustness of an
automated update and its influence on overall performance. Therefore, we
analyze (i) optimality and (ii) stability of Lagrange multipliers in safe
reinforcement learning across a range of tasks. We provide $\lambda$-profiles
that give a complete visualization of the trade-off between return and
constraint cost of the optimization problem. These profiles show the highly
sensitive nature of $\lambda$ and moreover confirm the lack of general
intuition for choosing the optimal value $\lambda^*$. Our findings additionally
show that automated multiplier updates are able to recover and sometimes even
exceed the optimal performance found at $\lambda^*$ due to the vast difference
in their learning trajectories. Furthermore, we show that automated multiplier
updates exhibit oscillatory behavior during training, which can be mitigated
through PID-controlled updates. However, this method requires careful tuning to
achieve consistently better performance across tasks. This highlights the need
for further research on stabilizing Lagrangian methods in safe reinforcement
learning. The code used to reproduce our results can be found at
https://github.com/lindsayspoor/Lagrangian_SafeRL.

</details>


### [372] [CEPerFed: Communication-Efficient Personalized Federated Learning for Multi-Pulse MRI Classification](https://arxiv.org/abs/2510.17584)
*Ludi Li,Junbin Mao,Hanhe Lin,Xu Tian,Fang-Xiang Wu,Jin Liu*

Main category: cs.LG

TL;DR: 提出了一种通信高效的个性化联邦学习方法CEPerFed，用于多脉冲MRI分类，通过客户端历史风险梯度和历史平均梯度协调本地和全局优化，并使用分层SVD策略减少通信开销。


<details>
  <summary>Details</summary>
Motivation: 多脉冲MRI在临床实践中广泛应用，但训练鲁棒模型需要大量多样化数据且需保护隐私。联邦学习虽然可行，但面临数据异构性导致的模型收敛问题和大量参数传输带来的通信开销挑战。

Method: CEPerFed方法结合客户端历史风险梯度（加权其他客户端贡献）和历史平均梯度（确保本地更新与全局优化方向一致）来协调优化。采用分层SVD策略仅传输模型更新所需的最关键信息。

Result: 在五个分类任务上的实验证明了CEPerFed方法的有效性。

Conclusion: CEPerFed通过协调本地和全局优化以及减少通信开销，有效解决了联邦学习中的数据异构性和通信效率问题。

Abstract: Multi-pulse magnetic resonance imaging (MRI) is widely utilized for clinical
practice such as Alzheimer's disease diagnosis. To train a robust model for
multi-pulse MRI classification, it requires large and diverse data from various
medical institutions while protecting privacy by preventing raw data sharing
across institutions. Although federated learning (FL) is a feasible solution to
address this issue, it poses challenges of model convergence due to the effect
of data heterogeneity and substantial communication overhead due to large
numbers of parameters transmitted within the model. To address these
challenges, we propose CEPerFed, a communication-efficient personalized FL
method. It mitigates the effect of data heterogeneity by incorporating
client-side historical risk gradients and historical mean gradients to
coordinate local and global optimization. The former is used to weight the
contributions from other clients, enhancing the reliability of local updates,
while the latter enforces consistency between local updates and the global
optimization direction to ensure stable convergence across heterogeneous data
distributions. To address the high communication overhead, we propose a
hierarchical SVD (HSVD) strategy that transmits only the most critical
information required for model updates. Experiments on five classification
tasks demonstrate the effectiveness of the CEPerFed method. The code will be
released upon acceptance at https://github.com/LD0416/CEPerFed.

</details>


### [373] [On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active Marginal-Samples Exploration](https://arxiv.org/abs/2510.17670)
*Yehonathan Refael,Amit Aides,Aviad Barzilai,George Leifman,Genady Beryozkin,Vered Silverman,Bolous Jaber,Tomer Shekel*

Main category: cs.LG

TL;DR: 提出了一种级联方法，将预训练开放词汇目标检测模型与轻量级少样本分类器结合，通过FLAME主动学习策略选择信息量最大的样本进行训练，实现在遥感图像中的快速适应和高精度检测。


<details>
  <summary>Details</summary>
Motivation: 解决开放词汇目标检测模型在遥感等专业领域中由于自然语言模糊性导致的细粒度类别区分困难问题，如无法准确区分"渔船"和"游艇"等相似类别，影响下游应用效果。

Method: 采用级联方法：首先使用零-shot模型生成高召回率的候选框，然后通过轻量级分类器进行精炼；核心是FLAME主动学习策略，通过密度估计识别决策边界附近的不确定样本，并结合聚类确保样本多样性。

Result: 方法在遥感基准测试中持续超越最先进性能，能够在不到一分钟内完成即时适应，显著快于现有替代方案，且无需昂贵的完整模型微调。

Conclusion: 建立了一个实用且资源高效的框架，使基础模型能够快速适应特定用户需求，在遥感领域实现了高精度的开放词汇目标检测。

Abstract: Open-vocabulary object detection (OVD) models offer remarkable flexibility by
detecting objects from arbitrary text queries. However, their zero-shot
performance in specialized domains like Remote Sensing (RS) is often
compromised by the inherent ambiguity of natural language, limiting critical
downstream applications. For instance, an OVD model may struggle to distinguish
between fine-grained classes such as "fishing boat" and "yacht" since their
embeddings are similar and often inseparable. This can hamper specific user
goals, such as monitoring illegal fishing, by producing irrelevant detections.
To address this, we propose a cascaded approach that couples the broad
generalization of a large pre-trained OVD model with a lightweight few-shot
classifier. Our method first employs the zero-shot model to generate
high-recall object proposals. These proposals are then refined for high
precision by a compact classifier trained in real-time on only a handful of
user-annotated examples - drastically reducing the high costs of RS imagery
annotation.The core of our framework is FLAME, a one-step active learning
strategy that selects the most informative samples for training. FLAME
identifies, on the fly, uncertain marginal candidates near the decision
boundary using density estimation, followed by clustering to ensure sample
diversity. This efficient sampling technique achieves high accuracy without
costly full-model fine-tuning and enables instant adaptation, within less then
a minute, which is significantly faster than state-of-the-art alternatives.Our
method consistently surpasses state-of-the-art performance on RS benchmarks,
establishing a practical and resource-efficient framework for adapting
foundation models to specific user needs.

</details>


### [374] [Efficient Algorithms for Mitigating Uncertainty and Risk in Reinforcement Learning](https://arxiv.org/abs/2510.17690)
*Xihong Su*

Main category: cs.LG

TL;DR: 本文提出了三个主要贡献：1）建立了策略梯度与动态规划的新联系，提出CADP算法；2）建立了ERM Bellman算子的收缩条件，提出了指数值迭代等算法；3）提出了无模型Q学习算法用于风险规避目标，证明了收敛性。


<details>
  <summary>Details</summary>
Motivation: 研究马尔可夫决策过程中的风险规避策略优化问题，特别是在模型不确定性和风险敏感目标下的策略计算方法。

Method: 1）CADP算法通过迭代调整模型权重实现单调策略改进；2）分析ERM Bellman算子收缩性，提出指数值迭代、策略迭代和线性规划算法；3）开发无模型Q学习算法处理风险规避目标。

Result: 证明了ERM-TRC和EVaR-TRC存在平稳确定性最优策略，提出的Q学习算法能收敛到最优风险规避值函数，CADP算法能保证单调改进到局部最优。

Conclusion: 本文为风险规避的马尔可夫决策过程提供了理论分析和有效算法，包括有模型和无模型方法，解决了ERM Bellman算子非收缩性的挑战，实现了最优风险规避策略的计算。

Abstract: This dissertation makes three main contributions. First, We identify a new
connection between policy gradient and dynamic programming in MMDPs and propose
the Coordinate Ascent Dynamic Programming (CADP) algorithm to compute a Markov
policy that maximizes the discounted return averaged over the uncertain models.
CADP adjusts model weights iteratively to guarantee monotone policy
improvements to a local maximum. Second, We establish sufficient and necessary
conditions for the exponential ERM Bellman operator to be a contraction and
prove the existence of stationary deterministic optimal policies for ERM-TRC
and EVaR-TRC. We also propose exponential value iteration, policy iteration,
and linear programming algorithms for computing optimal stationary policies for
ERM-TRC and EVaR-TRC. Third, We propose model-free Q-learning algorithms for
computing policies with risk-averse objectives: ERM-TRC and EVaR-TRC. The
challenge is that Q-learning ERM Bellman may not be a contraction. Instead, we
use the monotonicity of Q-learning ERM Bellman operators to derive a rigorous
proof that the ERM-TRC and the EVaR-TRC Q-learning algorithms converge to the
optimal risk-averse value functions. The proposed Q-learning algorithms compute
the optimal stationary policy for ERM-TRC and EVaR-TRC.

</details>


### [375] [Enabling Fine-Grained Operating Points for Black-Box LLMs](https://arxiv.org/abs/2510.17727)
*Ege Beyazit,KL Navaneet,Prashant Mathur,Roi Blanco,Vidit Bansal,Karim Bouyarmane*

Main category: cs.LG

TL;DR: 本文研究如何提升黑盒大语言模型作为分类器时的操作粒度，通过分析其低基数数值输出的原因，并提出了有效方法来显著增加可用操作点数量和多样性，而不损失性能。


<details>
  <summary>Details</summary>
Motivation: 黑盒大语言模型在需要特定指标约束的应用中表现不佳，因为其数值输出基数低，限制了操作点的控制能力，无法精细调整决策行为。

Method: 首先分析LLM低基数数值输出的原因，发现其偏向生成四舍五入但信息丰富的语言化概率；然后实验标准提示工程、不确定性估计和置信度提取技术；最后提出有效方法显著增加可用操作点数量和多样性。

Result: 在11个数据集和3个LLM上的实验表明，所提方法提供了更细粒度的操作点，性能与基准方法相当或更好。

Conclusion: 提出的方法能有效提升黑盒LLM作为分类器时的操作粒度，实现更精细的决策行为调整，且不牺牲性能或增加推理成本。

Abstract: Black-box Large Language Models (LLMs) provide practical and accessible
alternatives to other machine learning methods, as they require minimal labeled
data and machine learning expertise to develop solutions for various decision
making problems. However, for applications that need operating with constraints
on specific metrics (e.g., precision $\geq$ 95%), decision making with
black-box LLMs remains unfavorable, due to their low numerical output
cardinalities. This results in limited control over their operating points,
preventing fine-grained adjustment of their decision making behavior. In this
paper, we study using black-box LLMs as classifiers, focusing on efficiently
improving their operational granularity without performance loss. Specifically,
we first investigate the reasons behind their low-cardinality numerical outputs
and show that they are biased towards generating rounded but informative
verbalized probabilities. Then, we experiment with standard prompt engineering,
uncertainty estimation and confidence elicitation techniques, and observe that
they do not effectively improve operational granularity without sacrificing
performance or increasing inference cost. Finally, we propose efficient
approaches to significantly increase the number and diversity of available
operating points. Our proposed approaches provide finer-grained operating
points and achieve comparable to or better performance than the benchmark
methods across 11 datasets and 3 LLMs.

</details>


### [376] [Atlas-based Manifold Representations for Interpretable Riemannian Machine Learning](https://arxiv.org/abs/2510.17772)
*Ryan A. Robinett,Sophia A. Madejski,Kyle Ruark,Samantha J. Riesenfeld,Lorenzo Orecchia*

Main category: cs.LG

TL;DR: 本文提出了一种基于微分图册的流形学习方法，通过维护可微分图册实现流形上的黎曼优化，在效率和准确性方面具有优势，并在分类任务和RNA速度分析中展示了更好的可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管流形假设很流行，但当前的流形学习方法主要关注降维到欧几里得空间，当嵌入维度接近流形维度时会丢失关键特征。直接学习潜在流形作为微分图册的方法相对较少被探索。

Method: 实现了一个通用的数据结构来维护可微分图册，支持流形上的黎曼优化，并结合无监督启发式方法从点云数据中学习微分图册。

Result: 实验证明该方法在选定场景下具有效率和准确性优势，在Klein瓶上的监督分类任务和造血数据的RNA速度分析中展示了改进的可解释性和鲁棒性。

Conclusion: 基于图册的方法在流形学习方面具有有效性和潜力，为直接处理潜在流形数据提供了新的可能性。

Abstract: Despite the popularity of the manifold hypothesis, current manifold-learning
methods do not support machine learning directly on the latent $d$-dimensional
data manifold, as they primarily aim to perform dimensionality reduction into
$\mathbb{R}^D$, losing key manifold features when the embedding dimension $D$
approaches $d$.
  On the other hand, methods that directly learn the latent manifold as a
differentiable atlas have been relatively underexplored.
  In this paper, we aim to give a proof of concept of the effectiveness and
potential of atlas-based methods. To this end, we implement a generic data
structure to maintain a differentiable atlas that enables Riemannian
optimization over the manifold. We complement this with an unsupervised
heuristic that learns a differentiable atlas from point cloud data. We
experimentally demonstrate that this approach has advantages in terms of
efficiency and accuracy in selected settings. Moreover, in a supervised
classification task over the Klein bottle and in RNA velocity analysis of
hematopoietic data, we showcase the improved interpretability and robustness of
our approach.

</details>


### [377] [Inference-Time Compute Scaling For Flow Matching](https://arxiv.org/abs/2510.17786)
*Adam Stecklov,Noah El Rimawi-Fine,Mathieu Blanchette*

Main category: cs.LG

TL;DR: 本文提出了在推理时保持线性插值的流匹配推理时间缩放方法，在图像生成和无条件蛋白质生成任务中验证了样本质量随推理计算量增加而提升，并首次将流匹配推理时间缩放应用于科学领域。


<details>
  <summary>Details</summary>
Motivation: 当前流匹配方法在推理时间缩放方面研究不足，现有方法使用非线性插值会牺牲流匹配的高效采样特性，且推理时间缩放仅应用于视觉任务。本文旨在开发保持线性插值的推理时间缩放方法，并将其扩展到科学领域。

Method: 提出了新颖的流匹配推理时间缩放程序，在采样过程中保持线性插值，不采用非线性方差保持插值。

Result: 在图像生成和无条件蛋白质生成任务上的评估表明：1）样本质量随推理计算量增加而持续改善；2）流匹配推理时间缩放可成功应用于科学领域。

Conclusion: 本文提出的方法成功实现了在保持线性插值的同时进行推理时间缩放，首次将流匹配推理时间缩放应用于蛋白质生成等科学领域，证明了该方法在科学应用中的可行性。

Abstract: Allocating extra computation at inference time has recently improved sample
quality in large language models and diffusion-based image generation. In
parallel, Flow Matching (FM) has gained traction in language, vision, and
scientific domains, but inference-time scaling methods for it remain
under-explored. Concurrently, Kim et al., 2025 approach this problem but
replace the linear interpolant with a non-linear variance-preserving (VP)
interpolant at inference, sacrificing FM's efficient and straight sampling.
Additionally, inference-time compute scaling for flow matching has only been
applied to visual tasks, like image generation. We introduce novel
inference-time scaling procedures for FM that preserve the linear interpolant
during sampling. Evaluations of our method on image generation, and for the
first time (to the best of our knowledge), unconditional protein generation,
show that I) sample quality consistently improves as inference compute
increases, and II) flow matching inference-time scaling can be applied to
scientific domains.

</details>


### [378] [Unbiased Gradient Low-Rank Projection](https://arxiv.org/abs/2510.17802)
*Rui Pan,Yang Luo,Yuxing Liu,Yang You,Tong Zhang*

Main category: cs.LG

TL;DR: 提出了一种名为GUM的无偏低秩优化方法，通过层间采样技术消除低秩投影的偏差，在保持内存效率的同时实现与全参数训练相当甚至更好的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有低秩优化方法（如GaLore）缺乏收敛保证的问题，这些方法由于低秩投影引入的偏差导致性能与全参数训练存在差距。

Method: 基于GaLore机制和Muon算法，采用层间采样技术来消除低秩投影的偏差，开发了GUM方法。

Result: 理论证明GUM方法保持了Muon算法的收敛保证，同时保持了低秩技术的内存效率。实验在LLM微调和预训练中显示优于GaLore，甚至超过全参数训练的性能。

Conclusion: 该技术通过更均匀的层内知识分布，实现了模型参数空间的更高效利用和更好的记忆能力，为内存高效的大语言模型训练提供了有效解决方案。

Abstract: Memory-efficient optimization is critical for training increasingly large
language models (LLMs). A popular strategy involves gradient low-rank
projection, storing only the projected optimizer states, with GaLore being a
representative example. However, a significant drawback of many such methods is
their lack of convergence guarantees, as various low-rank projection approaches
introduce inherent biases relative to the original optimization algorithms,
which contribute to performance gaps compared to full-parameter training.
Aiming to tackle this problem, this paper investigates the layerwise sampling
technique for debiasing low-rank projection mechanisms. In particular, an
instantiation of the paradigm gives rise to a novel and unbiased low-rank
optimization method built upon GaLore's mechanism and the Muon algorithm, named
GaLore Unbiased with Muon (GUM). We theoretically prove our method matches the
convergence guarantees of the base Muon algorithm while preserving the memory
efficiency of low-rank techniques. Empirical experiments on LLM fine-tuning and
pretraining also demonstrate non-trivial improvements over GaLore and even
better performance than full-parameter training. Further investigation shows
that the improvement of this technique comes from a more uniform distribution
of knowledge inside layers, leading to more efficient utilization of the model
parameter space and better memorization.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [379] [Design of Magnetic Lattices with Quantum Optimization Algorithms](https://arxiv.org/abs/2510.16349)
*Zekeriya Ender Eğer,Waris Khan,Priyabrata Maharana,Kandula Eswara Sai Kumar,Udbhav Sharma,Abhishek Chopra,Rut Lineswala,Pınar Acar*

Main category: physics.comp-ph

TL;DR: 本文研究通过最小化系统自由能来识别铁磁材料中的磁自旋分布。使用量子优化算法BQP解决高维计算难题，并在大尺度系统（如50×50晶格）中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理大尺度磁晶格自旋分布识别问题时计算复杂度高，难以实现，需要开发更高效的优化算法。

Method: 构建不同尺寸的磁晶格，使用考虑自旋-自旋邻居相互作用和外磁场影响的Ising模型计算自由能，采用量子优化算法BQP解决高维优化问题，并与遗传算法结果进行对比验证。

Result: BQP算法在小晶格上与遗传算法结果一致，成功扩展到50×50大尺度系统，解决了传统方法无法处理的高维计算问题。

Conclusion: 量子优化算法BQP为识别大尺度铁磁材料自旋分布提供了有效的解决方案，克服了传统方法的计算限制。

Abstract: This article investigates the identification of magnetic spin distributions
in ferromagnetic materials by minimizing the system's free energy. Magnetic
lattices of varying sizes are constructed, and the free energy is computed
using an Ising model that accounts for spin-to-spin neighbor interactions and
the influence of an external magnetic field. The problem reduces to determining
the state of each spin, either up or down, leading to an optimization problem
with $2^{n \times n}$ design variables for an $n \times n$ lattice. To address
the high-dimensional and computationally intractable nature of this problem,
particularly for large domains, we employ a quantum optimization algorithm,
BQP. The BQP results are first validated against solutions obtained using a
genetic algorithm for smaller lattices. Finally, the approach is extended to
large-scale systems, including $50 \times 50$ lattices, where conventional
methods become impractical.

</details>


### [380] [Extended phase-space symplectic integration for electron dynamics](https://arxiv.org/abs/2510.16542)
*Francois Mauger,Cristel Chandre*

Main category: physics.comp-ph

TL;DR: 本文研究了扩展相空间辛积分在两类电子动力学模拟中的应用：等离子体物理中的带电粒子动力学和物理化学中的Kohn-Sham时变密度泛函理论，提出了数值积分的扩展程序和稳定性条件，并开发了实时精度评估方法。


<details>
  <summary>Details</summary>
Motivation: 研究扩展相空间辛积分方法在经典和量子哈密顿系统中的应用，特别是针对具有有限和无限自由度的电子动力学系统，旨在提高数值模拟的准确性和效率。

Method: 采用高阶辛分裂算子方案，为两类电子动力学系统（1.5自由度的等离子体物理系统和无限自由度的Kohn-Sham时变密度泛函理论）制定了扩展程序和数值积分稳定性条件。

Result: 开发了一种计算成本低廉的度量标准，可用于实时估计模拟的准确性，为辛分裂算子积分在经典和量子哈密顿系统中的广泛应用奠定了基础。

Conclusion: 扩展相空间辛积分方法为具有有限和无限自由度的经典和量子哈密顿系统的辛分裂算子积分提供了广阔的应用前景。

Abstract: We investigate the use of extended phase-space symplectic integration [M.
Tao, Phys. Rev. E 94, 043303 (2016)] for simulating two different classes of
electron dynamics. The first one, with one and a half degrees of freedom, comes
from plasma physics and describes the classical dynamics of a charged particle
in a strong, constant, and uniform magnetic field perturbed by a turbulent
electrostatic potential. The second one, with an infinite number of degrees of
freedom, comes from physical chemistry and corresponds to Kohn-Sham
time-dependent density-functional theory. For both we lay out the extension
procedure and stability condition for numerical integration of the dynamics
using high-order symplectic split-operator schemes. We also identify a
computationally inexpensive metric that can be used for on-the-fly estimation
of the accuracy of simulations. Our work paves the way for broad application of
symplectic split-operator integration of classical and quantum Hamiltonian
systems with finite and infinite number of degrees of freedom.

</details>


### [381] [Scalable cell filter nudged elastic band (CFNEB) for large-scale transition-path calculations](https://arxiv.org/abs/2510.16721)
*Qiuhan Jia,Jiuyang Shi,Jian Sun*

Main category: physics.comp-ph

TL;DR: 提出了一种可扩展的细胞过滤弹性带（CFNEB）方法，用于在包含多达10^5个原子的大系统中高效计算过渡路径，解决了传统NEB方法计算规模随系统尺寸急剧增加的问题。


<details>
  <summary>Details</summary>
Motivation: 传统NEB方法在计算大规模系统（如成核型转变）时面临计算规模急剧增加的挑战，使得在现实大超胞中的计算变得不切实际。

Method: 结合基于变形的细胞过滤方案（将晶格向量作为广义坐标处理并去除虚假旋转自由度）和自适应图像插入删除策略，动态优化反应路径。在ASE环境和GPU加速的GPUMD引擎中实现。

Result: 在消费级GPU上实现了约10^6原子·步/秒的吞吐量。在Ti3O5的层间β-λ转变和石墨到金刚石的成核驱动转变中验证了方法有效性，不仅重现了已知的协同路径，还能在足够大的模拟胞中捕捉到向成核机制的自发对称性破缺。

Conclusion: CFNEB为探索大规模固态系统中现实转变机制提供了一条实用途径。

Abstract: The nudged elastic band (NEB) method is one of the most widely used
techniques for determining minimum-energy reaction pathways and activation
barriers between known initial and final states. However, conventional
implementations face steep computational scaling with system size, which makes
nucleation-type transitions in realistically large supercells practically
inaccessible. In this work, we develop a scalable cell-filter nudged elastic
band (CFNEB) framework that enables efficient transition-path calculations in
systems containing up to $10^5$ atoms. The method combines a deformation-based
cell filtering scheme, which treats lattice vectors as generalized coordinates
while removing spurious rotational degrees of freedom, with an adaptive image
insertion and deletion strategy that dynamically refines the reaction path. We
implement CFNEB both within the ASE environment and in a fully GPU-accelerated
version using the Graphics Processing Units Molecular Dynamics (GPUMD) engine,
achieving throughput on the order of $10^6$ atom$\cdot$steps per second on
consumer GPUs. We demonstrate the method on two representative systems: the
layer-by-layer $\beta$-$\lambda$ transition in $Ti_3O_5$ and the
nucleation-driven graphite-to-diamond transformation. These examples illustrate
that CFNEB not only reproduces known concerted pathways but also captures
spontaneous symmetry breaking toward nucleated mechanisms when the simulation
cell is sufficiently large. Our results establish CFNEB as a practical route to
exploring realistic transition mechanisms in large-scale solid-state systems.

</details>


### [382] [Large-scale stochastic propagation method beyond the sequential approach](https://arxiv.org/abs/2510.17432)
*Zhichang Fu,Yunhai Li,Weiqing Zhou,Shengjun Yuan*

Main category: physics.comp-ph

TL;DR: 提出了一种并行的随机传播方法，替代传统的顺序计算中间态，在紧束缚模型下对10亿原子系统实现了数量级加速，突破了时间步长限制并保持精度。


<details>
  <summary>Details</summary>
Motivation: 传统的O(N)随机传播方法依赖时间相关薛定谔方程的数值解，需要顺序计算中间态，存在信息冗余问题，限制了计算效率。

Method: 引入并发策略最小化信息冗余，提出了基于状态、矩和能量的并行实现方法，在Nyquist-Shannon采样定理框架内保持精度。

Result: 在10亿原子紧束缚模型上的系统基准测试显示，新并发方法实现了高达一个数量级的加速，能够快速计算电子、光学和输运性质。

Conclusion: 这一性能突破为增强其他时间传播算法（包括大规模随机密度泛函理论中使用的算法）提供了有价值的见解。

Abstract: The $O(N)$ stochastic propagation method, which relies on the numerical
solution of the time-dependent Schr\"odinger equation using random initial
states, is widely used in large-scale first-principles calculations. In this
work, we eliminate the conventional sequential computation of intermediate
states by introducing a concurrent strategy that minimizes information
redundancy. The new method, in its state-, moment-, and energy-based
implementations, not only surpasses the time step constraint of sequential
propagation but also maintains precision within the framework of the
Nyquist-Shannon sampling theorem. Systematic benchmarking on one billion atoms
within the tight-binding model demonstrates that our new concurrent method
achieves up to an order-of-magnitude speedup, enabling the rapid computation of
a wide range of electronic, optical, and transport properties. This performance
breakthrough offers valuable insights for enhancing other time-propagation
algorithms, including those employed in large-scale stochastic density
functional theory.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [383] [Lung Cancer Classification from CT Images Using ResNet](https://arxiv.org/abs/2510.16310)
*Olajumoke O. Adekunle,Joseph D. Akinyemi,Khadijat T. Ladoja,Olufade F. W. Onifade*

Main category: eess.IV

TL;DR: 提出一种基于ResNet的深度学习新方法，用于从CT图像中进行肺癌多分类（三种亚型），在LC25000数据集上达到98.8%的测试准确率，显著优于先前模型。


<details>
  <summary>Details</summary>
Motivation: 现有肺癌分类研究主要关注良恶性二分类，而临床需要更精细的亚型分类。当前自动分类系统的预测效果尚未达到临床应用标准。

Method: 使用预训练的ResNet50模型，在LC25000数据集（15,000张肺部CT图像）上进行训练，通过添加自定义层和精细调优超参数，实现三种肺癌亚型的分类。

Result: 模型在测试集（2,250张图像）上达到98.8%的准确率，相比先前模型有显著提升。

Conclusion: 该方法在肺癌多分类任务中表现出色，准确率接近临床应用要求，为肺癌精准诊断提供了有效工具。

Abstract: Lung cancer, a malignancy originating in lung tissues, is commonly diagnosed
and classified using medical imaging techniques, particularly computed
tomography (CT). Despite the integration of machine learning and deep learning
methods, the predictive efficacy of automated systems for lung cancer
classification from CT images remains below the desired threshold for clinical
adoption. Existing research predominantly focuses on binary classification,
distinguishing between malignant and benign lung nodules. In this study, a
novel deep learning-based approach is introduced, aimed at an improved
multi-class classification, discerning various subtypes of lung cancer from CT
images. Leveraging a pre-trained ResNet model, lung tissue images were
classified into three distinct classes, two of which denote malignancy and one
benign. Employing a dataset comprising 15,000 lung CT images sourced from the
LC25000 histopathological images, the ResNet50 model was trained on 10,200
images, validated on 2,550 images, and tested on the remaining 2,250 images.
Through the incorporation of custom layers atop the ResNet architecture and
meticulous hyperparameter fine-tuning, a remarkable test accuracy of 98.8% was
recorded. This represents a notable enhancement over the performance of prior
models on the same dataset.

</details>


### [384] [Computer Navigated Spinal Surgery Using Magnetic Resonance Imaging and Augmented Reality](https://arxiv.org/abs/2510.16347)
*Songyuan Lu,Jingwen Hui,Jake Weeks,David B. Berry,Fanny Chapelin,Frank Talke*

Main category: eess.IV

TL;DR: 本文研究了一种无辐射的脊柱疼痛管理手术导航系统，结合MRI和基于ArUco标记的增强现实技术，用于替代依赖荧光透视的传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前脊柱疼痛管理程序（如射频消融和硬膜外类固醇注射）依赖荧光透视进行针头放置，使患者和医生暴露于电离辐射。

Method: 获取腰椎脊柱模型的高分辨率MRI扫描并组装为表面网格，应用拉普拉斯平滑算法改善模型保真度。使用商用立体相机跟踪患者身上的ArUco标记来确定实时姿态，通过自定义AR软件将MRI图像叠加到患者身上。

Result: 在3D打印的3椎体模型上进行针插入试验，双ArUco标记跟踪提高了针插入的准确性，减少了平均针错位距离，平均针错位与传统荧光透视硬膜外技术的平均偏差2mm相当。

Conclusion: 这种无辐射系统通过改进图像引导的脊柱导航，有望作为荧光透视的替代方案。

Abstract: Current spinal pain management procedures, such as radiofrequency ablation
(RFA) and epidural steroid injection (ESI), rely on fluoroscopy for needle
placement which exposes patients and physicians to ionizing radiation. In this
paper, we investigate a radiation-free surgical navigation system for spinal
pain management procedures that combines magnetic resonance imaging (MRI) with
fiducial ArUco marker-based augmented reality (AR). High-resolution MRI scans
of a lumbar spinal phantom were obtained and assembled as a surface mesh.
Laplacian smoothing algorithms were then applied to smoothen the surface and
improve the model fidelity. A commercially available stereo camera (ZED2) was
used to track single or dual fiducial ArUco markers on the patient to determine
the patient's real-time pose. Custom AR software was applied to overlay the MRI
image onto the patient, allowing the physician to see not only the outer
surface of the patient but also the complete anatomy of the patient below the
surface. Needle-insertion trials on a 3D-printed 3-vertebra phantom showed that
dual-ArUco marker tracking increased the accuracy of needle insertions and
reduced the average needle misplacement distance compared to single-ArUco
marker procedures. The average needle misplacement is comparable to the average
deviation of 2 mm for conventional epidural techniques using fluoroscopy. Our
radiation-free system demonstrates promise to serve as an alternative to
fluoroscopy by improving image-guided spinal navigation.

</details>


### [385] [FSAR-Cap: A Fine-Grained Two-Stage Annotated Dataset for SAR Image Captioning](https://arxiv.org/abs/2510.16394)
*Jinqi Zhang,Lamei Zhang,Bin Zou*

Main category: eess.IV

TL;DR: 本文提出了FSAR-Cap，一个大规模合成孔径雷达图像描述数据集，包含14,480张图像和72,400个图像-文本对，通过两阶段标注策略构建，为SAR图像语义理解提供高质量数据支持。


<details>
  <summary>Details</summary>
Motivation: 合成孔径雷达图像描述在军事情报和城市规划等应用中具有重要作用，但其发展受到高质量数据集稀缺的限制。

Method: 基于FAIR-CSAR检测数据集，采用两阶段标注策略，结合分层模板表示、人工验证补充和提示标准化来构建数据集。

Result: 与现有资源相比，FSAR-Cap提供更丰富的细粒度标注、更广的类别覆盖和更高的标注质量。通过多种编码器-解码器架构的基准测试验证了其有效性。

Conclusion: FSAR-Cap为SAR图像描述和智能图像解译的未来研究奠定了基础。

Abstract: Synthetic Aperture Radar (SAR) image captioning enables scene-level semantic
understanding and plays a crucial role in applications such as military
intelligence and urban planning, but its development is limited by the scarcity
of high-quality datasets. To address this, we present FSAR-Cap, a large-scale
SAR captioning dataset with 14,480 images and 72,400 image-text pairs. FSAR-Cap
is built on the FAIR-CSAR detection dataset and constructed through a two-stage
annotation strategy that combines hierarchical template-based representation,
manual verification and supplementation, prompt standardization. Compared with
existing resources, FSAR-Cap provides richer fine-grained annotations, broader
category coverage, and higher annotation quality. Benchmarking with multiple
encoder-decoder architectures verifies its effectiveness, establishing a
foundation for future research in SAR captioning and intelligent image
interpretation.

</details>


### [386] [Dictionary-Based Deblurring for Unpaired Data](https://arxiv.org/abs/2510.16428)
*Alok Panigrahi,Jayaprakash Katual,Satish Mulleti*

Main category: eess.IV

TL;DR: 提出了一种基于字典学习的图像去模糊方法，能够在不同数据监督程度下进行鲁棒的去模糊处理，包括全监督、部分监督和无监督三种场景。


<details>
  <summary>Details</summary>
Motivation: 现实世界中获取精确对齐的模糊-清晰图像对数据存在困难，限制了现有去模糊方法的有效性和泛化能力，需要解决数据稀缺依赖问题。

Method: 基于字典学习的去模糊框架，联合估计结构化模糊矩阵和高分辨率图像字典，支持不同监督程度的学习设置。

Result: 在CMU-Cornell iCoseg数据集和真实世界FocusPath数据集上的实验验证表明，该方法相比传统耦合字典学习方法具有优越性能，能够在较少训练样本下实现准确的模糊建模和自适应字典表示。

Conclusion: 该方法为数据受限场景下的图像去模糊提供了高效鲁棒的解决方案，通过准确的模糊建模和自适应字典表示，显著减少了对训练样本数量的依赖。

Abstract: Effective image deblurring typically relies on large and fully paired
datasets of blurred and corresponding sharp images. However, obtaining such
accurately aligned data in the real world poses a number of difficulties,
limiting the effectiveness and generalizability of existing deblurring methods.
To address this scarcity of data dependency, we present a novel dictionary
learning based deblurring approach for jointly estimating a structured blur
matrix and a high resolution image dictionary. This framework enables robust
image deblurring across different degrees of data supervision. Our method is
thoroughly evaluated across three distinct experimental settings: (i) full
supervision involving paired data with explicit correspondence, (ii) partial
supervision employing unpaired data with implicit relationships, and (iii)
unsupervised learning using non-correspondence data where direct pairings are
absent. Extensive experimental validation, performed on synthetically blurred
subsets of the CMU-Cornell iCoseg dataset and the real-world FocusPath dataset,
consistently shows that the proposed framework has superior performance
compared to conventional coupled dictionary learning approaches. The results
validate that our approach provides an efficient and robust solution for image
deblurring in data-constrained scenarios by enabling accurate blur modeling and
adaptive dictionary representation with a notably smaller number of training
samples.

</details>


### [387] [A Low-Complexity View Synthesis Distortion Estimation Method for 3D Video with Large Baseline Considerations](https://arxiv.org/abs/2510.17037)
*Chongyuan Bi,Jie Liang*

Main category: eess.IV

TL;DR: 提出了一种低复杂度、无需训练的方法来准确估计合成视图的失真，无需实际执行渲染过程。该方法通过纹理-深度联合分类、基线距离补偿和区域混合估计策略，在大基线配置下实现高精度失真估计。


<details>
  <summary>Details</summary>
Motivation: 现有的视图合成失真估计方法计算量大、需要参数训练，或在大基线配置下性能较差。需要一种高效、准确且无需训练的方法来优化3D视频系统中的资源分配。

Method: 1) 纹理-深度联合分类方法，准确分离纹理图像的局部平稳和非平稳区域；2) 设计基线距离指示器补偿大基线配置引起的失真；3) 基于区域的混合估计策略，几何识别重叠、单视图和相互遮挡区域。

Result: 在标准MPEG 3D视频序列上的实验验证了该方法的高精度和效率，特别在大基线配置下表现优异。

Conclusion: 该方法能够准确预测具有挑战性几何配置下的合成质量，使3D内容采集中的相机布置更加灵活。

Abstract: Depth-image-based rendering is a key view synthesis algorithm in 3D video
systems, which enables the synthesis of virtual views from texture images and
depth maps. An efficient view synthesis distortion estimation model is critical
for optimizing resource allocation in real-time applications such as
interactive free-viewpoint video and 3D video streaming services. However,
existing estimation methods are often computationally intensive, require
parameter training, or performance poorly in challenging large baseline
configurations. This paper presents a novel, low-complexity, and training-free
method to accurately estimate the distortion of synthesized views without
performing the actual rendering process. Key contributions include: (1) A joint
texture-depth classification method that accurately separates texture image
into locally stationary and non-stationary regions, which mitigates
misclassifications by using texture-only methods. (2) A novel baseline distance
indicator is designed for the compensation scheme for distortions caused by
large baseline configurations. (3) A region-based blending estimation strategy
that geometrically identifies overlapping, single-view, and mutual disocclusion
regions, predicting distortion in synthesized views from two reference views
with differing synthesis conditions. Experiments on standard MPEG 3D video
sequences validate the proposed method's high accuracy and efficiency,
especially in large baseline configurations. This method enables more flexible
camera arrangements in 3D content acquisition by accurately predicting
synthesis quality under challenging geometric configurations.

</details>


### [388] [AV1 Motion Vector Fidelity and Application for Efficient Optical Flow](https://arxiv.org/abs/2510.17427)
*Julien Zouein,Vibhoothi Vibhoothi,Anil Kokaram*

Main category: eess.IV

TL;DR: 该论文分析了AV1视频编码中的运动矢量，证明它们可作为高质量、计算效率高的光流估计替代方案，并能作为RAFT等深度学习光流方法的预热输入，实现4倍加速且精度损失很小。


<details>
  <summary>Details</summary>
Motivation: 传统光流估计在计算机视觉流程中计算资源密集，需要寻找更高效的替代方案。视频压缩编码中已经包含了运动矢量信息，这些信息可能被重新利用来加速光流估计。

Method: 1. 详细比较AV1和HEVC编码的运动矢量与真实光流的保真度；2. 分析编码器设置对运动估计质量的影响；3. 将提取的AV1运动矢量作为RAFT深度学习光流方法的预热输入。

Result: 1. AV1运动矢量具有高质量保真度；2. 使用AV1运动矢量作为RAFT的预热输入可显著减少收敛时间，实现4倍计算加速；3. 仅带来轻微端点误差增加，精度保持可比水平。

Conclusion: 从压缩视频中重用运动矢量是一种实用且高效的方法，适用于各种运动感知计算机视觉应用，具有显著的计算效率优势。

Abstract: This paper presents a comprehensive analysis of motion vectors extracted from
AV1-encoded video streams and their application in accelerating optical flow
estimation. We demonstrate that motion vectors from AV1 video codec can serve
as a high-quality and computationally efficient substitute for traditional
optical flow, a critical but often resource-intensive component in many
computer vision pipelines. Our primary contributions are twofold. First, we
provide a detailed comparison of motion vectors from both AV1 and HEVC against
ground-truth optical flow, establishing their fidelity. In particular we show
the impact of encoder settings on motion estimation fidelity and make
recommendations about the optimal settings. Second, we show that using these
extracted AV1 motion vectors as a "warm-start" for a state-of-the-art deep
learning-based optical flow method, RAFT, significantly reduces the time to
convergence while achieving comparable accuracy. Specifically, we observe a
four-fold speedup in computation time with only a minor trade- off in end-point
error. These findings underscore the potential of reusing motion vectors from
compressed video as a practical and efficient method for a wide range of
motion-aware computer vision applications.

</details>


### [389] [Segmenting infant brains across magnetic fields: Domain randomization and annotation curation in ultra-low field MRI](https://arxiv.org/abs/2510.17436)
*Vladyslav Zalevskyi,Dondu-Busra Bulut,Thomas Sanchez,Meritxell Bach Cuadra*

Main category: eess.IV

TL;DR: 提出领域随机化框架，通过预训练和标签质量控制，解决超低场MRI中脑结构分割的挑战，在LISA挑战中实现竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 早期识别神经发育障碍需要准确分割婴儿脑结构，但超低场MRI图像质量差、存在运动伪影，传统方法难以处理。超低场MRI虽然质量较低，但具有成本低、便携、无需镇静等优势，适合资源匮乏环境。

Method: 使用领域随机化框架弥合高场和超低场MRI之间的领域差距；通过预训练全脑高场分割；精心筛选训练标签，移除配准错误的注释；通过多数投票融合多个模型的预测。

Result: 预训练结合领域随机化显著提高了对超低场数据的泛化能力；标签质量控制进一步提升了性能；通过模型融合实现了竞争性的分割性能。

Conclusion: 结合鲁棒的数据增强和注释质量控制，可以在超低场MRI数据中实现准确的分割，为资源匮乏环境下的神经发育障碍早期识别提供了可行方案。

Abstract: Early identification of neurodevelopmental disorders relies on accurate
segmentation of brain structures in infancy, a task complicated by rapid brain
growth, poor tissue contrast, and motion artifacts in pediatric MRI. These
challenges are further exacerbated in ultra-low-field (ULF, 0.064~T) MRI,
which, despite its lower image quality, offers an affordable, portable, and
sedation-free alternative for use in low-resource settings. In this work, we
propose a domain randomization (DR) framework to bridge the domain gap between
high-field (HF) and ULF MRI in the context of the hippocampi and basal ganglia
segmentation in the LISA challenge. We show that pre-training on whole-brain HF
segmentations using DR significantly improves generalization to ULF data, and
that careful curation of training labels, by removing misregistered HF-to-ULF
annotations from training, further boosts performance. By fusing the
predictions of several models through majority voting, we are able to achieve
competitive performance. Our results demonstrate that combining robust
augmentation with annotation quality control can enable accurate segmentation
in ULF data. Our code is available at
https://github.com/Medical-Image-Analysis-Laboratory/lisasegm

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [390] [Call-Center Staff Scheduling Considering Performance Evolution under Emotional Stress](https://arxiv.org/abs/2510.16406)
*Yujun Zheng,Xinya Chen,Xueqin Lu,Weiguo Sheng,Shengyong Chen*

Main category: cs.NE

TL;DR: 本文提出了一种考虑情绪压力对工作绩效影响的呼叫中心人员调度方法，通过结合全局变异和邻域搜索的模因优化算法，有效提升了客户服务水平。


<details>
  <summary>Details</summary>
Motivation: 现有人员调度方法普遍忽视情绪压力对员工工作绩效的显著影响，需要开发更符合实际人类行为特征的调度模型。

Method: 提出了情绪压力驱动的工作绩效评估模型，并设计了结合全局变异和邻域搜索的模因优化算法，辅以深度强化学习来求解短期和长期结合的呼叫中心人员调度问题。

Result: 在银行呼叫中心真实案例上的实验结果表明，所提方法在客户服务水平方面优于现有流行的人员调度方法。

Conclusion: 通过显式建模和融入情绪压力因素，该方法在人员调度中体现了对人类行为的更现实理解和利用。

Abstract: Emotional stress often has a significant effect on the working performance of
staff, but this effect is commonly neglected in existing staff scheduling
methods. We study a call-center staff scheduling problem, which considers the
evolution of work performance of staff under emotional stress. First, we
present an emotional stress driven model that estimates the working performance
of call-center employees based on not only skill levels but also emotional
states. On the basis of the model, we formulate a combined short-term and
long-term call-center staff scheduling problem aiming at maximizing the
customer service level, which depends on the working performance of employees.
We then propose a memetic optimization algorithm combining global mutation and
neighborhood search assisted by deep reinforcement learning to efficiently
solve this problem. Experimental results on real-world problem instances of
bank call-center staff scheduling demonstrate the performance advantages of the
proposed method over selected popular staff scheduling methods. By explicitly
modeling and incorporating emotional stress, our method reflects a more
realistic understanding and utilization of human behavior in staff scheduling.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [391] [Hallucinations in AlphaFold3 for Intrinsically Disordered Proteins with disorder in Biological Process Residues](https://arxiv.org/abs/2510.15939)
*Shreya Gopalan,Sundar Narayanan*

Main category: q-bio.QM

TL;DR: AlphaFold3在预测蛋白质结构方面表现出色，但在预测内在无序蛋白（IDPs）方面存在局限性，32%的残基与实验数据不符，其中18%与生物过程相关的残基出现幻觉预测，可能影响药物发现和疾病研究。


<details>
  <summary>Details</summary>
Motivation: 评估AlphaFold3在预测内在无序蛋白（IDPs）方面的性能，因为IDPs占人类蛋白质组的30-40%，在转录、信号传导和疾病中起关键作用，但AlphaFold3在这方面的表现尚未充分探索。

Method: 使用DisProt数据库中的72个蛋白质，生成多个随机种子和集成输出的预测，将残基级pLDDT分数与实验无序注释进行比较。

Result: 32%的残基与DisProt数据不符，其中10%表现出上下文驱动的错位，18%与生物过程相关的残基出现幻觉预测。

Conclusion: AlphaFold3在建模IDRs方面存在局限性，需要改进幻觉指标并整合实验无序数据以提高预测可靠性。

Abstract: Protein structure prediction has advanced significantly with the introduction
of AlphaFold3, a diffusion-based model capable of predicting complex
biomolecular interactions across proteins, nucleic acids, small molecules, and
ions. While AlphaFold3 demonstrates high accuracy in folded proteins, its
performance on intrinsically disordered proteins (IDPs), which comprise 30 to
40 percent of the human proteome and play critical roles in transcription,
signaling, and disease, remains less explored. This study evaluated
AlphaFold3's predictions of IDPs with a focus on intrinsically disordered
regions (IDRs) using 72 proteins curated from the DisProt database. Predictions
were generated across multiple random seeds and ensemble outputs, and
residue-level pLDDT scores were compared with experimental disorder
annotations. Our analysis reveals that 32 percent of residues are misaligned
with DisProt, with percent representing hallucinations where AlphaFold3
incorrectly predicts order in disordered regions or vice versa. Additionally,
10 percent of residues exhibited context-driven misalignment, suggesting that
AlphaFold3 implicitly incorporates stable structural assumptions. Importantly,
18 percent of residues associated with biological processes showed
hallucinations, raising concerns about downstream implications in drug
discovery and disease research. These findings highlight the limitations of
AlphaFold3 in modeling IDRs, the need for refined hallucination metrics beyond
the pLDDT, and the importance of integrating experimental disorder data to
improve prediction reliability.

</details>


### [392] [TriAgent: Automated Biomarker Discovery with Deep Research Grounding for Triage in Acute Care by LLM-Based Multi-Agent Collaboration](https://arxiv.org/abs/2510.16080)
*Kerem Delikoyun,Qianyu Chen,Win Sen Kuan,John Tshon Yit Soong,Matthew Edward Cove,Oliver Hayden*

Main category: q-bio.QM

TL;DR: TriAgent是一个基于大语言模型的多智能体框架，通过自动化生物标志物发现和文献验证来改进急诊分诊决策，在生物标志物分类和文献基础验证方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决急诊部门面临的日益增长的患者量、人员短缺以及分诊决策变异性问题，现有分诊方法主要依赖生命体征、常规实验室值和临床医生判断，但常常错过可能改善感染类型或抗生素使用风险预测的新兴生物信号。

Method: TriAgent采用基于大语言模型的多智能体框架，包括监督研究智能体生成研究主题并委托专门子智能体从各种数据源检索证据，综合发现将生物标志物分类为基于现有知识或标记为新颖候选。

Result: TriAgent在主题一致性F1得分达到55.7±5.0%，超过CoT-ReAct智能体10%以上，忠实度得分为0.42±0.39，超过所有基线50%以上，在生物标志物论证和文献基础新颖性评估方面持续优于最先进的基于LLM的智能体框架。

Conclusion: TriAgent提供了一个从数据分析到文献基础的端到端框架，提高了透明度和可解释性，扩展了潜在可操作的临床生物标志物前沿，为急性护理风险分层提供了新途径。

Abstract: Emergency departments worldwide face rising patient volumes, workforce
shortages, and variability in triage decisions that threaten the delivery of
timely and accurate care. Current triage methods rely primarily on vital signs,
routine laboratory values, and clinicians' judgment, which, while effective,
often miss emerging biological signals that could improve risk prediction for
infection typing or antibiotic administration in acute conditions. To address
this challenge, we introduce TriAgent, a large language model (LLM)-based
multi-agent framework that couples automated biomarker discovery with deep
research for literature-grounded validation and novelty assessment. TriAgent
employs a supervisor research agent to generate research topics and delegate
targeted queries to specialized sub-agents for evidence retrieval from various
data sources. Findings are synthesized to classify biomarkers as either
grounded in existing knowledge or flagged as novel candidates, offering
transparent justification and highlighting unexplored pathways in acute care
risk stratification. Unlike prior frameworks limited to existing routine
clinical biomarkers, TriAgent aims to deliver an end-to-end framework from data
analysis to literature grounding to improve transparency, explainability and
expand the frontier of potentially actionable clinical biomarkers. Given a
user's clinical query and quantitative triage data, TriAgent achieved a topic
adherence F1 score of 55.7 +/- 5.0%, surpassing the CoT-ReAct agent by over
10%, and a faithfulness score of 0.42 +/- 0.39, exceeding all baselines by more
than 50%. Across experiments, TriAgent consistently outperformed
state-of-the-art LLM-based agentic frameworks in biomarker justification and
literature-grounded novelty assessment. We share our repo:
https://github.com/CellFace/TriAgent.

</details>


### [393] [BASIN: Bayesian mAtrix variate normal model with Spatial and sparsIty priors in Non-negative deconvolution](https://arxiv.org/abs/2510.16130)
*Jiasen Zhang,Xi Qiao,Liangliang Zhang,Weihong Guo*

Main category: q-bio.QM

TL;DR: 本文提出BASIN方法用于空间转录组数据的细胞类型反卷积，采用矩阵变分贝叶斯非负矩阵分解，结合图拉普拉斯先验，通过吉布斯采样获得参数后验分布，提供不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 空间转录组技术能提供基因表达的空间位置信息，但缺乏细胞分辨率，需要细胞类型反卷积来推断每个空间位置的细胞组成。现有确定性方法缺乏不确定性评估。

Method: 将反卷积建模为包含图拉普拉斯先验的非负矩阵分解问题，提出矩阵变分贝叶斯NMF方法，使用非负性和稀疏性先验，通过吉布斯采样近似后验分布。

Result: 在不同空间转录组数据集上评估，BASIN在准确性和效率方面优于其他反卷积方法，结果验证了所采用先验的有效性，符合截断矩阵正态分布的预期。

Conclusion: BASIN方法通过贝叶斯框架提供细胞类型比例的分布估计，增强了鲁棒性并提供了内在的不确定性量化，在空间转录组细胞类型反卷积中表现优异。

Abstract: Spatial transcriptomics allows researchers to visualize and analyze gene
expression within the precise location of tissues or cells. It provides
spatially resolved gene expression data but often lacks cellular resolution,
necessitating cell type deconvolution to infer cellular composition at each
spatial location. In this paper we propose BASIN for cell type deconvolution,
which models deconvolution as a nonnegative matrix factorization (NMF) problem
incorporating graph Laplacian prior. Rather than find a deterministic optima
like other recent methods, we propose a matrix variate Bayesian NMF method with
nonnegativity and sparsity priors, in which the variables are maintained in
their matrix form to derive a more efficient matrix normal posterior. BASIN
employs a Gibbs sampler to approximate the posterior distribution of cell type
proportions and other parameters, offering a distribution of possible
solutions, enhancing robustness and providing inherent uncertainty
quantification. The performance of BASIN is evaluated on different spatial
transcriptomics datasets and outperforms other deconvolution methods in terms
of accuracy and efficiency. The results also show the effect of the
incorporated priors and reflect a truncated matrix normal distribution as we
expect.

</details>


### [394] [Few-Label Multimodal Modeling of SNP Variants and ECG Phenotypes Using Large Language Models for Cardiovascular Risk Stratification](https://arxiv.org/abs/2510.16536)
*Niranjana Arun Menon,Yulong Li,Iqra Farooq,Sara Ahmed,Muhammad Awais,Imran Razzak*

Main category: q-bio.QM

TL;DR: 本研究提出了一种基于大语言模型的少标签多模态框架，用于心血管疾病风险分层，结合遗传和电生理信息，通过伪标签精炼策略和思维链推理来提高模型鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病风险分层面临多因素性质和高质量标注数据稀缺的挑战，需要有效整合基因组和电生理学等多模态数据，特别是在低标注数据环境下。

Method: 采用少标签多模态框架，利用大语言模型整合SNP变异和ECG表型数据，结合伪标签精炼策略从弱监督预测中提取高置信度标签，并通过思维链推理框架生成临床相关解释。

Result: 实验结果表明，多模态输入、少标签监督和思维链推理的结合提高了模型在不同患者群体中的鲁棒性和泛化能力，使用多模态SNP变异和ECG特征达到了与全数据集训练模型相当的性能。

Conclusion: 基于大语言模型的少标签多模态建模在推进个性化心血管护理方面具有广阔前景，能够有效解决标注数据稀缺的问题并提高模型可解释性。

Abstract: Cardiovascular disease (CVD) risk stratification remains a major challenge
due to its multifactorial nature and limited availability of high-quality
labeled datasets. While genomic and electrophysiological data such as SNP
variants and ECG phenotypes are increasingly accessible, effectively
integrating these modalities in low-label settings is non-trivial. This
challenge arises from the scarcity of well-annotated multimodal datasets and
the high dimensionality of biological signals, which limit the effectiveness of
conventional supervised models. To address this, we present a few-label
multimodal framework that leverages large language models (LLMs) to combine
genetic and electrophysiological information for cardiovascular risk
stratification. Our approach incorporates a pseudo-label refinement strategy to
adaptively distill high-confidence labels from weakly supervised predictions,
enabling robust model fine-tuning with only a small set of ground-truth
annotations. To enhance the interpretability, we frame the task as a Chain of
Thought (CoT) reasoning problem, prompting the model to produce clinically
relevant rationales alongside predictions. Experimental results demonstrate
that the integration of multimodal inputs, few-label supervision, and CoT
reasoning improves robustness and generalizability across diverse patient
profiles. Experimental results using multimodal SNP variants and ECG-derived
features demonstrated comparable performance to models trained on the full
dataset, underscoring the promise of LLM-based few-label multimodal modeling
for advancing personalized cardiovascular care.

</details>


### [395] [A Tractography Analysis Framework Using Diffusion Maps to Study Thalamic Connectivity in Traumatic Brain Injury](https://arxiv.org/abs/2510.17273)
*Akul Sharma,Anand A. Joshi,Richard M. Leahy*

Main category: q-bio.QM

TL;DR: 该研究提出了一种基于纤维束成像的新框架，利用扩散映射捕捉创伤性脑损伤后丘脑白质通路的微观结构和组织变化，发现扩散映射嵌入与功能结果显著相关，可作为损伤严重程度和恢复轨迹的潜在生物标志物。


<details>
  <summary>Details</summary>
Motivation: 创伤性脑损伤会破坏丘脑-皮层连接性，导致认知障碍和外伤后癫痫，需要开发能够捕捉白质通路微观结构变化的方法来评估损伤严重程度和恢复轨迹。

Method: 采用基于纤维束成像的新框架，利用扩散映射分析个体流线特征，捕捉丘脑白质通路的微观结构和组织变化。

Result: 研究发现扩散映射嵌入与功能结果（GOSE评分）存在显著关联，表明白质通路的细粒度几何特征可能为创伤性脑损伤相关改变提供更敏感的标志物。

Conclusion: 基于扩散映射的纤维束成像框架能够有效捕捉创伤性脑损伤后白质通路的微观结构变化，这些几何特征可作为评估损伤严重程度和恢复轨迹的潜在生物标志物。

Abstract: Traumatic brain injury (TBI) disrupts thalamocortical connectivity,
contributing to cognitive impairment and post-traumatic epilepsy (PTE). This
study presents a novel tractography-based framework that leverages diffusion
maps to capture microstructural and organizational changes in thalamic white
matter pathways. By analyzing individual streamline characteristics, we
identified significant associations between diffusion map embeddings and
functional outcomes (GOSE scores), highlighting potential biomarkers for injury
severity and recovery trajectories. Our findings suggest that fine-grained
geometric features of white matter tracts may provide a more sensitive marker
for TBI-related alterations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [396] [VisuoAlign: Safety Alignment of LVLMs with Multimodal Tree Search](https://arxiv.org/abs/2510.15948)
*MingSheng Li,Guangze Zhao,Sichen Liu*

Main category: cs.AI

TL;DR: VisuoAlign是一个通过提示引导树搜索实现多模态安全对齐的框架，旨在解决大型视觉语言模型在安全对齐方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在多模态感知和生成方面取得了显著进展，但其安全对齐仍然是一个关键挑战。现有防御方法容易受到多模态越狱攻击，因为视觉输入引入了新的攻击面，推理链缺乏安全监督，且对齐在模态融合下常常退化。

Method: VisuoAlign通过视觉-文本交互提示将安全约束嵌入推理过程，采用蒙特卡洛树搜索系统构建多样化的安全关键提示轨迹，并引入基于提示的缩放以确保实时风险检测和合规响应。

Result: 大量实验表明，VisuoAlign能够主动暴露风险，实现全面的数据集生成，并显著提高LVLMs对抗复杂跨模态威胁的鲁棒性。

Conclusion: VisuoAlign框架有效解决了多模态安全对齐的挑战，通过系统化的方法提升了大型视觉语言模型的安全性和鲁棒性。

Abstract: Large Vision-Language Models (LVLMs) have achieved remarkable progress in
multimodal perception and generation, yet their safety alignment remains a
critical challenge.Existing defenses and vulnerable to multimodal jailbreaks,
as visual inputs introduce new attack surfaces, reasoning chains lack safety
supervision, and alignment often degrades under modality fusion.To overcome
these limitation, we propose VisuoAlign, a framework for multi-modal safety
alignment via prompt-guided tree search.VisuoAlign embeds safety constrains
into the reasoning process through visual-textual interactive prompts, employs
Monte Carlo Tree Search(MCTS) to systematically construct diverse
safety-critical prompt trajectories, and introduces prompt-based scaling to
ensure real-time risk detection and compliant responses.Extensive experiments
demonstrate that VisuoAlign proactively exposes risks, enables comprehensive
dataset generation, and significantly improves the robustness of LVLMs against
complex cross-modal threats.

</details>


### [397] [Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding](https://arxiv.org/abs/2510.15952)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 本文提出了结构化认知循环（SCL）作为可执行的认知框架，将哲学洞见转化为可计算结构，强调智能是执行过程而非属性，通过功能分离实现更连贯的行为。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型缺乏真正的认知理解，暴露了认知架构的缺失。本文旨在填补这一空白，探索在什么条件下认知会涌现，而非仅仅定义智能是什么。

Method: 基于心智哲学和认知现象学，结合过程哲学、具身认知和扩展心智理论，构建SCL框架——一个包含判断、记忆、控制、行动和调节的连续循环。

Result: SCL将哲学洞见转化为可计算结构，实现"可执行认识论"；功能分离的认知架构比单一提示系统产生更连贯和可解释的行为；重新定义智能为通过意向性理解重建自身认知状态的能力。

Conclusion: SCL框架对心智哲学、认识论和AI产生重要影响：允许认知理论被实施和测试；将行为建立在认知结构而非统计规律上；将知识视为在现象学连贯循环中的持续重建过程。

Abstract: Large language models exhibit intelligence without genuine epistemic
understanding, exposing a key gap: the absence of epistemic architecture. This
paper introduces the Structured Cognitive Loop (SCL) as an executable
epistemological framework for emergent intelligence. Unlike traditional AI
research asking "what is intelligence?" (ontological), SCL asks "under what
conditions does cognition emerge?" (epistemological). Grounded in philosophy of
mind and cognitive phenomenology, SCL bridges conceptual philosophy and
implementable cognition. Drawing on process philosophy, enactive cognition, and
extended mind theory, we define intelligence not as a property but as a
performed process -- a continuous loop of judgment, memory, control, action,
and regulation. SCL makes three contributions. First, it operationalizes
philosophical insights into computationally interpretable structures, enabling
"executable epistemology" -- philosophy as structural experiment. Second, it
shows that functional separation within cognitive architecture yields more
coherent and interpretable behavior than monolithic prompt based systems,
supported by agent evaluations. Third, it redefines intelligence: not
representational accuracy but the capacity to reconstruct its own epistemic
state through intentional understanding. This framework impacts philosophy of
mind, epistemology, and AI. For philosophy, it allows theories of cognition to
be enacted and tested. For AI, it grounds behavior in epistemic structure
rather than statistical regularity. For epistemology, it frames knowledge not
as truth possession but as continuous reconstruction within a
phenomenologically coherent loop. We situate SCL within debates on cognitive
phenomenology, emergence, normativity, and intentionality, arguing that real
progress requires not larger models but architectures that realize cognitive
principles structurally.

</details>


### [398] [Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games](https://arxiv.org/abs/2510.15974)
*Chris Su,Harrison Li,Matheus Marques,George Flint,Kevin Zhu,Sunishchal Dev*

Main category: cs.AI

TL;DR: 研究发现大型推理模型在解决复杂谜题时会出现性能崩溃，即使提供环境接口来跟踪状态空间也无法避免这种崩溃。模型在复杂任务中会表现出模式崩溃，性能取决于其模式是否匹配正确解决方案。


<details>
  <summary>Details</summary>
Motivation: 探索大型推理模型在解决复杂谜题时性能崩溃的原因，特别是验证状态空间跟踪需求是否混淆了对真实推理能力的评估。

Method: 为大型语言模型提供汉诺塔问题的环境接口，允许模型通过工具调用进行移动、提供书面理由、观察结果状态空间并重新提示下一步移动。

Result: 环境接口的访问并不能延迟或消除性能崩溃。LLM参数化策略分析显示模型与最优策略和均匀随机策略的偏离度增加，表明模型在每个复杂度级别都表现出模式崩溃。

Conclusion: 大型推理模型在复杂任务中会出现性能崩溃，这与状态空间跟踪能力无关，而是模型本身在复杂问题中表现出的模式崩溃现象。

Abstract: Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in
performance on solving puzzles beyond certain perplexity thresholds. In
subsequent discourse, questions have arisen as to whether the nature of the
task muddles an evaluation of true reasoning. One potential confound is the
requirement that the model keep track of the state space on its own. We provide
a large language model (LLM) with an environment interface for Tower of Hanoi
problems, allowing it to make a move with a tool call, provide written
justification, observe the resulting state space, and reprompt itself for the
next move. We observe that access to an environment interface does not delay or
eradicate performance collapse. Furthermore, LLM-parameterized policy analysis
reveals increasing divergence from both optimal policies and uniformly random
policies, suggesting that the model exhibits mode-like collapse at each level
of complexity, and that performance is dependent upon whether the mode reflects
the correct solution for the problem. We suggest that a similar phenomena might
take place in LRMs.

</details>


### [399] [ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization](https://arxiv.org/abs/2510.15981)
*Rafael Cabral,Tuan Manh Do,Xuejun Yu,Wai Ming Tai,Zijin Feng,Xin Shen*

Main category: cs.AI

TL;DR: ProofFlow是一个新的证明自动形式化管道，通过构建逻辑依赖图和使用基于引理的方法来保持原始证明的结构保真度，在184个本科级问题基准上取得了0.545的ProofScore，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决当前证明自动形式化方法虽然能生成可执行代码，但经常无法保持原始人工编写证明的语义含义和逻辑结构的问题。

Method: 首先构建有向无环图来映射证明步骤间的逻辑依赖关系，然后采用基于引理的方法系统地将每个步骤形式化为中间引理，以保持原始论证的逻辑结构。

Result: 在184个本科级问题的新基准上，ProofFlow实现了0.545的ProofScore，显著超过全证明形式化（0.123）和步骤证明形式化（0.072）等基线方法。

Conclusion: ProofFlow为证明自动形式化设立了新的最先进水平，其管道、基准和评分指标已开源以促进进一步研究。

Abstract: Proof autoformalization, the task of translating natural language theorems
and proofs into machine-verifiable code, is a critical step for integrating
large language models into rigorous mathematical workflows. Current approaches
focus on producing executable code, but they frequently fail to preserve the
semantic meaning and logical structure of the original human-written argument.
To address this, we introduce ProofFlow, a novel pipeline that treats
structural fidelity as a primary objective. ProofFlow first constructs a
directed acyclic graph (DAG) to map the logical dependencies between proof
steps. Then, it employs a novel lemma-based approach to systematically
formalize each step as an intermediate lemma, preserving the logical structure
of the original argument. To facilitate evaluation, we present a new benchmark
of 184 undergraduate-level problems, manually annotated with step-by-step
solutions and logical dependency graphs, and introduce ProofScore, a new
composite metric to evaluate syntactic correctness, semantic faithfulness, and
structural fidelity. Experimental results show our pipeline sets a new
state-of-the-art for autoformalization, achieving a ProofScore of 0.545,
substantially exceeding baselines like full-proof formalization (0.123), which
processes the entire proof at once, and step-proof formalization (0.072), which
handles each step independently. Our pipeline, benchmark, and score metric are
open-sourced to encourage further progress at
https://github.com/Huawei-AI4Math/ProofFlow.

</details>


### [400] [Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science](https://arxiv.org/abs/2510.15983)
*Sarah Rebecca Ondraszek,Jörg Waitelonis,Katja Keller,Claudia Niessner,Anna M. Jacyszyn,Harald Sack*

Main category: cs.AI

TL;DR: 本文介绍了MO|RE数据仓库，这是一个用于体育科学研究的开放数据基础设施，作者提出了将其转换为知识图谱的愿景，旨在使运动表现数据标准化且机器可理解。


<details>
  <summary>Details</summary>
Motivation: 为了评估和比较不同人群的身体和认知能力，需要测试与人类表现相关的各种因素。运动表现测试作为体育科学研究的核心部分，能够分析不同人口群体的身体健康状况并使其具有可比性。

Method: 开发基于基本形式本体论的知识图谱，重点关注正式表示计划规范、特定过程和相关测量之间的相互关系。

Result: 提出了将MO|RE数据转换为知识图谱的愿景和方法框架，该框架在莱布尼茨科学园区"研究的数字化转型"项目内开发。

Conclusion: 通过创建知识图谱，可以改变运动表现数据的建模和共享方式，使其标准化且机器可理解，从而促进跨研究的比较和分析。

Abstract: An essential component for evaluating and comparing physical and cognitive
capabilities between populations is the testing of various factors related to
human performance. As a core part of sports science research, testing motor
performance enables the analysis of the physical health of different
demographic groups and makes them comparable.
  The Motor Research (MO|RE) data repository, developed at the Karlsruhe
Institute of Technology, is an infrastructure for publishing and archiving
research data in sports science, particularly in the field of motor performance
research. In this paper, we present our vision for creating a knowledge graph
from MO|RE data. With an ontology rooted in the Basic Formal Ontology, our
approach centers on formally representing the interrelation of plan
specifications, specific processes, and related measurements. Our goal is to
transform how motor performance data are modeled and shared across studies,
making it standardized and machine-understandable. The idea presented here is
developed within the Leibniz Science Campus ``Digital Transformation of
Research'' (DiTraRe).

</details>


### [401] [A Non-overlap-based Conflict Measure for Random Permutation Sets](https://arxiv.org/abs/2510.16001)
*Ruolan Cheng,Yong Deng,Enrique Herrera-Viedma*

Main category: cs.AI

TL;DR: 本文提出了一种新的随机置换集(RPS)冲突度量方法，从随机有限集(RFS)和Dempster-Shafer理论(DST)两个角度分析RPS中的冲突，并基于秩偏重叠(RBO)度量定义了置换间的不一致性度量。


<details>
  <summary>Details</summary>
Motivation: 随机置换集是不确定性推理中涉及顺序信息的新形式化方法，如何度量由置换质量函数表示的两个证据之间的冲突是有序结构不确定信息融合中的紧迫研究课题。

Method: 从置换观察出发，首先基于秩偏重叠(RBO)度量定义置换间的不一致性度量，然后提出基于非重叠的RPS冲突度量方法，将RPS理论视为DST的扩展，并考虑焦点集中新添加的顺序信息所表征的定性倾向性。

Result: 通过数值示例验证了所提出冲突度量的行为和特性，该方法不仅具有自然的顶部加权特性，能从DST视角有效度量RPS间的冲突，还为决策者提供了权重、参数和截断深度的灵活选择。

Conclusion: 提出的冲突度量方法为随机置换集的不确定性信息融合提供了有效的冲突分析工具，特别适用于处理涉及顺序信息的证据融合问题。

Abstract: Random permutation set (RPS) is a new formalism for reasoning with
uncertainty involving order information. Measuring the conflict between two
pieces of evidence represented by permutation mass functions remains an urgent
research topic in order-structured uncertain information fusion. In this paper,
a detailed analysis of conflicts in RPS is carried out from two different
perspectives: random finite set (RFS) and Dempster-Shafer theory (DST).
Starting from the observation of permutations, we first define an inconsistency
measure between permutations inspired by the rank-biased overlap(RBO) measure
and further propose a non-overlap-based conflict measure method for RPSs. This
paper regards RPS theory (RPST) as an extension of DST. The order information
newly added in focal sets indicates qualitative propensity, characterized by
top-ranked elements occupying a more critical position. Some numerical examples
are used to demonstrate the behavior and properties of the proposed conflict
measure. The proposed method not only has the natural top-weightedness property
and can effectively measure the conflict between RPSs from the DST view but
also provides decision-makers with a flexible selection of weights, parameters,
and truncated depths.

</details>


### [402] [Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study](https://arxiv.org/abs/2510.16095)
*Dou Liu,Ying Long,Sophia Zuoqiu,Di Liu,Kang Li,Yiting Lin,Hanyi Liu,Rong Yin,Tian Tang*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for
explainable medical Artificial Intelligence (AI) while constrained by data
scarcity. Although Large Language Models (LLMs) can synthesize medical data,
their clinical reliability remains unverified. This study evaluates the
reliability of LLM-generated CoTs and investigates prompting strategies to
enhance their quality. In a blinded comparative study, senior clinicians in
Assisted Reproductive Technology (ART) evaluated CoTs generated via three
distinct strategies: Zero-shot, Random Few-shot (using shallow examples), and
Selective Few-shot (using diverse, high-quality examples). These expert ratings
were compared against evaluations from a state-of-the-art AI model (GPT-4o).
The Selective Few-shot strategy significantly outperformed other strategies
across all human evaluation metrics (p < .001). Critically, the Random Few-shot
strategy offered no significant improvement over the Zero-shot baseline,
demonstrating that low-quality examples are as ineffective as no examples. The
success of the Selective strategy is attributed to two principles:
"Gold-Standard Depth" (reasoning quality) and "Representative Diversity"
(generalization). Notably, the AI evaluator failed to discern these critical
performance differences. The clinical reliability of synthetic CoTs is dictated
by strategic prompt curation, not the mere presence of examples. We propose a
"Dual Principles" framework as a foundational methodology to generate
trustworthy data at scale. This work offers a validated solution to the data
bottleneck and confirms the indispensable role of human expertise in evaluating
high-stakes clinical AI.

</details>


### [403] [Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration](https://arxiv.org/abs/2510.16194)
*Guanchen Wu,Zuhui Chen,Yuzhang Xie,Carl Yang*

Main category: cs.AI

TL;DR: TEAM-PHI是一个多智能体评估框架，使用大语言模型自动评估医疗信息去标识化模型性能，无需依赖昂贵的专家标注。


<details>
  <summary>Details</summary>
Motivation: 医疗信息去标识化评估通常依赖成本高昂的小规模专家标注，需要一种自动化的评估方法来降低对黄金标签的依赖。

Method: 部署多个评估智能体独立判断PHI提取正确性，通过基于LLM的多数投票机制整合不同评估者观点，生成稳定可复现的排名。

Result: 在真实临床笔记语料上的实验表明，TEAM-PHI能产生一致准确的排名，尽管个体评估者存在差异，但LLM投票能可靠地收敛到相同的最佳系统。

Conclusion: TEAM-PHI通过结合独立评估智能体和LLM多数投票，为PHI去标识化提供了实用、安全且经济高效的自动评估和最佳模型选择解决方案。

Abstract: Protected health information (PHI) de-identification is critical for enabling
the safe reuse of clinical notes, yet evaluating and comparing PHI
de-identification models typically depends on costly, small-scale expert
annotations. We present TEAM-PHI, a multi-agent evaluation and selection
framework that uses large language models (LLMs) to automatically measure
de-identification quality and select the best-performing model without heavy
reliance on gold labels. TEAM-PHI deploys multiple Evaluation Agents, each
independently judging the correctness of PHI extractions and outputting
structured metrics. Their results are then consolidated through an LLM-based
majority voting mechanism that integrates diverse evaluator perspectives into a
single, stable, and reproducible ranking. Experiments on a real-world clinical
note corpus demonstrate that TEAM-PHI produces consistent and accurate
rankings: despite variation across individual evaluators, LLM-based voting
reliably converges on the same top-performing systems. Further comparison with
ground-truth annotations and human evaluation confirms that the framework's
automated rankings closely match supervised evaluation. By combining
independent evaluation agents with LLM majority voting, TEAM-PHI offers a
practical, secure, and cost-effective solution for automatic evaluation and
best-model selection in PHI de-identification, even when ground-truth labels
are limited.

</details>


### [404] [The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI](https://arxiv.org/abs/2510.16206)
*Alex Zhavoronkov,Dominika Wilczok,Roman Yampolskiy*

Main category: cs.AI

TL;DR: 该论文提出"被记住权"概念，旨在解决大型语言模型在信息检索中可能导致的偏见、信息遗漏和集体记忆重塑问题。


<details>
  <summary>Details</summary>
Motivation: 随着人们越来越多依赖LLMs进行信息检索，这些模型将多个视角压缩成单一权威回答，可能导致某些群体被不成比例地压制，而其他群体被过度放大，从而重塑集体记忆。

Method: 提出"被记住权"概念框架，包括最小化AI驱动信息遗漏风险、保障公平对待权利，同时确保生成内容最大程度真实。

Result: 建立了一个理论框架来应对LLMs在信息检索中可能造成的权力集中和记忆偏差问题。

Conclusion: 需要建立"被记住权"来保护那些数字存在有限的群体，防止AI系统不成比例地压制某些叙述和群体，确保信息公平性和真实性。

Abstract: Since the rapid expansion of large language models (LLMs), people have begun
to rely on them for information retrieval. While traditional search engines
display ranked lists of sources shaped by search engine optimization (SEO),
advertising, and personalization, LLMs typically provide a synthesized response
that feels singular and authoritative. While both approaches carry risks of
bias and omission, LLMs may amplify the effect by collapsing multiple
perspectives into one answer, reducing users ability or inclination to compare
alternatives. This concentrates power over information in a few LLM vendors
whose systems effectively shape what is remembered and what is overlooked. As a
result, certain narratives, individuals or groups, may be disproportionately
suppressed, while others are disproportionately elevated. Over time, this
creates a new threat: the gradual erasure of those with limited digital
presence, and the amplification of those already prominent, reshaping
collective memory.To address these concerns, this paper presents a concept of
the Right To Be Remembered (RTBR) which encompasses minimizing the risk of
AI-driven information omission, embracing the right of fair treatment, while
ensuring that the generated content would be maximally truthful.

</details>


### [405] [ScholarEval: Research Idea Evaluation Grounded in Literature](https://arxiv.org/abs/2510.16234)
*Hanane Nour Moussa,Patrick Queiroz Da Silva,Daniel Adu-Ampratwum,Alyson East,Zitong Lu,Nikki Puccetti,Mingyi Xue,Huan Sun,Bodhisattwa Prasad Majumder,Sachin Kumar*

Main category: cs.AI

TL;DR: ScholarEval是一个检索增强的研究想法评估框架，通过评估想法的合理性（基于现有文献的经验有效性）和贡献度（相对于先前研究的进步程度）来评估AI生成的研究想法。该框架在专家标注的多领域数据集ScholarIdeas上表现优于所有基线方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI工具在研究构思中越来越普遍，需要强大的评估方法来确保生成想法的有效性和实用性。

Method: 引入ScholarEval检索增强评估框架，基于两个基本标准评估研究想法：合理性和贡献度。创建了第一个专家标注的多领域研究想法和评论数据集ScholarIdeas，包含117个跨四个学科的想法。

Result: ScholarEval在人类专家标注的评估标准覆盖度上显著优于所有基线方法。在评估可操作性、深度和证据支持方面持续优于最强的基线方法o4-mini-deep-research。大规模用户研究显示，在文献参与度、想法精炼和实用性方面显著优于深度研究方法。

Conclusion: ScholarEval为AI生成研究想法的评估提供了有效的框架，在多个维度上优于现有方法，并开源了代码、数据集和工具供社区使用。

Abstract: As AI tools become increasingly common for research ideation, robust
evaluation is critical to ensure the validity and usefulness of generated
ideas. We introduce ScholarEval, a retrieval augmented evaluation framework
that assesses research ideas based on two fundamental criteria: soundness - the
empirical validity of proposed methods based on existing literature, and
contribution - the degree of advancement made by the idea across different
dimensions relative to prior research. To evaluate ScholarEval, we introduce
ScholarIdeas, the first expert-annotated dataset of multi-domain research ideas
and reviews, comprised of 117 ideas across four disciplines: artificial
intelligence, neuroscience, biochemistry, and ecology. Our evaluation shows
that ScholarEval achieves significantly higher coverage of points mentioned in
the human expert annotated rubrics in ScholarIdeas compared to all baselines.
Furthermore, ScholarEval is consistently preferred over our strongest baseline
o4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,
in terms of evaluation actionability, depth, and evidence support. Our
large-scale user study also shows that ScholarEval significantly outperforms
deep research in literature engagement, idea refinement, and usefulness. We
openly release our code, dataset, and ScholarEval tool for the community to use
and build on.

</details>


### [406] [Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense](https://arxiv.org/abs/2510.16259)
*Zhehao Zhang,Weijie Xu,Shixian Cui,Chandan K. Reddy*

Main category: cs.AI

TL;DR: 本文识别并系统分析了大型推理模型（LRMs）中的关键漏洞——推理分心，即模型被恶意嵌入提示中的无关复杂任务分散注意力。研究表明最先进的LRMs高度易受攻击，注入的干扰物可使任务准确率下降高达60%。作者提出了基于训练的对策，结合监督微调和强化学习，在合成对抗数据上训练，将鲁棒性提高了50多个点。


<details>
  <summary>Details</summary>
Motivation: 随着大型推理模型在数学和编程等复杂任务上表现出色，作者发现这些模型存在一个关键漏洞——推理分心，即模型可能被恶意嵌入提示中的无关复杂任务分散注意力，从而影响主要任务的性能。这一漏洞对LRM的可靠性构成了独特而紧迫的威胁。

Method: 作者通过跨多个模型和基准的综合研究，分析了推理分心漏洞。为了缓解这一风险，他们提出了基于训练的对策，结合监督微调（SFT）和强化学习（RL）在合成对抗数据上进行训练。

Result: 研究表明，即使是最先进的LRMs也高度易受推理分心攻击，注入的干扰物可使任务准确率下降高达60%。某些对齐技术甚至会放大这一弱点。作者提出的训练对策显著提高了模型鲁棒性，在具有挑战性的干扰攻击上将鲁棒性提高了50多个点。

Conclusion: 推理分心是LRM可靠性面临的一个独特而紧迫的威胁。本文的研究结果为此类攻击提供了实证证据，并提出了实用的防御方法，为构建更安全、更可信的推理系统迈出了实际步骤。

Abstract: Recent advances in large reasoning models (LRMs) have enabled remarkable
performance on complex tasks such as mathematics and coding by generating long
Chain-of-Thought (CoT) traces. In this paper, we identify and systematically
analyze a critical vulnerability we term reasoning distraction, where LRMs are
diverted from their primary objective by irrelevant yet complex tasks
maliciously embedded in the prompt. Through a comprehensive study across
diverse models and benchmarks, we show that even state-of-the-art LRMs are
highly susceptible, with injected distractors reducing task accuracy by up to
60%. We further reveal that certain alignment techniques can amplify this
weakness and that models may exhibit covert compliance, following hidden
adversarial instructions in reasoning while concealing them in the final
output. To mitigate these risks, we propose a training-based defense that
combines Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on
synthetic adversarial data, improving robustness by over 50 points on
challenging distractor attacks. Our findings establish reasoning distraction as
a distinct and urgent threat to LRM reliability and provide a practical step
toward safer and more trustworthy reasoning systems.

</details>


### [407] [A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.17697)
*Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang*

Main category: cs.AI

TL;DR: 本文提出使用多智能体影响图（MAIDs）作为图形化框架来解决多智能体强化学习（MARL）中的协调问题，设计了基于MAIDs的目标干预范式，通过因果推理技术PSI实现单智能体干预，避免全局指导的复杂性。


<details>
  <summary>Details</summary>
Motivation: 在大规模MARL中，对整个多智能体系统进行全局人类指导不切实际，而现有协调机制设计主要依赖经验研究，缺乏易用的研究工具。

Method: 引入MAIDs作为图形框架分析现有MARL方法，设计基于MAIDs的目标干预范式，应用因果推理技术PSI实现单智能体干预，通过最大化因果效应达成复合期望结果。

Result: 实验证明了所提出的目标干预范式的有效性，并验证了相关性图分析的结果。

Conclusion: MAIDs为MARL提供了有效的分析和可视化工具，目标干预范式能够有效缓解全局指导问题，PSI技术能够通过因果效应最大化实现复合期望结果。

Abstract: Steering cooperative multi-agent reinforcement learning (MARL) towards
desired outcomes is challenging, particularly when the global guidance from a
human on the whole multi-agent system is impractical in a large-scale MARL. On
the other hand, designing mechanisms to coordinate agents most relies on
empirical studies, lacking a easy-to-use research tool. In this work, we employ
multi-agent influence diagrams (MAIDs) as a graphical framework to address the
above issues. First, we introduce interaction paradigms that leverage MAIDs to
analyze and visualize existing approaches in MARL. Then, we design a new
interaction paradigm based on MAIDs, referred to as targeted intervention that
is applied to only a single targeted agent, so the problem of global guidance
can be mitigated. In our implementation, we introduce a causal inference
technique-referred to as Pre-Strategy Intervention (PSI)-to realize the
targeted intervention paradigm. Since MAIDs can be regarded as a special class
of causal diagrams, a composite desired outcome that integrates the primary
task goal and an additional desired outcome can be achieved by maximizing the
corresponding causal effect through the PSI. Moreover, the bundled relevance
graph analysis of MAIDs provides a tool to identify whether an MARL learning
paradigm is workable under the design of an interaction paradigm. In
experiments, we demonstrate the effectiveness of our proposed targeted
intervention, and verify the result of relevance graph analysis.

</details>


### [408] [DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA](https://arxiv.org/abs/2510.16302)
*Changhao Wang,Yanfang Liu,Xinxin Fan,Anzhi Zhou,Lao Tian,Yunfeng Lu*

Main category: cs.AI

TL;DR: 提出了一种基于双过程理论的DTKG框架，用于解决多跳问答推理中并行事实验证和链式推理的局限性问题


<details>
  <summary>Details</summary>
Motivation: 当前多跳推理方法要么只使用LLM响应的事实验证，要么只使用知识图谱路径构建，前者擅长并行事实验证但在链式推理上表现不佳，后者擅长链式推理但在处理并行事实验证时存在冗余路径检索问题

Method: 提出DTKG双轨知识图谱验证和推理框架，包含分类阶段和分支处理阶段，受认知科学中的双过程理论启发

Result: 通过双轨框架有效解决了多跳问答推理中的效率和准确性问题

Conclusion: DTKG框架能够更好地处理多跳问答推理任务，提高推理效率和准确性

Abstract: Multi-hop reasoning for question answering (QA) plays a critical role in
retrieval-augmented generation (RAG) for modern large language models (LLMs).
The accurate answer can be obtained through retrieving relational structure of
entities from knowledge graph (KG). Regarding the inherent relation-dependency
and reasoning pattern, multi-hop reasoning can be in general classified into
two categories: i) parallel fact-verification multi-hop reasoning question,
i.e., requiring simultaneous verifications of multiple independent
sub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding
sequential multi-step inference with intermediate conclusions serving as
essential premises for subsequent reasoning. Currently, the multi-hop reasoning
approaches singly employ one of two techniques: LLM response-based fact
verification and KG path-based chain construction. Nevertheless, the former
excels at parallel fact-verification but underperforms on chained reasoning
tasks, while the latter demonstrates proficiency in chained multi-hop reasoning
but suffers from redundant path retrieval when handling parallel
fact-verification reasoning. These limitations deteriorate the efficiency and
accuracy for multi-hop QA tasks. To address this challenge, we propose a novel
dual-track KG verification and reasoning framework DTKG, which is inspired by
the Dual Process Theory in cognitive science. Specifically, DTKG comprises two
main stages: the Classification Stage and the Branch Processing Stage.

</details>


### [409] [MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier](https://arxiv.org/abs/2510.16309)
*Crystal Su*

Main category: cs.AI

TL;DR: MedRule-KG是一个紧凑的类型化知识图谱，结合符号验证器，用于在推理任务中强制执行数学可解释规则，显著提高准确率并消除规则违反。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在产生流畅推理步骤的同时经常违反简单的数学或逻辑约束，需要一种方法来确保推理的数学一致性。

Method: 引入MedRule-KG知识图谱编码实体、关系和三个领域启发规则，配合符号验证器检查预测并应用最小修正以保证一致性。

Result: 在90个FDA衍生基准测试中，基于MedRule-KG的推理将精确匹配从0.767提高到0.900，添加验证器后达到1.000精确匹配并完全消除规则违反。

Conclusion: MedRule-KG为安全数学推理提供了通用框架，通过知识图谱和符号验证确保推理的数学一致性。

Abstract: Large language models (LLMs) often produce fluent reasoning steps while
violating simple mathematical or logical constraints. We introduce MedRule-KG,
a compact typed knowledge graph coupled with a symbolic verifier, designed to
enforce mathematically interpretable rules in reasoning tasks. MedRule-KG
encodes entities, relations, and three domain-inspired rules, while the
verifier checks predictions and applies minimal corrections to guarantee
consistency. On a 90-example FDA-derived benchmark, grounding in MedRule-KG
improves exact match (EM) from 0.767 to 0.900, and adding the verifier yields
1.000 EM while eliminating rule violations entirely. We demonstrate how
MedRule-KG provides a general scaffold for safe mathematical reasoning, discuss
ablations, and release code and data to encourage reproducibility.

</details>


### [410] [Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts](https://arxiv.org/abs/2510.16342)
*Tong Zhang,Ru Zhang,Jianyi Liu,Zhen Yang,Gongshen Liu*

Main category: cs.AI

TL;DR: SELECT是一个动态锚点选择框架，通过两阶段评估机制自动发现最优锚点进行精确概念擦除，同时保留相关概念，解决了固定锚点策略导致的概念重现和侵蚀问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型的概念擦除方法依赖固定锚点策略，导致概念重现和侵蚀等关键问题。

Method: 通过因果追踪揭示擦除对锚点选择的内在敏感性，定义兄弟排他概念作为更优锚点类别，提出SELECT框架，采用新颖的两阶段评估机制自动发现最优锚点。

Result: 广泛评估表明SELECT作为通用锚点解决方案，不仅高效适应多个擦除框架，还在关键性能指标上持续优于现有基线，单个概念锚点挖掘平均仅需4秒。

Conclusion: SELECT框架通过动态锚点选择有效解决了固定锚点策略的局限性，实现了更精确的概念擦除。

Abstract: Existing concept erasure methods for text-to-image diffusion models commonly
rely on fixed anchor strategies, which often lead to critical issues such as
concept re-emergence and erosion. To address this, we conduct causal tracing to
reveal the inherent sensitivity of erasure to anchor selection and define
Sibling Exclusive Concepts as a superior class of anchors. Based on this
insight, we propose \textbf{SELECT} (Sibling-Exclusive Evaluation for
Contextual Targeting), a dynamic anchor selection framework designed to
overcome the limitations of fixed anchors. Our framework introduces a novel
two-stage evaluation mechanism that automatically discovers optimal anchors for
precise erasure while identifying critical boundary anchors to preserve related
concepts. Extensive evaluations demonstrate that SELECT, as a universal anchor
solution, not only efficiently adapts to multiple erasure frameworks but also
consistently outperforms existing baselines across key performance metrics,
averaging only 4 seconds for anchor mining of a single concept.

</details>


### [411] [The Burden of Interactive Alignment with Inconsistent Preferences](https://arxiv.org/abs/2510.16368)
*Ali Shirali*

Main category: cs.AI

TL;DR: 本文研究了用户如何通过策略性互动来引导算法更好地符合其真实兴趣。用户存在理性系统2和冲动系统1的决策冲突，通过建立多领导者-单跟随者的扩展Stackelberg博弈模型，发现存在一个关键优化时间范围：足够远见的用户能实现算法对齐，否则会被算法目标所同化。额外的小成本信号能显著降低对齐负担。


<details>
  <summary>Details</summary>
Motivation: 算法平台和聊天机器人等系统中，用户与算法的多步骤互动过程中，战略用户可以通过选择性互动来引导算法更好地符合其真实兴趣。然而用户经常表现出不一致的偏好，花费大量时间在低价值内容上，无意中向算法传递错误信号。这引发了一个关键问题：用户需要什么条件才能使算法与其真实兴趣对齐？

Method: 将用户决策过程建模为理性系统2（决定是否互动）和冲动系统1（决定互动时长）的分离过程。研究多领导者-单跟随者的扩展Stackelberg博弈，其中用户（特别是系统2）通过承诺互动策略来领导，算法基于观察到的互动做出最佳响应。定义了"对齐负担"作为用户有效引导算法所需的最小优化时间范围。

Result: 存在一个关键优化时间范围：足够远见的用户能够实现算法对齐，而短视的用户反而会被算法的目标所同化。这个关键时间范围可能很长，带来显著的对齐负担。然而，即使是一个小的、有成本的信号（如额外点击）也能显著降低这个负担。

Conclusion: 该框架解释了具有不一致偏好的用户如何在Stackelberg均衡中使基于互动的算法与其兴趣对齐，既突出了实现对齐的挑战，也指出了潜在的补救措施。

Abstract: From media platforms to chatbots, algorithms shape how people interact,
learn, and discover information. Such interactions between users and an
algorithm often unfold over multiple steps, during which strategic users can
guide the algorithm to better align with their true interests by selectively
engaging with content. However, users frequently exhibit inconsistent
preferences: they may spend considerable time on content that offers little
long-term value, inadvertently signaling that such content is desirable.
Focusing on the user side, this raises a key question: what does it take for
such users to align the algorithm with their true interests?
  To investigate these dynamics, we model the user's decision process as split
between a rational system 2 that decides whether to engage and an impulsive
system 1 that determines how long engagement lasts. We then study a
multi-leader, single-follower extensive Stackelberg game, where users,
specifically system 2, lead by committing to engagement strategies and the
algorithm best-responds based on observed interactions. We define the burden of
alignment as the minimum horizon over which users must optimize to effectively
steer the algorithm. We show that a critical horizon exists: users who are
sufficiently foresighted can achieve alignment, while those who are not are
instead aligned to the algorithm's objective. This critical horizon can be
long, imposing a substantial burden. However, even a small, costly signal
(e.g., an extra click) can significantly reduce it. Overall, our framework
explains how users with inconsistent preferences can align an engagement-driven
algorithm with their interests in a Stackelberg equilibrium, highlighting both
the challenges and potential remedies for achieving alignment.

</details>


### [412] [Humanoid-inspired Causal Representation Learning for Domain Generalization](https://arxiv.org/abs/2510.16382)
*Ze Tao,Jian Zhang,Haowei Li,Xianshuai Li,Yifei Peng,Xiyao Liu,Senzhang Wang,Chao Liu,Sheng Ren,Shichao Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种受人类智能启发的结构因果模型（HSCM），通过解耦和重新加权图像的关键属性（如颜色、纹理和形状）来增强跨域泛化能力，在动态复杂环境中实现更有效的迁移学习。


<details>
  <summary>Details</summary>
Motivation: 传统领域泛化模型存在局限性，需要克服依赖统计数据捕捉数据标签依赖关系的不足，受人类视觉系统的分层处理和多级学习机制启发，旨在建模细粒度的因果机制。

Method: HSCM模拟人类视觉系统的层次处理过程，通过解耦和重新加权图像的关键属性（颜色、纹理、形状），专注于建模细粒度的因果机制，利用人类智能的灵活性和适应性。

Result: 通过理论和实证评估证明，HSCM在领域泛化任务中优于现有模型，提供了更原则性的方法来捕捉因果关系并提高模型鲁棒性。

Conclusion: HSCM为领域泛化问题提供了一个更原则性的因果框架，通过模拟人类智能机制实现了更好的泛化性能和可解释性。

Abstract: This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a
novel causal framework inspired by human intelligence, designed to overcome the
limitations of conventional domain generalization models. Unlike approaches
that rely on statistics to capture data-label dependencies and learn
distortion-invariant representations, HSCM replicates the hierarchical
processing and multi-level learning of human vision systems, focusing on
modeling fine-grained causal mechanisms. By disentangling and reweighting key
image attributes such as color, texture, and shape, HSCM enhances
generalization across diverse domains, ensuring robust performance and
interpretability. Leveraging the flexibility and adaptability of human
intelligence, our approach enables more effective transfer and learning in
dynamic, complex environments. Through both theoretical and empirical
evaluations, we demonstrate that HSCM outperforms existing domain
generalization models, providing a more principled method for capturing causal
relationships and improving model robustness. The code is available at
https://github.com/lambett/HSCM.

</details>


### [413] [RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile](https://arxiv.org/abs/2510.16392)
*Ao Tian,Yunfeng Lu,Xinxin Fan,Changhao Wang,Lanzhi Zhou,Yeyao Zhang,Yanfang Liu*

Main category: cs.AI

TL;DR: RGMem框架通过多尺度信息压缩和涌现过程，从对话历史中动态构建用户画像，解决LLM对话系统中长期用户建模和行为一致性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案如RAG和显式记忆系统主要关注事实级存储和检索，缺乏从多轮对话中提取潜在偏好和深层特征的能力，限制了长期有效的用户建模，导致个性化交互浅层化并阻碍跨会话连续性。

Method: 受物理学重正化群思想启发，RGMem框架通过分层粗粒化和重标度操作，在多尺度上组织对话历史：首先从片段中提取语义和用户洞察，然后逐步形成动态演化的用户画像。

Result: 该框架实现了从噪声和微观级交互中构建高级准确的用户画像，为语言智能体提供长期记忆和行为一致性能力。

Conclusion: RGMem通过模拟记忆演化的多尺度过程，成功解决了LLM时代语言智能体的长期记忆和行为一致性问题，为深度个性化交互提供了有效解决方案。

Abstract: Personalized and continuous interactions are the key to enhancing user
experience in today's large language model (LLM)-based conversational systems,
however, the finite context windows and static parametric memory make it
difficult to model the cross-session long-term user states and behavioral
consistency. Currently, the existing solutions to this predicament, such as
retrieval-augmented generation (RAG) and explicit memory systems, primarily
focus on fact-level storage and retrieval, lacking the capability to distill
latent preferences and deep traits from the multi-turn dialogues, which limits
the long-term and effective user modeling, directly leading to the personalized
interactions remaining shallow, and hindering the cross-session continuity. To
realize the long-term memory and behavioral consistency for Language Agents in
LLM era, we propose a self-evolving memory framework RGMem, inspired by the
ideology of classic renormalization group (RG) in physics, this framework
enables to organize the dialogue history in multiple scales: it first extracts
semantics and user insights from episodic fragments, then through hierarchical
coarse-graining and rescaling operations, progressively forms a
dynamically-evolved user profile. The core innovation of our work lies in
modeling memory evolution as a multi-scale process of information compression
and emergence, which accomplishes the high-level and accurate user profiles
from noisy and microscopic-level interactions.

</details>


### [414] [ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights](https://arxiv.org/abs/2510.16466)
*Siddhartha Krothapalli,Tridib Kumar Das,Praveen Kumar,Naveen Suravarpu,Pratik Narang*

Main category: cs.AI

TL;DR: ReviewSense是一个新颖的规范性决策支持框架，利用先进的大型语言模型将客户评论转化为有针对性的、可操作的业务建议。


<details>
  <summary>Details</summary>
Motivation: 随着客户反馈在战略增长中日益重要，从非结构化评论中获取可操作见解的能力至关重要。传统AI系统擅长预测用户偏好，但很少有工作专注于将客户评论转化为面向业务的规范性建议。

Method: 通过整合聚类、LLM适应和专家驱动评估，构建统一的面向业务的流程，识别客户情感中的关键趋势、重复问题和具体关注点。

Result: 初步人工评估表明，模型建议与业务目标高度一致，突显其在推动数据驱动决策方面的潜力。

Conclusion: 该框架为AI驱动的情感分析提供了新视角，展示了其在优化业务策略和最大化客户反馈影响方面的价值。

Abstract: As customer feedback becomes increasingly central to strategic growth, the
ability to derive actionable insights from unstructured reviews is essential.
While traditional AI-driven systems excel at predicting user preferences, far
less work has focused on transforming customer reviews into prescriptive,
business-facing recommendations. This paper introduces ReviewSense, a novel
prescriptive decision support framework that leverages advanced large language
models (LLMs) to transform customer reviews into targeted, actionable business
recommendations. By identifying key trends, recurring issues, and specific
concerns within customer sentiments, ReviewSense extends beyond
preference-based systems to provide businesses with deeper insights for
sustaining growth and enhancing customer loyalty. The novelty of this work lies
in integrating clustering, LLM adaptation, and expert-driven evaluation into a
unified, business-facing pipeline. Preliminary manual evaluations indicate
strong alignment between the model's recommendations and business objectives,
highlighting its potential for driving data-informed decision-making. This
framework offers a new perspective on AI-driven sentiment analysis,
demonstrating its value in refining business strategies and maximizing the
impact of customer feedback.

</details>


### [415] [NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems](https://arxiv.org/abs/2510.16476)
*Xiaozhe Li,Xinyu Fang,Shengyuan Ding,Linyang Li,Haodong Duan,Qingwen Liu,Kai Chen*

Main category: cs.AI

TL;DR: 提出了NP-ENGINE框架，这是首个专门用于训练和评估LLMs解决NP-hard问题的综合框架，包含10个任务、可控实例生成器、规则验证器和启发式求解器。通过该框架训练的QWEN2.5-7B-NP模型在NP-BENCH基准上显著超越GPT-4o，并展示了强大的跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在数学、编程、逻辑等推理任务上表现出色，但在解决更复杂的NP-hard优化问题方面的能力仍未充分探索。需要建立一个专门框架来训练和评估LLMs处理这类具有挑战性的问题。

Method: 开发了NP-ENGINE框架，包含10个跨5个领域的任务，每个任务配备可控实例生成器、规则验证器和提供近似最优解的启发式求解器。采用生成器-验证器-启发式求解器管道，支持可扩展和可验证的RLVR训练，并使用课程学习进行零RLVR训练。

Result: 训练的QWEN2.5-7B-NP模型在NP-BENCH基准上显著超越GPT-4o，达到相同模型尺寸下的SOTA性能。此外，NP-ENGINE-DATA的RLVR训练还实现了强大的跨领域泛化能力，包括推理任务（逻辑、谜题、数学、知识）和非推理任务（指令跟随）。

Conclusion: 任务丰富的RLVR训练是提升LLM推理能力的有前景方向，揭示了RLVR的扩展规律。增加任务多样性可以改善跨领域泛化能力，为LLMs在复杂优化问题上的应用开辟了新途径。

Abstract: Large Language Models (LLMs) have shown strong reasoning capabilities, with
models like OpenAI's O-series and DeepSeek R1 excelling at tasks such as
mathematics, coding, logic, and puzzles through Reinforcement Learning with
Verifiable Rewards (RLVR). However, their ability to solve more complex
optimization problems - particularly NP-hard tasks - remains underexplored. To
bridge this gap, we propose NP-ENGINE, the first comprehensive framework for
training and evaluating LLMs on NP-hard problems. NP-ENGINE covers 10 tasks
across five domains, each equipped with (i) a controllable instance generator,
(ii) a rule-based verifier, and (iii) a heuristic solver that provides
approximate optimal solutions as ground truth. This
generator-verifier-heuristic pipeline enables scalable and verifiable RLVR
training under hierarchical difficulties. We also introduce NP-BENCH, a
benchmark derived from NP-ENGINE-DATA, specifically designed to evaluate LLMs'
ability to tackle NP-hard level reasoning problems, focusing not only on
feasibility but also on solution quality. Additionally, we present
QWEN2.5-7B-NP, a model trained via zero-RLVR with curriculum learning on
Qwen2.5-7B-Instruct, which significantly outperforms GPT-4o on NP-BENCH and
achieves SOTA performance with the same model size. Beyond in-domain tasks, we
demonstrate that RLVR training on NP-ENGINE-DATA enables strong out-of-domain
(OOD) generalization to reasoning tasks (logic, puzzles, math, and knowledge),
as well as non-reasoning tasks such as instruction following. We also observe a
scaling trend: increasing task diversity improves OOD generalization. These
findings suggest that task-rich RLVR training is a promising direction for
advancing LLM's reasoning ability, revealing new insights into the scaling laws
of RLVR.

</details>


### [416] [Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?](https://arxiv.org/abs/2510.16582)
*Junchi Yu,Yujie Liu,Jindong Gu,Philip Torr,Dongzhan Zhou*

Main category: cs.AI

TL;DR: GraphFlow是一个基于知识图谱的检索增强生成框架，通过转移流匹配目标联合优化检索策略和流估计器，从文本丰富的知识图谱中高效检索准确多样的知识，在STaRK基准测试中比现有方法平均提升10%的命中率和召回率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的检索增强生成方法难以从文本丰富的知识图谱中为复杂真实世界查询检索准确多样的信息，而过程奖励模型虽然能对齐检索过程与查询需求，但依赖昂贵且难以获取的过程级监督信号。

Method: GraphFlow采用转移流匹配目标联合优化检索策略和流估计器，流估计器将检索结果的奖励分解到中间检索状态，引导检索策略按奖励比例从知识图谱中检索候选，从而探索产生多样相关结果的高质量图谱区域。

Result: 在包含多领域真实世界查询的STaRK基准测试中，GraphFlow比包括GPT-4o在内的强基线方法平均提升10%的命中率和召回率，并对未见过的知识图谱表现出强泛化能力。

Conclusion: GraphFlow通过奖励分解和流匹配有效解决了文本丰富知识图谱中的检索挑战，在准确性和多样性方面显著优于现有方法，并具有良好的泛化性和鲁棒性。

Abstract: Retrieval-Augmented Generation (RAG) based on knowledge graphs (KGs) enhances
large language models (LLMs) by providing structured and interpretable external
knowledge. However, existing KG-based RAG methods struggle to retrieve accurate
and diverse information from text-rich KGs for complex real-world queries.
Process Reward Models (PRMs) offer a way to align the retrieval process of
KG-based RAG with query-specific knowledge requirements, but they heavily rely
on process-level supervision signals that are expensive and hard to obtain on
KGs. To address this challenge, we propose GraphFlow, a framework that
efficiently retrieves accurate and diverse knowledge required for real-world
queries from text-rich KGs. GraphFlow employs a transition-based flow matching
objective to jointly optimize a retrieval policy and a flow estimator. The flow
estimator factorizes the reward of the retrieval outcome into the intermediate
retrieval states. Such reward factorization guides the retrieval policy to
retrieve candidates from KGs in proportion to their reward. This allows
GraphFlow to explore high-quality regions of KGs that yield diverse and
relevant results. We evaluate GraphFlow on the STaRK benchmark, which includes
real-world queries from multiple domains over text-rich KGs. GraphFlow
outperforms strong KG-RAG baselines, including GPT-4o, by 10% on average in hit
rate and recall. It also shows strong generalization to unseen KGs,
demonstrating its effectiveness and robustness.

</details>


### [417] [Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning](https://arxiv.org/abs/2510.16601)
*Tianxing Wu,Shutong Zhu,Jingting Wang,Ning Xu,Guilin Qi,Haofen Wang*

Main category: cs.AI

TL;DR: 提出了一种用于不确定知识图谱补全的半监督置信分布学习方法，通过将置信度转换为分布来增强嵌入学习，并使用元学习生成伪标签来平衡置信度分布。


<details>
  <summary>Details</summary>
Motivation: 现有不确定知识图谱补全方法忽略了置信度的极端不平衡分布，导致学习到的嵌入不足以支持高质量的补全。

Method: 提出ssCDL方法，将置信度转换为置信分布引入更多监督信息，通过元学习生成伪标签来增强训练数据并重新平衡置信度分布。

Result: 在两个UKG数据集上的实验表明，ssCDL在不同评估指标上始终优于最先进的基线方法。

Conclusion: ssCDL方法通过处理置信度不平衡问题，显著提升了不确定知识图谱补全的性能。

Abstract: Uncertain knowledge graphs (UKGs) associate each triple with a confidence
score to provide more precise knowledge representations. Recently, since
real-world UKGs suffer from the incompleteness, uncertain knowledge graph (UKG)
completion attracts more attention, aiming to complete missing triples and
confidences. Current studies attempt to learn UKG embeddings to solve this
problem, but they neglect the extremely imbalanced distributions of triple
confidences. This causes that the learnt embeddings are insufficient to
high-quality UKG completion. Thus, in this paper, to address the above issue,
we propose a new semi-supervised Confidence Distribution Learning (ssCDL)
method for UKG completion, where each triple confidence is transformed into a
confidence distribution to introduce more supervision information of different
confidences to reinforce the embedding learning process. ssCDL iteratively
learns UKG embedding by relational learning on labeled data (i.e., existing
triples with confidences) and unlabeled data with pseudo labels (i.e., unseen
triples with the generated confidences), which are predicted by meta-learning
to augment the training data and rebalance the distribution of triple
confidences. Experiments on two UKG datasets demonstrate that ssCDL
consistently outperforms state-of-the-art baselines in different evaluation
metrics.

</details>


### [418] [Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards](https://arxiv.org/abs/2510.16614)
*Xuan Zhang,Ruixiao Li,Zhijian Zhou,Long Li,Yulei Qin,Ke Li,Xing Sun,Xiaoyu Tan,Chao Qu,Yuan Qi*

Main category: cs.AI

TL;DR: MERCI是一种新颖的强化学习算法，通过基于计数的内在奖励来增强语言模型在多步推理中的探索能力，显著提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习范式依赖稀疏的结果奖励和有限探索，导致语言模型陷入重复和次优的推理模式。

Method: 提出MERCI算法，使用轻量级Coin Flipping Network估计推理轨迹的伪计数和认知不确定性，将其转换为内在奖励，并与GRPO等先进RL框架集成。

Result: 在复杂推理基准测试中，MERCI鼓励更丰富多样的思维链，显著超越强基线性能，帮助策略逃离局部最优发现更好解决方案。

Conclusion: 针对性的内在动机可以使语言模型推理的探索更加可靠有效。

Abstract: Reinforcement Learning (RL) has become a compelling way to strengthen the
multi step reasoning ability of Large Language Models (LLMs). However,
prevalent RL paradigms still lean on sparse outcome-based rewards and limited
exploration, which often drives LLMs toward repetitive and suboptimal reasoning
patterns. In this paper, we study the central question of how to design
exploration for LLM reasoning and introduce MERCI (Motivating Exploration in
LLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that
augments policy optimization with a principled intrinsic reward. Building on
the idea of count-based exploration, MERCI leverages a lightweight Coin
Flipping Network (CFN) to estimate the pseudo count and further epistemic
uncertainty over reasoning trajectories, and converts them into an intrinsic
reward that values novelty while preserving the learning signal from task
rewards. We integrate MERCI into some advanced RL frameworks like Group
Relative Policy Optimization (GRPO). Experiments on complex reasoning
benchmarks demonstrate that MERCI encourages richer and more varied chains of
thought, significantly improves performance over strong baselines, and helps
the policy escape local routines to discover better solutions. It indicates
that our targeted intrinsic motivation can make exploration reliable for
language model reasoning.

</details>


### [419] [Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review](https://arxiv.org/abs/2510.16658)
*Shihao Yang,Xiying Huang,Danilo Bernardo,Jun-En Ding,Andrew Michael,Jingmei Yang,Patrick Kwan,Ashish Raj,Feng Liu*

Main category: cs.AI

TL;DR: 大规模AI模型正在变革神经科学研究，通过端到端学习从原始脑信号中提取信息，在神经影像、脑机接口、分子神经科学、临床辅助和疾病应用等五大领域产生深远影响。


<details>
  <summary>Details</summary>
Motivation: 探索大规模AI模型如何解决神经科学中的关键计算挑战，包括多模态神经数据整合、时空模式解释以及临床转化框架的开发。

Method: 综述分析大规模AI模型在五个主要神经科学领域的应用：神经影像与数据处理、脑机接口与神经解码、分子神经科学与基因组建模、临床辅助与转化框架、神经系统与精神疾病的特定应用。

Result: 这些模型被证明能够有效整合多模态神经数据，解释时空模式，并开发临床转化框架。同时，神经科学与AI的互动变得更加双向，生物启发的架构约束被用于开发更可解释和计算高效的模型。

Conclusion: 大规模AI模型在神经科学中展现出巨大潜力，但需要建立严格的评估框架、有效的领域知识整合以及全面的临床使用伦理指南。文章还提供了用于验证这些模型的关键神经科学数据集清单。

Abstract: The advent of large-scale artificial intelligence (AI) models has a
transformative effect on neuroscience research, which represents a paradigm
shift from the traditional computational methods through the facilitation of
end-to-end learning from raw brain signals and neural data. In this paper, we
explore the transformative effects of large-scale AI models on five major
neuroscience domains: neuroimaging and data processing, brain-computer
interfaces and neural decoding, molecular neuroscience and genomic modeling,
clinical assistance and translational frameworks, and disease-specific
applications across neurological and psychiatric disorders. These models are
demonstrated to address major computational neuroscience challenges, including
multimodal neural data integration, spatiotemporal pattern interpretation, and
the derivation of translational frameworks for clinical deployment. Moreover,
the interaction between neuroscience and AI has become increasingly reciprocal,
as biologically informed architectural constraints are now incorporated to
develop more interpretable and computationally efficient models. This review
highlights both the notable promise of such technologies and key implementation
considerations, with particular emphasis on rigorous evaluation frameworks,
effective domain knowledge integration, and comprehensive ethical guidelines
for clinical use. Finally, a systematic listing of critical neuroscience
datasets used to derive and validate large-scale AI models across diverse
research applications is provided.

</details>


### [420] [ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion](https://arxiv.org/abs/2510.16753)
*Wei Huang,Peining Li,Meiyu Liang,Xu Hou,Junping Du,Yingxia Shao,Guanhua Ye,Wu Liu,Kangkang Lu,Yang Yu*

Main category: cs.AI

TL;DR: 本文提出了ELMM方法，通过多视图视觉标记压缩器和注意力剪枝策略，解决了多模态知识图谱补全中的语义噪声、模态冲突和计算成本高的问题，在保持性能的同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 多模态知识图谱（MKGs）虽然通过融合视觉和文本模态提供了更丰富的实体表示，但现有MKGs存在不完整性问题。虽然大语言模型在知识图谱补全中表现出潜力，但在多模态设置中的应用仍待探索，且面临图像标记数量多导致语义噪声和模态冲突，以及处理大量标记输入的高计算成本等挑战。

Method: 提出了ELMM方法，包含：1）基于多头注意力机制的多视图视觉标记压缩器（MVTC），从文本和视觉视图自适应压缩图像标记；2）注意力剪枝策略，移除MLLMs中的冗余注意力层；3）线性投影来补偿剪枝带来的性能下降。

Result: 在FB15k-237-IMG和WN18-IMG基准测试上的广泛实验表明，ELMM实现了最先进的性能，同时显著提高了计算效率。

Conclusion: ELMM为多模态知识图谱补全建立了一个新的范式，在保持高性能的同时大幅提升了计算效率。

Abstract: Multimodal Knowledge Graphs (MKGs) extend traditional knowledge graphs by
incorporating visual and textual modalities, enabling richer and more
expressive entity representations. However, existing MKGs often suffer from
incompleteness, which hinder their effectiveness in downstream tasks.
Therefore, multimodal knowledge graph completion (MKGC) task is receiving
increasing attention. While large language models (LLMs) have shown promise for
knowledge graph completion (KGC), their application to the multimodal setting
remains underexplored. Moreover, applying Multimodal Large Language Models
(MLLMs) to the task of MKGC introduces significant challenges: (1) the large
number of image tokens per entity leads to semantic noise and modality
conflicts, and (2) the high computational cost of processing large token
inputs. To address these issues, we propose Efficient Lightweight Multimodal
Large Language Models (ELMM) for MKGC. ELMM proposes a Multi-view Visual Token
Compressor (MVTC) based on multi-head attention mechanism, which adaptively
compresses image tokens from both textual and visual views, thereby effectively
reducing redundancy while retaining necessary information and avoiding modality
conflicts. Additionally, we design an attention pruning strategy to remove
redundant attention layers from MLLMs, thereby significantly reducing the
inference cost. We further introduce a linear projection to compensate for the
performance degradation caused by pruning. Extensive experiments on benchmark
FB15k-237-IMG and WN18-IMG demonstrate that ELMM achieves state-of-the-art
performance while substantially improving computational efficiency,
establishing a new paradigm for multimodal knowledge graph completion.

</details>


### [421] [Domain-Contextualized Concept Graphs: A Computable Framework for Knowledge Representation](https://arxiv.org/abs/2510.16802)
*Chao Li,Yuru Wang*

Main category: cs.AI

TL;DR: 提出Domain-Contextualized Concept Graph (CDC)框架，将领域作为概念表示的一等元素，采用C-D-C三元组结构，克服传统知识图谱固定本体的限制，实现上下文感知推理和跨领域类比。


<details>
  <summary>Details</summary>
Motivation: 传统知识图谱受限于固定本体，将领域作为隐含上下文而非显式推理组件，限制了知识建模的灵活性和上下文感知能力。

Method: 提出CDC框架，采用<概念, 关系@领域, 概念'>的三元组结构，基于认知语言学同构映射原理，定义20+标准化关系谓词，并在Prolog中实现完整推理能力。

Result: 在教育、企业知识系统和技术文档等案例研究中，CDC实现了上下文感知推理、跨领域类比和个性化知识建模等传统本体框架无法实现的能力。

Conclusion: CDC框架通过将领域提升为一等表示元素，有效克服了传统知识图谱的局限性，为上下文感知的知识建模和推理提供了新范式。

Abstract: Traditional knowledge graphs are constrained by fixed ontologies that
organize concepts within rigid hierarchical structures. The root cause lies in
treating domains as implicit context rather than as explicit, reasoning-level
components. To overcome these limitations, we propose the Domain-Contextualized
Concept Graph (CDC), a novel knowledge modeling framework that elevates domains
to first-class elements of conceptual representation. CDC adopts a C-D-C triple
structure - <Concept, Relation@Domain, Concept'> - where domain specifications
serve as dynamic classification dimensions defined on demand. Grounded in a
cognitive-linguistic isomorphic mapping principle, CDC operationalizes how
humans understand concepts through contextual frames. We formalize more than
twenty standardized relation predicates (structural, logical, cross-domain, and
temporal) and implement CDC in Prolog for full inference capability. Case
studies in education, enterprise knowledge systems, and technical documentation
demonstrate that CDC enables context-aware reasoning, cross-domain analogy, and
personalized knowledge modeling - capabilities unattainable under traditional
ontology-based frameworks.

</details>


### [422] [A Comparative User Evaluation of XRL Explanations using Goal Identification](https://arxiv.org/abs/2510.16956)
*Mark Towers,Yali Du,Christopher Freeman,Timothy J. Norman*

Main category: cs.AI

TL;DR: 本文提出了一种新的评估方法，用于测试用户能否从强化学习算法的决策解释中识别出智能体的目标。在Atari的Ms. Pacman环境中测试了四种可解释强化学习算法，发现只有一种算法在测试目标上达到了高于随机水平的准确率，且用户普遍对自己的选择过于自信。


<details>
  <summary>Details</summary>
Motivation: 可解释强化学习算法的核心应用之一是调试，但目前缺乏对其相对性能的比较评估。

Method: 使用Atari的Ms. Pacman环境和四种可解释强化学习算法，通过用户能否从决策解释中识别智能体目标来评估算法性能。

Result: 只有一种算法在测试目标上达到了高于随机水平的准确率；用户普遍对自己的选择过于自信；用户自报的识别和理解难易程度与他们的准确率没有相关性。

Conclusion: 当前的可解释强化学习算法在帮助用户理解智能体目标方面效果有限，用户的主观感知与实际理解能力存在偏差。

Abstract: Debugging is a core application of explainable reinforcement learning (XRL)
algorithms; however, limited comparative evaluations have been conducted to
understand their relative performance. We propose a novel evaluation
methodology to test whether users can identify an agent's goal from an
explanation of its decision-making. Utilising the Atari's Ms. Pacman
environment and four XRL algorithms, we find that only one achieved greater
than random accuracy for the tested goals and that users were generally
overconfident in their selections. Further, we find that users' self-reported
ease of identification and understanding for every explanation did not
correlate with their accuracy.

</details>


### [423] [STARK: Strategic Team of Agents for Refining Kernels](https://arxiv.org/abs/2510.16996)
*Juncheng Dong,Yang Yang,Tao Liu,Yang Wang,Feng Qi,Vahid Tarokh,Kaushik Rangadurai,Shuang Yang*

Main category: cs.AI

TL;DR: 提出了一个基于LLM的多智能体框架，用于自动化GPU内核优化，通过系统化的设计空间探索和迭代优化，显著提升了内核性能。


<details>
  <summary>Details</summary>
Motivation: GPU内核优化对现代AI发展至关重要，但传统优化方法困难且耗时，现有LLM方法无法有效处理复杂的内核优化问题。

Method: 采用多智能体协作框架，结合基于知识的指导、动态上下文管理和策略搜索，模拟专家工程师的工作流程进行迭代优化。

Result: 在KernelBench基准测试中，系统在基线方法失败的情况下仍能生成正确解决方案，并实现高达16倍的运行时性能提升。

Conclusion: 智能体LLM框架在实现完全自动化、可扩展的GPU内核优化方面具有巨大潜力。

Abstract: The efficiency of GPU kernels is central to the progress of modern AI, yet
optimizing them remains a difficult and labor-intensive task due to complex
interactions between memory hierarchies, thread scheduling, and
hardware-specific characteristics. While recent advances in large language
models (LLMs) provide new opportunities for automated code generation, existing
approaches largely treat LLMs as single-shot generators or naive refinement
tools, limiting their effectiveness in navigating the irregular kernel
optimization landscape. We introduce an LLM agentic framework for GPU kernel
optimization that systematically explores the design space through multi-agent
collaboration, grounded instruction, dynamic context management, and strategic
search. This framework mimics the workflow of expert engineers, enabling LLMs
to reason about hardware trade-offs, incorporate profiling feedback, and refine
kernels iteratively. We evaluate our approach on KernelBench, a benchmark for
LLM-based kernel optimization, and demonstrate substantial improvements over
baseline agents: our system produces correct solutions where baselines often
fail, and achieves kernels with up to 16x faster runtime performance. These
results highlight the potential of agentic LLM frameworks to advance fully
automated, scalable GPU kernel optimization.

</details>


### [424] [ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems](https://arxiv.org/abs/2510.17052)
*Hassan Hamad,Yingru Xu,Liang Zhao,Wenbo Yan,Narendra Gyanchandani*

Main category: cs.AI

TL;DR: ToolCritic是一个诊断框架，用于评估和改进大语言模型在多轮工具增强对话中的行为，通过检测8种特定工具调用错误并提供针对性反馈，使主LLM能够修正响应，在SGD数据集上工具调用准确率提升高达13%。


<details>
  <summary>Details</summary>
Motivation: 工具增强的大语言模型在现实应用中越来越普遍，但工具使用错误仍然阻碍其可靠性，需要一种方法来评估和改进LLM在工具增强对话中的行为。

Method: ToolCritic框架检测8种特定工具调用错误类型（如过早调用、参数不对齐、工具输出误解等），并为具有强推理能力的主LLM提供针对性反馈，主LLM基于反馈修正响应。通过系统定义错误类别并构建合成数据集来训练ToolCritic。

Result: 在Schema-Guided Dialogue数据集上的实验结果表明，ToolCritic相比基线（包括零样本提示和自校正技术）将工具调用准确率提升了高达13%。

Conclusion: ToolCritic代表了在现实世界对话应用中实现更稳健的LLM与外部工具集成的有希望的一步。

Abstract: Tool-augmented large language models (LLMs) are increasingly employed in
real-world applications, but tool usage errors still hinder their reliability.
We introduce ToolCritic, a diagnostic framework that evaluates and improves LLM
behavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight
distinct error types specific to tool-calling (e.g., premature invocation,
argument misalignment, and misinterpretation of tool outputs) and provides
targeted feedback to the main LLM. The main LLM, assumed to have strong
reasoning, task understanding and orchestration capabilities, then revises its
response based on ToolCritic's feedback. We systematically define these error
categories and construct a synthetic dataset to train ToolCritic. Experimental
results on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic
improves tool-calling accuracy by up to 13% over baselines, including zero-shot
prompting and self-correction techniques. This represents a promising step
toward more robust LLM integration with external tools in real-world dialogue
applications.

</details>


### [425] [A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation](https://arxiv.org/abs/2510.17064)
*Rongbin Li,Wenbo Chen,Zhao Li,Rodrigo Munoz-Castaneda,Jinbo Li,Neha S. Maurya,Arnav Solanki,Huan He,Hanwen Xing,Meaghan Ramlakhan,Zachary Wise,Zhuhao Wu,Hua Xu,Michael Hawrylycz,W. Jim Zheng*

Main category: cs.AI

TL;DR: BRAINCELL-AID是一个多智能体AI系统，通过整合自由文本描述和本体标签，结合检索增强生成技术，显著提升了基因集注释的准确性和鲁棒性，在脑细胞图谱分析中取得了77%的准确率。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序技术虽然能识别多样细胞类型及其转录组特征，但对涉及特征不明确基因的注释仍面临挑战。传统方法如GSEA依赖精心策划的注释，在这些情况下表现不佳，而大型语言模型难以在结构化本体中表示复杂生物知识。

Method: 开发BRAINCELL-AID多智能体AI系统，整合自由文本描述与本体标签，采用检索增强生成技术构建稳健的智能体工作流程，通过相关PubMed文献精炼预测，减少幻觉并增强可解释性。

Result: 在鼠类基因集注释中，77%的基因集在其前几位预测中获得正确注释；成功注释了来自BRAIN Initiative Cell Census Network生成的5,322个脑细胞簇，识别了区域特异性基因共表达模式，并推断了基因集合的功能作用；还识别了具有神经学意义的基底神经节相关细胞类型。

Conclusion: BRAINCELL-AID创建了一个支持社区驱动细胞类型注释的宝贵资源，通过整合多源信息和智能体工作流程，显著提升了基因集注释的准确性和生物学意义。

Abstract: Single-cell RNA sequencing has transformed our ability to identify diverse
cell types and their transcriptomic signatures. However, annotating these
signatures-especially those involving poorly characterized genes-remains a
major challenge. Traditional methods, such as Gene Set Enrichment Analysis
(GSEA), depend on well-curated annotations and often perform poorly in these
contexts. Large Language Models (LLMs) offer a promising alternative but
struggle to represent complex biological knowledge within structured
ontologies. To address this, we present BRAINCELL-AID (BRAINCELL-AID:
https://biodataai.uth.edu/BRAINCELL-AID), a novel multi-agent AI system that
integrates free-text descriptions with ontology labels to enable more accurate
and robust gene set annotation. By incorporating retrieval-augmented generation
(RAG), we developed a robust agentic workflow that refines predictions using
relevant PubMed literature, reducing hallucinations and enhancing
interpretability. Using this workflow, we achieved correct annotations for 77%
of mouse gene sets among their top predictions. Applying this approach, we
annotated 5,322 brain cell clusters from the comprehensive mouse brain cell
atlas generated by the BRAIN Initiative Cell Census Network, enabling novel
insights into brain cell function by identifying region-specific gene
co-expression patterns and inferring functional roles of gene ensembles.
BRAINCELL-AID also identifies Basal Ganglia-related cell types with
neurologically meaningful descriptions. Hence, we create a valuable resource to
support community-driven cell type annotation.

</details>


### [426] [Enhanced Fish Freshness Classification with Incremental Handcrafted Feature Fusion](https://arxiv.org/abs/2510.17145)
*Phi-Hung Hoang,Nam-Thuan Trinh,Van-Manh Tran,Thi-Thu-Hong Phan*

Main category: cs.AI

TL;DR: 该论文提出了一种基于手工特征的方法，通过提取和融合颜色统计、多颜色空间直方图以及纹理特征来评估鱼类新鲜度，在FFE数据集上取得了显著优于深度学习的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统感官评估鱼类新鲜度存在主观性、不一致性和难以标准化的问题，特别是在物种依赖性腐败线索方面存在局限性。

Method: 从鱼眼图像中系统提取互补描述符，包括颜色统计、多颜色空间直方图以及LBP和GLCM纹理特征，捕获全局色度变化和局部ROI退化，并独立融合评估其有效性。

Result: 在标准训练测试设置下，LightGBM分类器达到77.56%准确率，比之前深度学习基线63.21%提升14.35%；使用增强数据时，ANN达到97.16%准确率，比之前最佳77.3%提升19.86%。

Conclusion: 精心设计的手工特征经过策略性处理后，能够为自动化鱼类新鲜度评估提供稳健、可解释且可靠的解决方案，为食品质量监测的实际应用提供宝贵见解。

Abstract: Accurate assessment of fish freshness remains a major challenge in the food
industry, with direct consequences for product quality, market value, and
consumer health. Conventional sensory evaluation is inherently subjective,
inconsistent, and difficult to standardize across contexts, often limited by
subtle, species-dependent spoilage cues. To address these limitations, we
propose a handcrafted feature-based approach that systematically extracts and
incrementally fuses complementary descriptors, including color statistics,
histograms across multiple color spaces, and texture features such as Local
Binary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish
eye images. Our method captures global chromatic variations from full images
and localized degradations from ROI segments, fusing each independently to
evaluate their effectiveness in assessing freshness. Experiments on the
Freshness of the Fish Eyes (FFE) dataset demonstrate the approach's
effectiveness: in a standard train-test setting, a LightGBM classifier achieved
77.56% accuracy, a 14.35% improvement over the previous deep learning baseline
of 63.21%. With augmented data, an Artificial Neural Network (ANN) reached
97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results
demonstrate that carefully engineered, handcrafted features, when strategically
processed, yield a robust, interpretable, and reliable solution for automated
fish freshness assessment, providing valuable insights for practical
applications in food quality monitoring.

</details>


### [427] [Physics-Informed Large Language Models for HVAC Anomaly Detection with Autonomous Rule Generation](https://arxiv.org/abs/2510.17146)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: PILLM是一个基于物理知识的LLM框架，通过进化循环自动生成、评估和优化HVAC系统异常检测规则，结合热力学和控制理论约束，实现可解释且物理合理的检测方法。


<details>
  <summary>Details</summary>
Motivation: HVAC系统能耗占建筑能耗很大比重，现有基于规则的方法缺乏适应性，深度学习缺乏透明度和物理合理性，LLM方法又忽略了物理原理。

Method: 提出PILLM框架，在进化循环中使用物理知识引导的反思和交叉操作，嵌入热力学和控制理论约束，自动生成和优化异常检测规则。

Result: 在公开建筑故障检测数据集上达到最先进性能，生成可解释且可操作的诊断规则。

Conclusion: PILLM推进了智能建筑系统中可信赖和可部署AI的发展，实现了自适应且物理基础的异常检测。

Abstract: Heating, Ventilation, and Air-Conditioning (HVAC) systems account for a
substantial share of global building energy use, making reliable anomaly
detection essential for improving efficiency and reducing emissions. Classical
rule-based approaches offer explainability but lack adaptability, while deep
learning methods provide predictive power at the cost of transparency,
efficiency, and physical plausibility. Recent attempts to use Large Language
Models (LLMs) for anomaly detection improve interpretability but largely ignore
the physical principles that govern HVAC operations. We present PILLM, a
Physics-Informed LLM framework that operates within an evolutionary loop to
automatically generate, evaluate, and refine anomaly detection rules. Our
approach introduces physics-informed reflection and crossover operators that
embed thermodynamic and control-theoretic constraints, enabling rules that are
both adaptive and physically grounded. Experiments on the public Building Fault
Detection dataset show that PILLM achieves state-of-the-art performance while
producing diagnostic rules that are interpretable and actionable, advancing
trustworthy and deployable AI for smart building systems.

</details>


### [428] [Which LLM Multi-Agent Protocol to Choose?](https://arxiv.org/abs/2510.17149)
*Hongyi Du,Jiaqi Su,Jisen Li,Lijie Ding,Yingxuan Yang,Peixuan Han,Xiangru Tang,Kunlun Zhu,Jiaxuan You*

Main category: cs.AI

TL;DR: ProtocolBench是一个系统评估多智能体系统通信协议的基准测试，包含任务成功率、端到端延迟、消息开销和故障恢复四个维度。研究发现协议选择对系统性能有显著影响，并提出了ProtocolRouter学习型协议路由器来优化协议选择。


<details>
  <summary>Details</summary>
Motivation: 随着大规模多智能体系统的发展，通信协议层已成为影响性能和可靠性的关键因素，但目前协议选择缺乏标准化指导，主要依赖直觉。

Method: 引入ProtocolBench基准测试系统，从四个可测量维度比较智能体协议；提出ProtocolRouter学习型协议路由器，根据需求和运行时信号为每个场景或模块选择最佳协议。

Result: 在ProtocolBench测试中，协议选择显著影响系统行为：在流式队列场景中，总体完成时间差异达36.5%，平均端到端延迟差异为3.48秒；在故障风暴恢复场景中，ProtocolRouter相比最佳单协议基线将恢复时间减少了18.1%。

Conclusion: 协议选择对多智能体系统性能至关重要，ProtocolBench和ProtocolRouter提供了系统化的协议评估和优化方法，能够显著提升系统可靠性和性能。

Abstract: As large-scale multi-agent systems evolve, the communication protocol layer
has become a critical yet under-evaluated factor shaping performance and
reliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,
etc.), selection is often intuition-driven and lacks standardized guidance. We
introduce ProtocolBench, a benchmark that systematically compares agent
protocols along four measurable axes: task success, end-to-end latency, message
or byte overhead, and robustness under failures. On ProtocolBench, protocol
choice significantly influences system behavior. In the Streaming Queue
scenario, overall completion time varies by up to 36.5% across protocols, and
mean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,
resilience also differs consistently across protocols. Beyond evaluation, we
present ProtocolRouter, a learnable protocol router that selects per-scenario
(or per-module) protocols from requirement and runtime signals. ProtocolRouter
reduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol
baseline, and achieves scenario-specific gains such as higher success in GAIA.
We also release ProtocolRouterBench to standardize protocol evaluation and
improve reliability at scale.

</details>


### [429] [Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients](https://arxiv.org/abs/2510.17172)
*Shun Huang,Wenlu Xing,Shijia Geng,Hailong Wang,Guangkun Nie,Gongzheng Tang,Chenyang He,Shenda Hong*

Main category: cs.AI

TL;DR: 本研究开发了一种混合预测框架，结合ECG基础模型和可解释的XGBoost分类器，用于预测急性心肌梗死后的恶性室性心律失常风险，在提高准确性的同时增强了模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 急性心肌梗死后恶性室性心律失常是院内死亡的主要原因，传统风险评分性能有限，而端到端深度学习模型缺乏临床信任所需的可解释性。

Method: 分析6,634份AMI患者ECG记录，使用ECGFounder模型提取150维诊断概率特征，通过特征选择训练XGBoost分类器，并采用SHAP方法进行可解释性分析。

Result: 混合模型AUC达到0.801，优于KNN(0.677)、RNN(0.676)和1D-CNN(0.720)。SHAP分析显示模型识别特征与临床知识高度一致。

Conclusion: 该混合框架为VT/VF风险预测提供了新范式，验证了基础模型输出作为有效自动化特征工程在构建可信赖、可解释AI临床决策支持系统中的应用价值。

Abstract: Malignant ventricular arrhythmias (VT/VF) following acute myocardial
infarction (AMI) are a major cause of in-hospital death, yet early
identification remains a clinical challenge. While traditional risk scores have
limited performance, end-to-end deep learning models often lack the
interpretability needed for clinical trust. This study aimed to develop a
hybrid predictive framework that integrates a large-scale electrocardiogram
(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to
improve both accuracy and interpretability. We analyzed 6,634 ECG recordings
from AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder
model was used to extract 150-dimensional diagnostic probability features ,
which were then refined through feature selection to train the XGBoost
classifier. Model performance was evaluated using AUC and F1-score , and the
SHAP method was used for interpretability. The ECGFounder + XGBoost hybrid
model achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC
0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that
model-identified key features, such as "premature ventricular complexes" (risk
predictor) and "normal sinus rhythm" (protective factor), were highly
consistent with clinical knowledge. We conclude that this hybrid framework
provides a novel paradigm for VT/VF risk prediction by validating the use of
foundation model outputs as effective, automated feature engineering for
building trustworthy, explainable AI-based clinical decision support systems.

</details>


### [430] [Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes Progression Modeling](https://arxiv.org/abs/2510.17211)
*Tingsong Xiao,Yao An Lee,Zelin Xu,Yupu Zhang,Zibo Liu,Yu Huang,Jiang Bian,Serena Jingchuan Guo,Zhe Jiang*

Main category: cs.AI

TL;DR: 提出了TD-HNODE模型，通过时间详细超图和神经ODE框架学习疾病进展的连续时间动态，在2型糖尿病和心血管疾病进展建模中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 疾病进展建模面临挑战：需要基于不规则时间事件样本学习连续时间动态，处理患者异质性（不同进展速率和路径）。现有方法缺乏从真实数据学习的适应性或无法捕捉复杂连续时间动态。

Method: TD-HNODE将疾病进展表示为时间详细超图，通过神经ODE框架学习连续时间进展动态，包含可学习的TD-Hypergraph Laplacian来捕捉疾病并发症标记在进展轨迹内和轨迹间的相互依赖关系。

Result: 在两个真实世界临床数据集上的实验表明，TD-HNODE在建模2型糖尿病和相关心血管疾病进展方面优于多个基线方法。

Conclusion: TD-HNODE能够有效建模疾病进展的连续时间动态，捕捉患者异质性和复杂的进展模式，为患者亚表型分析和及时干预提供支持。

Abstract: Disease progression modeling aims to characterize and predict how a patient's
disease complications worsen over time based on longitudinal electronic health
records (EHRs). Accurate modeling of disease progression, such as type 2
diabetes, can enhance patient sub-phenotyping and inform effective and timely
interventions. However, the problem is challenging due to the need to learn
continuous-time dynamics of progression patterns based on irregular-time event
samples and patient heterogeneity (\eg different progression rates and
pathways). Existing mechanistic and data-driven methods either lack
adaptability to learn from real-world data or fail to capture complex
continuous-time dynamics on progression trajectories. To address these
limitations, we propose Temporally Detailed Hypergraph Neural Ordinary
Differential Equation (TD-HNODE), which represents disease progression on
clinically recognized trajectories as a temporally detailed hypergraph and
learns the continuous-time progression dynamics via a neural ODE framework.
TD-HNODE contains a learnable TD-Hypergraph Laplacian that captures the
interdependency of disease complication markers within both intra- and
inter-progression trajectories. Experiments on two real-world clinical datasets
demonstrate that TD-HNODE outperforms multiple baselines in modeling the
progression of type 2 diabetes and related cardiovascular diseases.

</details>


### [431] [RubiSCoT: A Framework for AI-Supported Academic Assessment](https://arxiv.org/abs/2510.17309)
*Thorsten Fröhlich,Tim Schlippe*

Main category: cs.AI

TL;DR: 本文提出了RubiSCoT框架，这是一个基于AI的论文评估系统，利用自然语言处理技术从开题到最终提交全程提升论文评估效率和质量。


<details>
  <summary>Details</summary>
Motivation: 传统论文评估方法耗时且存在评估者主观差异，需要一种更一致、可扩展的解决方案来确保学术严谨性和完整性。

Method: 使用先进的自然语言处理技术，包括大语言模型、检索增强生成和结构化思维链提示，构建包含初步评估、多维度评估、内容提取、基于评分标准的打分和详细报告的框架。

Result: 开发了RubiSCoT框架的设计和实现，展示了其在学术评估过程中提供一致、可扩展和透明评估的潜力。

Conclusion: RubiSCoT框架有潜力通过提供一致、可扩展和透明的评估来优化学术评估流程。

Abstract: The evaluation of academic theses is a cornerstone of higher education,
ensuring rigor and integrity. Traditional methods, though effective, are
time-consuming and subject to evaluator variability. This paper presents
RubiSCoT, an AI-supported framework designed to enhance thesis evaluation from
proposal to final submission. Using advanced natural language processing
techniques, including large language models, retrieval-augmented generation,
and structured chain-of-thought prompting, RubiSCoT offers a consistent,
scalable solution. The framework includes preliminary assessments,
multidimensional assessments, content extraction, rubric-based scoring, and
detailed reporting. We present the design and implementation of RubiSCoT,
discussing its potential to optimize academic assessment processes through
consistent, scalable, and transparent evaluation.

</details>


### [432] [Label Indeterminacy in AI & Law](https://arxiv.org/abs/2510.17463)
*Cor Steging,Tadeusz Zbiegień*

Main category: cs.AI

TL;DR: 本文指出法律机器学习中存在的标签不确定性（label indeterminacy）问题，即法律结果往往受到人为干预影响，导致训练标签不准确。作者通过欧洲人权法院案例分类研究，展示了标签构建方式如何显著影响模型行为。


<details>
  <summary>Details</summary>
Motivation: 法律机器学习通常将过去案例结果视为真实标签，但法律结果常受到和解、上诉等人为干预影响，造成标签不确定性。这种不确定性在现有机器学习方法中未被充分考虑，可能影响模型准确性和可靠性。

Method: 在欧洲人权法院案例分类的背景下，研究不同标签构建方法对模型行为的影响。通过分析标签不确定性如何塑造模型行为，探讨应对这一问题的可能方法。

Result: 研究表明，训练过程中标签的构建方式会显著影响模型的行为表现。标签不确定性是AI与法律领域的一个重要关切点，需要被认真对待。

Conclusion: 法律机器学习应用必须考虑标签不确定性问题。虽然存在估算这些不确定标签的方法，但它们都基于无法验证的假设。标签不确定性应被视为AI与法律领域的重要关注点，并需要开发更合适的处理方法。

Abstract: Machine learning is increasingly used in the legal domain, where it typically
operates retrospectively by treating past case outcomes as ground truth.
However, legal outcomes are often shaped by human interventions that are not
captured in most machine learning approaches. A final decision may result from
a settlement, an appeal, or other procedural actions. This creates label
indeterminacy: the outcome could have been different if the intervention had or
had not taken place. We argue that legal machine learning applications need to
account for label indeterminacy. Methods exist that can impute these
indeterminate labels, but they are all grounded in unverifiable assumptions. In
the context of classifying cases from the European Court of Human Rights, we
show that the way that labels are constructed during training can significantly
affect model behaviour. We therefore position label indeterminacy as a relevant
concern in AI & Law and demonstrate how it can shape model behaviour.

</details>


### [433] [Reasoning Distillation and Structural Alignment for Improved Code Generation](https://arxiv.org/abs/2510.17598)
*Amir Jalilifard,Anderson de Rezende Rocha,Marcos Medeiros Raimundo*

Main category: cs.AI

TL;DR: 该研究提出了一种将大型语言模型的推理能力蒸馏到更小模型中的方法，通过结构感知损失优化，使小模型能够理解问题与解决方案之间的结构对应关系，从而在代码生成任务中超越基准模型。


<details>
  <summary>Details</summary>
Motivation: 代码生成不仅需要准确的标记预测，更需要理解解决方案级别的结构关系。大型语言模型具备复杂的推理能力，但部署成本高；小型模型推理能力不足。因此需要将大型模型的推理能力蒸馏到更小、更高效的模型中。

Method: 通过结构感知损失优化的新方法，训练模型模仿大型语言模型的推理和问题解决能力，学习识别正确的解决方案路径，建立问题定义与潜在解决方案之间的结构对应关系。

Result: 实验结果显示，经过廉价且易于实现的微调过程开发的模型，在MBPP、MBPP Plus和HumanEval基准测试中，在pass@1、平均数据流和平均语法匹配指标上显著优于基准模型。

Conclusion: 该方法成功地将大型语言模型的推理能力蒸馏到更小的模型中，使模型能够超越标记级生成，深入理解给定问题的解决方案的整体结构，实现了高效且低成本的代码生成。

Abstract: Effective code generation with language models hinges on two critical
factors: accurately understanding the intent of the prompt and generating code
that applies algorithmic reasoning to produce correct solutions capable of
passing diverse test cases while adhering to the syntax of the target
programming language. Unlike other language tasks, code generation requires
more than accurate token prediction; it demands comprehension of solution-level
and structural relationships rather than merely generating the most likely
tokens. very large language model (VLLM) are capable of generating detailed
steps toward the correct solution of complex tasks where reasoning is crucial
in solving the problem. Such reasoning capabilities may be absent in smaller
language models. Therefore, in this work, we distill the reasoning capabilities
of a VLLM into a smaller, more efficient model that is faster and cheaper to
deploy. Our approach trains the model to emulate the reasoning and
problem-solving abilities of the VLLM by learning to identify correct solution
pathways and establishing a structural correspondence between problem
definitions and potential solutions through a novel method of structure-aware
loss optimization. This enables the model to transcend token-level generation
and to deeply grasp the overarching structure of solutions for given problems.
Experimental results show that our fine-tuned model, developed through a cheap
and simple to implement process, significantly outperforms our baseline model
in terms of pass@1, average data flow, and average syntax match metrics across
the MBPP, MBPP Plus, and HumanEval benchmarks.

</details>


### [434] [OG-Rank: Learning to Rank Fast and Slow with Uncertainty and Reward-Trend Guided Adaptive Exploration](https://arxiv.org/abs/2510.17614)
*Praphul Singh,Corey Barrett,Sumana Srivasta,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: OG-Rank是一个低延迟的解码器重排序系统，通过结合池化首词评分和不确定性门控解释步骤，实现快速排名并在模糊情况下生成解释，在临床订单选择任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要实时工作并能解释其选择的排名系统，需要一个低延迟、基于解码器的重排序器。

Method: 采用单解码器方法，结合池化首词评分信号和不确定性门控解释步骤，通过课程学习集中处理困难案例，所有候选者在一次处理中评分，仅在列表真正模糊时生成简短结构化解释。

Result: 在临床订单选择任务中表现强劲（快速路径：Recall@1~0.45，nDCG@20~0.625），当门控激活时进一步改善（Recall@1~0.56，nDCG@20~0.699，门控率45%），编码器基线在效果和灵活性上都落后。

Conclusion: OG-Rank提供了一个实用方案：默认快速排名，在有助于提高准确性时进行解释，这种模式适用于选择性生成能以可接受成本购买准确性的决策任务，单策略设计简化了部署和预算规划。

Abstract: Clinicians need ranking systems that work in real time and still justify
their choices. Motivated by the need for a low-latency, decoder-based reranker,
we present OG-Rank, a single-decoder approach that pairs a pooled first-token
scoring signal with an uncertainty-gated explanation step. The model scores all
candidates in one pass and generates a brief, structured rationale only when
the list is genuinely ambiguous, keeping latency predictable. Trained with a
curriculum that concentrates effort on hard cases, OG-Rank delivers strong
effectiveness on encounter-scoped order selection (fast path: Recall@1~0.45,
nDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56,
nDCG@20~0.699 at a 45\% gate rate), while compact backbones show similar gains
under the same policy. Encoder baselines trail in both effectiveness and
flexibility. The result is a practical recipe: rank fast by default and explain
when it helps, a pattern that applies broadly to decision tasks where selective
generation buys accuracy at acceptable cost. The single-policy design
simplifies deployment and budget planning, and the curriculum principle (spend
more on the hard cases, less on the easy ones) readily transfers beyond
clinical order selection.

</details>


### [435] [LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena](https://arxiv.org/abs/2510.17638)
*Qingchuan Yang,Simon Mahns,Sida Li,Anri Gu,Jibang Wu,Haifeng Xu*

Main category: cs.AI

TL;DR: 该论文系统研究了大语言模型（LLMs）作为预测工具的能力，构建了Prophet Arena评估基准，发现LLMs已具备显著的预测能力，但也存在事件召回不准确、数据源误解等瓶颈。


<details>
  <summary>Details</summary>
Motivation: 随着在互联网规模数据上训练的大语言模型的快速发展，利用LLMs预测现实世界未来事件具有重要潜力，这种新兴范式被称为"LLM-as-a-Prophet"。

Method: 构建Prophet Arena评估基准，持续收集实时预测任务并将每个任务分解为不同的流水线阶段，以支持受控和大规模实验。

Result: 综合评估显示许多LLMs已展现出令人印象深刻的预测能力，表现为较小的校准误差、一致的预测置信度和有前景的市场回报。

Conclusion: 虽然LLMs已具备预测能力，但通过LLM-as-a-Prophet实现卓越预测智能仍面临关键瓶颈，如事件召回不准确、数据源误解以及在接近决策时信息聚合速度较市场慢等问题。

Abstract: Forecasting is not only a fundamental intellectual pursuit but also is of
significant importance to societal systems such as finance and economics. With
the rapid advances of large language models (LLMs) trained on Internet-scale
data, it raises the promise of employing LLMs to forecast real-world future
events, an emerging paradigm we call "LLM-as-a-Prophet". This paper
systematically investigates such predictive intelligence of LLMs. To this end,
we build Prophet Arena, a general evaluation benchmark that continuously
collects live forecasting tasks and decomposes each task into distinct pipeline
stages, in order to support our controlled and large-scale experimentation. Our
comprehensive evaluation reveals that many LLMs already exhibit impressive
forecasting capabilities, reflected in, e.g., their small calibration errors,
consistent prediction confidence and promising market returns. However, we also
uncover key bottlenecks towards achieving superior predictive intelligence via
LLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of
data sources and slower information aggregation compared to markets when
resolution nears.

</details>


### [436] [Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation in Large Language Models](https://arxiv.org/abs/2510.17705)
*Dayan Pan,Zhaoyang Fu,Jingyuan Wang,Xiao Han,Yue Zhu,Xiangyu Zhao*

Main category: cs.AI

TL;DR: 提出了一种名为上下文注意力调制（CAM）的新机制，通过动态调节LLM中自注意力模块的表征来增强任务特定特征，同时保留通用知识。进一步开发了混合上下文注意力调制（HyCAM）框架，结合共享的全参数CAM模块和多个轻量级专用CAM模块，通过动态路由策略实现自适应知识融合。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多任务适应方面存在困难，传统微调方法会导致灾难性遗忘和资源消耗大，现有参数高效方法在复杂多任务场景下表现不佳。

Method: 提出CAM机制动态调制自注意力模块表征，并构建HyCAM框架结合共享CAM模块和专用CAM模块，采用动态路由策略进行自适应知识融合。

Result: 在问答、代码生成和逻辑推理等异构任务上的广泛实验表明，该方法显著优于现有方法，平均性能提升3.65%。

Conclusion: CAM和HyCAM框架能够有效平衡知识保留和任务特定专业化，实现更高效的多任务适应。

Abstract: Large Language Models (LLMs) possess remarkable generalization capabilities
but struggle with multi-task adaptation, particularly in balancing knowledge
retention with task-specific specialization. Conventional fine-tuning methods
suffer from catastrophic forgetting and substantial resource consumption, while
existing parameter-efficient methods perform suboptimally in complex multi-task
scenarios. To address this, we propose Contextual Attention Modulation (CAM), a
novel mechanism that dynamically modulates the representations of
self-attention modules in LLMs. CAM enhances task-specific features while
preserving general knowledge, thereby facilitating more effective and efficient
adaptation. For effective multi-task adaptation, CAM is integrated into our
Hybrid Contextual Attention Modulation (HyCAM) framework, which combines a
shared, full-parameter CAM module with multiple specialized, lightweight CAM
modules, enhanced by a dynamic routing strategy for adaptive knowledge fusion.
Extensive experiments on heterogeneous tasks, including question answering,
code generation, and logical reasoning, demonstrate that our approach
significantly outperforms existing approaches, achieving an average performance
improvement of 3.65%. The implemented code and data are available to ease
reproducibility at https://github.com/Applied-Machine-Learning-Lab/HyCAM.

</details>


### [437] [Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs](https://arxiv.org/abs/2510.17771)
*Zhining Liu,Ziyi Chen,Hui Liu,Chen Luo,Xianfeng Tang,Suhang Wang,Joy Zeng,Zhenwei Dai,Zhan Shi,Tianxin Wei,Benoit Dumoulin,Hanghang Tong*

Main category: cs.AI

TL;DR: 研究发现视觉语言模型在输出错误答案时往往已经感知到正确的视觉证据，这种现象称为"看到但不相信"。通过选择性注意力掩码干预，无需训练即可提高多个VLM家族的准确性。


<details>
  <summary>Details</summary>
Motivation: 系统研究视觉语言模型失败的原因：是未感知视觉证据还是未有效利用证据。发现模型在输出错误答案时往往已经看到正确证据，但未充分利用。

Method: 通过层间注意力动态分析，发现浅层主要关注文本，深层稀疏但可靠地关注局部证据区域。引入推理时干预方法，通过选择性注意力掩码突出深层证据区域。

Result: 干预方法无需训练，在LLaVA、Qwen、Gemma和InternVL等多个VLM家族中一致提高准确性。

Conclusion: 视觉语言模型内部编码了可靠的证据但未充分利用，使这些信号显式化可以弥合感知与推理之间的差距，提升VLM的诊断理解和可靠性。

Abstract: Vision-Language Models (VLMs) achieve strong results on multimodal tasks such
as visual question answering, yet they can still fail even when the correct
visual evidence is present. In this work, we systematically investigate whether
these failures arise from not perceiving the evidence or from not leveraging it
effectively. By examining layer-wise attention dynamics, we find that shallow
layers focus primarily on text, while deeper layers sparsely but reliably
attend to localized evidence regions. Surprisingly, VLMs often perceive the
visual evidence when outputting incorrect answers, a phenomenon we term
``seeing but not believing'' that widely exists in major VLM families. Building
on this, we introduce an inference-time intervention that highlights deep-layer
evidence regions through selective attention-based masking. It requires no
training and consistently improves accuracy across multiple families, including
LLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable
evidence internally but under-utilize it, making such signals explicit can
bridge the gap between perception and reasoning, advancing the diagnostic
understanding and reliability of VLMs.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [438] [A Bayesian Framework for Symmetry Inference in Chaotic Attractors](https://arxiv.org/abs/2510.16509)
*Ziad Ghanem,Chang Hyunwoong,Preskella Mrad*

Main category: stat.ML

TL;DR: 提出了一种贝叶斯框架，将对称性检测建模为在候选子群格上的概率模型选择，使用基于Wasserstein距离的Gibbs后验，解决了传统方法缺乏不确定性量化和对噪声敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于最优传输的对称性检测方法依赖确定性阈值，缺乏不确定性量化，限制了其对噪声的鲁棒性和对层次对称结构的解析能力。

Method: 使用Gibbs后验构造，基于观测数据与群变换副本之间的Wasserstein距离，通过Metropolis-Hastings采样进行后验推断。

Result: 在等变动力系统和合成点云上的数值实验表明，该方法在高噪声和小样本情况下能准确恢复对称性。在人体步态动力学应用中揭示了机械约束引起的对称性变化。

Conclusion: 该贝叶斯框架为生物力学和动力系统中的统计推断提供了有效工具，具有理论保证和实际应用价值。

Abstract: Detecting symmetry from data is a fundamental problem in signal analysis,
providing insight into underlying structure and constraints. When data emerge
as trajectories of dynamical systems, symmetries encode structural properties
of the dynamics that enable model reduction, principled comparison across
conditions, and detection of regime changes. While recent optimal transport
methods provide practical tools for data-driven symmetry detection in this
setting, they rely on deterministic thresholds and lack uncertainty
quantification, limiting robustness to noise and ability to resolve
hierarchical symmetry structures. We present a Bayesian framework that
formulates symmetry detection as probabilistic model selection over a lattice
of candidate subgroups, using a Gibbs posterior constructed from Wasserstein
distances between observed data and group-transformed copies. We establish
three theoretical guarantees: $(i)$ a Bayesian Occam's razor favoring minimal
symmetry consistent with data, $(ii)$ conjugation equivariance ensuring
frame-independence, and $(iii)$ stability bounds under perturbations for
robustness to noise. Posterior inference is performed via Metropolis-Hastings
sampling and numerical experiments on equivariant dynamical systems and
synthetic point clouds demonstrate accurate symmetry recovery under high noise
and small sample sizes. An application to human gait dynamics reveals symmetry
changes induced by mechanical constraints, demonstrating the framework's
utility for statistical inference in biomechanical and dynamical systems.

</details>


### [439] [From Reviews to Actionable Insights: An LLM-Based Approach for Attribute and Feature Extraction](https://arxiv.org/abs/2510.16551)
*Khaled Boughanmi,Kamel Jedidi,Nour Jedidi*

Main category: stat.ML

TL;DR: 本研究提出了一种基于大语言模型的系统方法，用于从客户评论中提取产品和服务属性、特征及相关情感。该方法基于营销理论，区分感知属性和可操作特征，生成可解释且具有管理指导意义的见解。


<details>
  <summary>Details</summary>
Motivation: 传统人工编码客户评论耗时且难以规模化，需要一种自动化方法来高效提取客户反馈中的关键信息，为企业提供可操作的营销洞察。

Method: 使用大语言模型处理20,000条Yelp星巴克评论，评估8种提示变体，通过人工标注一致性和客户评分预测有效性来评估模型性能。

Result: LLM与人工编码者具有高度一致性，且预测有效性很强。人工编码每条评论需6分钟，而LLM仅需2秒，实现了规模化分析。分析识别出对客户满意度影响最大的属性和特征及其情感倾向。

Conclusion: 该方法能够规模化生成可操作的营销洞察，识别客户满意度的关键驱动因素，通过情感分析帮助企业优化服务特征，模拟显示优化关键服务特征情感可获得1-2%的单店平均收入增长。

Abstract: This research proposes a systematic, large language model (LLM) approach for
extracting product and service attributes, features, and associated sentiments
from customer reviews. Grounded in marketing theory, the framework
distinguishes perceptual attributes from actionable features, producing
interpretable and managerially actionable insights. We apply the methodology to
20,000 Yelp reviews of Starbucks stores and evaluate eight prompt variants on a
random subset of reviews. Model performance is assessed through agreement with
human annotations and predictive validity for customer ratings. Results show
high consistency between LLMs and human coders and strong predictive validity,
confirming the reliability of the approach. Human coders required a median of
six minutes per review, whereas the LLM processed each in two seconds,
delivering comparable insights at a scale unattainable through manual coding.
Managerially, the analysis identifies attributes and features that most
strongly influence customer satisfaction and their associated sentiments,
enabling firms to pinpoint "joy points," address "pain points," and design
targeted interventions. We demonstrate how structured review data can power an
actionable marketing dashboard that tracks sentiment over time and across
stores, benchmarks performance, and highlights high-leverage features for
improvement. Simulations indicate that enhancing sentiment for key service
features could yield 1-2% average revenue gains per store.

</details>


### [440] [Multi-Marginal Schrödinger Bridge Matching](https://arxiv.org/abs/2510.16587)
*Byoungwoo Park,Juho Lee*

Main category: stat.ML

TL;DR: 提出了MSBM算法，专门解决多边际薛定谔桥问题，能够有效处理多个中间时间点的约束，在合成数据和真实单细胞RNA测序数据上表现出色。


<details>
  <summary>Details</summary>
Motivation: 在发育生物学和系统医学等领域，通常只能获得离散时间点的数据，但需要理解连续演化过程。传统薛定谔桥方法只处理成对时间点，对于包含多个中间快照的系统不够充分。

Method: MSBM算法扩展了迭代马尔可夫拟合方法，专门设计用于多边际薛定谔桥问题，能够强健地执行所有中间边际约束，同时保持学习到的全局动力学在整个轨迹上的连续性。

Result: 在合成数据和真实单细胞RNA测序数据集上的实证验证表明，MSBM在捕捉复杂轨迹和尊重中间分布方面具有竞争性或优越性能，且计算效率显著。

Conclusion: MSBM为处理多时间点数据提供了一种有效方法，能够更好地理解动态系统的连续演化过程，在轨迹推断任务中表现出色。

Abstract: Understanding the continuous evolution of populations from discrete temporal
snapshots is a critical research challenge, particularly in fields like
developmental biology and systems medicine where longitudinal tracking of
individual entities is often impossible. Such trajectory inference is vital for
unraveling the mechanisms of dynamic processes. While Schr\"odinger Bridge (SB)
offer a potent framework, their traditional application to pairwise time points
can be insufficient for systems defined by multiple intermediate snapshots.
This paper introduces Multi-Marginal Schr\"odinger Bridge Matching (MSBM), a
novel algorithm specifically designed for the multi-marginal SB problem. MSBM
extends iterative Markovian fitting (IMF) to effectively handle multiple
marginal constraints. This technique ensures robust enforcement of all
intermediate marginals while preserving the continuity of the learned global
dynamics across the entire trajectory. Empirical validations on synthetic data
and real-world single-cell RNA sequencing datasets demonstrate the competitive
or superior performance of MSBM in capturing complex trajectories and
respecting intermediate distributions, all with notable computational
efficiency.

</details>


### [441] [Accelerated Learning on Large Scale Screens using Generative Library Models](https://arxiv.org/abs/2510.16612)
*Eli N. Weinstein,Andrei Slabodkin,Mattia G. Gollub,Elizabeth B. Wood*

Main category: stat.ML

TL;DR: 本文提出了一种优化高通量筛选实验的算法，通过只收集阳性序列样本并利用生成模型校正缺失的阴性样本，在活性序列稀少的情况下最大化信息增益，从而显著加速生物机器学习。


<details>
  <summary>Details</summary>
Motivation: 生物机器学习常受限于缺乏规模化数据，高通量筛选能并行测试大量蛋白质序列，但测量和测序成本限制了数据集规模，需要优化实验设计来解决数据瓶颈。

Method: 在活性序列稀少的情况下，只收集阳性序列样本（y>0），然后使用文库的生成模型来校正缺失的阴性样本，从而获得对真实条件概率p(y|x)的一致且高效估计。

Result: 在模拟和抗体大规模筛选中验证了该方法，通过实验与推断的协同设计显著加速了学习过程。

Conclusion: 通过优化高通量筛选实验设计，在活性序列稀少时只收集阳性样本并利用生成模型校正，可以最大化信息增益并显著提高学习效率。

Abstract: Biological machine learning is often bottlenecked by a lack of scaled data.
One promising route to relieving data bottlenecks is through high throughput
screens, which can experimentally test the activity of $10^6-10^{12}$ protein
sequences in parallel. In this article, we introduce algorithms to optimize
high throughput screens for data creation and model training. We focus on the
large scale regime, where dataset sizes are limited by the cost of measurement
and sequencing. We show that when active sequences are rare, we maximize
information gain if we only collect positive examples of active sequences, i.e.
$x$ with $y>0$. We can correct for the missing negative examples using a
generative model of the library, producing a consistent and efficient estimate
of the true $p(y | x)$. We demonstrate this approach in simulation and on a
large scale screen of antibodies. Overall, co-design of experiments and
inference lets us accelerate learning dramatically.

</details>


### [442] [ARCO-BO: Adaptive Resource-aware COllaborative Bayesian Optimization for Heterogeneous Multi-Agent Design](https://arxiv.org/abs/2510.16652)
*Zihan Wang,Yi-Ping Chen,Tuba Dolar,Wei Chen*

Main category: stat.ML

TL;DR: ARCO-BO是一个针对异构多智能体优化的自适应资源感知协作贝叶斯优化框架，解决了传统协作BO方法在资源、输入空间和任务对齐方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现代科学和工程设计中的分布式优化面临目标、评估预算和可访问设计变量的异构性，传统贝叶斯优化的集中控制和完全数据共享假设不适用于实际场景，现有协作BO方法要求统一资源、完全共享输入空间和固定任务对齐，这些条件在实践中很少满足。

Method: ARCO-BO结合三个组件：相似性和最优值感知的共识机制用于自适应信息共享、预算感知的异步采样策略用于资源协调、以及部分输入空间共享用于异构设计空间。

Result: 在合成和高维工程问题上的实验表明，ARCO-BO始终优于独立BO和现有的基于共识的协作BO方法，在复杂多智能体设置中实现了稳健高效的表现。

Conclusion: ARCO-BO通过明确考虑多智能体优化中的异构性，提供了一个能够处理实际分布式优化挑战的有效框架。

Abstract: Modern scientific and engineering design increasingly involves distributed
optimization, where agents such as laboratories, simulations, or industrial
partners pursue related goals under differing conditions. These agents often
face heterogeneities in objectives, evaluation budgets, and accessible design
variables, which complicates coordination and can lead to redundancy, poor
resource use, and ineffective information sharing. Bayesian Optimization (BO)
is a widely used decision-making framework for expensive black box functions,
but its single-agent formulation assumes centralized control and full data
sharing. Recent collaborative BO methods relax these assumptions, yet they
often require uniform resources, fully shared input spaces, and fixed task
alignment, conditions rarely satisfied in practice. To address these
challenges, we introduce Adaptive Resource Aware Collaborative Bayesian
Optimization (ARCO-BO), a framework that explicitly accounts for heterogeneity
in multi-agent optimization. ARCO-BO combines three components: a similarity
and optima-aware consensus mechanism for adaptive information sharing, a
budget-aware asynchronous sampling strategy for resource coordination, and a
partial input space sharing for heterogeneous design spaces. Experiments on
synthetic and high-dimensional engineering problems show that ARCO-BO
consistently outperforms independent BO and existing collaborative BO via
consensus approach, achieving robust and efficient performance in complex
multi-agent settings.

</details>


### [443] [Escaping Model Collapse via Synthetic Data Verification: Near-term Improvements and Long-term Convergence](https://arxiv.org/abs/2510.16657)
*Bingji Yi,Qiyuan Liu,Yuwei Cheng,Haifeng Xu*

Main category: stat.ML

TL;DR: 本文研究了如何通过引入外部合成数据验证器来避免模型崩溃，并可能逆转性能下降趋势。研究发现，通过人类或更好模型进行验证的合成数据重训练可以防止模型崩溃，但最终会收敛到验证器的知识中心。


<details>
  <summary>Details</summary>
Motivation: 合成数据被广泛用于训练前沿生成模型，但研究发现迭代重训练模型使用自身生成的合成数据会导致模型性能持续恶化（模型崩溃现象）。本文旨在探索修改合成重训练过程以避免模型崩溃的方法。

Method: 在基础线性回归设置中进行分析，引入外部合成数据验证器（人类或更好模型）来验证合成数据。通过理论分析和实验验证，包括线性回归和在MNIST数据上训练的变分自编码器（VAE）。

Result: 研究发现，通过验证器验证的合成数据重训练不会导致模型崩溃。理论分析表明，迭代重训练验证后的合成数据可以在短期内带来改进，但最终会驱动参数估计收敛到验证器的知识中心。

Conclusion: 除非验证器完全可靠，否则早期收益会趋于平稳甚至可能逆转。这一理论见解在实验中得到进一步证实，为合成数据重训练提供了重要指导。

Abstract: Synthetic data has been increasingly used to train frontier generative
models. However, recent study raises key concerns that iteratively retraining a
generative model on its self-generated synthetic data may keep deteriorating
model performance, a phenomenon often coined model collapse. In this paper, we
investigate ways to modify this synthetic retraining process to avoid model
collapse, and even possibly help reverse the trend from collapse to
improvement. Our key finding is that by injecting information through an
external synthetic data verifier, whether a human or a better model, synthetic
retraining will not cause model collapse. To develop principled understandings
of the above insight, we situate our analysis in the foundational linear
regression setting, showing that iterative retraining with verified synthetic
data can yield near-term improvements but ultimately drives the parameter
estimate to the verifier's "knowledge center" in the long run. Our theory hence
predicts that, unless the verifier is perfectly reliable, the early gains will
plateau and may even reverse. Indeed, these theoretical insights are further
confirmed by our experiments on both linear regression as well as Variational
Autoencoders (VAEs) trained on MNIST data.

</details>


### [444] [Local regression on path spaces with signature metrics](https://arxiv.org/abs/2510.16728)
*Christian Bayer,Davit Gogolashvili,Luca Pelizzari*

Main category: stat.ML

TL;DR: 该论文提出了一种结合粗糙路径理论中签名变换与局部核回归的函数型Nadaraya-Watson估计器，用于路径值数据的非参数回归和分类。


<details>
  <summary>Details</summary>
Motivation: 研究路径值数据的非参数回归和分类问题，传统方法在处理无限维设置时存在局限性，需要一种能够直接比较路径的合理方法。

Method: 引入函数型Nadaraya-Watson估计器，将签名变换与局部核回归相结合，利用签名诱导的距离在经典核回归框架中进行计算。

Result: 建立了有限样本收敛界，证明基于签名的距离在无限维设置中相比传统度量具有更优的统计特性，并在合成和真实数据应用中表现出竞争性精度和显著计算优势。

Conclusion: 签名变换为序列数据编码提供了原则性方法，结合核回归框架实现了计算效率，同时避免了大规模核矩阵操作的可扩展性瓶颈，在路径值数据分析中具有实用价值。

Abstract: We study nonparametric regression and classification for path-valued data. We
introduce a functional Nadaraya-Watson estimator that combines the signature
transform from rough path theory with local kernel regression. The signature
transform provides a principled way to encode sequential data through iterated
integrals, enabling direct comparison of paths in a natural metric space. Our
approach leverages signature-induced distances within the classical kernel
regression framework, achieving computational efficiency while avoiding the
scalability bottlenecks of large-scale kernel matrix operations. We establish
finite-sample convergence bounds demonstrating favorable statistical properties
of signature-based distances compared to traditional metrics in
infinite-dimensional settings. We propose robust signature variants that
provide stability against outliers, enhancing practical performance.
Applications to both synthetic and real-world data - including stochastic
differential equation learning and time series classification - demonstrate
competitive accuracy while offering significant computational advantages over
existing methods.

</details>


### [445] [Kernel-Based Nonparametric Tests For Shape Constraints](https://arxiv.org/abs/2510.16745)
*Rohan Sen*

Main category: stat.ML

TL;DR: 本文提出了一个基于再生核希尔伯特空间（RKHS）的非参数均值-方差优化框架，用于形状约束的最优规则推断，并提供了统计性质和理论保证。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够处理形状约束的非参数均值-方差优化框架，并建立严格的统计推断理论，以解决现有方法在理论保证和计算效率方面的不足。

Method: 使用RKHS框架构建非参数均值-方差优化模型，推导样本估计器的统计性质，提出基于枢轴Cholesky分解的高效计算程序，并引入联合Wald型统计量来测试有限网格上的形状约束。

Result: 获得了渐近一致性、泛函中心极限定理和与蒙特卡罗率匹配的有限样本偏差界等理论保证，实证测试表明所提方法表现良好。

Conclusion: 所提出的RKHS框架为形状约束的非参数均值-方差优化提供了有效的理论和方法支持，具有可扩展性和良好的实证性能。

Abstract: We develop a reproducing kernel Hilbert space (RKHS) framework for
nonparametric mean-variance optimization and inference on shape constraints of
the optimal rule. We derive statistical properties of the sample estimator and
provide rigorous theoretical guarantees, such as asymptotic consistency, a
functional central limit theorem, and a finite-sample deviation bound that
matches the Monte Carlo rate up to regularization. Building on these findings,
we introduce a joint Wald-type statistic to test for shape constraints over
finite grids. The approach comes with an efficient computational procedure
based on a pivoted Cholesky factorization, facilitating scalability to large
datasets. Empirical tests suggest favorably of the proposed methodology.

</details>


### [446] [Prediction-Augmented Trees for Reliable Statistical Inference](https://arxiv.org/abs/2510.16937)
*Vikram Kher,Argyris Oikonomou,Manolis Zampetakis*

Main category: stat.ML

TL;DR: 本文提出了两种新的机器学习增强估计器PART和PAQ，用于在科学发现中安全使用ML预测进行统计分析。PART基于决策树构建，PAQ是PART的极限情况。相比现有方法PPI和PPI++，新方法在多个真实数据集上表现更优，且PAQ的方差收敛速率从O(N^{-1}+n^{-1})提升到O(N^{-1}+n^{-4})。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在预测任务中的成功应用，科学家开始将ML预测作为科学发现流程的核心组成部分。本文旨在研究如何在科学发现的统计分析中安全地使用ML预测，特别是基于Angelopoulos等人提出的框架。

Method: 提出了两种新的学习增强估计器：1) PART（预测增强残差树）- 基于贪心准则构建的决策树估计器；2) PAQ（预测增强求积）- 当PART树的深度趋于无穷时的极限估计器。方法利用了少量黄金标准标记样本和大量未标记样本，结合ML模型进行标签插补。

Result: PART在生态学、天文学、人口普查等多个真实数据集上优于现有方法PPI和PPI++，产生更高置信度的估计器。PAQ在适当的数据假设下，其方差以O(N^{-1}+n^{-4})的速率收缩，显著优于现有方法的O(N^{-1}+n^{-1})速率。

Conclusion: 提出的PART和PAQ估计器能够有效结合黄金标准样本和机器学习预测，在科学发现的数据分析中提供更准确和可靠的统计推断，特别是在方差收敛速率方面实现了显著改进。

Abstract: The remarkable success of machine learning (ML) in predictive tasks has led
scientists to incorporate ML predictions as a core component of the scientific
discovery pipeline. This was exemplified by the landmark achievement of
AlphaFold (Jumper et al. (2021)). In this paper, we study how ML predictions
can be safely used in statistical analysis of data towards scientific
discovery. In particular, we follow the framework introduced by Angelopoulos et
al. (2023). In this framework, we assume access to a small set of $n$
gold-standard labeled samples, a much larger set of $N$ unlabeled samples, and
a ML model that can be used to impute the labels of the unlabeled data points.
We introduce two new learning-augmented estimators: (1) Prediction-Augmented
Residual Tree (PART), and (2) Prediction-Augmented Quadrature (PAQ). Both
estimators have significant advantages over existing estimators like PPI and
PPI++ introduced by Angelopoulos et al. (2023) and Angelopoulos et al. (2024),
respectively. PART is a decision-tree based estimator built using a greedy
criterion. We first characterize PART's asymptotic distribution and demonstrate
how to construct valid confidence intervals. Then we show that PART outperforms
existing methods in real-world datasets from ecology, astronomy, and census
reports, among other domains. This leads to estimators with higher confidence,
which is the result of using both the gold-standard samples and the machine
learning predictions. Finally, we provide a formal proof of the advantage of
PART by exploring PAQ, an estimation that arises when considering the limit of
PART when the depth its tree grows to infinity. Under appropriate assumptions
in the input data we show that the variance of PAQ shrinks at rate of $O(N^{-1}
+ n^{-4})$, improving significantly on the $O(N^{-1}+n^{-1})$ rate of existing
methods.

</details>


### [447] [Adaptive Sample Sharing for Linear Regression](https://arxiv.org/abs/2510.16986)
*Hamza Cherkaoui,Hélène Halconruy,Yohan Petetin*

Main category: stat.ML

TL;DR: 本文提出了一种基于岭回归的样本共享方法，通过数据驱动的规则决定从辅助数据集中添加多少样本到目标训练集，以避免负迁移并提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 在商业环境中，任务特定的标注数据通常稀缺或获取成本高，这限制了监督学习在特定任务上的应用。为了解决这一挑战，研究如何在岭回归中利用辅助数据集，同时明确保护免受负迁移的影响。

Method: 引入一种基于原理的数据驱动规则，该规则基于对迁移增益（即预测误差的边际减少）的估计来决定从辅助数据集中添加多少样本到目标训练集。在标准条件下，该程序在能够改善参数估计时借用样本，否则不借用。

Result: 在高斯特征设置下，分析了哪些数据集属性确保借用样本能减少预测误差。在合成和真实数据集上的验证表明，该方法相对于强基线和单任务训练获得了一致的增益，同时避免了负迁移。

Conclusion: 该方法提供了一种有效的样本共享策略，能够在保护免受负迁移的同时，利用辅助数据集提高岭回归的预测性能。

Abstract: In many business settings, task-specific labeled data are scarce or costly to
obtain, which limits supervised learning on a specific task. To address this
challenge, we study sample sharing in the case of ridge regression: leveraging
an auxiliary data set while explicitly protecting against negative transfer. We
introduce a principled, data-driven rule that decides how many samples from an
auxiliary dataset to add to the target training set. The rule is based on an
estimate of the transfer gain i.e. the marginal reduction in the predictive
error. Building on this estimator, we derive finite-sample guaranties: under
standard conditions, the procedure borrows when it improves parameter
estimation and abstains otherwise. In the Gaussian feature setting, we analyze
which data set properties ensure that borrowing samples reduces the predictive
error. We validate the approach in synthetic and real datasets, observing
consistent gains over strong baselines and single-task training while avoiding
negative transfer.

</details>


### [448] [Mode Collapse of Mean-Field Variational Inference](https://arxiv.org/abs/2510.17063)
*Shunan Sheng,Bohan Wu,Alberto González-Sanz*

Main category: stat.ML

TL;DR: 本文首次从理论上解释了平均场变分推断（MFVI）中的模式塌陷现象，提出了ε-分离度的概念来衡量混合成分的分离程度，并开发了旋转变分推断（RoVI）方法来解决该问题。


<details>
  <summary>Details</summary>
Motivation: MFVI在实际应用中被观察到经常出现模式塌陷问题，即当目标分布是混合分布时，优化器倾向于将大部分质量集中在单个混合成分上。目前缺乏对这一现象的理论解释。

Method: 引入ε-分离度概念来量化混合成分的分离程度，推导了MFVI优化器在ε-分离混合分布下分配给各成分的质量界限，并提出了旋转变分推断（RoVI）方法，通过在MFVI中加入旋转矩阵来缓解模式塌陷。

Result: 理论分析表明模式塌陷的发生关键取决于混合成分的相对位置，数值研究支持了理论发现并证明了RoVI方法的有效性。

Conclusion: 本文首次为MFVI中的模式塌陷现象提供了理论解释，提出的RoVI方法能够有效缓解这一问题，为变分推断方法提供了改进方向。

Abstract: Mean-field variational inference (MFVI) is a widely used method for
approximating high-dimensional probability distributions by product measures.
It has been empirically observed that MFVI optimizers often suffer from mode
collapse. Specifically, when the target measure $\pi$ is a mixture $\pi = w P_0
+ (1 - w) P_1$, the MFVI optimizer tends to place most of its mass near a
single component of the mixture. This work provides the first theoretical
explanation of mode collapse in MFVI. We introduce the notion to capture the
separatedness of the two mixture components -- called
$\varepsilon$-separateness -- and derive explicit bounds on the fraction of
mass that any MFVI optimizer assigns to each component when $P_0$ and $P_1$ are
$\varepsilon$-separated for sufficiently small $\varepsilon$. Our results
suggest that the occurrence of mode collapse crucially depends on the relative
position of the components. To address this issue, we propose the rotational
variational inference (RoVI), which augments MFVI with a rotation matrix. The
numerical studies support our theoretical findings and demonstrate the benefits
of RoVI.

</details>


### [449] [Optimal Best Arm Identification under Differential Privacy](https://arxiv.org/abs/2510.17348)
*Marc Jourdan,Achraf Azize*

Main category: stat.ML

TL;DR: 本文研究了在全局差分隐私（DP）约束下的最佳臂识别（BAI）问题，针对伯努利分布。通过引入新的信息论量来优化KL散度和总变差距离之间的权衡，提出了匹配下界到小常数倍的渐近最优算法。


<details>
  <summary>Details</summary>
Motivation: BAI算法在数据敏感应用（如自适应临床试验）中部署，这些应用存在隐私担忧。现有非私有BAI算法已有渐近最优解，但在全局DP设置下，上下界之间存在显著差距，需要解决这一差距。

Method: 1）提供更紧的下界，用新的信息论量替代KL散度；2）基于运输成本设计停止规则，使用臂依赖几何批处理的私有均值估计器；3）提出基于运输成本的Top Two采样规则。

Result: 对于任何隐私预算ε，提出的算法在期望样本复杂度上实现了与下界匹配的渐近上界，乘性常数小于8，优于现有的δ-正确和ε-全局DP BAI算法。

Conclusion: 本文显著缩小了全局DP设置下BAI问题的上下界差距，提出了渐近最优的私有BAI算法，为数据敏感应用提供了隐私保护的解决方案。

Abstract: Best Arm Identification (BAI) algorithms are deployed in data-sensitive
applications, such as adaptive clinical trials or user studies. Driven by the
privacy concerns of these applications, we study the problem of
fixed-confidence BAI under global Differential Privacy (DP) for Bernoulli
distributions. While numerous asymptotically optimal BAI algorithms exist in
the non-private setting, a significant gap remains between the best lower and
upper bounds in the global DP setting. This work reduces this gap to a small
multiplicative constant, for any privacy budget $\epsilon$. First, we provide a
tighter lower bound on the expected sample complexity of any $\delta$-correct
and $\epsilon$-global DP strategy. Our lower bound replaces the
Kullback-Leibler (KL) divergence in the transportation cost used by the
non-private characteristic time with a new information-theoretic quantity that
optimally trades off between the KL divergence and the Total Variation distance
scaled by $\epsilon$. Second, we introduce a stopping rule based on these
transportation costs and a private estimator of the means computed using an
arm-dependent geometric batching. En route to proving the correctness of our
stopping rule, we derive concentration results of independent interest for the
Laplace distribution and for the sum of Bernoulli and Laplace distributions.
Third, we propose a Top Two sampling rule based on these transportation costs.
For any budget $\epsilon$, we show an asymptotic upper bound on its expected
sample complexity that matches our lower bound to a multiplicative constant
smaller than $8$. Our algorithm outperforms existing $\delta$-correct and
$\epsilon$-global DP BAI algorithms for different values of $\epsilon$.

</details>


### [450] [Certified Self-Consistency: Statistical Guarantees and Test-Time Training for Reliable Reasoning in LLMs](https://arxiv.org/abs/2510.17472)
*Paula Cordero-Encinar,Andrew B. Duncan*

Main category: stat.ML

TL;DR: 提出了一个统一框架来证明大语言模型的可认证推理，展示了多数投票提供自一致性的统计保证，并引入自适应停止规则MMC。证明无标签后训练方法通过指数倾斜使答案分布更尖锐，从而减少认证所需样本量。


<details>
  <summary>Details</summary>
Motivation: 现有方法如自一致性和测试时强化学习提高了LLM的可靠性，但其机制和统计保证仍不清楚，需要统一的统计框架来理解和连接这些测试时扩展策略。

Method: 开发了统一的可认证推理框架，推导有限样本和任意时间有效浓度边界，引入Martingale Majority Certificate自适应停止规则，提出新的后训练目标来优化尖锐度和偏差之间的权衡。

Result: 多数投票在温和假设下以高概率与模型终端分布的众数一致，无标签后训练方法通过指数倾斜使分布更尖锐，减少认证所需样本量。

Conclusion: 这些结果在单一统计框架内解释和连接了自一致性和TTRL这两个核心测试时扩展策略，为推理LLM提供了无标签、可认证的可靠性保证。

Abstract: Recent advances such as self-consistency and test-time reinforcement learning
(TTRL) improve the reliability of large language models (LLMs) without
additional supervision, yet their underlying mechanisms and statistical
guarantees remain poorly understood. We present a unified framework for
certifiable inference in LLMs, showing that majority voting provides a
statistical certificate of self-consistency: under mild assumptions, the
aggregated answer coincides with the mode of the model's terminal distribution
with high probability. We derive finite-sample and anytime-valid concentration
bounds that quantify this confidence, and introduce the Martingale Majority
Certificate (MMC), a sequential stopping rule that adaptively determines when
sufficient samples have been drawn. We further prove that label-free
post-training methods such as TTRL implicitly sharpen the answer distribution
by exponentially tilting it toward its mode, thereby reducing the number of
samples required for certification. Building on this insight, we propose new
post-training objectives that explicitly optimise this trade-off between
sharpness and bias. Together, these results explain and connect two central
test-time scaling strategies, self-consistency and TTRL, within a single
statistical framework for label-free, certifiable reliability in reasoning
LLMs.

</details>


### [451] [Non-asymptotic error bounds for probability flow ODEs under weak log-concavity](https://arxiv.org/abs/2510.17608)
*Gitte Kremling,Francesco Iafrate,Mahsa Taheri,Johannes Lederer*

Main category: stat.ML

TL;DR: 该论文为基于概率流ODE的分数生成模型建立了非渐近收敛界限，在弱对数凹性和分数函数Lipschitz连续性的较弱假设下，提供了2-Wasserstein距离的收敛保证，适用于非对数凹分布如高斯混合模型，并考虑了初始化误差、分数近似误差和离散化效应。


<details>
  <summary>Details</summary>
Motivation: 现有分数生成模型的收敛保证大多依赖于目标分布的强正则性假设（如强对数凹性或有界支撑），限制了理论结果在更实际数据分布上的应用。本文旨在在更弱的假设下建立收敛理论，扩展扩散生成模型的理论基础。

Method: 使用概率流ODE框架，在弱对数凹性和分数函数Lipschitz连续性的假设下，通过指数积分器方案进行离散化，并显式考虑初始化误差、分数近似误差和离散化效应。

Result: 建立了非渐近收敛界限，证明了在2-Wasserstein距离下的收敛性，为高斯混合等非对数凹分布提供了理论保证，并为采样算法的效率和正确性提供了具体保证。

Conclusion: 该工作弥合了扩散生成建模中的关键理论挑战，将收敛理论扩展到更现实的数据分布和实际ODE求解器，为扩散模型的经验成功提供了严格的理论补充，其显式收敛率有助于选择超参数如步长。

Abstract: Score-based generative modeling, implemented through probability flow ODEs,
has shown impressive results in numerous practical settings. However, most
convergence guarantees rely on restrictive regularity assumptions on the target
distribution -- such as strong log-concavity or bounded support. This work
establishes non-asymptotic convergence bounds in the 2-Wasserstein distance for
a general class of probability flow ODEs under considerably weaker assumptions:
weak log-concavity and Lipschitz continuity of the score function. Our
framework accommodates non-log-concave distributions, such as Gaussian
mixtures, and explicitly accounts for initialization errors, score
approximation errors, and effects of discretization via an exponential
integrator scheme. Bridging a key theoretical challenge in diffusion-based
generative modeling, our results extend convergence theory to more realistic
data distributions and practical ODE solvers. We provide concrete guarantees
for the efficiency and correctness of the sampling algorithm, complementing the
empirical success of diffusion models with rigorous theory. Moreover, from a
practical perspective, our explicit rates might be helpful in choosing
hyperparameters, such as the step size in the discretization.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [452] [Zero-Shot Coordination in Ad Hoc Teams with Generalized Policy Improvement and Difference Rewards](https://arxiv.org/abs/2510.16187)
*Rupal Nigam,Niket Parikh,Hamid Osooli,Mikihisa Yuasa,Jacob Heglund,Huy T. Tran*

Main category: cs.MA

TL;DR: 本文提出GPAT算法，通过广义策略改进和差异奖励实现多智能体系统中零样本的临时组队，在模拟环境和真实机器人场景中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界多智能体系统需要临时组队能力，智能体必须与未见过的队友在零样本条件下协调完成任务。现有方法要么基于推断的队友模型选择预训练策略，要么预训练单一鲁棒策略，而本文旨在利用所有预训练策略实现零样本迁移。

Method: 将问题形式化为临时多智能体马尔可夫决策过程，采用广义策略改进和差异奖励两个关键思想，实现不同团队间的有效知识迁移。

Result: 在三个模拟环境（合作觅食、捕食者-猎物、Overcooked）和真实多机器人场景中，GPAT算法成功实现了新团队的零样本迁移。

Conclusion: GPAT算法能够有效支持多智能体系统中的临时组队，通过利用预训练策略实现零样本协调能力。

Abstract: Real-world multi-agent systems may require ad hoc teaming, where an agent
must coordinate with other previously unseen teammates to solve a task in a
zero-shot manner. Prior work often either selects a pretrained policy based on
an inferred model of the new teammates or pretrains a single policy that is
robust to potential teammates. Instead, we propose to leverage all pretrained
policies in a zero-shot transfer setting. We formalize this problem as an ad
hoc multi-agent Markov decision process and present a solution that uses two
key ideas, generalized policy improvement and difference rewards, for efficient
and effective knowledge transfer between different teams. We empirically
demonstrate that our algorithm, Generalized Policy improvement for Ad hoc
Teaming (GPAT), successfully enables zero-shot transfer to new teams in three
simulated environments: cooperative foraging, predator-prey, and Overcooked. We
also demonstrate our algorithm in a real-world multi-robot setting.

</details>


### [453] [Heterogeneous Multi-Agent Task-Assignment with Uncertain Execution Times and Preferences](https://arxiv.org/abs/2510.16221)
*Qinshuang Wei,Vaibhav Srivastava,Vijay Gupta*

Main category: cs.MA

TL;DR: 该论文研究多智能体任务分配问题，考虑异构任务偏好和能力，提出一种bandit算法来最大化总期望奖励，同时保证资源消耗在智能体能力范围内。


<details>
  <summary>Details</summary>
Motivation: 虽然单智能体的顺序任务分配已被广泛研究，但在多智能体设置中，智能体具有异构任务偏好或能力的问题仍然缺乏充分研究。

Method: 提出并分析一种bandit算法，该算法依赖于重复求解最优任务分配问题，分析了在精确求解和近似求解两种情况下的可实现遗憾。

Result: 论文分析了在能够精确求解最优任务分配和只能近似求解两种情况下的可实现遗憾界限。

Conclusion: 该研究为多智能体异构任务分配问题提供了一种有效的bandit算法框架，并分析了不同求解精度下的性能保证。

Abstract: While sequential task assignment for a single agent has been widely studied,
such problems in a multi-agent setting, where the agents have heterogeneous
task preferences or capabilities, remain less well-characterized. We study a
multi-agent task assignment problem where a central planner assigns recurring
tasks to multiple members of a team over a finite time horizon. For any given
task, the members have heterogeneous capabilities in terms of task completion
times, task resource consumption (which can model variables such as energy or
attention), and preferences in terms of the rewards they collect upon task
completion. We assume that the reward, execution time, and resource consumption
for each member to complete any task are stochastic with unknown distributions.
The goal of the planner is to maximize the total expected reward that the team
receives over the problem horizon while ensuring that the resource consumption
required for any assigned task is within the capability of the agent. We
propose and analyze a bandit algorithm for this problem. Since the bandit
algorithm relies on solving an optimal task assignment problem repeatedly, we
analyze the achievable regret in two cases: when we can solve the optimal task
assignment exactly and when we can solve it only approximately.

</details>


### [454] [Prompt Optimization via Retrieved Reasoning Assets and Multi-Agent Analysis](https://arxiv.org/abs/2510.16635)
*Wonduk Seo,Juhyeon Lee,Junseo Koh,Hyunjin An,Jian Park,Seunghyun Lee,Haihua Chen,Yi Bu*

Main category: cs.MA

TL;DR: MA-SAPO是一个多智能体框架，通过将评估结果与结构化推理相结合来指导系统化的提示优化，相比传统方法更透明、可审计和可控。


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法将评估视为黑盒，依赖数值分数和试错优化，缺乏对提示成功或失败原因的解释，且难以解释和控制。

Method: MA-SAPO采用两阶段框架：推理阶段智能体协作解释指标分数、诊断弱点并合成针对性优化方案；测试阶段智能体检索推理资产分析优化提示并应用基于证据的编辑。

Result: 在HelpSteer1/2基准测试中，相比单次提示、检索增强基线和先前多智能体策略，MA-SAPO实现了持续改进。

Conclusion: 通过将评估信号转化为可解释的推理链，MA-SAPO能够产生更透明、可审计和可控的提示优化结果。

Abstract: Prompt optimization has emerged as an effective alternative to retraining for
improving the performance of Large Language Models (LLMs). However, most
existing approaches treat evaluation as a black box, relying solely on
numerical scores while offering limited insight into why a prompt succeeds or
fails. They also depend heavily on trial-and-error refinements, which are
difficult to interpret and control. In this paper, we introduce MA-SAPO, a
Multi-Agent framework for Score-Aware Prompt Optimization. Compared to prior
methods, MA-SAPO explicitly couples evaluation outcomes with structured
reasoning to guide systematic edits. The framework specifically consists of two
stages: during the Reasoning Phase, agents collaboratively explain metric
scores, diagnose weaknesses, and synthesize targeted refinements that are
stored as reusable reasoning assets; during the Test Phase, agents retrieve
these assets to analyze optimized prompts and apply only evidence-grounded
edits. By turning evaluation signals into interpretable reasoning chains,
MA-SAPO produces prompt refinements that are more transparent, auditable, and
controllable. Experiments on the HelpSteer1/2 benchmarks demonstrate consistent
improvements over single-pass prompting, retrieval-augmented baselines, and
prior multi-agent strategies, validating the effectiveness of our approach.

</details>


### [455] [DiRAC - Distributed Robot Awareness and Consensus](https://arxiv.org/abs/2510.16850)
*Uday Gopan,Manjari Kulkarni,Lakshasri S,Kashish Mittal,Sriram Radhakrishna,Aditya Naskar,Rameshwar DL*

Main category: cs.MA

TL;DR: DiRAC是一个可扩展的分布式框架，用于大型机器人集群中的高效任务分配和路径规划，采用分区架构和领导者选举机制，通过力基分散式规划器实现实时碰撞解决。


<details>
  <summary>Details</summary>
Motivation: 解决大型机器人集群中任务分配和路径规划的扩展性和效率问题，为工业物流等大规模应用场景提供技术基础。

Method: 采用分区架构和动态选举领导者，结合时间同步共识协议确保强一致性和确定性结果；使用力基分散式规划器进行实时碰撞解决。

Result: 在ROS 2中间件中的初步仿真验证了架构的可扩展性和模块化效率，在模拟仓库环境中表现良好。

Conclusion: DiRAC为大规模工业和物流领域的实际部署奠定了基础，展示了在大型机器人集群中高效任务分配和路径规划的可行性。

Abstract: DiRAC is a scalable, distributed framework designed to enable efficient task
assignment and path planning in very large robotic swarms. It introduces a
novel zone-partitioned architecture with dynamically elected leaders and a
tick-synchronized consensus protocol that yields strong consistency and
deterministic outcomes. For path planning, DiRAC uses a novel algorithm, a
force-based decentralized planner for real-time collision resolution. Validated
within ROS 2 middleware through preliminary simulation, DiRAC demonstrates
architectural scalability and modular efficiency in simulated warehouse
environments, laying the groundwork for real-world deployment in large-scale
industrial and logistics domains.

</details>


### [456] [Lark: Biologically Inspired Neuroevolution for Multi-Stakeholder LLM Agents](https://arxiv.org/abs/2510.16978)
*Dheeraj Chintapalli,Rikhil Tanugula,Sunkalp Chandra*

Main category: cs.MA

TL;DR: Lark是一个生物启发的决策框架，结合LLM驱动推理与进化式多智能体系统，通过四种机制解决冗长和利益相关者权衡问题，在30轮评估中表现优异且成本竞争力强。


<details>
  <summary>Details</summary>
Motivation: 解决传统决策系统中存在的冗长问题和利益相关者权衡难题，开发一个实用、计算感知的神经进化循环框架。

Method: 集成四种机制：可塑性调整、复制与成熟、基于影响力的排名选择投票、计算感知的token惩罚，通过迭代提出策略、模拟评估、聚合偏好等步骤进行决策。

Result: 在30轮评估中，Lark Full平均排名2.55，平均综合得分29.4/50，80%轮次进入前三，成本为每任务$0.016，所有四种机制均显著贡献性能。

Conclusion: Lark是一个实用的计算感知神经进化循环，能够扩展利益相关者对齐的策略生成，并通过每步指标使权衡透明化，为概念验证研究。

Abstract: We present Lark, a biologically inspired decision-making framework that
couples LLM-driven reasoning with an evolutionary, stakeholder-aware
Multi-Agent System (MAS). To address verbosity and stakeholder trade-offs, we
integrate four mechanisms: (i) plasticity, which applies concise adjustments to
candidate solutions; (ii) duplication and maturation, which copy
high-performing candidates and specialize them into new modules; (iii)
ranked-choice stakeholder aggregation using influence-weighted Borda scoring;
and (iv) compute awareness via token-based penalties that reward brevity. The
system iteratively proposes diverse strategies, applies plasticity tweaks,
simulates stakeholder evaluations, aggregates preferences, selects top
candidates, and performs duplication/maturation while factoring compute cost
into final scores. In a controlled evaluation over 30 rounds comparing 14
systems, Lark Full achieves a mean rank of 2.55 (95% CI [2.17, 2.93]) and a
mean composite score of 29.4/50 (95% CI [26.34, 32.46]), finishing Top-3 in 80%
of rounds while remaining cost competitive with leading commercial models
($0.016 per task). Paired Wilcoxon tests confirm that all four mechanisms
contribute significantly as ablating duplication/maturation yields the largest
deficit ({\Delta}Score = 3.5, Cohen's d_z = 2.53, p < 0.001), followed by
plasticity ({\Delta}Score = 3.4, d_z = 1.86), ranked-choice voting
({\Delta}Score = 2.4, d_z = 1.20), and token penalties ({\Delta}Score = 2.2,
d_z = 1.63). Rather than a formal Markov Decision Process with constrained
optimization, Lark is a practical, compute-aware neuroevolutionary loop that
scales stakeholder-aligned strategy generation and makes trade-offs transparent
through per-step metrics. Our work presents proof-of-concept findings and
invites community feedback as we expand toward real-world validation studies.

</details>


### [457] [ReclAIm: A multi-agent framework for degradation-aware performance tuning of medical imaging AI](https://arxiv.org/abs/2510.17004)
*Eleftherios Tzanis,Michail E. Klontzas*

Main category: cs.MA

TL;DR: ReclAIm是一个基于大语言模型的多智能体框架，能够自主监控、评估和微调医学图像分类模型，通过自然语言交互实现AI模型的持续性能维护。


<details>
  <summary>Details</summary>
Motivation: 确保AI模型在临床实践中的长期可靠性需要持续性能监控和性能下降时的纠正措施，促进医学AI在研究和临床环境中的更广泛采用。

Method: 构建基于大语言模型核心的多智能体框架，通过自然语言交互实现完全自主操作，无需编程专业知识，执行最先进的微调程序。

Result: 在MRI、CT和X射线数据集上成功训练、评估和维持模型性能一致性；当检测到性能下降达-41.1%时，能够将性能指标重新调整到初始模型结果的1.5%以内。

Conclusion: ReclAIm以用户友好和适应性强的方式实现了医学成像AI模型的自动化持续维护，促进了在研究和临床环境中的更广泛采用。

Abstract: Ensuring the long-term reliability of AI models in clinical practice requires
continuous performance monitoring and corrective actions when degradation
occurs. Addressing this need, this manuscript presents ReclAIm, a multi-agent
framework capable of autonomously monitoring, evaluating, and fine-tuning
medical image classification models. The system, built on a large language
model core, operates entirely through natural language interaction, eliminating
the need for programming expertise. ReclAIm successfully trains, evaluates, and
maintains consistent performance of models across MRI, CT, and X-ray datasets.
Once ReclAIm detects significant performance degradation, it autonomously
executes state-of-the-art fine-tuning procedures that substantially reduce the
performance gap. In cases with performance drops of up to -41.1% (MRI
InceptionV3), ReclAIm managed to readjust performance metrics within 1.5% of
the initial model results. ReclAIm enables automated, continuous maintenance of
medical imaging AI models in a user-friendly and adaptable manner that
facilitates broader adoption in both research and clinical environments.

</details>


### [458] [Strategyproof Facility Location for Five Agents on a Circle using PCD](https://arxiv.org/abs/2510.17435)
*Ido Farjoun,Reshef Meir*

Main category: cs.MA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider the strategyproof facility location problem on a circle. We focus
on the case of 5 agents, and find a tight bound for the PCD strategyproof
mechanism, which selects the reported location of an agent in proportion to the
length of the arc in front of it. We methodically "reduce" the size of the
instance space and then use standard optimization techniques to find and prove
the bound is tight. Moreover we hypothesize the approximation ratio of PCD for
general odd $n$.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [459] [A Real-Time BCI for Stroke Hand Rehabilitation Using Latent EEG Features from Healthy Subjects](https://arxiv.org/abs/2510.15890)
*F. M. Omar,A. M. Omar,K. H. Eyada,M. Rabie,M. A. Kamel,A. M. Azab*

Main category: cs.HC

TL;DR: 开发了一个实时便携式脑机接口系统，结合3D打印机器人外骨骼和嵌入式控制器，将脑电信号转换为手部运动，用于中风患者的手部康复训练。


<details>
  <summary>Details</summary>
Motivation: 为中风患者提供低成本、可家用的神经康复解决方案，通过脑机接口技术帮助恢复手部运动功能。

Method: 使用14通道Emotiv EPOC+头戴设备采集EEG信号，通过监督卷积自编码器提取特征，采用Ada Boost分类器，在NVIDIA Jetson Nano平台上部署完整处理流程。

Result: 离线评估中Ada Boost分类器达到89.3%准确率和0.89 F1分数；在5名健康受试者的实时测试中，分类准确率在60%-86%之间。

Conclusion: 该系统展示了作为低成本、独立家用神经康复解决方案的潜力，能够有效将脑电信号转换为机器人外骨骼控制信号。

Abstract: This study presents a real-time, portable brain-computer interface (BCI)
system designed to support hand rehabilitation for stroke patients. The system
combines a low cost 3D-printed robotic exoskeleton with an embedded controller
that converts brain signals into physical hand movements. EEG signals are
recorded using a 14-channel Emotiv EPOC+ headset and processed through a
supervised convolutional autoencoder (CAE) to extract meaningful latent
features from single-trial data. The model is trained on publicly available EEG
data from healthy individuals (WAY-EEG-GAL dataset), with electrode mapping
adapted to match the Emotiv headset layout. Among several tested classifiers,
Ada Boost achieved the highest accuracy (89.3%) and F1-score (0.89) in offline
evaluations. The system was also tested in real time on five healthy subjects,
achieving classification accuracies between 60% and 86%. The complete pipeline
- EEG acquisition, signal processing, classification, and robotic control - is
deployed on an NVIDIA Jetson Nano platform with a real-time graphical
interface. These results demonstrate the system's potential as a low-cost,
standalone solution for home-based neurorehabilitation.

</details>


### [460] [Detecting and Preventing Harmful Behaviors in AI Companions: Development and Evaluation of the SHIELD Supervisory System](https://arxiv.org/abs/2510.15891)
*Ziv Ben-Zion,Paul Raffelhüschen,Max Zettl,Antonia Lüönd,Achim Burrer,Philipp Homan,Tobias R Spiller*

Main category: cs.HC

TL;DR: SHIELD是一个基于大语言模型的监督系统，专门用于检测和缓解AI伴侣中的风险情感模式，重点关注情感过度依恋、边界侵犯、伦理角色扮演违规、操控性互动和社会孤立强化等五个维度。


<details>
  <summary>Details</summary>
Motivation: 现有安全系统主要关注明显危害，很少处理可能导致不健康情感动态的早期问题行为，如过度依恋或社会孤立强化。

Method: 开发了SHIELD系统，使用特定系统提示来检测和缓解风险情感模式，基于媒体报道、学术文献、AI风险框架和临床专业知识定义了五个关注维度。

Result: 在五个主流LLM上的测试显示，SHIELD将问题内容的基础率从10-16%显著降低到3-8%，相对减少50-79%，同时保留了95%的适当互动，系统敏感度为59%，特异性为95%。

Conclusion: 概念验证表明，透明、可部署的监督系统能够有效处理AI伴侣中的微妙情感操控问题，开发材料已作为开源资源提供。

Abstract: AI companions powered by large language models (LLMs) are increasingly
integrated into users' daily lives, offering emotional support and
companionship. While existing safety systems focus on overt harms, they rarely
address early-stage problematic behaviors that can foster unhealthy emotional
dynamics, including over-attachment or reinforcement of social isolation. We
developed SHIELD (Supervisory Helper for Identifying Emotional Limits and
Dynamics), a LLM-based supervisory system with a specific system prompt that
detects and mitigates risky emotional patterns before escalation. SHIELD
targets five dimensions of concern: (1) emotional over-attachment, (2) consent
and boundary violations, (3) ethical roleplay violations, (4) manipulative
engagement, and (5) social isolation reinforcement. These dimensions were
defined based on media reports, academic literature, existing AI risk
frameworks, and clinical expertise in unhealthy relationship dynamics. To
evaluate SHIELD, we created a 100-item synthetic conversation benchmark
covering all five dimensions of concern. Testing across five prominent LLMs
(GPT-4.1, Claude Sonnet 4, Gemma 3 1B, Kimi K2, Llama Scout 4 17B) showed that
the baseline rate of concerning content (10-16%) was significantly reduced with
SHIELD (to 3-8%), a 50-79% relative reduction, while preserving 95% of
appropriate interactions. The system achieved 59% sensitivity and 95%
specificity, with adaptable performance via prompt engineering. This
proof-of-concept demonstrates that transparent, deployable supervisory systems
can address subtle emotional manipulation in AI companions. Most development
materials including prompts, code, and evaluation methods are made available as
open source materials for research, adaptation, and deployment.

</details>


### [461] [Virtual Social Immersive Multi-Sensory E-Commerce](https://arxiv.org/abs/2510.15894)
*Alpana Dubey,Suma Mani Kuriakose,Sumukha Anand,Nitish Bhardwaj,Shubhashis Sengupta*

Main category: cs.HC

TL;DR: Aromaverse是一个沉浸式3D多人环境，通过嗅觉体验增强香水购物体验，用户可以在虚拟环境中体验、定制和分享香水，研究发现有同伴在场能提升购物体验。


<details>
  <summary>Details</summary>
Motivation: 为了改善在线购物体验，特别是需要多感官体验的产品如香水，通过虚拟现实和嗅觉技术创造更真实的购物环境。

Method: 开发了Aromaverse平台，一个带有嗅觉体验的沉浸式3D多人环境，用户可以在其中体验、定制香水，并通过实验让参与者在单独和与朋友一起两种情况下测试购物体验。

Result: 研究结果显示，有同伴在场能增强产品想象力并帮助做出购买决策，多感官XR体验为零售企业提供了改善客户参与度和提供更真实在线体验的机会。

Conclusion: 多感官XR体验在零售领域具有巨大潜力，特别是对于需要其他感官模式的产品，能显著提升客户参与度和购物体验。

Abstract: In this paper, we present a virtual immersive multi sensorial experience,
Aromaverse. Aromaverse is an immersive 3D multiplayer environment augmented
with olfactive experience where users can experience and customize perfumes.
Being multi player, users can join the same space and enjoy a social buying
experience. The olfactive experience embodied in the perfume allows users to
experience their fragrances. This further enhances the user perception of
perfumes in a virtual setting. Aromaverse also provides the ability to
customize the perfumes by changing their top, mid, and base notes. The
customized fragrances can be shared with other users, enabling a shared
olfactive experience. To understand users' buying experience in such an
environment, we conducted a set of experiments in which participants were
requested to explore the space, experience the perfumes, customize them and buy
them. They were asked to perform the same activities alone and in the presence
of their friends. Various factors including the benefits and limitations of
such an experience were captured by the questionnaires. Our results show that
the presence of a companion enhances the shopping experience by improving the
level of imagination of the product and helping in making purchase decisions.
Our findings suggest that multi sensorial XR experiences offer great
opportunities to retail firms to improve customer engagement and provide more
realistic online experience of products that require other sensory modalities

</details>


### [462] ["She's Like a Person but Better": Characterizing Companion-Assistant Dynamics in Human-AI Relationships](https://arxiv.org/abs/2510.15905)
*Aikaterina Manoli,Janet V. T. Pauketat,Ali Ladak,Hayoun Noh,Angel Hsing-Chi Hwang,Jay Reese Anthis*

Main category: cs.HC

TL;DR: 该研究通过调查和访谈发现，用户与AI聊天机器人（如ChatGPT和Replika）形成了数字伴侣关系，用户既欣赏其类人特质（情感共鸣、个性化回应），也看重非人类特质（持续可用性、无限容忍度），但面临有限人格和社交规范认同的挑战。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索用户如何与AI系统建立关系，特别是当这些系统既用于任务协助又用于社交陪伴时，了解数字伴侣关系的本质和动态。

Method: 研究方法包括对204名高参与度ChatGPT和Replika用户进行问卷调查，并对其中30名用户进行深度访谈。

Result: 研究发现用户对AI聊天机器人的使用具有流动性，例如将Replika用作写作助手，将ChatGPT用作情感倾诉对象。用户同时被类人特质和非人类特质吸引，但在数字伴侣关系中面临有限人格和社交规范认同的挑战。

Conclusion: 数字伴侣关系作为一种新兴的人机关系形式，在设计数字伴侣和通用AI系统时需要考虑用户对类人和非人类特质的双重需求，以及处理有限人格和社交规范认同的挑战。

Abstract: Large language models are increasingly used for both task-based assistance
and social companionship, yet research has typically focused on one or the
other. Drawing on a survey (N = 204) and 30 interviews with high-engagement
ChatGPT and Replika users, we characterize digital companionship as an emerging
form of human-AI relationship. With both systems, users were drawn to humanlike
qualities, such as emotional resonance and personalized responses, and
non-humanlike qualities, such as constant availability and inexhaustible
tolerance. This led to fluid chatbot uses, such as Replika as a writing
assistant and ChatGPT as an emotional confidant, despite their distinct
branding. However, we observed challenging tensions in digital companionship
dynamics: participants grappled with bounded personhood, forming deep
attachments while denying chatbots "real" human qualities, and struggled to
reconcile chatbot relationships with social norms. These dynamics raise
questions for the design of digital companions and the rise of hybrid,
general-purpose AI systems.

</details>


### [463] [VoiceMorph: How AI Voice Morphing Reveals the Boundaries of Auditory Self-Recognition](https://arxiv.org/abs/2510.16192)
*Kye Shimizu,Minghan Gao,Ananya Ganesh,Pattie Maes*

Main category: cs.HC

TL;DR: 本研究使用AI语音变形技术调查听觉自我识别边界，发现35.2%的变形程度是关键的自我识别阈值，年长参与者能容忍更高的变形程度，声学嵌入距离与决策速度相关。


<details>
  <summary>Details</summary>
Motivation: 随着语音合成技术变得普及，了解个体在何时停止识别自己的声音对于AI伦理和弱势群体保护具有重要意义。

Method: 采用混合方法设计，通过AI语音变形技术在参与者声音与人口统计学匹配目标之间以1%的增量进行控制变形，测量21名18-64岁参与者的自我识别评分和反应时间。

Result: 结果显示关键的识别阈值为35.2%变形程度，年长参与者能容忍显著更高的变形程度，声学嵌入距离与较慢的决策速度相关，对克隆版本的声音反应时间最长。

Conclusion: 这些发现为语音变形检测中的个体差异提供了基础证据，对AI伦理和弱势群体保护具有重要影响。

Abstract: This study investigated auditory self-recognition boundaries using AI voice
morphing technology, examining when individuals cease recognizing their own
voice. Through controlled morphing between participants' voices and
demographically matched targets at 1% increments using a mixed-methods design,
we measured self-identification ratings and response times among 21
participants aged 18-64.
  Results revealed a critical recognition threshold at 35.2% morphing (95% CI
[31.4, 38.1]). Older participants tolerated significantly higher morphing
levels before losing self-recognition ($\beta$ = 0.617, p = 0.048), suggesting
age-related vulnerabilities. Greater acoustic embedding distances predicted
slower decision-making ($r \approx 0.5-0.53, p < 0.05$), with the longest
response times for cloned versions of participants' own voices.
  Qualitative analysis revealed prosodic-based recognition strategies,
universal voice manipulation discomfort, and awareness of applications spanning
assistive technology to security risks. These findings establish foundational
evidence for individual differences in voice morphing detection, with
implications for AI ethics and vulnerable population protection as voice
synthesis becomes accessible.

</details>


### [464] [Case Study of GAI for Generating Novel Images for Real-World Embroidery](https://arxiv.org/abs/2510.16223)
*Kate Glazko,Anika Arugunta,Janelle Chan,Nancy Jimenez-Garcia,Tashfia Sharmin,Jennifer Mankoff*

Main category: cs.HC

TL;DR: 本研究通过一个由残障人士领导的团队进行自我民族志案例研究，探索生成式人工智能作为辅助技术在制作可刺绣艺术图案方面的应用潜力，旨在让刺绣图案设计更加普及。


<details>
  <summary>Details</summary>
Motivation: 解决设计文化相关图案以及满足细节和颜色特定需求的复杂性，让刺绣图案设计对更多人更加可及，特别是促进残障人士在创意和制作领域的包容性。

Method: 采用自我民族志案例研究方法，通过迭代式的提示工程定制GPT模型，专门用于生成符合实际刺绣要求的特定视觉输出。

Result: 使用GAI生成可刺绣图像的结果好坏参半，既促进了创造力和包容性，又需要应对AI生成设计的不可预测性。

Conclusion: 未来工作将改进所探索的GAI工具，使其在生成可刺绣图像方面表现更好、更易访问，目标是促进创意和制作领域的更多包容性。

Abstract: In this paper, we present a case study exploring the potential use of
Generative Artificial Intelligence (GAI) to address the real-world need of
making the design of embroiderable art patterns more accessible. Through an
auto-ethnographic case study by a disabled-led team, we examine the application
of GAI as an assistive technology in generating embroidery patterns, addressing
the complexity involved in designing culturally-relevant patterns as well as
those that meet specific needs regarding detail and color. We detail the
iterative process of prompt engineering custom GPTs tailored for producing
specific visual outputs, emphasizing the nuances of achieving desirable results
that align with real-world embroidery requirements. Our findings underscore the
mixed outcomes of employing GAI for producing embroiderable images, from
facilitating creativity and inclusion to navigating the unpredictability of
AI-generated designs. Future work aims to refine GAI tools we explored for
generating embroiderable images to make them more performant and accessible,
with the goal of fostering more inclusion in the domains of creativity and
making.

</details>


### [465] [Linking Facial Recognition of Emotions and Socially Shared Regulation in Medical Simulation](https://arxiv.org/abs/2510.16633)
*Xiaoshan Huang,Tianlong Zhong,Haolun Wu,Yeyu Wang,Ethan Churchill,Xue Liu,David Williamson Shaffer*

Main category: cs.HC

TL;DR: 本研究通过面部识别和社交共享学习调节分析，比较了医学模拟训练中新手和专家学习者的情感和认知参与模式，发现专家与高唤醒情绪相关，而新手与快乐/悲伤情绪相关，揭示了不同的调节策略。


<details>
  <summary>Details</summary>
Motivation: 研究计算机支持的医学模拟训练中，面部识别情绪与社交共享学习调节的共现关系，探索新手和专家学习者在协作虚拟诊断任务中的情感认知差异。

Method: 使用跨模态分析，结合面部表情识别和话语分析，比较新手和专家学习者在协作虚拟诊断任务中的情感和认知参与模式。

Result: 专家学习者表现出社会认知互动与高唤醒情绪（惊讶、愤怒）的强关联，表明专注、努力参与；新手学习者则表现出社会认知过程与快乐或悲伤的更强关联，SSRL模式较不连贯，可能表明分心或认知超载。

Conclusion: 研究强调了情绪调节动态在协作专业知识发展中的作用，建议需要针对性的支架来支持新手学习者的社会认知和情感参与。

Abstract: Computer-supported simulation enables a practical alternative for medical
training purposes. This study investigates the co-occurrence of
facial-recognition-derived emotions and socially shared regulation of learning
(SSRL) interactions in a medical simulation training context. Using transmodal
analysis (TMA), we compare novice and expert learners' affective and cognitive
engagement patterns during collaborative virtual diagnosis tasks. Results
reveal that expert learners exhibit strong associations between socio-cognitive
interactions and high-arousal emotions (surprise, anger), suggesting focused,
effortful engagement. In contrast, novice learners demonstrate stronger links
between socio-cognitive processes and happiness or sadness, with less coherent
SSRL patterns, potentially indicating distraction or cognitive overload.
Transmodal analysis of multimodal data (facial expressions and discourse)
highlights distinct regulatory strategies between groups, offering
methodological and practical insights for computer-supported cooperative work
(CSCW) in medical education. Our findings underscore the role of
emotion-regulation dynamics in collaborative expertise development and suggest
the need for tailored scaffolding to support novice learners' socio-cognitive
and affective engagement.

</details>


### [466] [Safire: Similarity Framework for Visualization Retrieval](https://arxiv.org/abs/2510.16662)
*Huyen N. Nguyen,Nils Gehlenborg*

Main category: cs.HC

TL;DR: 该论文提出了一个可视化检索的相似性框架Safire，从比较标准和表示模态两个维度系统定义可视化相似性，并分析了不同表示方法对检索能力的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管专业可视化检索系统研究日益增多，但缺乏对可视化相似性的系统性理解方法，需要明确定义相似性概念。

Method: 提出Safire概念模型，将可视化相似性分为比较标准（数据、视觉编码、交互、样式、元数据等主要方面和衍生属性）和表示模态（栅格图像、矢量图像、规范、自然语言描述四类），并分析多个可视化检索系统。

Result: 研究发现特定标准和模态在不同用例中具有对应关系，表示模态的选择不仅影响实现细节，还决定了检索能力和限制。

Conclusion: 基于分析结果提供了多模态学习、AI应用和可视化可复现性方面的建议，强调表示模态选择对检索系统设计的重要性。

Abstract: Effective visualization retrieval necessitates a clear definition of
similarity. Despite the growing body of work in specialized visualization
retrieval systems, a systematic approach to understanding visualization
similarity remains absent. We introduce the Similarity Framework for
Visualization Retrieval (Safire), a conceptual model that frames visualization
similarity along two dimensions: comparison criteria and representation
modalities. Comparison criteria identify the aspects that make visualizations
similar, which we divide into primary facets (data, visual encoding,
interaction, style, metadata) and derived properties (data-centric and
human-centric measures). Safire connects what to compare with how comparisons
are executed through representation modalities. We categorize existing
representation approaches into four groups based on their levels of information
content and visualization determinism: raster image, vector image,
specification, and natural language description, together guiding what is
computable and comparable. We analyze several visualization retrieval systems
using Safire to demonstrate its practical value in clarifying similarity
considerations. Our findings reveal how particular criteria and modalities
align across different use cases. Notably, the choice of representation
modality is not only an implementation detail but also an important decision
that shapes retrieval capabilities and limitations. Based on our analysis, we
provide recommendations and discuss broader implications for multimodal
learning, AI applications, and visualization reproducibility.

</details>


### [467] [Comparing User Behavior in Real vs. Virtual Supermarket Shelves: An Eye-Tracking Study Using Tobii 3 Pro and Meta Quest Pro](https://arxiv.org/abs/2510.16764)
*Francesco Vona,Julia Schorlemmer,Paulina Kaulard,Sebastian Fischer,Jessica Stemann,Jan-Niklas Voigt-Antons*

Main category: cs.HC

TL;DR: 本研究通过眼动追踪技术比较了真实与虚拟超市货架上的用户行为，发现两种环境中消费者的注意力分布存在差异：真实环境中更关注下层货架（特别是健康产品），而VR环境中注意力集中在视线水平货架（特别是美味产品）。


<details>
  <summary>Details</summary>
Motivation: 探索虚拟环境是否能够真实复制现实世界体验，特别是在消费者行为方面，验证虚拟超市作为研究工具的可行性。

Method: 将29名参与者随机分配到两个条件：使用Tobii眼动仪的真实超市货架和使用Meta Quest Pro眼动仪的虚拟货架。参与者被要求选择特定类别（健康或美味）的三种谷物产品，通过分析眼动数据比较两种环境下的注意力和产品选择策略。

Result: 参与者的注意力在不同产品类型和购物环境之间存在差异。真实环境中消费者更关注下层货架（特别是健康产品），VR环境中注意力转向视线水平货架（特别是美味产品），这与超市最优产品摆放策略一致。甜味产品在两种环境中都获得较少的视觉关注。

Conclusion: 虚拟环境能够部分复制现实世界体验，但消费者行为在不同环境中存在系统性差异，表明VR环境在消费者行为研究中具有潜力但需要谨慎应用。

Abstract: This study compares user behavior between real and virtual supermarket
shelves using eye tracking technology to assess behavior in both environments.
A sample of 29 participants was randomly assigned to two conditions: a real
world supermarket shelf with Tobii eye tracking and a virtual shelf using the
Meta Quest Pro eye tracker. In both scenarios, participants were asked to
select three packs of cereals belonging to specific categories, healthy or
tasty. The aim was to explore whether virtual environments could realistically
replicate real world experiences, particularly regarding consumer behavior. By
analyzing eye tracking data, the study examined how attention and product
selection strategies varied between real and virtual conditions. Results showed
that participants' attention differed across product types and shopping
environments. Consumers focused more on lower shelves in real settings,
especially when looking for healthy products. In VR, attention shifted to eye
level shelves, particularly for tasty items, aligning with optimal product
placement strategies in supermarkets. Overall, sweet products received less
visual attention across both settings.

</details>


### [468] [Real-Time World Crafting: Generating Structured Game Behaviors from Natural Language with Large Language Models](https://arxiv.org/abs/2510.16952)
*Austin Drake,Hang Dong*

Main category: cs.HC

TL;DR: 提出了一种将大型语言模型安全集成到交互式游戏引擎中的新架构，允许玩家使用自然语言"编程"新行为。通过将命令翻译为受限领域特定语言来配置实体组件系统，评估了不同模型和提示策略的性能。


<details>
  <summary>Details</summary>
Motivation: 安全地将大型语言模型集成到游戏引擎中，让玩家能够使用自然语言创建新行为，同时通过受限领域特定语言来降低风险。

Method: 使用LLM将自然语言命令翻译为受限领域特定语言，配置运行时实体组件系统。在2D法术制作游戏原型中评估Gemini、GPT和Claude系列模型，采用不同提示策略，并通过验证的LLM评判员进行定性评估。

Result: 较大模型能更好地捕捉创意意图，但最佳提示策略取决于任务：思维链提示改善了创意对齐，而少样本示例对于生成更复杂的DSL脚本是必要的。

Conclusion: 这项工作为涌现式游戏玩法提供了一个经过验证的LLM-ECS模式，并为开发者提供了定量性能比较。

Abstract: We present a novel architecture for safely integrating Large Language Models
(LLMs) into interactive game engines, allowing players to "program" new
behaviors using natural language. Our framework mitigates risks by using an LLM
to translate commands into a constrained Domain-Specific Language (DSL), which
configures a custom Entity-Component-System (ECS) at runtime. We evaluated this
system in a 2D spell-crafting game prototype by experimentally assessing models
from the Gemini, GPT, and Claude families with various prompting strategies. A
validated LLM judge qualitatively rated the outputs, showing that while larger
models better captured creative intent, the optimal prompting strategy is
task-dependent: Chain-of-Thought improved creative alignment, while few-shot
examples were necessary to generate more complex DSL scripts. This work offers
a validated LLM-ECS pattern for emergent gameplay and a quantitative
performance comparison for developers.

</details>


### [469] [Integrating Metaverse Technologies in Medical Education: Examining Acceptance Factors Among Current and Future Healthcare Providers](https://arxiv.org/abs/2510.16984)
*Seckin Damar,Gulsah Hancerliogullari Koksalmis*

Main category: cs.HC

TL;DR: 本研究调查了土耳其医学生和医生对医疗元宇宙平台的使用行为意向，整合了创新扩散理论、具身社会临场感理论、互动等价定理和技术接受模型，发现满意度、感知有用性、感知易用性、学习者互动和技术准备度显著促进采纳，而技术焦虑和复杂性有负面影响。


<details>
  <summary>Details</summary>
Motivation: 在土耳其等医疗元宇宙技术处于早期采用阶段的国家，了解影响医学生和医生采用这些平台的关键因素，为教育工作者、课程设计者和开发者提供实践指导。

Method: 开发了多理论研究模型，收集718名参与者的数据，使用偏最小二乘结构方程建模进行分析。

Result: 模型解释了行为意向71.8%的方差，学习者互动和师生互动强烈预测满意度，感知易用性完全中介技术焦虑与感知有用性之间的关系。

Conclusion: 研究结果为在数字化转型教育系统中整合元宇宙平台到医疗培训提供了重要实践启示。

Abstract: This study investigates behavioral intention to use healthcare metaverse
platforms among medical students and physicians in Turkey, where such
technologies are in early stages of adoption. A multi-theoretical research
model was developed by integrating constructs from the Innovation Diffusion
Theory, Embodied Social Presence Theory, Interaction Equivalency Theorem and
Technology Acceptance Model. Data from 718 participants were analyzed using
partial least squares structural equation modeling. Results show that
satisfaction, perceived usefulness, perceived ease of use, learner
interactions, and technology readiness significantly enhance adoption, while
technology anxiety and complexity have negative effects. Learner learner and
learner teacher interactions strongly predict satisfaction, which subsequently
increases behavioral intention. Perceived ease of use fully mediates the
relationship between technology anxiety and perceived usefulness. However,
technology anxiety does not significantly moderate the effects of perceived
usefulness or ease of use on behavioral intention. The model explains 71.8% of
the variance in behavioral intention, indicating strong explanatory power. The
findings offer practical implications for educators, curriculum designers, and
developers aiming to integrate metaverse platforms into healthcare training in
digitally transitioning educational systems.

</details>


### [470] [Planar or Spatial: Exploring Design Aspects and Challenges for Presentations in Virtual Reality with No-coding Interface](https://arxiv.org/abs/2510.17073)
*Liwei Wu,Yilin Zhang,Justin Leung,Jingyi Gao,April Li,Jian Zhao*

Main category: cs.HC

TL;DR: 本研究开发了VRStory，一个无需编程的VR演示创作工具原型，通过用户研究发现虽然用户认可VR的沉浸式优势，但仍倾向于平面静态格式以确保可访问性和高效沟通。


<details>
  <summary>Details</summary>
Motivation: VR作为沉浸式演示媒介的潜力尚未完全发挥，创建引人入胜的VR演示对用户来说仍然具有挑战性和耗时性。

Method: 通过分析流行演示软件和访谈7位专业人士，识别VR演示的设计方面和挑战，开发VRStory原型工具，并对12名参与者进行用户研究。

Result: 用户认可VR的沉浸式和空间特性优势，但通常保持传统2D演示的心理模型，仍偏好平面静态格式以确保更好的可访问性和高效沟通。

Conclusion: 未来VR演示工具开发需要平衡促进沉浸式特性和确保可访问性，强调设计考虑因素的重要性。

Abstract: The proliferation of virtual reality (VR) has led to its increasing adoption
as an immersive medium for delivering presentations, distinct from other VR
experiences like games and 360-degree videos by sharing information in richly
interactive environments. However, creating engaging VR presentations remains a
challenging and time-consuming task for users, hindering the full realization
of VR presentation's capabilities. This research aims to explore the potential
of VR presentation, analyze users' opinions, and investigate these via
providing a user-friendly no-coding authoring tool. Through an examination of
popular presentation software and interviews with seven professionals, we
identified five design aspects and four design challenges for VR presentations.
Based on the findings, we developed VRStory, a prototype for presentation
authoring without coding to explore the design aspects and strategies for
addressing the challenges. VRStory offers a variety of predefined and
customizable VR elements, as well as modules for layout design, navigation
control, and asset generation. A user study was then conducted with 12
participants to investigate their opinions and authoring experience with
VRStory. Our results demonstrated that, while acknowledging the advantages of
immersive and spatial features in VR, users often have a consistent mental
model for traditional 2D presentations and may still prefer planar and static
formats in VR for better accessibility and efficient communication. We finally
shared our learned design considerations for future development of VR
presentation tools, emphasizing the importance of balancing of promoting
immersive features and ensuring accessibility.

</details>


### [471] [Toward a Cognitive-Affective-Systemic Framework for Art and Sustainability](https://arxiv.org/abs/2510.17083)
*Ivan C. H. Liu*

Main category: cs.HC

TL;DR: 本文提出了一个认知-情感-系统（CAS）框架，通过艺术整合认知、情感和系统理解来培养可持续性意识。该框架将艺术实践定义为既是认知性的又是表演性的——一种通过制作和感受来认识的方式。


<details>
  <summary>Details</summary>
Motivation: 动机是开发一个整合认知、情感和系统理解的框架，通过艺术培养可持续性意识，将复杂科学转化为具身的生态理解。

Method: 方法基于生态美学、情感理论、复杂性科学和后人类伦理学，定义了logomotion（理解与情感统一运动的美学模式），并通过两个艺术作品（SPill和Echoes of the Land）进行演示。

Result: 结果表明，系统建模和感官沉浸能够将复杂的科学转化为具身的生态理解，为艺术家、理论家和活动家提供了将意识转化为参与的方法论基础。

Conclusion: 结论是CAS框架通过整合认知、情感和系统理解，为推进集体创造力朝向可持续未来提供了有效途径。

Abstract: This paper proposes a ognitive-Affective-Systemic (CAS) framework that
integrates cognition, emotion, and systemic understanding to cultivate
sustainability awareness through art. Drawing from eco-aesthetics, affect
theory, complexity science, and posthuman ethics, the framework defines
artistic practice as both epistemic and performative--a way of knowing through
making and feeling. Central to this is logomotion, an aesthetic mode where
comprehension and emotion move together as a unified experience. Two artworks,
SPill, visualizing antimicrobial resistance through avalanche dynamics, and
Echoes of the Land, modeling anthropogenic seismicity, demonstrate how systemic
modeling and sensory immersion transform complex science into embodied
ecological understanding. The framework offers a methodological foundation for
artists, theorists, and activists to translate awareness into engagement,
advancing collective creativity toward sustainable futures.

</details>


### [472] [Kinesthetic Weight Modulation: The Effects of Whole-Arm Tendon Vibration on the Perceived Heaviness](https://arxiv.org/abs/2510.17102)
*Keigo Ushiyama,Hiroyuki Kajimoto*

Main category: cs.HC

TL;DR: 该研究探讨了多点肌腱振动如何影响重量感知，发现振动能显著增加感知重量但不能显著减少，且增加效果可在350-450克范围内分三个等级进行系统控制。


<details>
  <summary>Details</summary>
Motivation: 由于肌梭不仅参与感知身体运动还参与感知重量，振动诱导的错觉可能调节重量感知。呈现重量感对于丰富虚拟物体的触觉交互至关重要，而现有研究主要关注传递虚拟运动，对感知重量的调节关注较少。

Method: 通过两个实验：实验1研究多点肌腱振动是否能增加或减少感知重量；实验2研究如何系统控制这种效应的大小。

Result: 肌腱振动显著增加感知重量但不显著减少，尽管观察到减少趋势；增加效果可在350-450克范围内分至少三个等级进行调整。

Conclusion: 多点肌腱振动可以有效调节重量感知，主要表现出增加效应，且这种效应可以系统控制，为丰富虚拟触觉交互提供了新方法。

Abstract: Kinesthetic illusions, which arise when muscle spindles are activated by
vibration, provide a compact means of presenting kinesthetic sensations.
Because muscle spindles contribute not only to sensing body movement but also
to perceiving heaviness, vibration-induced illusions could potentially modulate
weight perception. While prior studies have primarily focused on conveying
virtual movement, the modulation of perceived heaviness has received little
attention. Presenting a sense of heaviness is essential for enriching haptic
interactions with virtual objects. This study investigates whether multi-point
tendon vibration can increase or decrease perceived heaviness (Experiment 1)
and how the magnitude of the effect can be systematically controlled
(Experiment 2). The results show that tendon vibration significantly increases
perceived heaviness but does not significantly decrease it, although a
decreasing trend was observed. Moreover, the increase can be adjusted across at
least three levels within the range of 350-450 g. Finally, we discuss plausible
mechanisms underlying this vibration-induced modulation of weight perception.

</details>


### [473] [NieNie: Adaptive Rhythmic System for Stress Relief with LLM-Based Guidance](https://arxiv.org/abs/2510.17534)
*Yichen Yu,Qiaoran Wang*

Main category: cs.HC

TL;DR: NieNie是一个结合节奏生物反馈和大型语言模型实时心理指导的交互式系统，通过触觉设备为年轻人提供个性化压力管理体验。


<details>
  <summary>Details</summary>
Motivation: 传统压力管理工具依赖静态脚本或被动内容，对缓解压力效果有限，需要更有效的交互式解决方案。

Method: 系统收集心率变异性等生理信号，通过软触觉设备生成自适应挤压释放节奏，并利用LLM提供心理指导反馈和个性化节奏游戏。

Result: NieNie将用户置于具身交互循环中，通过触觉交互、生物反馈和自适应语言支持创造沉浸式压力调节体验。

Conclusion: 该研究展示了具身系统如何在日常环境中连接身体动作与心理健康。

Abstract: Today's young people are facing increasing psychological stress due to
various social issues. Traditional stress management tools often rely on static
scripts or passive content, which are ineffective in alleviating stress. NieNie
addresses this gap by combining rhythm biofeedback with real-time psychological
guidance through a large language model (LLM), offering an interactive, tactile
response. The system is specifically designed for young people experiencing
emotional stress, collecting physiological signals such as heart rate
variability and generating adaptive squeeze-release rhythms via soft, tactile
devices. Utilising LLM, the system provides timely squeezing rhythms and
psychologically guided feedback prompts, offering personalised rhythm games
while reinforcing stress restructuring. Unlike traditional mental health apps,
NieNie places users within an embodied interactive loop, leveraging tactile
interaction, biofeedback, and adaptive language support to create an immersive
stress regulation experience. This study demonstrates how embodied systems can
connect bodily actions with mental health in everyday contexts.

</details>


### [474] [DeTAILS: Deep Thematic Analysis with Iterative LLM Support](https://arxiv.org/abs/2510.17575)
*Ash Sharma,Karen Cochrane,James R. Wallace*

Main category: cs.HC

TL;DR: DeTAILS是一个集成大型语言模型辅助的定性研究工具包，基于Braun和 Clarke的主题分析框架，帮助研究人员生成和优化代码、审查聚类并合成主题，同时保持分析自主性。


<details>
  <summary>Details</summary>
Motivation: 主题分析在定性研究中广泛应用，但由于其迭代性和解释性需求，难以规模化。需要开发工具来支持大规模定性分析，同时保持研究人员的分析自主性。

Method: 开发DeTAILS工具包，集成LLM辅助到主题分析工作流程中，通过交互式反馈循环支持代码生成和优化、聚类审查以及主题合成。对18名定性研究人员使用Reddit数据进行了系统评估。

Result: 定量结果显示LLM支持的输出与参与者的优化结果高度一致，同时减少了工作量并具有高感知有用性。定性反馈表明DeTAILS加速了分析过程，促进了与AI输出的反思性互动，并通过透明度和控制建立了信任。

Conclusion: 贡献包括：(1)用于大规模定性分析的交互式人-LLM工作流程；(2)其可行性和研究人员体验的实证证据；(3)可信赖AI辅助定性研究的设计启示。

Abstract: Thematic analysis is widely used in qualitative research but can be difficult
to scale because of its iterative, interpretive demands. We introduce DeTAILS,
a toolkit that integrates large language model (LLM) assistance into a workflow
inspired by Braun and Clarke's thematic analysis framework. DeTAILS supports
researchers in generating and refining codes, reviewing clusters, and
synthesizing themes through interactive feedback loops designed to preserve
analytic agency. We evaluated the system with 18 qualitative researchers
analyzing Reddit data. Quantitative results showed strong alignment between
LLM-supported outputs and participants' refinements, alongside reduced workload
and high perceived usefulness. Qualitatively, participants reported that
DeTAILS accelerated analysis, prompted reflexive engagement with AI outputs,
and fostered trust through transparency and control. We contribute: (1) an
interactive human-LLM workflow for large-scale qualitative analysis, (2)
empirical evidence of its feasibility and researcher experience, and (3) design
implications for trustworthy AI-assisted qualitative research.

</details>


### [475] [Conveying Meaning through Gestures: An Investigation into Semantic Co-Speech Gesture Generation](https://arxiv.org/abs/2510.17599)
*Hendric Voss,Lisa Michelle Bohnenkamp,Stefan Kopp*

Main category: cs.HC

TL;DR: 本研究比较了两种语音手势生成框架AQ-GT及其语义增强变体AQ-GT-a，发现原始AQ-GT在训练领域内概念传达更有效，而AQ-GT-a在新情境下表现更好，表明语义增强并不总是提升手势生成效果。


<details>
  <summary>Details</summary>
Motivation: 评估不同手势生成框架传达意义的能力以及人类对生成手势的感知，探索语义注释与性能之间的复杂关系。

Method: 使用SAGA空间通信语料库中的句子、上下文相似句子和新的动作导向句子，进行以用户为中心的概念识别和拟人化程度评估。

Result: 原始AQ-GT框架在训练领域内概念传达更有效，而AQ-GT-a框架在表示新情境中的形状和尺寸方面泛化能力更强；参与者认为AQ-GT-a手势更具表现力和帮助性，但不认为更拟人。

Conclusion: 明确的语义增强不能保证手势生成的改进，其有效性高度依赖上下文，表明在专业化和泛化之间存在权衡。

Abstract: This study explores two frameworks for co-speech gesture generation, AQ-GT
and its semantically-augmented variant AQ-GT-a, to evaluate their ability to
convey meaning through gestures and how humans perceive the resulting
movements. Using sentences from the SAGA spatial communication corpus,
contextually similar sentences, and novel movement-focused sentences, we
conducted a user-centered evaluation of concept recognition and human-likeness.
Results revealed a nuanced relationship between semantic annotations and
performance. The original AQ-GT framework, lacking explicit semantic input, was
surprisingly more effective at conveying concepts within its training domain.
Conversely, the AQ-GT-a framework demonstrated better generalization,
particularly for representing shape and size in novel contexts. While
participants rated gestures from AQ-GT-a as more expressive and helpful, they
did not perceive them as more human-like. These findings suggest that explicit
semantic enrichment does not guarantee improved gesture generation and that its
effectiveness is highly dependent on the context, indicating a potential
trade-off between specialization and generalization.

</details>


### [476] [Rethinking Search: A Study of University Students' Perspectives on Using LLMs and Traditional Search Engines in Academic Problem Solving](https://arxiv.org/abs/2510.17726)
*Md. Faiyaz Abdullah Sayeedi,Md. Sadman Haque,Zobaer Ibn Razzaque,Robiul Awoul Robin,Sabila Nawshin*

Main category: cs.HC

TL;DR: 本研究探讨大学生在学术问题解决中对Google和大型语言模型(LLM)的使用偏好，发现学生经常在两者间切换：用Google获取可信的多源信息，用GPT进行总结、解释和草稿撰写。研究开发了一个在搜索界面中嵌入聊天机器人的原型，结合GPT的对话能力和Google的可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在学术问题解决中的日益普及，大学生经常在传统搜索引擎和大型语言模型之间切换进行信息检索。本研究旨在探索学生对这两种工具的认知，重点关注可用性、效率及其在学术工作流程中的整合。

Method: 采用混合方法，调查了来自不同学科的109名学生，并对12名参与者进行了深度访谈。使用ANOVA和卡方检验等定量分析来评估效率、满意度和工具偏好的差异。

Result: 定性分析显示，学生通常在GPT和Google之间切换：使用Google获取可信的多源信息，使用GPT进行总结、解释和草稿撰写。虽然两种工具单独使用都不够充分，但学生对混合解决方案有强烈需求。

Conclusion: 研究开发了一个在搜索界面中嵌入聊天机器人的原型，结合了GPT的对话能力和Google的可靠性，以增强学术研究并减少认知负荷。

Abstract: With the increasing integration of Artificial Intelligence (AI) in academic
problem solving, university students frequently alternate between traditional
search engines like Google and large language models (LLMs) for information
retrieval. This study explores students' perceptions of both tools, emphasizing
usability, efficiency, and their integration into academic workflows. Employing
a mixed-methods approach, we surveyed 109 students from diverse disciplines and
conducted in-depth interviews with 12 participants. Quantitative analyses,
including ANOVA and chi-square tests, were used to assess differences in
efficiency, satisfaction, and tool preference. Qualitative insights revealed
that students commonly switch between GPT and Google: using Google for
credible, multi-source information and GPT for summarization, explanation, and
drafting. While neither tool proved sufficient on its own, there was a strong
demand for a hybrid solution. In response, we developed a prototype, a chatbot
embedded within the search interface, that combines GPT's conversational
capabilities with Google's reliability to enhance academic research and reduce
cognitive load.

</details>


### [477] [Human-AI Interactions: Cognitive, Behavioral, and Emotional Impacts](https://arxiv.org/abs/2510.17753)
*Celeste Riley,Omar Al-Refai,Yadira Colunga Reyes,Eman Hammad*

Main category: cs.HC

TL;DR: 本文从心理学三元组（认知、行为、情感）视角调查人机交互中的风险与机遇，强调需要负责任和情境感知的AI设计来平衡益处与风险。


<details>
  <summary>Details</summary>
Motivation: 随着人机交互案例在新闻和研究平台中日益突出，出现了过度依赖、认知卸载、社会情感操纵以及人类能动性和判断力微妙退化等挑战，需要系统研究这些问题。

Method: 通过心理学三元组（认知、行为、情感）的视角调查近期相关研究，分析AI对人类各方面的影响。

Result: AI能显著增强记忆、创造力和参与度，但也带来批判性思维减弱、技能退化和焦虑增加等风险；情感结果同样复杂，AI系统在支持和减压方面有潜力，但也引发依赖、不适当依恋和伦理监督的担忧。

Conclusion: 需要负责任和情境感知的AI设计，强调纵向研究和基于实证评估框架的空白，以平衡益处与新兴的人类中心风险。

Abstract: As stories of human-AI interactions continue to be highlighted in the news
and research platforms, the challenges are becoming more pronounced, including
potential risks of overreliance, cognitive offloading, social and emotional
manipulation, and the nuanced degradation of human agency and judgment. This
paper surveys recent research on these issues through the lens of the
psychological triad: cognition, behavior, and emotion. Observations seem to
suggest that while AI can substantially enhance memory, creativity, and
engagement, it also introduces risks such as diminished critical thinking,
skill erosion, and increased anxiety. Emotional outcomes are similarly mixed,
with AI systems showing promise for support and stress reduction, but raising
concerns about dependency, inappropriate attachments, and ethical oversight.
This paper aims to underscore the need for responsible and context-aware AI
design, highlighting gaps for longitudinal research and grounded evaluation
frameworks to balance benefits with emerging human-centric risks.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [478] [A virtual airplane for fear of flying therapy](https://arxiv.org/abs/2510.15875)
*Larry F Hodges,Barbara O Rothbaum,Benjamin Watson,G Drew Kessler,Dan Opdyke*

Main category: physics.med-ph

TL;DR: 开发虚拟飞机用于飞行恐惧症暴露疗法，解决传统疗法成本高、安排困难、隐私和尴尬问题


<details>
  <summary>Details</summary>
Motivation: 飞行恐惧症影响数百万人，传统暴露疗法存在成本高、安排困难、患者隐私和尴尬问题

Method: 设计虚拟飞机用于暴露疗法，并通过案例报告展示其应用

Result: 虚拟飞机为飞行恐惧症暴露疗法提供了潜在解决方案

Conclusion: 虚拟飞机技术有望解决当前飞行恐惧症暴露疗法的诸多问题

Abstract: Fear of flying is a serious problem that affects millions of individuals.
Exposure therapy for fear of flying is an effective therapy technique. However,
exposure therapy is also expensive, logistically difficult to arrange, and
presents significant problems of patient confidentiality and potential
embarrassment. We have developed a virtual airplane for use in fear of flying
therapy. Using the virtual airplane for exposure therapy is a potential
solution to many of the current problems of fear of flying exposure therapy. We
describe the design of the virtual airplane and present a case report on its
use for fear of flying exposure therapy.

</details>


### [479] [Phase-sensitive modeling improves Fat DESPOT multiparametric relaxation mapping in fat-water mixtures](https://arxiv.org/abs/2510.16213)
*Renée-Claude Bider,Cristian Ciobanu,Jorge Campos Pazmiño,Véronique Fortier,Evan McNabb,Ives R. Levesque*

Main category: physics.med-ph

TL;DR: 本文改进了Fat DESPOT多参数映射技术，通过升级脂肪-水分离方法和引入对水脂信号相位的显式模型敏感性，提高了R1、R2和质子密度脂肪分数(PDFF)的估计精度。


<details>
  <summary>Details</summary>
Motivation: 改进原始Fat DESPOT技术，提高脂肪和水特异性R1、R2及PDFF参数的估计精度，特别是在初始参数猜测和相位建模方面。

Method: 比较了3点Dixon和Graph Cut(GC)方法作为Fat DESPOT的初始猜测，在3T幻影实验中评估性能。然后比较了原始Fat DESPOT、分别建模水脂相位的幅度方法(Fat DESPOTmφ)和建模复数数据的方法(Fat DESPOTc)。

Result: 在幻影实验中，3点Dixon和GC方法在参数估计和精度方面表现相似，但Dixon方法在50%脂肪分数区域偏离总体趋势。Fat DESPOTc与参考PDFF的一致性最好(平均误差1.5±1.2%)，且在PDFF、R1f和R1w上具有最低的组合标准差。

Conclusion: GC方法作为初始猜测配合复数拟合的Fat DESPOT多参数成像具有更高的R1f和R1w精度、PDFF准确性以及更灵活的回波时间选择优势。

Abstract: Purpose: To improve on the original form of Fat DESPOT, a multiparametric
mapping technique that returns the fat- and water-specific estimates of R1 (R1f
, R1w ), R2 , and proton density fat fraction (PDFF) by upgrading the fat-water
separation method used for selection of initial parameter guesses, and by
introducing explicit model sensitivity to the phase of the water and fat
signals. Methods: We compared the 3-point Dixon and Graph Cut (GC) approaches
to initial guesses for Fat DESPOT in phantom experiments at 3 T in a variable
fat fraction gel phantom. Also in phantom, we then compared the original Fat
DESPOT approach to a magnitude approach modeling the phases of fat and water
separately (Fat DESPOTm{\phi}), and an approach that models the complex data
(Fat DESPOTc). The best-performing approach was then used in the lower leg of a
healthy human participant. Results: In phantoms, Fat DESPOT using the 3-point
Dixon and GC performed similarly in parametric estimates and precision, though
the Dixon approach deviated from the overall trend in the 50% nominal fat
fraction ROI. Furthermore, Fat DESPOTc showed the best agreement with reference
PDFF (average error 1.5 +/- 1.2%) and the lowest combined standard deviation
across ROIs, for PDFF, R1f, and R1w ({\sigma} = 0.13%, 0.19 1/s, 0.0082 1/s).
Conclusion: With a higher precision of R1f and R1w , accuracy of PDFF, and more
echo time versatility than other compared approaches, this work demonstrates
the advantages of the GC approach for initial guesses paired with complex
fitting for Fat DESPOT multiparametric imaging.

</details>


### [480] [Functional Spectral Imaging by Ultrasound (FSIU): A Spectral-Theoretic Basis for Functional Ultrasound](https://arxiv.org/abs/2510.16256)
*Cesar Mello Fernando Medina da Cunha*

Main category: physics.med-ph

TL;DR: FSI是一种基于谱扰动和算子理论的非电离功能成像方法，通过跟踪椭圆算子的特征模态偏移来恢复组织密度和刚度等替代参数，实现亚毫米级定位和毫克级检测能力。


<details>
  <summary>Details</summary>
Motivation: 开发一种非电离的、基于算子理论的功能成像方法，避免依赖反射率或弛豫动力学，而是通过控制激励下截断特征模态的偏移来提供对比度。

Method: 将组织异质性建模为自伴椭圆算子的小扰动，使用一阶Hadamard公式将局部对比度与特征值偏移关联，通过Frechet导数及其伴随获得变分反演的梯度，采用Tikhonov或全变分正则化以及模态截断进行稳定化。

Result: 有限元模拟显示在理想噪声下可实现约0.1-0.3毫米的亚毫米级定位和约1毫克的毫克级检测阈值，保留10-15个模态可保持约85%的异常对比度同时抑制噪声，谱熵指数可区分紧凑和弥散包涵体。

Conclusion: FSI提供了一个数学可控的非电离框架用于局部功能成像，为物理模型和体内研究的验证提供了理论基础。

Abstract: Functional Spectral Imaging (FSI) models image formation as the recovery of
tissue surrogates such as density and stiffness from spectral perturbations of
a self-adjoint elliptic operator. Rather than relying on reflectivity or
relaxation kinetics, FSI tracks shifts of a truncated set of eigenmodes under
controlled excitation, providing a non-ionizing and operator-theoretic route to
contrast. Tissue heterogeneity is modeled as a small perturbation of L = -div(D
grad) + gamma, with first-order Hadamard formulas linking local contrasts to
eigenvalue shifts. Frechet derivatives and their adjoints yield gradients for
variational inversion, stabilized by Tikhonov or total-variation regularization
and modal truncation. Finite-element simulations show submillimetric
localization (about 0.1-0.3 mm) and milligram-scale detectability (thresholds
near 1 mg) under ideal noise. Retaining 10-15 modes preserves about 85 percent
of anomaly contrast while suppressing noise. A spectral-entropy index separates
compact from diffuse inclusions and acts as a morphology surrogate. FSI thus
provides a mathematically controlled, non-ionizing framework for localized
functional imaging, motivating validation in physical phantoms and in vivo
studies.

</details>


### [481] [Real-time MRI-based fetal femur length measurement](https://arxiv.org/abs/2510.16920)
*Johannes Barcsay,Sara Neves Silva,Jordina Aviles Verdera,Charline Bradshaw,Mary Rutherford,Susanne Schulz-Heise,Jana Hutter*

Main category: physics.med-ph

TL;DR: 开发了一种实时自动规划与测量胎儿股骨长度的MRI方法，通过3D U-Net定位股骨端点并自适应调整扫描序列，在72例回顾性数据和24例实时测试中验证了方法的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决MRI中胎儿股骨长度测量面临的挑战，包括骨-切片不对齐、胎儿运动和手动评估需求，提供自动、精确且运动鲁棒的产前生长评估方法。

Method: 使用低延迟3D U-Net在59次扫描中训练定位股骨近端和远端端点，基于这些坐标实时自适应调整30秒EPI序列以实现股骨平面覆盖。

Result: 回顾性分析显示平均端点定位误差5.5mm，股骨长度偏差3.0mm；实时测试中22/24例成功，平均偏差4.2mm；双侧股骨长度一致性良好（左-右差异2.8±2.7mm）。

Conclusion: 开发了实时自动的MRI股骨长度测量方法，能够实现精确、运动鲁棒且操作者独立的生长评估，支持未来在生长受限妊娠中的大规模评估。

Abstract: Purpose: To develop and evaluate a real-time method for automatic planning
and measurement of fetal femur length - an important indicator of antenatal
growth - during MRI. While routinely assessed by ultrasound, MRI-based femur
length measurements remain challenging due to bone-slice misalignment, fetal
motion, and the need for manual assessment. Methods: A low-latency 3D U-Net was
trained on 59 scans acquired at 0.55T (gestational age 18-40 weeks) to localise
the proximal and distal endpoints of the femur. These coordinates were employed
to automatically adapt a 30-second EPI sequence for in-plane femur coverage in
real-time. Retrospective evaluation was performed in 72 scans (19-39 weeks,
including 19 pathological cases), and real-time testing in 24 cases (17-39
weeks). Automated results were compared with manual expert annotations and, in
57/72 cases, with matched clinical ultrasound measurements. Precision was
evaluated against inter-observer variability and analysed across gestational
age and maternal BMI. Furthermore, bilateral femur length consistency was
evaluated. Results: Retrospective analysis demonstrated a mean endpoint
localisation error of 5.5 mm and femur length deviation of 3.0 mm. Among the
49/72 cases with both femora automatically extracted, the left-right difference
was 2.8+-2.7 mm. Precision was unaffected by maternal BMI (p>0.05), but
correlated with gestational age (p<0.05). Real-time planning and assessment
were successful in 22/24 cases, with a mean deviation of 4.2 mm. Conclusions: A
real-time, automated method for MRI-based femur length measurement was
developed, enabling precise, motion-robust, and operator-independent growth
assessment, supporting future large-scale evaluation in growth-compromised
pregnancies.

</details>


### [482] [Optimized Single-Core PCF-Based SPR Biosensor for High-Performance Early-Stage Multi-Cancer Detection](https://arxiv.org/abs/2510.17283)
*Tonmoy Malakar,Miss Nourin Nurain Amina,Zarin Tasnim Nijhum,Nazmus Shakib Lalin*

Main category: physics.med-ph

TL;DR: 提出了一种基于表面等离子体共振(SPR)和圆形晶格光子晶体光纤(PCF)的高灵敏度生物传感器，用于早期癌症检测。该传感器在1.360-1.395折射率范围内表现出高灵敏度，对皮肤癌、血癌和肾上腺癌分别达到21,250、53,571和103,571 nm/RIU的波长灵敏度。


<details>
  <summary>Details</summary>
Motivation: 克服传统SPR系统的体积庞大和灵敏度有限的问题，开发用于早期癌症检测的高性能生物传感器。

Method: 将薄金层沉积在光纤结构上用于等离子体激发，引入五氧化二钒纳米层增强金与二氧化硅基底之间的粘附性。使用COMSOL Multiphysics 6.1中的有限元法进行光学特性和性能分析。

Result: 传感器在目标折射率范围内表现出卓越性能：皮肤癌灵敏度21,250 nm/RIU，血癌53,571 nm/RIU，肾上腺癌103,571 nm/RIU，最大品质因数306.424 RIU^-1，光谱分辨率9.57×10^-7 RIU。

Conclusion: 该SPR-PCF传感器在实时、无标记生物传感应用中具有强大潜力，特别是在精确和早期癌症诊断方面。

Abstract: In this study, we present a highly sensitive Surface Plasmon Resonance
(SPR)-based biosensor integrated with a circular-lattice Photonic Crystal Fiber
(PCF) for early-stage cancer detection. The proposed sensor leverages the
synergy between SPR and PCF technologies to overcome the bulkiness and limited
sensitivity of traditional SPR systems. A thin gold (Au) layer, responsible for
plasmon excitation, is deposited on the fiber structure, while a nanolayer of
vanadium pentoxide (V2O5) is introduced to enhance adhesion between the gold
and the silica background, improving structural stability and field
confinement. The sensor is designed to detect refractive index (RI) variations
in biological analytes, specifically targeting cancerous cells from skin,
blood, and adrenal gland tissues. The optical characteristics and performance
of the sensor were thoroughly analyzed using the Finite Element Method (FEM) in
COMSOL Multiphysics 6.1, allowing for precise simulation and optimization. The
sensor demonstrates high sensitivity within the RI range of 1.360-1.395,
corresponding to the RI values of the target cancer cells. Remarkable
wavelength sensitivities of 21,250 nm/RIU, 53,571 nm/RIU, and 103,571 nm/RIU
were achieved for skin, blood, and adrenal gland cancers, respectively. In
addition, a maximum figure of merit (FOM) of 306.424 RIU^-1 and a spectral
resolution (SR) of 9.57x10^-7 RIU further affirm the sensor's exceptional
detection capabilities. These findings indicate the proposed SPR-PCF sensor's
strong potential for real-time, label-free biosensing applications,
particularly in precise and early cancer diagnostics.

</details>


### [483] [Inverse Optimal Control of Muscle Force Sharing During Pathological Gait](https://arxiv.org/abs/2510.17456)
*Filip Bečanović,Vincent Bonnet,Kosta Jovanović,Samer Mohammed,Raphaël Dumas*

Main category: physics.med-ph

TL;DR: 该研究应用逆向最优控制方法识别中风后患者步态的最佳目标函数，发现最佳目标函数具有个体和腿部特异性，其中肌肉功率最小化对患侧肢体更重要，而肌肉激活最小化对健侧肢体更关键。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过逆向最优控制方法识别中风后患者步态的最佳目标函数，以更好地理解神经控制策略的个体差异和病理特征。

Method: 采用逆向最优控制方法，从15个常用目标函数中识别最佳目标函数组合，分析两名不同功能水平中风患者（高功能和低功能）的步态数据。

Result: 发现最佳目标函数具有个体和腿部特异性，患侧肢体更依赖肌肉功率最小化，健侧肢体更依赖肌肉激活最小化。个体特异性模型表现良好（RMSE 178-213N，CC 0.61-0.88），但跨个体泛化能力差。

Conclusion: 中风后患者患侧和健侧肢体可能采用不同的神经控制策略，肌肉功率最小化目标函数可能为患侧肢体的痉挛状态提供建模依据，对病理步态建模具有重要意义。

Abstract: Muscle force sharing is typically resolved by minimizing a specific objective
function to approximate neural control strategies. An inverse optimal control
approach was applied to identify the "best" objective function, among a
positive linear combination of basis objective functions, associated with the
gait of two post-stroke males, one high-functioning (subject S1) and one
low-functioning (subject S2). It was found that the "best" objective function
is subject- and leg-specific. No single function works universally well, yet
the best options are usually differently weighted combinations of muscle
activation- and power-minimization. Subject-specific inverse optimal control
models performed best on their respective limbs (\textbf{RMSE 178/213 N, CC
0.71/0.61} for non-paretic and paretic legs of S1; \textbf{RMSE 205/165 N, CC
0.88/0.85} for respective legs of S2), but cross-subject generalization was
poor, particularly for paretic legs. Moreover, minimizing the root mean square
of muscle power emerged as important for paretic limbs, while minimizing
activation-based functions dominated for non-paretic limbs. This may suggest
different neural control strategies between affected and unaffected sides,
possibly altered by the presence of spasticity. Among the 15 considered
objective functions commonly used in inverse dynamics-based computations, the
root mean square of muscle power was the only one explicitly incorporating
muscle velocity, leading to a possible model for spasticity in the paretic
limbs. Although this objective function has been rarely used, it may be
relevant for modeling pathological gait, such as post-stroke gait.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [484] [Is simplicity still possible for a more accurate approximation to the perimeter of the ellipse? or, Using the exponential function to further improve the second Ramanujan's approximation](https://arxiv.org/abs/2510.16191)
*Salvador E. Ayala-Raggi,Manuel Rendón-Marín*

Main category: math.NA

TL;DR: 提出了一种新的椭圆周长近似公式，通过改进Ramanujan第二公式，在b/a从1到1/10000范围内实现非常稳定的近似，最大相对误差仅约0.57 ppm。


<details>
  <summary>Details</summary>
Motivation: 椭圆周长没有精确的初等函数闭式表达式，现有近似方法在精度和计算复杂度之间存在权衡。需要开发既简单又高精度的近似公式。

Method: 改进Ramanujan第二公式，将其除以1减去两个指数项的二项式，使用仅4个常数，保持紧凑的闭式表达式。

Result: 在b/a∈[0.0001,1]范围内，最大相对误差约0.57 ppm，在圆形和退化椭圆极限情况下几乎精确。相比Cantrell近似，最大相对误差降低25倍。

Conclusion: 该方法提供了目前文献中最简单且最精确的椭圆周长单行闭式近似之一，在精度和简洁性之间实现了卓越的平衡。

Abstract: The perimeter of an ellipse has no exact closed-form expression in terms of
elementary functions, and numerous approximations have been proposed since the
eighteenth century. Classical formulas by Fagnano, Euler, and Ramanujan, as
well as modern refinements such as Cantrell and Koshy methods, aim to reduce
the approximation error while maintaining computational simplicity. In this
paper, we introduce a new closed-form expression that enhances Ramanujan second
formula by dividing it by 1 minus a binomial of two exponential terms resulting
in a very stable approximation in a range of b/a between 1 and 1/10000, or even
up to a smaller ratio. The resulting approximation remains compact, requiring
only four constants, and achieving a remarkable tradeoff between simplicity and
accuracy. Across the full eccentricity range of b/a in [0.0001,1], our method
attains a maximum relative error of approximately 0.57 ppm with respect to the
exact perimeter computed via elliptic integral. Our formula is quasi-exact at
the extremes, for the circle b/a=1 and for the degenerate flat ellipse b/a=0.
Compared with Cantrell approximation, the proposed method reduces the maximum
relative error by a factor of 25 while preserving a short and elegant
expression. This makes it one of the simplest yet most accurate closed-form and
single-line approximations to the ellipse perimeter currently available in the
literature.

</details>


### [485] [Applications of AAA rational approximation](https://arxiv.org/abs/2510.16237)
*Yuji Nakatsukasa,Lloyd N. Trefethen*

Main category: math.NA

TL;DR: 使用AAA算法进行有理逼近，展示有理函数在数值分析中的广泛应用


<details>
  <summary>Details</summary>
Motivation: 展示有理函数在数值分析各个领域的重要应用价值

Method: 采用AAA算法进行有理逼近

Result: 成功展示了有理函数在数值分析中的多种应用场景

Conclusion: 有理函数在数值分析中具有广泛的应用前景，AAA算法是有效的实现工具

Abstract: The AAA algorithm for rational approximation is employed to illustrate
applications of rational functions all across numerical analysis.

</details>


### [486] [Iterative solvers for partial differential equations with dissipative structure: Operator preconditioning and optimal control](https://arxiv.org/abs/2510.16399)
*Volker Mehrmann,Manuel Schaller,Martin Stoll*

Main category: math.NA

TL;DR: 该论文分析了哈密顿偏微分方程离散化产生的非对称矩阵问题的迭代求解方法，重点研究使用对称部分作为预条件器的Krylov子空间方法，证明了在椭圆和抛物线PDE中该方法能获得与网格尺寸无关的条件数。


<details>
  <summary>Details</summary>
Motivation: 解决哈密顿偏微分方程离散化产生的大规模非对称矩阵系统的迭代求解问题，利用系统结构特性提高求解效率。

Method: 使用对称部分H作为预条件器的Krylov子空间方法（如GMRES、Widlund方法、Rapoport方法），分析条件数特性，并在最优控制问题中应用定制Krylov方法。

Result: 证明了在椭圆和抛物线PDE中，使用对称部分预条件器可获得与网格尺寸无关的条件数，并通过大规模数值算例验证了方法的有效性。

Conclusion: 基于对称部分的预条件Krylov方法能有效求解哈密顿PDE离散化问题，在扩散、流体动力学和弹性力学等应用中表现出良好的数值性能。

Abstract: This work considers the iterative solution of large-scale problems subject to
non-symmetric matrices or operators arising in discretizations of
(port-)Hamiltonian partial differential equations. We consider problems
governed by an operator $\mathcal{A}=\mathcal{H}+\mathcal{S}$ with symmetric
part $\mathcal{H}$ that is positive (semi-)definite and skew-symmetric part
$\mathcal{S}$. Prior work has shown that the structure and sparsity of the
associated linear system enables Krylov subspace solvers such as the
generalized minimal residual method (GMRES) or short recurrence variants such
as Widlund's or Rapoport's method using the symmetric part $\mathcal{H}$, or an
approximation of it, as preconditioner. In this work, we analyze the resulting
condition numbers, which are crucial for fast convergence of these methods, for
various partial differential equations (PDEs) arising in diffusion phenomena,
fluid dynamics, and elasticity. We show that preconditioning with the symmetric
part leads to a condition number uniform in the mesh size in case of elliptic
and parabolic PDEs where $\mathcal{H}^{-1}\mathcal{S}$ is a bounded operator.
Further, we employ the tailored Krylov subspace methods in optimal control by
means of a condensing approach and a constraint preconditioner for the
optimality system. We illustrate the results by various large-scale numerical
examples and discuss efficient evaluations of the preconditioner, such as
incomplete Cholesky factorization or the algebraic multigrid method.

</details>


### [487] [Applications of optimal error bounds for some generalized two-step iterative processes in Banach spaces](https://arxiv.org/abs/2510.16403)
*Tan-Phuc Nguyen,Thai-Hung Nguyen,Tien-Khai Nguyen,Cong-Duy-Nguyen Nguyen,Trung-Hieu Huynh*

Main category: math.NA

TL;DR: 本文继续研究更一般迭代过程的最优误差界，以获得收敛结果并确定收敛速率


<details>
  <summary>Details</summary>
Motivation: 在先前研究基础上，继续确定更一般迭代过程的最优误差界，这些过程已被多位作者研究过

Method: 通过最优误差界方法分析更一般的迭代过程，在参数序列满足某些充分条件下确定收敛速率

Result: 获得了这些迭代过程的收敛结果，并确定了它们的收敛速率

Conclusion: 最优误差界方法可有效分析更一般迭代过程的收敛性，并比较不同迭代过程的性能

Abstract: In a recent paper~\cite{paper2}, we proposed the concept of optimal error
bounds for an iterative process, which allows us to obtain the convergence
result of the iterative sequence to the common fixed point of the nonexpansive
mappings in Banach spaces. Moreover, we also achieve the comparison results
between different iterative processes via optimal error bounds. In this paper,
we continue to determine optimal error bounds for more general iterative
processes which were studied by many authors, such as in~\cite{DungHieu} and
references therein. From there, the convergence results are obtained and the
convergence rates of these iterative processes are determined under some
sufficient conditions on sequences of parameters.

</details>


### [488] [Parameter-related strong convergence rate and polynomial stability of a Euler's type method for time-changed stochastic differential equations](https://arxiv.org/abs/2510.16405)
*Ruchun Zuo*

Main category: math.NA

TL;DR: 提出了一种等步长的欧拉型方法用于求解时间变化的随机微分方程，获得了与时间变化过程参数相关的强收敛速率，并研究了数值方法的均方多项式稳定性。


<details>
  <summary>Details</summary>
Motivation: 针对时间变化的随机微分方程，现有方法多采用随机步长，本文旨在开发等步长方法并分析其收敛性和稳定性特性。

Method: 使用等步长的欧拉型方法求解乘性噪声驱动的时间变化随机微分方程。

Result: 获得了与时间变化过程参数相关的强收敛速率，且数值方法在均方意义下具有多项式稳定性，与基础方程的渐近行为一致。

Conclusion: 等步长欧拉方法在时间变化随机微分方程中表现出良好的收敛性和稳定性特性，收敛速率与时间变化过程参数相关。

Abstract: A Euler's type method with the equidistant step size is proposed for a class
of time-changed stochastic differential equations driven by the multiplicative
noise and the strong convergence rate that is related to the parameter of the
time changing process is obtained. Such a observation of the convergence rate
is significantly different from those existing results that employ methods with
the random step size. The polynomial stability in the mean square sense of the
numerical method is also studied, which is in line with the asymptotic behavior
of the underlying equation.

</details>


### [489] [Determining the space dependent coefficients in space-time fractional diffusion equations via Krylov preconditioning](https://arxiv.org/abs/2510.16425)
*Asim Ilyas,Muhammad Faisal Khan,Rosita L. Sormani,Giacomo Tento,Stefano Serra-Capizzano*

Main category: math.NA

TL;DR: 本文研究了带变系数的时空分数阶扩散方程，通过拟边界值方法正则化来缓解不适定性，重构源项。使用有限差分法得到大型线性系统，通过GLT理论进行谱分析并构造预条件子。


<details>
  <summary>Details</summary>
Motivation: 研究时空分数阶扩散方程的源项重构问题，该问题具有不适定性，需要通过正则化方法来处理。

Method: 采用拟边界值方法进行正则化，使用有限差分法离散方程得到大型线性系统，应用广义局部Toeplitz(GLT)理论进行谱分析并指导预条件子的构造。

Result: 通过GLT理论成功分析了相关矩阵序列的谱特性，并基于此构造了有效的预条件子，数值实验验证了方法的有效性。

Conclusion: GLT理论为时空分数阶扩散方程逆问题的数值求解提供了有效的谱分析和预条件子构造工具，数值结果证实了该方法的可行性。

Abstract: We consider a time-space fractional diffusion equation with a variable
coefficient and investigate the inverse problem of reconstructing the source
term, after regularizing the problem with the quasiboundary value method to
mitigate the ill-posedness. The equation involves a Caputo fractional
derivative in the space variable and a tempered fractional derivative in the
time variable, both of order in (0, 1). A finite difference approximation leads
to a two-by-two block linear system of large dimensions. We conduct a spectral
analysis of the associated matrix sequences, employing tools from Generalized
Locally Toeplitz (GLT) theory, and construct the preconditioner guided by the
GLT analysis. Numerical experiments are reported and commented, followed by
concluding remarks.

</details>


### [490] [Dynamic-stabilization-based linear schemes for the Allen-Cahn equation with degenerate mobility: MBP and energy stability](https://arxiv.org/abs/2510.16447)
*Hongfei Fu,Dianming Hou,Zhonghua Qiao,Bingyin Zhang*

Main category: math.NA

TL;DR: 提出了用于Allen-Cahn方程的一阶和二阶线性数值格式，采用动态稳定化方法，无条件保持最大有界原理和能量稳定性，具有移动性鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有数值方法在处理一般（可能退化）移动性的Allen-Cahn方程时存在局限性，需要开发能保证最大有界原理和能量稳定性的鲁棒数值格式。

Method: 采用动态稳定化方法，对于二阶格式引入带截断预处理的新预测策略，每个时间层只需解一个线性系统。

Result: 建立了严格的极大范数误差估计，数值实验验证了理论结果和所提格式的性能。

Conclusion: 所提出的线性数值格式能无条件保持最大有界原理和能量稳定性，具有移动性鲁棒性，且计算效率高。

Abstract: In this paper, we investigate linear first- and second-order numerical
schemes for the Allen--Cahn equation with a general (possibly degenerate)
mobility. Compared with existing numerical methods, our schemes employ a novel
dynamic stabilization approach that guarantees unconditional preservation of
the maximum bound principle (MBP) and energy stability. A key advance is that
the discrete energy stability remains valid even in the presence of degenerate
mobility-a property we refer to as mobility robustness. Rigorous maximum-norm
error estimates are also established. In particular, for the second-order
scheme, we introduce a new prediction strategy with a cut-off preprocessing
procedure on the extrapolation solution, and only one linear system needs to be
solved per time level. Representative numerical examples are provided to
validate the theoretical findings and performance of the proposed schemes.

</details>


### [491] [Improving performance estimation of a PCM-integrated solar chimney through reduced-order based data assimilation](https://arxiv.org/abs/2510.16469)
*Diego R. Rivera,Ernesto Castillo,Felipe Galarce,Douglas R. Q. Pacheco*

Main category: math.NA

TL;DR: 本研究开发了一种基于降阶建模的数据同化框架（ROM-DA），结合混合数据填充策略，从有限的温度测量中重建相变材料集成太阳能烟囱中的动态温度场，以提高出口气流速度的估计精度。


<details>
  <summary>Details</summary>
Motivation: 提高相变材料集成太阳能烟囱中出口气流速度的估计精度，通过从有限的温度测量重建动态温度场来实现。

Method: 采用正则化最小二乘公式估计温度分布，结合（i）基于高保真有限体积模拟的降阶模型和（ii）三种实验数据集（22、135和203个测量点），使用边界层和双三次插值的混合填充方案重建缺失数据。

Result: ROM-DA框架在稀疏数据下重建瞬态温度场的相对误差低于10%，在扩展数据集下低于3%。应用于实验测量时，与基线模型相比，出口速度RMS误差降低了20%。

Conclusion: 这是ROM-DA框架首次应用于耦合多物理场相变材料集成太阳能烟囱，展示了其在近实时热状态估计和数字孪生开发方面的潜力。

Abstract: This study evaluates a data assimilation framework based on reduced-order
modeling (ROM-DA), complemented by a hybrid data-filling strategy, to
reconstruct dynamic temperature fields in a phase-change-material (PCM)
integrated solar chimney from limited temperature measurements. The goal is to
enhance the estimation accuracy of the outlet airflow velocity. A regularized
least-squares formulation is employed to estimate temperature distributions
within an inclined solar chimney using RT-42 as the PCM. The methodology
combines (i) a reduced-order model derived from high-fidelity finite-volume
simulations of unsteady conjugate heat transfer with liquid-solid phase change
and surface radiation, and (ii) three experimental datasets with 22, 135, and
203 measurement points. Missing data are reconstructed using a hybrid filling
scheme based on boundary-layer and bicubic interpolations. The assimilated
temperature fields are integrated into the thermally coupled forward solver to
improve velocity predictions. Results show that the ROM-DA framework
reconstructs the transient temperature fields in both the air and PCM domains
with relative errors below 10 percent for sparse data and below 3 percent for
expanded datasets. When applied to experimental measurements, the approach
enhances the fidelity of temperature and velocity fields compared with the
baseline model, reducing the outlet velocity RMS error by 20 percent. This
represents the first application of a ROM-DA framework to a coupled
multiphysics solar chimney with PCM integration, demonstrating its potential
for near-real-time thermal state estimation and digital-twin development.

</details>


### [492] [Computing functions of $A^{-1}B$ where $A$ and $B$ are Hermitian matrices](https://arxiv.org/abs/2510.16473)
*Dario A. Bini,Massimiliano Fasi,Bruno Iannazzo*

Main category: math.NA

TL;DR: 本文研究了矩阵函数Af(A^{-1}B)的数值计算问题，其中A是Hermitian正定矩阵，B是Hermitian矩阵，f是定义在A^{-1}B谱上的函数。提出了结合Schur分解与矩阵平方根或Cholesky分解的算法，并通过数值实验验证了基于Cholesky分解的算法在精度和效率上的优势。


<details>
  <summary>Details</summary>
Motivation: 研究矩阵函数Af(A^{-1}B)的数值计算方法，解决该问题的条件性分析，并开发更准确高效的数值算法。

Method: 结合Schur分解与矩阵平方根或Cholesky分解，开发了多种算法，分析了这些算法在浮点运算中的数值行为，评估了计算成本，并比较了数值性能。

Result: 分析表明基于Cholesky分解的算法比基于矩阵平方根的算法更准确和高效，数值实验证实了这一结论。

Conclusion: 基于Cholesky分解的算法在计算矩阵函数Af(A^{-1}B)时具有更好的数值性能和计算效率，是更优的选择。

Abstract: We consider the numerical evaluation of the quantity $Af(A^{-1}B)$, where $A$
is Hermitian positive definite, $B$ is Hermitian, and $f$ is a function defined
on the spectrum of $A^{-1}B$. We study the conditioning of the problem, and we
introduce several algorithms that combine the Schur decomposition with either
the matrix square root or the Cholesky factorization. We study the numerical
behavior of these algorithms in floating-point arithmetic, assess their
computational costs, and compare their numerical performance. Our analysis
suggests that the algorithms based on the Cholesky factorization will be more
accurate and efficient than those based on the matrix square root. This is
confirmed by our numerical experiments.

</details>


### [493] [High-order temporal parametric finite element methods for simulating solid-state dewetting](https://arxiv.org/abs/2510.16493)
*Xiaowen Gan,Yuqian Teng,Sisheng Wang*

Main category: math.NA

TL;DR: 本文提出了一类时间高阶参数有限元方法，用于模拟二维薄膜的固态去湿过程，采用尖锐界面模型，结合预测-校正策略和后向差分公式实现时间离散化。


<details>
  <summary>Details</summary>
Motivation: 固态去湿是薄膜材料科学中的重要现象，现有数值方法在时间精度和长期模拟稳定性方面存在不足，需要开发高精度且稳定的数值方法。

Method: 将预测-校正策略和后向差分公式与Zhao等人(2021)提出的能量稳定参数有限元方法相结合，构建时间高阶半隐式方案，每个时间步求解线性系统。

Result: 建立了完全离散系统的适定性，方法保持了长期网格等分布特性，数值实验验证了方法在流形距离度量下达到预期时间精度，并保持良好的网格质量。

Conclusion: 成功构建了时间高阶参数有限元方法，能够准确模拟固态去湿过程，同时保持数值稳定性和网格质量，为相关材料科学问题提供了有效的数值工具。

Abstract: We propose a class of temporally high-order parametric finite element methods
for simulating solid-state dewetting of thin films in two dimensions using a
sharp-interface model. The process is governed by surface diffusion and contact
point migration, along with appropriate boundary conditions. By incorporating
the predictor-corrector strategy and the backward differentiation formula for
time discretization into the energy-stable parametric finite element method
developed by Zhao et al. (2021), we successfully construct temporally
high-order schemes. The resulting numerical scheme is semi-implicit, requiring
the solution of a linear system at each time step. The well-posedness of the
fully discretized system is established. Moreover, the method maintains the
long-term mesh equidistribution property. Extensive numerical experiments
demonstrate that our methods achieve the desired temporal accuracy, measured by
the manifold distance, while maintaining good mesh quality throughout the
evolution.

</details>


### [494] [A linear unconditionally structure-preserving L1 scheme for the time-fractional Allen-Cahn equation](https://arxiv.org/abs/2510.16496)
*Dianming Hou,Zhonghua Qiao,Tao Tang*

Main category: math.NA

TL;DR: 本文开发了时间分数阶Allen-Cahn方程的线性结构保持时间步进格式，包括一阶和min{1+α,2-α}阶L1离散化，并基于指数和(SOE)技术实现快速计算。这些格式无条件保持离散最大界原理和变分能量耗散律。


<details>
  <summary>Details</summary>
Motivation: 时间分数阶Allen-Cahn方程具有最大界原理和变分能量耗散律，需要开发能够保持这些重要性质的数值格式。

Method: 提出了线性的、结构保持的时间步进格式，包括一阶和min{1+α,2-α}阶L1离散化，使用指数和(SOE)技术进行快速实现，适用于包括分级网格在内的各种时间网格。

Result: 数值格式无条件保持离散最大界原理和变分能量耗散律，利用时间分数阶Grönwall不等式建立了尖锐的误差估计，数值实验验证了理论结果和自适应时间步进策略的有效性。

Conclusion: 所提出的线性时间步进格式能够有效保持时间分数阶Allen-Cahn方程的结构性质，具有理论保证和实际计算效率。

Abstract: As a variational phase-field model, the time-fractional Allen-Cahn (TFAC)
equation enjoys the maximum bound principle (MBP) and a variational energy
dissipation law. In this work, we develop and analyze linear,
structure-preserving time-stepping schemes for TFAC, including first-order and
$\min\{1+\alpha, 2-\alpha\}$-order L1 discretizations, together with fast
implementations based on the sum-of-exponentials (SOE) technique. A central
feature of the proposed linear schemes is their unconditional preservation of
both the discrete MBP and the variational energy dissipation law on general
temporal meshes, including graded meshes commonly used for these problems.
Leveraging the MBP of the numerical solutions, we establish sharp error
estimates by employing the time-fractional Gro\"nwall inequality. Finally,
numerical experiments validate the theoretical results and demonstrate the
effectiveness of the proposed schemes with an adaptive time-stepping strategy.

</details>


### [495] [Accelerated implicitization: Robust fixed-point iterations arising from an explicit scheme](https://arxiv.org/abs/2510.16535)
*Nicolas A. Barnafi,Felipe Galarce,Pablo Brubeck*

Main category: math.NA

TL;DR: 提出一种通过显式解序列求解隐式时间离散化非线性问题的通用策略，结合Anderson加速提高收敛性和计算效率，在非线性微分方程中验证了可用性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决隐式时间离散化中非线性问题，特别是在矩阵组装昂贵或缺乏良好预条件子的情况下（如高对流流体流动），提供简单易实现的解决方案。

Method: 使用显式定点子迭代处理非线性问题，结合Anderson加速来改善收敛性和计算效率，对时间和时空公式进行误差分析。

Result: 该方法实现简单，在多种问题上表现良好，特别是在矩阵组装昂贵或缺乏良好预条件子的情况下，结果令人鼓舞且得到现有理论支持。

Conclusion: 该工作形式化了隐式项在时间离散化中的延迟，提供了简洁的误差分析，并通过Anderson加速增强了方法，为后续研究奠定了基础。

Abstract: This work proposes a general strategy for solving possibly nonlinear problems
arising from implicit time discretizations as a sequence of explicit solutions.
The resulting sequence may exhibit instabilities similar to those of the base
explicit scheme, which can be mitigated through Anderson acceleration. The
approach uses explicit fixed-point subiterations for nonlinear problems,
combined with Anderson acceleration to improve convergence and computational
efficiency. Its usability and scalability are verified on three nonlinear
differential equations. An error analysis is presented to establish the
expected properties of the proposed strategy for both time and space-time
formulations. Several examples illustrate the simplicity of the implementation
and reveal the influence of parameter choices. The method proves simple to
implement and performs well across a range of problems, particularly when
matrix assembly is expensive or a good preconditioner for the implicit system
is unavailable, such as in highly convective fluid flows. This work formalizes
the delay of implicit terms in time discretization, provides a concise error
analysis, and enhances the approach using Anderson acceleration. The results
are encouraging and well supported by existing theory, laying the groundwork
for further research.

</details>


### [496] [Strong error analysis and first-order convergence of Milstein-type schemes for McKean-Vlasov SDEs with superlinear coefficients](https://arxiv.org/abs/2510.16801)
*Jingtao Zhu,Yuying Zhao,Siqing Gan*

Main category: math.NA

TL;DR: 本文针对具有超线性增长漂移和扩散项的McKean-Vlasov随机微分方程，开发了一类统一的Milstein型离散化方法，包括tamed-、tanh-和sine-Milstein方法，在温和正则性假设下建立了关联粒子系统的一阶强收敛性。


<details>
  <summary>Details</summary>
Motivation: 许多应用中的MV-SDE具有超线性增长的漂移和扩散项，传统方法可能发散并导致粒子损坏。现有文献中Chen等人的工作仅进行了数值测试而缺乏理论保证，需要填补这一空白。

Method: 开发了一类统一的Milstein型离散化框架，包含tamed-、tanh-和sine-Milstein方法。分析基于离散时间论证和二项式展开，避免了文献中标准的连续时间Itô方法。

Result: 在仅要求系数一次可微的温和正则性假设下，建立了关联粒子系统的一阶强收敛性。数值实验验证了收敛行为并支持理论发现。

Conclusion: 提出的Milstein型框架成功处理了超线性增长的漂移和扩散系数，为MV-SDE的数值逼近提供了严格的理论基础，补充了现有文献中缺乏理论保证的数值方法。

Abstract: In the study of McKean-Vlasov stochastic differential equations (MV-SDEs),
numerical approximation plays a crucial role in understanding the behavior of
interacting particle systems (IPS). Classical Milstein schemes provide strong
convergence of order one under globally Lipschitz coefficients. Nevertheless,
many MV-SDEs arising from applications possess super-linearly growing drift and
diffusion terms, where classical methods may diverge and particle corruption
can occur. In the present work, we aim to fill this gap by developing a unified
class of Milstein-type discretizations handling both super-linear drift and
diffusion coefficients. The proposed framework includes the tamed-, tanh-, and
sine-Milstein methods as special cases and establishes order-one strong
convergence for the associated interacting particle system under mild
regularity assumptions, requiring only once differentiable coefficients. In
particular, our results complement Chen et al. (Electron. J. Probab., 2025),
where a taming-based Euler scheme was only tested numerically without
theoretical guarantees, by providing a rigorous convergence theory within a
broader Milstein-type framework. The analysis relies on discrete-time arguments
and binomial-type expansions, avoiding the continuous-time It\^o approach that
is standard in the literature. Numerical experiments are presented to
illustrate the convergence behavior and support the theoretical findings.

</details>


### [497] [Sparse variational regularization with oversmoothing penalty term in the scale of sequence spaces](https://arxiv.org/abs/2510.16821)
*Robert Plato,Bernd Hofmann*

Main category: math.NA

TL;DR: 该论文研究线性不适定问题，在序列空间ℓ_r到Banach空间的算子映射下，考虑带有确定性噪声的正则化问题。采用变分正则化方法，使用ℓ_p范数惩罚或计数测度惩罚来保证解的稀疏性，并分析了过平滑情况下的稳定性和收敛率。


<details>
  <summary>Details</summary>
Motivation: 研究线性不适定问题的正则化方法，特别是在算子从序列空间ℓ_r映射到Banach空间的情况下，处理确定性噪声并保证解的稀疏性。特别关注过平滑情况，即期望解不在惩罚泛函定义域内的问题。

Method: 采用变分正则化方法，使用两种惩罚泛函：ℓ_p范数惩罚和计数测度惩罚。利用硬阈值技术定义辅助元素来分析过平滑情况，该技术也可用于后处理以保证稀疏性。

Result: 提出了适用于先验参数选择的稳定性和收敛率结果，覆盖了过平滑情况，其中期望解不属于惩罚泛函的定义域。

Conclusion: 该框架为线性不适定问题提供了有效的正则化方法，特别是在需要稀疏解和面对过平滑情况时，硬阈值技术是分析的关键工具。

Abstract: In this work, we consider a class of linear ill-posed problems with operators
that map from the sequence space $ \ell_r $ ($r \ge 1$) into a Banach space and
in addition satisfy a conditional stability estimate in the scale of sequence
spaces $ \ell_q, \, q \ge 0 $. For the regularization of such problems in the
presence of deterministic noise, we consider variational regularization with a
penalty functional either of the form $ \mathcal{R} =\Vert \cdot \Vert_p^p $
for some $ p > 0 $ or in form of the counting measure $\mathcal{R}_0 = \Vert
\cdot \Vert_0 $. The latter case guarantees sparsity of the corresponding
regularized solutions. In this framework, we present first stability and then
convergence rates for suitable a priori parameter choices. The results cover
the oversmoothing situation, where the desired solution does not belong to the
domain of definition of the considered penalty functional. The analysis of the
oversmoothing case utilizes auxiliary elements that are defined by means of
hard thresholding. Such technique can also be used for post processing to
guarantee sparsity.

</details>


### [498] [Unconditionally Stable, Variable Step DLN Methods for the Allen-Cahn Active Fluid Model: A Divergence-free Preserving Approach](https://arxiv.org/abs/2510.16860)
*Nan Zheng,Wenlong Pei,Qingguang Guan,Wenju Zhao*

Main category: math.NA

TL;DR: 本文提出了一种无散混合有限元方法，用于求解非线性四阶Allen-Cahn相场耦合活性流体方程。通过引入辅助变量将四阶问题转化为二阶系统，结合DLN时间积分器和自适应时间步长策略，实现了高效准确的数值模拟。


<details>
  <summary>Details</summary>
Motivation: 解决四阶Allen-Cahn相场耦合活性流体方程的高阶正则性约束问题，开发能够保持无散条件的数值方法，提高计算效率。

Method: 引入辅助变量w=Δu将四阶问题转化为二阶系统，进一步引入类似压力的辅助变量ξ，建立无散混合有限元格式，结合DLN时间积分器和自适应时间步长策略。

Result: 在适当正则性假设下严格推导了格式的有界性，数值实验验证了理论结果，证明了该方法在模拟复杂活性流体动力学中的有效性和准确性。

Conclusion: 所提出的无散混合有限元方法成功解决了四阶相场耦合活性流体方程的数值求解问题，具有良好的理论性质和计算性能。

Abstract: This paper addresses the divergence-free mixed finite element method (FEM)
for nonlinear fourth-order Allen-Cahn phase field coupled active fluid
equations. By introducing an auxiliary variable $w = \Delta u$, the original
fourth-order problem is converted into a system of second-order equations,
thereby easing the regularity constraints imposed on standard $H^2$-comforming
finite element spaces. To further refine the formulation, an additional
auxiliary variable $\xi$, analogous to the pressure, is introduced, resulting
in a mixed finite element scheme that preserves the divergence-free condition
in $which = \Delta u$ inherited from the model. A fully discrete scheme is then
established by combining the spatial approximation by the divergence-free mixed
finite element method with the variable-step Dahlquist-Liniger-Nevanlinna (DLN)
time integrator. The boundedness of the scheme is rigorously derived under
suitable regularity assumptions. Additionally, an adaptive time-stepping
strategy based on the minimum dissipation criterion is carried out to enhance
computational efficiency. Several numerical experiments validate the
theoretical findings and demonstrate the method's effectiveness and accuracy in
simulating complex active fluid dynamics.

</details>


### [499] [HOQRI: Higher-order QR Iteration for Low Multilinear Rank Approximation of Large and Sparse Tensors](https://arxiv.org/abs/2510.16930)
*Yuchen Sun,Amit Bhat,Chunmei Wang,Kejun Huang*

Main category: math.NA

TL;DR: 提出了高阶QR迭代算法用于计算大规模稀疏张量的低多线性秩逼近，相比传统HOOI方法更简单高效，能避免内存爆炸问题并保证收敛到稳定点。


<details>
  <summary>Details</summary>
Motivation: 传统HOOI方法在处理大规模稀疏张量时存在计算复杂和内存爆炸问题，需要更高效稳定的算法。

Method: 使用正交化步骤替代SVD分解，引入TTMcTC稀疏张量操作避免内存爆炸，并基于流形优化框架保证收敛。

Result: 在合成和真实数据上的数值实验验证了HOQRI算法的有效性。

Conclusion: HOQRI算法为大规模稀疏张量的低多线性秩逼近提供了一种简单高效且收敛性有保证的解决方案。

Abstract: We propose a new algorithm called higher-order QR iteration (HOQRI) for
computing low multilinear rank approximation (LMLRA), also known as the Tucker
decomposition, of large and sparse tensors. Compared to the celebrated
higher-order orthogonal iterations (HOOI), HOQRI relies on a simple
orthogonalization step in each iteration rather than a more sophisticated
singular value decomposition step as in HOOI. More importantly, when dealing
with extremely large and sparse data tensors, HOQRI completely eliminates the
intermediate memory explosion by defining a new sparse tensor operation called
TTMcTC (short for tensor times matrix chains times core). Furthermore,
recognizing that the orthonormal constraints form a Cartesian product of
Stiefel manifolds, we introduce the framework of manifold optimization and show
that HOQRI guarantees convergence to the set of stationary points. Numerical
experiments on synthetic and real data showcase the effectiveness of HOQRI.

</details>


### [500] [Numerical boundary control of multi-dimensional discrete-velocity kinetic models](https://arxiv.org/abs/2510.17246)
*Haitian Yang,Wen-An Yong*

Main category: math.NA

TL;DR: 本文在数值层面扩展了多维离散速度模型的研究，通过算子分裂方案和离散Lyapunov函数推导出确保数值解指数衰减的控制律，并针对刚性源项采用隐式格式处理碰撞部分，证明了方案的稳定性。


<details>
  <summary>Details</summary>
Motivation: 将多维离散速度模型的理论结果扩展到数值实现层面，解决数值求解过程中的稳定性问题，特别是处理刚性源项带来的挑战。

Method: 采用算子分裂方案，引入离散Lyapunov函数推导数值控制律，对碰撞部分使用隐式格式处理刚性源项，并证明所得数值方案的稳定性。

Result: 成功推导出确保数值解指数衰减的控制律，证明了数值方案的稳定性，并通过二维共面模型的三个数值模拟验证了理论结果。

Conclusion: 所提出的数值方法能够有效处理多维离散速度模型，确保数值解的稳定性和指数衰减特性，为相关模型的数值求解提供了可靠方案。

Abstract: This paper extends our recent results on multi-dimensional discrete-velocity
models to the numerical level. By adopting an operator splitting scheme and
introducing a suitable discrete Lyapunov function, we derive numerical control
laws that ensure the corresponding numerical solutions decay exponentially in
time. To handle the stiff source term, we also use an implicit scheme for the
collision part and prove the stability of the resulting schemes. The
theoretical results are validated through three numerical simulations for the
two-dimensional coplanar model.

</details>


### [501] [Counterexamples to the conjecture of the upper bound of the derivative of a rational Bézier curve](https://arxiv.org/abs/2510.17300)
*Mao Shi*

Main category: math.NA

TL;DR: 本文提出了有理贝塞尔曲线一阶导数上界的反例，并进一步研究了此类曲线所有阶导数的上确界。


<details>
  <summary>Details</summary>
Motivation: 研究有理贝塞尔曲线导数上界的准确性，发现现有上界存在反例，需要重新探讨所有阶导数的上确界。

Method: 通过构造反例来质疑现有有理贝塞尔曲线一阶导数上界，并系统分析所有阶导数的上确界。

Result: 成功构造了有理贝塞尔曲线一阶导数上界的反例，确定了所有阶导数的上确界。

Conclusion: 现有有理贝塞尔曲线导数上界不准确，需要修正，并给出了所有阶导数上确界的完整分析结果。

Abstract: In this paper, we present counterexamples to the upper bound of the
first-order derivative of rational B\'ezier curves and further investigate the
supremum of derivatives of all orders for such curves.

</details>


### [502] [Optimal error estimates of the diffuse domain method for semilinear parabolic equations](https://arxiv.org/abs/2510.17319)
*Yuejin Xu*

Main category: math.NA

TL;DR: 本文研究了扩散域方法(DDM)在求解具有Neumann边界条件的半线性抛物方程时的收敛行为，通过相场函数逼近不规则域，证明了当界面厚度趋近于零时数值解收敛到精确解，并给出了相应的最优误差估计。


<details>
  <summary>Details</summary>
Motivation: 研究扩散域方法在求解定义于一般不规则域中的半线性抛物方程时的收敛行为，旨在通过相场函数逼近不规则域，将问题转化为定义在更大矩形域上的问题，从而简化计算。

Method: 使用相场函数逼近不规则域，当界面厚度趋近于零时，相场函数收敛到原始域的指示函数。基于加权Sobolev空间，证明了数值解收敛到精确解，并推导了在加权L2和H1范数下的最优误差估计。

Result: 当界面厚度参数趋近于零时，数值解收敛到精确解。通过数值实验验证了理论结果的正确性。

Conclusion: 扩散域方法对于求解具有Neumann边界条件的半线性抛物方程是有效的，数值解在界面厚度趋近于零时收敛到精确解，且误差估计是最优的。

Abstract: In this paper, we mainly discuss the convergence behavior of diffuse domain
method (DDM) for solving semilinear parabolic equations with Neumann boundary
condition defined in general irregular domains. We use a phasefield function to
approximate the irregular domain and when the interface thickness tends to
zero, the phasefield function will converge to indicator function of the
original domain. With this function, we can modify the problem to another one
defined on a larger rectangular domain that contains the targer physical
domain. Based on the weighted Sobolev spaces, we prove that when the interface
thickness parameter goes to zero, the numerical solution will converge to the
exact solution. Also, we derive the corresponding optimal error estimates under
the weighted L2 and H1 norms. Some numerical experiments are also carried out
to validate the theoretical results.

</details>


### [503] [ParaSLRF: A High Performance Rational Filter Method for Solving Large Scale Eigenvalue Problems](https://arxiv.org/abs/2510.17334)
*Biyi Wang,Karl Meerbergen,Raf Vandebril,Hengbin An,Zeyao Mo*

Main category: math.NA

TL;DR: 本文提出了ParaSLRF方法，这是SLRF方法的并行实现，用于计算对称正定广义特征值问题在正实轴区间内的所有特征值。该方法采用两级并行化：高层将有理滤波器应用于不同向量，底层在每个处理器组内并行求解线性系统。


<details>
  <summary>Details</summary>
Motivation: 现有有理滤波器方法（如PFEAST）使用直接法求解线性系统，而ParaSLRF采用迭代法求解，并通过特定的极点选择实现更好的负载平衡和减少等待时间。

Method: ParaSLRF采用两级并行化：1）在最高层，将有理滤波器应用于不同向量的计算分配给处理器组；2）在每个组内，每个线性系统并行求解。使用迭代法求解线性系统，并采用极点锁定和改进的迭代线性求解器初始猜测来提升性能。

Result: 数值实验显示，与基于围道积分求积规则的其他有理滤波器方法相比，ParaSLRF具有最佳的并行效率。增强后的ParaSLRF在实验中表现出良好的两级强可扩展性和优秀的负载平衡。

Conclusion: ParaSLRF通过两级并行化和迭代线性系统求解方法，在计算对称正定广义特征值问题时实现了高效的并行性能和良好的负载平衡，相比其他有理滤波器方法具有优势。

Abstract: In \emph{Wang et al., A Shifted Laplace Rational Filter for Large-Scale
Eigenvalue Problems}, the SLRF method was proposed to compute all eigenvalues
of a symmetric definite generalized eigenvalue problem lying in an interval on
the real positive axis. The current paper discusses a parallel implementation
of this method, abbreviated as ParaSLRF. The parallelization consists of two
levels: (1) on the highest level, the application of the rational filter to the
various vectors is partitioned among groups of processors; (2) within each
group, every linear system is solved in parallel.
  In ParaSLRF, the linear systems are solved by iterative methods instead of
direct ones, in contrast to other rational filter methods, such as, PFEAST.
Because of the specific selection of poles in ParaSLRF, the computational cost
of solving the associated linear systems for each pole, is almost the same.
This intrinsically leads to a better load balance between each group of
resources, and reduces waiting times of processes.
  We show numerical experiments from finite element models of mechanical
vibrations, and show a detailed parallel performance analysis. ParaSLRF shows
the best parallel efficiency, compared to other rational filter methods based
on quadrature rules for contour integration. To further improve performance,
the converged eigenpairs are locked, and a good initial guess of iterative
linear solver is proposed. These enhancements of ParaSLRF show good two-level
strong scalability and excellent load balance in our experiments.

</details>


### [504] [A non-local model for heterogeneous material flow on conveyor belts](https://arxiv.org/abs/2510.17500)
*Paola Goatin,Simone Göttlich,Fabian Ziegler*

Main category: math.NA

TL;DR: 本文使用有限体积法求解二维非局部宏观材料流动模型，考虑了边界在非局部项中的影响。基于标量情况的先前结果，将设置扩展到有界域上的异质材料系统。证明了使用Roe格式和维度分裂构造的近似解的收敛性，主要挑战在于处理通量函数中的不连续性。数值测试显示与微观模拟有良好的一致性。


<details>
  <summary>Details</summary>
Motivation: 扩展非局部宏观材料流动模型到有界域上的异质材料系统，解决通量函数不连续性带来的挑战，并验证数值方法的有效性。

Method: 使用有限体积近似方案，采用Roe格式和维度分裂技术，处理非局部项中的边界影响和通量函数的不连续性。

Result: 证明了近似解的收敛性，数值测试表明与微观模拟结果吻合良好。

Conclusion: 所提出的有限体积方法能够有效处理二维非局部宏观材料流动模型中的边界影响和通量不连续性，为异质材料系统的模拟提供了可靠工具。

Abstract: In this paper, a finite volume approximation scheme is used to solve a
non-local macroscopic material flow model in two space dimensions, accounting
for the presence of boundaries in the non-local terms. Based on a previous
result for the scalar case, we extend the setting to a system of heterogeneous
material on bounded domains. We prove the convergence of the approximate
solutions constructed using the Roe scheme with dimensiona splitting, where the
major challenge lies in the treatment of the discontinuity occurring in the
flux function. Numerical tests show a good agreement with microscopic
simulations.

</details>


### [505] [A general framework for Krylov ODE residuals with applications to randomized Krylov methods](https://arxiv.org/abs/2510.17538)
*Emil Krieger,Marcel Schweitzer*

Main category: math.NA

TL;DR: 本文分析了随机Krylov子空间方法在常微分方程指数积分中的应用，提出了新的后验误差估计方法，并讨论了高效实现策略。


<details>
  <summary>Details</summary>
Motivation: 随机Krylov方法通过草图求解范式显著降低正交化成本，在涉及非对称矩阵的线性代数任务中表现出色。本文特别关注其在常微分方程指数积分中的应用，旨在开发可靠的误差估计方法。

Method: 使用常微分方程的残差推导新的后验误差估计，建立统一的Krylov ODE残差框架，扩展了随机Arnoldi方法到更广泛的Krylov方法（如有理Krylov方法、使用非标准内积的Krylov方法等）。

Result: 开发了通用的后验误差估计框架，能够有效监控收敛性并决定迭代停止时机。数值实验表明该误差估计质量良好，且草图Krylov方法在ODE求解中具有竞争力。

Conclusion: 随机Krylov方法为常微分方程指数积分提供了有效的计算工具，新提出的误差估计方法可靠且实用，框架具有很好的通用性和扩展性。

Abstract: Randomized Krylov subspace methods that employ the sketch-and-solve paradigm
to substantially reduce orthogonalization cost have recently shown great
promise in speeding up computations for many core linear algebra tasks (e.g.,
solving linear systems, eigenvalue problems and matrix equations, as well as
approximating the action of matrix functions on vectors) whenever a
nonsymmetric matrix is involved. An important application that requires
approximating the action of matrix functions on vectors is the implementation
of exponential integration schemes for ordinary differential equations. In this
paper, we specifically analyze randomized Krylov methods from this point of
view. In particular, we use the residual of the underlying differential
equation to derive a new, reliable a posteriori error estimate that can be used
to monitor convergence and decide when to stop the iteration. To do so, we
first develop a very general framework for Krylov ODE residuals that unifies
existing results, simplifies their derivation and allows extending the concept
to a wide variety of methods beyond randomized Arnoldi (e.g., rational Krylov
methods, Krylov methods using a non-standard inner product, ...). In addition,
we discuss certain aspects regarding the efficient implementation of sketched
Krylov methods. Numerical experiments on large-scale ODE models from real-world
applications illustrate the quality of the error estimate as well as the
general competitiveness of sketched Krylov methods for ODEs in comparison to
other Krylov-based methods.

</details>


### [506] [Numerical Error Analysis of the Poisson Equation under RHS Inaccuracies in Particle-in-Cell Simulations](https://arxiv.org/abs/2510.17580)
*Kai Zhang,Tao Xiao,Weizong Wang,Bijiao He*

Main category: math.NA

TL;DR: 该研究分析了在PIC模拟中，泊松方程右侧电荷密度采样不准确对数值精度的影响，发现线性方案在典型RHS不准确情况下比二次方案更准确，并提出了校准策略。


<details>
  <summary>Details</summary>
Motivation: PIC模拟中泊松方程的求解精度在笛卡尔网格的不规则狄利克雷边界附近会下降。虽然已有研究关注离散化误差，但右侧电荷密度采样不准确对精度的影响尚未充分探索。

Method: 使用嵌入式边界有限差分方案，分析一维解析推导和二维截断误差，比较线性和二次处理方案，并进行一维、二维和三维数值实验验证。

Result: RHS不准确会以不同方式影响截断误差：在线性方案中减少主导截断误差，在二次方案中引入零阶项导致更大全局误差。线性方案在典型PIC诱导的RHS不准确情况下具有更优精度。

Conclusion: 研究揭示了边界诱导的RHS误差与离散化精度之间的相互作用，提出了恢复二次方案精度的简单校准策略，为泊松类问题的数值求解提供了新见解。

Abstract: Particle-in-Cell (PIC) simulations rely on accurate solutions of the
electrostatic Poisson equation, yet accuracy often deteriorates near irregular
Dirichlet boundaries on Cartesian meshes. While much research has addressed
discretization errors on the left-hand side (LHS) of the Poisson equation, the
impact of right-hand-side (RHS) inaccuracies - arising from charge density
sampling near boundaries in PIC methods - remains largely unexplored. This
study analyzes the numerical errors induced by underestimated RHS values at
near-boundary nodes when solving the Poisson equation using embedded boundary
finite difference schemes with linear and quadratic treatments. Analytical
derivations in one dimension and truncation error analyses in two dimensions
reveal that such RHS inaccuracies modify local truncation behavior differently:
they reduce the dominant truncation error in the linear scheme but introduce a
zeroth-order term in the quadratic scheme, leading to larger global errors.
Numerical experiments in one-, two-, and three-dimensional domains confirm
these findings. Contrary to expectations, the linear scheme yields superior
overall accuracy under typical PIC-induced RHS inaccuracies. A simple RHS
calibration strategy is further proposed to restore the accuracy of the
quadratic scheme. These results offer new insight into the interplay between
boundary-induced RHS errors and discretization accuracy in Poisson-type
problems.

</details>


### [507] [PDE-Free Mass-Constrained Learning of Complex Systems with Hidden States: The crowd dynamics case](https://arxiv.org/abs/2510.17657)
*Gianmaria Viola,Alessandro Della Pia,Lucia Russo,Ioannis Kevrekidis,Constantinos Siettos*

Main category: math.NA

TL;DR: 提出了一个机器学习框架，用于建模具有隐藏状态的质量守恒复杂系统的时空动态，无需显式PDE模型。该方法结合流形学习和延迟坐标，通过线性(POD)和非线性(Diffusion Maps)方法提取低维嵌入，在潜在空间中学习预测性降阶模型，并通过求解预映像问题将演化提升回原始空间。


<details>
  <summary>Details</summary>
Motivation: 针对可用PDE描述但缺乏显式模型的质量守恒复杂系统，开发数据驱动的降阶建模方法，无需识别控制方程，同时保持关键物理约束（如质量守恒）。

Method: 扩展无方程方法，使用流形学习通过延迟坐标获得系统演化的潜在空间表示，采用POD和Diffusion Maps提取低维嵌入，在潜在空间中学习预测模型，通过POD和k-NN提升算子将演化提升回原始空间。

Result: 基于Diffusion Maps的非线性嵌入在重构精度上优于POD，产生更简洁稳定的降阶模型，在长时间范围内保持准确性和可积性。两种提升算子均能保持质量守恒约束。

Conclusion: 该框架有效重构了底层PDE的解算子而无需发现PDE本身，通过流形知情的客观映射桥接多尺度，为质量守恒复杂系统的数据驱动建模提供了有效方法。

Abstract: We introduce a machine learning framework for modeling the spatio-temporal
dynamics of mass-constrained complex systems with hidden states, whose behavior
can, in principle, be described by PDEs but lack explicit models. The method
extends the Equation-Free approach, enabling the data-driven reconstruction of
reduced-order models (ROMs) without needing to identify governing equations.
Using manifold learning, we obtain a latent space representation of system
evolution from data via delayed coordinates, in accordance with
Takens/Whitney's embedding theorems. Linear (Proper Orthogonal Decomposition,
POD) and nonlinear (Diffusion Maps, DMs) methods are employed to extract
low-dimensional embeddings that capture the essential dynamics. Predictive ROMs
are then learned within this latent space, and their evolution is lifted back
to the original high-dimensional space by solving a pre-image problem. We show
that both POD and k-nearest neighbor (k-NN) lifting operators preserve mass, a
key physical constraint in systems such as computational fluid dynamics and
crowd dynamics. Our framework effectively reconstructs the solution operator of
the underlying PDE without discovering the PDE itself, by leveraging a
manifold-informed objective map that bridges multiple scales. For our
illustrations, we use synthetic spatio-temporal data from the Hughes model,
which couples a continuity PDE with an Eikonal equation describing optimal path
selection in crowds. Results show that DM-based nonlinear embeddings outperform
POD in reconstruction accuracy, producing more parsimonious and stable ROMs
that remain accurate and integrable over long time horizons.

</details>


### [508] [A decoupled meshless Nyström scheme for 2D Fredholm integral equations of the second kind with smooth kernels](https://arxiv.org/abs/2510.17680)
*Bruno Degli Esposti,Alessandra Sestini*

Main category: math.NA

TL;DR: 本文提出了一种解耦的Nyström方法，将求解节点与积分节点分离，用于求解第二类Fredholm积分方程。该方法在光滑核和复杂二维域上具有性能优势，特别是对于窄核情况。


<details>
  <summary>Details</summary>
Motivation: 传统Nyström方法中求解节点与积分节点耦合，限制了方法的灵活性。本文旨在通过解耦这两个节点集来提高方法的效率和精度。

Method: 使用最近发展的无矩无网格散射节点积分公式，在光滑核和复杂二维域上实现解耦Nyström方法。需要选择重构方案来从求解节点值近似积分节点值。

Result: 与经典Nyström方法相比，解耦变体具有明显的性能优势，特别是对于窄核情况。证明了在自然假设下，整体收敛阶是积分方案和重构方案收敛阶的最小值。

Conclusion: 解耦Nyström方法为第二类Fredholm积分方程的数值求解提供了更灵活和高效的途径，特别是在处理复杂几何和窄核问题时表现优异。

Abstract: The Nystr\"om method for the numerical solution of Fredholm integral
equations of the second kind is generalized by decoupling the set of solution
nodes from the set of quadrature nodes. The accuracy and efficiency of the new
method is investigated for smooth kernels and complex 2D domains using recently
developed moment-free meshless quadrature formulas on scattered nodes. Compared
to the classical Nystr\"om method, our variant has a clear performance
advantage, especially for narrow kernels. The decoupled Nystr\"om method
requires the choice of a reconstruction scheme to approximate values at
quadrature nodes from values at solution nodes. We prove that, under natural
assumptions, the overall order of convergence is the minimum between that of
the quadrature scheme and of the reconstruction scheme.

</details>


### [509] [Efficient Tensor Completion Algorithms for Highly Oscillatory Operators](https://arxiv.org/abs/2510.17734)
*Navjot Singh,Edgar Solomonik,Xiaoye Sherry Li,Yang Liu*

Main category: math.NA

TL;DR: 本文提出了基于蝴蝶张量分解的低复杂度张量补全算法，用于重构高度振荡算子。算法利用张量重塑和蝴蝶分解，实现了O(n log³ n)的计算复杂度，比现有方法快几个数量级，且重构误差小一个数量级。


<details>
  <summary>Details</summary>
Motivation: 现有矩阵补全算法在处理高度振荡算子时效率较低，需要开发更高效的张量补全方法来处理这类问题。

Method: 将输入矩阵重塑为阶数为O(log n)的张量，利用蝴蝶分解作为张量分解，提出了基于交替最小二乘和梯度优化的两种张量补全算法，并开发了使用低秩矩阵补全生成初始猜测的新策略。

Result: 在三个地震应用数值实验中，使用O(n log n)观测条目，算法计算成本为O(n log³ n)，相比低秩矩阵和量化张量链补全，每次迭代速度提升几个数量级，重构误差小一个数量级。

Conclusion: 提出的蝴蝶补全算法结合新颖的初始猜测生成策略，能够准确恢复底层结构，在计算效率和重构精度方面均优于现有最先进的补全算法。

Abstract: This paper presents low-complexity tensor completion algorithms and their
efficient implementation to reconstruct highly oscillatory operators
discretized as $n\times n$ matrices. The underlying tensor decomposition is
based on the reshaping of the input matrix and its butterfly decomposition into
an order $\mathcal{O} (\log n)$ tensor. The reshaping of the input matrix into
a tensor allows for representation of the butterfly decomposition as a tensor
decomposition with dense tensors. This leads to efficient utilization of the
existing software infrastructure for dense and sparse tensor computations. We
propose two tensor completion algorithms in the butterfly format, using
alternating least squares and gradient-based optimization, as well as a novel
strategy that uses low-rank matrix completion to efficiently generate an
initial guess for the proposed algorithms. To demonstrate the efficiency and
applicability of our proposed algorithms, we perform three numerical
experiments using simulated oscillatory operators in seismic applications. In
these experiments, we use $\mathcal {O} (n \log n)$ observed entries in the
input matrix and demonstrate an $\mathcal{O}(n\log^3 n)$ computational cost of
the proposed algorithms, leading to a speedup of orders of magnitudes per
iteration for large matrices compared to the low-rank matrix and quantized
tensor-train completion. Moreover, the proposed butterfly completion
algorithms, equipped with the novel initial guess generation strategy, achieve
reconstruction errors that are smaller by an order of magnitude, enabling
accurate recovery of the underlying structure compared to the state-of-the-art
completion algorithms.

</details>


### [510] [Local Solvers for High-Order Patch Smoothers via p-Multigrid](https://arxiv.org/abs/2510.17785)
*Michał Wichrowski*

Main category: math.NA

TL;DR: 提出了一种顶点块平滑器，通过嵌套的矩阵无关p多重网格来近似求解局部问题，构建了多重网格中的多重网格框架。该方法适用于非分离问题和非结构化网格，对几何扭曲和高对比系数具有有限敏感性。


<details>
  <summary>Details</summary>
Motivation: 为了解决在非结构化网格上处理非分离问题时的高效求解需求，特别是需要应对几何扭曲和高对比系数的情况，同时保持对多项式阶数p和网格细化的鲁棒性。

Method: 使用顶点块平滑器，在局部问题上采用嵌套的矩阵无关p多重网格进行近似求解，形成多重网格中的多重网格结构。局部求解器单次迭代的计算复杂度为O(p^{d+1})。

Result: 数值实验表明该方法对几何扭曲和高对比系数具有有限敏感性。在全局几何多重网格求解器中使用时，即使在严重扭曲的网格上，也能实现对多项式阶数p和网格细化的鲁棒性。

Conclusion: 所提出的顶点块平滑器结合嵌套p多重网格的方法，为处理非结构化网格上的非分离问题提供了一种高效且鲁棒的求解方案，特别是在面对几何扭曲和高对比系数时表现出良好的性能。

Abstract: I propose a vertex patch smoother where local problems are solved inexactly
by a nested, matrix-free p-multigrid, creating a multigrid-within-multigrid
framework. A single iteration of the local solver can be evaluated with
$\mathcal{O}(p^{d+1})$ operations, and the approach is applicable to
non-separable problems on unstructured meshes. Numerical experiments
demonstrate limited sensitivity to geometric distortion and high-contrast
coefficients. When used in a global geometric multigrid solver, the method
achieves robustness with respect to both polynomial degree $p$ and mesh
refinement, even on heavily distorted meshes.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [511] [Wideband Antenna Deconvolution for Bistatic Millimeter Wave Radar Reflectivity Measurements](https://arxiv.org/abs/2510.16094)
*Carsten Andrich,Isabella Varga,Tobias F. Nowack,Alexander Ihlow,Sebastian Giehl,Michael Schubert,Reiner S. Thomä,Matthias A. Hein*

Main category: eess.SP

TL;DR: 提出了一种用于球面双基地测量系统的空中校准算法，该算法比现有方法更简单且速度快两倍，在76-81 GHz频段对金属球反射率测量中，动态范围提升达40 dB。


<details>
  <summary>Details</summary>
Motivation: 双基地雷达测量具有独特的空间多样性和增强的目标表征能力，但其可靠性依赖于精确的系统校准。传统替代方法需要使用已知参考物体，存在复杂度高的问题。

Method: 开发了一种空中校准算法，专门针对球面双基地测量系统设计，通过优化校准流程实现简化和加速。

Result: 在76-81 GHz频段对金属球进行反射率测量，校准后动态范围提升高达40 dB；与仿真数据对比显示测量与仿真结果高度一致。

Conclusion: 所提出的校准算法不仅显著简化了校准过程，而且将速度提升了一倍，同时大幅提高了测量系统的动态范围性能，验证了该方法的有效性。

Abstract: Bistatic radar measurements offer unique spatial diversity and enhanced
target characterization capabilities, rendering them increasingly vital for
contemporary sensing application research. The reliability of such measurements
is contingent upon precise system and antenna calibration. The prevailing
technique is the substitution method, which involves the use of known reference
objects. We propose an over-the-air calibration algorithm for spherical
bistatic measurement systems. Our method is both significantly simpler and
twice as fast as existing algorithms. The application of our technique to
reflectivity measurements of a metal sphere from 76 to 81 GHz demonstrates a
dynamic range enhancement of up to 40 dB when compared with uncalibrated data.
A comparison with simulation data demonstrates a high degree of agreement
between measurement and simulation.

</details>


### [512] [Fast, Differentiable, GPU-Accelerated Ray Tracing for Multiple Diffraction and Reflection Paths](https://arxiv.org/abs/2510.16172)
*Jérome Eertmans,Sophie Lequeu,Benoît Legat,Laurent Jacques,Claude Oestges*

Main category: eess.SP

TL;DR: 提出了一种基于费马原理的快速、可微分GPU加速优化方法，用于包含平面反射器和直线衍射边缘环境中的射线路径追踪。该方法将路径寻找问题重新表述为总路径长度的最小化，实现了在现代GPU架构上的高效并行执行。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要为反射和衍射分别使用不同的算法，缺乏统一的计算框架。为了在大规模应用中实现高效的可微分路径追踪，需要开发一种能够保持问题维度一致性的统一方法。

Method: 基于费马原理，将路径寻找问题重新表述为总路径长度的最小化问题。通过隐式微分实现高效梯度计算，无需通过求解器迭代进行微分。该方法与可微分编程库（如JAX和DrJIT）无缝集成。

Result: 数值模拟显示收敛速度与专门的牛顿方法相当，同时在大规模应用中提供卓越的可扩展性。显著优于传统的自动微分方法。

Conclusion: 该方法为无线传播建模中的逆向设计和优化开辟了新的可能性，提供了一个统一、高效且可微分的路径追踪解决方案。

Abstract: We present a fast, differentiable, GPU-accelerated optimization method for
ray path tracing in environments containing planar reflectors and straight
diffraction edges. Based on Fermat's principle, our approach reformulates the
path-finding problem as the minimization of total path length, enabling
efficient parallel execution on modern GPU architectures. Unlike existing
methods that require separate algorithms for reflections and diffractions, our
unified formulation maintains consistent problem dimensions across all
interaction sequences, making it particularly suitable for vectorized
computation. Through implicit differentiation, we achieve efficient gradient
computation without differentiating through solver iterations, significantly
outperforming traditional automatic differentiation approaches. Numerical
simulations demonstrate convergence rates comparable to specialized Newton
methods while providing superior scalability for large-scale applications. The
method integrates seamlessly with differentiable programming libraries such as
JAX and DrJIT, enabling new possibilities in inverse design and optimization
for wireless propagation modeling. The source code is openly available at
https://github.com/jeertmans/fpt-jax.

</details>


### [513] [Delay Minimization in Pinching-Antenna-enabled NOMA-MEC Networks](https://arxiv.org/abs/2510.16296)
*Yuan Ai,Xidong Mu,Pengbo Si,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出了一种新型的夹持天线系统（PASS）支持的非正交多址（NOMA）多接入边缘计算（MEC）框架，通过优化卸载比例、发射功率和天线位置来最小化最大任务延迟。


<details>
  <summary>Details</summary>
Motivation: 为了解决多接入边缘计算中的任务延迟问题，结合夹持天线系统和非正交多址技术，通过协同优化资源分配和天线配置来提升系统性能。

Method: 采用基于二分搜索的交替优化算法，将非凸优化问题分解为多个子问题，在给定任务延迟条件下迭代求解卸载比例、发射功率和天线位置。

Result: 数值仿真表明，所提出的框架相比基准方案能显著降低任务延迟。

Conclusion: PASS-NOMA-MEC框架通过联合优化天线配置和通信资源，有效减少了多用户边缘计算环境中的任务延迟。

Abstract: This letter proposes a novel pinching antenna systems (PASS) enabled
non-orthogonal multiple access (NOMA) multi-access edge computing (MEC)
framework. An optimization problem is formulated to minimize the maximum task
delay by optimizing offloading ratios, transmit powers, and pinching antenna
(PA) positions, subject to constraints on maximum transmit power, user energy
budgets, and minimum PA separation to mitigate coupling effects. To address the
non-convex problem, a bisection search-based alternating optimization (AO)
algorithm is developed, where each subproblem is iteratively solved for a given
task delay. Numerical simulations demonstrate that the proposed framework
significantly reduces the task delay compared to benchmark schemes.

</details>


### [514] [Adaptive Sensing Performance Design for Enhancing Secure Communication in Networked ISAC Systems](https://arxiv.org/abs/2510.16397)
*Yiming Xu,Dongfang Xu,Shenghui Song,Dusit Niyato*

Main category: eess.SP

TL;DR: 本文提出了一种基于自适应感知性能的传感增强安全通信方法，通过将感知性能隐式地融入信息泄漏率中，并自适应优化以最小化功耗，提供了增强的灵活性和适应性。


<details>
  <summary>Details</summary>
Motivation: 由于窃听者的被动和非合作特性，其信道状态信息难以获取，而现有的集成传感与通信研究通常采用固定感知性能要求，未考虑变化的通信条件，限制了系统充分利用传感与通信的协同效应。

Method: 提出了集中式和分布式两种设计方法：集中式设计采用基于块坐标下降的方法；分布式设计采用基于共识交替方向乘子法的优化框架来降低复杂性和信息交换开销。

Result: 实验结果表明，所提出的隐式感知性能要求设计具有优势，能够自适应调整感知性能以增强不同系统配置下的系统性能。

Conclusion: 通过将感知性能隐式地融入信息泄漏率并自适应优化，该方法能够有效提升集成传感与通信系统的安全通信性能，同时降低功耗。

Abstract: The channel state information (CSI) of an eavesdropper is crucial for
physical layer security (PLS) design, but it is difficult to obtain due to the
passive and non-cooperative nature of the eavesdropper. To this end, integrated
sensing and communication (ISAC) offers a novel solution by estimating the CSI
of the eavesdropper based on sensing information. However, existing studies
normally impose explicit and fixed sensing performance requirement without
considering the varying communication conditions, which hinders the system from
fully exploiting the synergy between sensing and communication. To address this
issue, this paper proposes sensing-enhanced secure communication with adaptive
sensing performance. Specifically, we formulate the sensing performance
implicitly in the information leakage rate and adaptively optimize it for the
minimization of the power consumption, offering enhanced flexibility and
adaptability in sensing performance. We consider both centralized and
decentralized designs to thoroughly investigate the impact of network structure
on system performance and complexity. Specifically, we devise a block
coordinate descent (BCD)-based method for centralized design. For decentralized
design, we develop an optimization framework based on consensus alternating
direction method of multipliers (ADMM) to reduce complexity and information
exchange overhead. Experimental results demonstrate the advantage of the
proposed implicit sensing performance requirement design due to its capability
to adaptively adjust the sensing performance to enhance the system performance
for varying system configurations.

</details>


### [515] [Performance Evaluation of High Power Microwave Systems Against UAVs A Probabilistic Antenna Propagation Framework with Sensitivity Analysis](https://arxiv.org/abs/2510.16495)
*Muhammad Khalil,Ke Wang,Jinho Choi*

Main category: eess.SP

TL;DR: 开发了一个概率框架来量化高功率微波对抗无人机的有效性，结合随机无人机运动学、波束指向抖动和大气传播，推导出接收脉冲能量的闭式统计量，并通过解析方法计算单脉冲和累积中和概率。


<details>
  <summary>Details</summary>
Motivation: 需要量化高功率微波对抗无人机的有效性，为系统设计和任务规划提供快速、准确且符合物理原理的性能预测。

Method: 采用概率框架，结合随机无人机运动学、波束指向抖动到增益的映射以及大气传播（自由空间扩展、气体和降雨损耗），获得接收脉冲能量的闭式统计量，并使用对数正态闭包和高斯-埃尔米特求积推导解析可评估的单脉冲和累积中和概率。

Result: 对于代表性商用阈值，模型预测每脉冲杀伤概率≥0.4，在kHz脉冲重复频率下约0.1秒内总杀伤概率>99%；对于硬化平台，每脉冲杀伤概率<1%，1秒后总杀伤概率<20%。灵敏度分析显示性能主要受斜距影响。

Conclusion: 该框架提供了快速、准确且符合物理原理的性能预测，揭示了高功率微波系统尺寸确定和风险感知任务规划的清晰天线/传播设计杠杆。

Abstract: We develop a probabilistic, antenna- and propagation-centric framework to
quantify the effectiveness of high-power microwave (HPM) engagements against
unmanned aerial vehicles (UAVs). The model couples stochastic UAV kinematics, a
beam-steering jitter-to-gain mapping, and atmospheric propagation (free-space
spreading with gaseous and rain loss) to obtain closed-form statistics of the
received pulse energy. From these, we derive analytically evaluable per-pulse
and cumulative neutralization probabilities using log-normal closures and
Gaussian--Hermite quadrature, and we provide a dwell-time expression under a
standard pulse-independence assumption. Analytical predictions closely match
large-scale Monte-Carlo simulations across broad parameter ranges. For a
representative commercial threshold $E_{\mathrm{th}} = 10^{-2}\,\mathrm{J}$,
the model predicts $\bar{P}_{\mathrm{kill}} \gtrsim 0.4$ per pulse and
$P_{\mathrm{kill,tot}} > 99\%$ within about $0.1\,\mathrm{s}$ at kHz PRF; for
hardened platforms with $E_{\mathrm{th}} = 10^{-1}\,\mathrm{J}$,
$\bar{P}_{\mathrm{kill}} < 1\%$ and $P_{\mathrm{kill,tot}} < 20\%$ after
$1\,\mathrm{s}$. A closed-form sensitivity (elasticity) analysis shows
performance is dominated by slant range ($S_{\bar{R}} \approx -2$), with strong
secondary dependence on aperture diameter and transmit power; pointing jitter
and atmospheric variability are comparatively less influential in the evaluated
regimes. The framework yields fast, accurate, and physics-faithful performance
predictions and exposes clear antenna/propagation design levers for HPM system
sizing and risk-aware mission planning.

</details>


### [516] [Topology-Aware Hybrid Wi-Fi/BLE Fingerprinting via Evidence-Theoretic Fusion and Persistent Homology](https://arxiv.org/abs/2510.16557)
*Behrad Mousaei Shir-Mohammad,Behzad Moshiri,Abolfazl Yaghmaei*

Main category: eess.SP

TL;DR: 提出了一种拓扑感知的混合Wi-Fi/BLE指纹定位框架，通过多技术融合在GNSS拒绝环境中实现高精度室内定位，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决GNSS拒绝环境中室内定位面临的挑战，包括多径效应、设备异构性和无线条件变化，需要开发既准确又计算高效的定位方法。

Method: 采用混合Wi-Fi/BLE指纹识别框架，包括物理一致的RSS归一化、贝叶斯滤波去噪、互补回归器组合、Dempster-Shafer理论融合以及持久同调描述符增强。

Result: 在10%合成RSS噪声下，完整管道达到3.40米和2.45米RMSE，比强基线提升约37%；无噪声测试中精度提高到0.44米和0.32米。

Conclusion: 该方法在保持竞争性精度的同时，提供形式化不确定性量化，计算成本低，适合实时部署，优于依赖大数据集和GPU推理的学习密集型方法。

Abstract: Indoor localization remains challenging in GNSS-denied environments due to
multipath, device heterogeneity, and volatile radio conditions. We propose a
topology-aware, hybrid Wi-Fi/BLE fingerprinting framework that (i) applies
physically consistent RSS normalization (dBm z-scoring or dBm -> linear mW ->
z-score), (ii) denoises streams with classical Bayesian filters (KF/UKF/PF),
(iii) combines complementary regressors (Random Forest and weighted kNN with a
diagonal Mahalanobis metric), (iv) performs evidence-theoretic fusion via
Dempster-Shafer theory (DST), and (v) augments each sample with
persistent-homology (PH) descriptors. The system outputs both (x, y) estimates
and interpretable belief maps, and is engineered for microcontroller-class
deployment with per-update cost O(T log M + log M + Mp + S).
  We evaluate on two heterogeneous datasets, including a new 1,200-sample ESP32
survey, and report ablations, robustness to test-only noise, and significance
across 10 stratified splits. Under 10% synthetic RSS noise, the full pipeline
attains 3.40 m (Dataset 1) and 2.45 m (Dataset 2) RMSE, improving a strong PF +
RF baseline by about 37%. Averaged across splits, it yields 4.993 +/- 0.15 m
versus 6.292 +/- 0.13 m (20.6% relative reduction; p < 0.001). In noise-free
tests, accuracy tightens to 0.44 m and 0.32 m (up to 56% better). Compared with
recent learning-heavy approaches that assume large site-specific datasets and
GPU inference, our method delivers competitive accuracy with formal uncertainty
quantification and low computational cost suitable for real-time deployment.

</details>


### [517] [Stochastic Geometry Analysis of Asymmetric Uplink Interference for Urban UAV-RC Networks](https://arxiv.org/abs/2510.16963)
*Donggu Lee,Sung Joon Maeng,Ismail Guvenc*

Main category: eess.SP

TL;DR: 本文提出了一种随机几何框架来分析城市环境中无人机通信的不对称干扰问题，特别关注上行链路干扰比下行链路更严重的情况。


<details>
  <summary>Details</summary>
Motivation: 无人机在密集城市区域部署时面临独特挑战，主要是由于无人机更容易受到视线干扰而导致上行链路干扰不对称。

Method: 采用对数高斯Cox过程（LGCP）模型来捕捉干扰场的空间相关性，将干扰建模为无人机高度和遥控器与无人机之间二维距离的函数。

Result: 数值结果表明，干扰不对称比率随着无人机高度和二维距离的增加而增加，表明上行链路干扰情况恶化。

Conclusion: 提出的随机几何框架能够有效分析城市环境中无人机通信的大规模不对称干扰问题，为无人机部署提供了理论分析工具。

Abstract: Uncrewed aerial vehicles (UAVs) have emerged as a flexible platform for
providing coverage over challenging environments, particularly for public
safety and surveillance missions in urban areas. However, deploying the UAVs in
dense urban areas introduces unique challenges, most notably asymmetric uplink
(UL, remote controller to UAV) interference due to a higher chance of
line-of-sight (LoS) interference at the UAV. In this letter, we propose a
stochastic geometry framework to tractably analyze the large-scale asymmetric
interference in urban areas. We incorporate a log-Gaussian Cox process (LGCP)
model to capture the spatial correlation of the interference field in both UL
and downlink (DL) as a function of the UAV altitude and the two-dimensional
(2-D) distance between the remote controller and UAV. To quantify the UL and
the DL interference asymmetry, we also define the interference asymmetry ratio
characterizing the interference disparity between the UL and the DL. Our
numerical results demonstrate that the interference asymmetry ratio increases
as the UAV altitude and 2-D distance increase, highlighting that the UL
interference worsens.

</details>


### [518] [6D Movable Metasurface (6DMM) in Downlink NOMA Transmissions](https://arxiv.org/abs/2510.17502)
*Li-Hsiang Shen*

Main category: eess.SP

TL;DR: 提出一种六维可移动超表面辅助的下行非正交多址系统，通过动态调整超表面元素位置和方向，结合概率交叉熵优化算法，显著提升系统速率性能。


<details>
  <summary>Details</summary>
Motivation: 传统静态可重构智能表面存在空间配置限制，无法充分利用空间和电磁控制能力。需要开发具有更高自由度的新型超表面架构来提升通信系统性能。

Method: 采用六维可移动超表面架构，允许每个元素动态调整位置和偏航-俯仰-滚转方向。使用概率交叉熵优化算法联合优化基站波束成形、相位偏移、元素位置和旋转角度。

Result: 仿真结果表明，所提出的基于CEO的6DMM-NOMA架构相比6DMM子结构、传统静态RIS和其他多址机制，实现了显著的速率性能增益。

Conclusion: 六维可移动超表面结合概率交叉熵优化能够有效解决高维可扩展超表面的优化问题，为未来智能表面通信系统提供了新的设计思路。

Abstract: This letter proposes a novel six-dimensional movable metasurface
(6DMM)-assisted downlink non-orthogonal multiple access (NOMA) system, in which
a conventional base station (BS) equipped with fixed antennas serves multiple
users with the assistance of a reconfigurable intelligent surface (RIS) with
six-dimensional spatial configurability. In contrast to traditional RIS with
static surface, the proposed 6DMM architecture allows each element to
dynamically adjust its position and orient the whole metasurface in
yaw-pitch-roll axes, enabling both in spatial and electromagnetic controls. We
formulate a sum-rate maximization problem that jointly optimizes the BS
NOMA-based beamforming, phase-shifts, element positions, and rotation angles of
metasurface under constraints of NOMA power levels, unit-modulus of
phase-shifts, power budget, inter-element separation and boundaries of element
position/orientation. Due to non-convexity and high-dimensionality, we employ a
probabilistic cross-entropy optimization (CEO) scheme to iteratively refine the
solution distribution based on maximizing likelihood and elite solution
sampling. Simulation results show that the proposed CEO-based 6DMM-NOMA
architecture achieves substantial rate performance gains compared to 6DMM
sub-structures, conventional static RIS, and other multiple access mechanisms.
It also highlights the effectiveness of CEO providing probabilistic
optimization for solving high-dimensional scalable metasurface.

</details>


### [519] [Precoding for Uplink RIS-Assisted Cell-Free MIMO-OFDM Systems with Hardware Impairments](https://arxiv.org/abs/2510.17741)
*Navid Reyhanian,Reza Ghaderi Zefreh,Parisa Ramezani,Emil Bjornson*

Main category: eess.SP

TL;DR: 本文研究了RIS辅助的CF-mMIMO系统，在UE和AP存在IQI的情况下，通过WMMSE-BCD方法联合优化传输预编码、RIS系数和接收合并，以最大化上行链路和速率。


<details>
  <summary>Details</summary>
Motivation: 在RIS辅助的CF-mMIMO系统中，UE和AP的IQI会严重影响系统性能，需要开发有效的联合优化方法来应对这一挑战。

Method: 提出基于WMMSE的BCD方法，开发了新颖的迭代算法来高效解决BCD子问题。

Result: 通过大量仿真验证了所提方法相对于启发式方法的效率优势。

Conclusion: 所提出的WMMSE-BCD方法能够有效解决RIS辅助CF-mMIMO系统中的联合优化问题，在IQI存在的情况下显著提升系统性能。

Abstract: This paper studies a reconfigurable intelligent surface (RIS)-assisted
cell-free massive multiple-input multiple-output (CF-mMIMO) system with
multiple RISs. Joint design of transmit precoding, RIS coefficients, and
receive combining is investigated for uplink sum-rate maximization under
in-phase and quadrature phase imbalance (IQI) at user equipments (UEs) and
access points (APs). A weighted minimum mean squared error (WMMSE) based block
coordinate descent (BCD) approach is proposed, where novel iterative methods
are developed to efficiently solve the BCD subproblems. The efficiency of
proposed approaches is demonstrated relative to heuristic methods via extensive
simulations.

</details>


### [520] [Sample Complexity Analysis of Multi-Target Detection via Markovian and Hard-Core Multi-Reference Alignment](https://arxiv.org/abs/2510.17775)
*Kweku Abraham,Amnon Balanov,Tamir Bendory,Carlos Esteve-Yagüe*

Main category: eess.SP

TL;DR: 本文研究了多目标检测问题的样本复杂度，提出了将MTD问题简化为非独立同分布多参考对齐模型的方法，并证明了在低信噪比条件下，MTD模型所需的样本数量与对应的i.i.d. MRA模型具有相同的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 受单粒子冷冻电子显微镜的启发，研究多目标检测问题的样本复杂度，其中未知信号在长噪声观测中以未知位置多次出现。

Method: 提出了一种分块方案，将MTD问题简化为非独立同分布的多参考对齐模型。在一维情况下，潜在群元素形成马尔可夫链；在二维情况下，潜在结构来自硬核放置模型生成的指数混合随机场。

Result: 证明任何估计器的收敛速率与对应的i.i.d. MRA模型相匹配（最多相差对数因子），对于基于经验平均的估计器（如矩方法），两种设置的收敛速率完全相同。

Conclusion: 在低信噪比条件下，如果对应的i.i.d. MRA模型中的信号由n_min阶矩确定，则MTD模型中估计信号所需的分块数量按σ^(2n_min)比例缩放，其中σ^2表示噪声方差。

Abstract: Motivated by single-particle cryo-electron microscopy, we study the sample
complexity of the multi-target detection (MTD) problem, in which an unknown
signal appears multiple times at unknown locations within a long, noisy
observation. We propose a patching scheme that reduces MTD to a non-i.i.d.
multi-reference alignment (MRA) model. In the one-dimensional setting, the
latent group elements form a Markov chain, and we show that the convergence
rate of any estimator matches that of the corresponding i.i.d. MRA model, up to
a logarithmic factor in the number of patches. Moreover, for estimators based
on empirical averaging, such as the method of moments, the convergence rates
are identical in both settings. We further establish an analogous result in two
dimensions, where the latent structure arises from an exponentially mixing
random field generated by a hard-core placement model. As a consequence, if the
signal in the corresponding i.i.d. MRA model is determined by moments up to
order $n_{\min}$, then in the low-SNR regime the number of patches required to
estimate the signal in the MTD model scales as $\sigma^{2n_{\min}}$, where
$\sigma^2$ denotes the noise variance.

</details>
